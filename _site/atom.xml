<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.5.2">Jekyll</generator><link href="http://localhost:4000/atom.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2018-06-28T17:45:29+08:00</updated><id>http://localhost:4000/</id><title type="html">iLeaf</title><subtitle>Yesterday you said tomorrow.</subtitle><author><name>Liv Yeh</name></author><entry><title type="html">Kerberos具体实践2-Kerberos与HDFS的整合操作</title><link href="http://localhost:4000/bigdata/2018/06/28/Kerberos%E5%85%B7%E4%BD%93%E5%AE%9E%E8%B7%B52-%E4%B8%8EHDFS-ZK%E7%9A%84%E6%95%B4%E5%90%88%E6%93%8D%E4%BD%9C/" rel="alternate" type="text/html" title="Kerberos具体实践2-Kerberos与HDFS的整合操作" /><published>2018-06-28T00:00:00+08:00</published><updated>2018-06-28T00:00:00+08:00</updated><id>http://localhost:4000/bigdata/2018/06/28/Kerberos%E5%85%B7%E4%BD%93%E5%AE%9E%E8%B7%B52-%E4%B8%8EHDFS%E3%80%81ZK%E7%9A%84%E6%95%B4%E5%90%88%E6%93%8D%E4%BD%9C</id><content type="html" xml:base="http://localhost:4000/bigdata/2018/06/28/Kerberos%E5%85%B7%E4%BD%93%E5%AE%9E%E8%B7%B52-%E4%B8%8EHDFS-ZK%E7%9A%84%E6%95%B4%E5%90%88%E6%93%8D%E4%BD%9C/">&lt;blockquote&gt;
  &lt;p&gt;本文属于Kerberos具体实践整理的第二部分，主要涉及kerberos与HDFS的整合操作。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h1 id=&quot;hdfs整合kerberos部署&quot;&gt;HDFS整合Kerberos（部署）&lt;/h1&gt;
&lt;h2 id=&quot;创建认证规则&quot;&gt;创建认证规则&lt;/h2&gt;
&lt;p&gt;在 Kerberos 安全机制里，一个principal就是realm里的一个对象，一个principal总是和一个密钥（secret key）成对出现的。&lt;br /&gt;
这个 principal 的对应物可以是service，可以是host，也可以是user，对于Kerberos来说，都没有区别。&lt;br /&gt;
Kdc(Key distribute center) 知道所有principal的secret key，但每个principal对应的对象只知道自己的那个secret key。这也是“共享密钥“的由来。&lt;br /&gt;
对于hadoop，principals的格式为username/fully.qualified.domain.name@YOUR-REALM.COM。&lt;br /&gt;
本次测试中，直接解压安装2.6.0-cdh5.11.0，并使用hadoop用户来进行NameNode和DataNode的启动，因此为集群中每个服务器节点添加principals：hadoop、HTTP、host（后续使用）。&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;补充：若通过yum源安装的cdh集群中，NameNode和DataNode是通过hdfs启动的，故为集群中每个服务器节点添加两个principals：hdfs、HTTP。-官网说法：The properties for each daemon (NameNode, Secondary NameNode, and DataNode) must specify both the HDFS and HTTP principals, as well as the path to the HDFS keytab file.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;在 KCD server 上（这里是 node1）创建 hadoop principal：&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;kadmin.local -q &quot;addprinc -randkey hadoop/node1@HADOOP.COM&quot;   
kadmin.local -q &quot;addprinc -randkey hadoop/node2@HADOOP.COM&quot;  
kadmin.local -q &quot;addprinc -randkey hadoop/node3@HADOOP.COM&quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;创建 HTTP principal：&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;kadmin.local -q &quot;addprinc -randkey HTTP/node1@HADOOP.COM&quot; 
kadmin.local -q &quot;addprinc -randkey HTTP/node2@HADOOP.COM&quot;  
kadmin.local -q &quot;addprinc -randkey HTTP/node3@HADOOP.COM&quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;blockquote&gt;
  &lt;p&gt;说明：randkey 标志没有为新principal 设置密码，而是指示kadmin生成一个随机密钥。之所以在这里使用这个标志，是因为此principal不需要用户交互。它是计算机的一个服务器帐户。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;创建完成后，查看：&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ kadmin.local -q &quot;listprincs&quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;操作结果小例子：&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;[root@node1 /]# kadmin.local -q &quot;addprinc -randkey hadoop/node1@HADOOP.COM&quot;
Authenticating as principal root/admin@HADOOP.COM with password.
WARNING: no policy specified for hadoop/node1@HADOOP.COM; defaulting to no policy
Principal &quot;hadoop/node1@HADOOP.COM&quot; created.
[root@node1 /]# kadmin.local -q &quot;addprinc -randkey hadoop/node2@HADOOP.COM&quot;
Authenticating as principal root/admin@HADOOP.COM with password.
WARNING: no policy specified for hadoop/node2@HADOOP.COM; defaulting to no policy
Principal &quot;hadoop/node2@HADOOP.COM&quot; created.
[root@node1 /]# kadmin.local -q &quot;addprinc -randkey hadoop/node3@HADOOP.COM&quot;
Authenticating as principal root/admin@HADOOP.COM with password.
WARNING: no policy specified for hadoop/node3@HADOOP.COM; defaulting to no policy
Principal &quot;hadoop/node3@HADOOP.COM&quot; created.
[root@node1 /]# kadmin.local -q &quot;addprinc -randkey HTTP/node1@HADOOP.COM&quot;
Authenticating as principal root/admin@HADOOP.COM with password.
WARNING: no policy specified for HTTP/node1@HADOOP.COM; defaulting to no policy
Principal &quot;HTTP/node1@HADOOP.COM&quot; created.
[root@node1 /]# kadmin.local -q &quot;addprinc -randkey HTTP/node2@HADOOP.COM&quot;
Authenticating as principal root/admin@HADOOP.COM with password.
WARNING: no policy specified for HTTP/node2@HADOOP.COM; defaulting to no policy
Principal &quot;HTTP/node2@HADOOP.COM&quot; created.
[root@node1 /]# kadmin.local -q &quot;addprinc -randkey HTTP/node3@HADOOP.COM&quot;
Authenticating as principal root/admin@HADOOP.COM with password.
WARNING: no policy specified for HTTP/node3@HADOOP.COM; defaulting to no policy
Principal &quot;HTTP/node3@HADOOP.COM&quot; created. 
[root@node1 hadoop_logs]# kadmin.local -q &quot;addprinc -randkey host/node1@HADOOP.COM&quot;
Authenticating as principal root/admin@HADOOP.COM with password.
WARNING: no policy specified for host/node1@HADOOP.COM; defaulting to no policy
Principal &quot;host/node1@HADOOP.COM&quot; created.
[root@node1 hadoop_logs]# kadmin.local -q &quot;addprinc -randkey host/node2@HADOOP.COM&quot;
Authenticating as principal root/admin@HADOOP.COM with password.
WARNING: no policy specified for host/node2@HADOOP.COM; defaulting to no policy
Principal &quot;host/node2@HADOOP.COM&quot; created.
[root@node1 hadoop_logs]# kadmin.local -q &quot;addprinc -randkey host/node3@HADOOP.COM&quot;
Authenticating as principal root/admin@HADOOP.COM with password.
WARNING: no policy specified for host/node3@HADOOP.COM; defaulting to no policy
Principal &quot;host/node3@HADOOP.COM&quot; created.
[root@node1 /]# kadmin.local -q &quot;listprincs&quot;
Authenticating as principal root/admin@HADOOP.COM with password.
HTTP/node1@HADOOP.COM
HTTP/node2@HADOOP.COM
HTTP/node3@HADOOP.COM
K/M@HADOOP.COM
hadoop/node1@HADOOP.COM
hadoop/node2@HADOOP.COM
hadoop/node3@HADOOP.COM
host/node1@HADOOP.COM
host/node2@HADOOP.COM
host/node3@HADOOP.COM
kadmin/admin@HADOOP.COM
kadmin/changepw@HADOOP.COM
kadmin/node1@HADOOP.COM
kiprop/node1@HADOOP.COM
krbtgt/HADOOP.COM@HADOOP.COM
root/admin@HADOOP.COM
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;h2 id=&quot;生成keytab&quot;&gt;生成keytab&lt;/h2&gt;
&lt;p&gt;keytab是包含principals和加密principal key的文件。keytab文件对于每个host是唯一的，因为key包含hostname。keytab文件用于不需要人工交互和保存纯文本密码，实现到kerberos上验证一个主机上的principal。因为服务器上可以访问keytab文件即可以以principal的身份通过 kerberos 的认证，所以，keytab文件应该被妥善保存，应该只有少数的用户可以访问。&lt;br /&gt;
创建包含hadoop principal和HTTP principal的keytab。&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;方法一：&lt;br /&gt;
在node1节点，即KDC server节点上执行下面命令，会在当前目录下创建keytab，名字为hdfs.keytab：
    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;1、kadmin.local进入kerberos shell中
2、kadmin.local:  xst -norandkey -k hdfs.keytab hadoop/node1@HADOOP.COM hadoop/node2@HADOOP.COM hadoop/node3@HADOOP.COM HTTP/node1@HADOOP.COM HTTP/node2@HADOOP.COM HTTP/node3@HADOOP.COM
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
    &lt;p&gt;使用klist显示hdfs.keytab文件列表,查看执行结果：&lt;/p&gt;
    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;[root@node1 etc]# klist -ket  hdfs.keytab
Keytab name: FILE:hdfs.keytab
KVNO Timestamp           Principal
---- ------------------- ------------------------------------------------------
1 09/06/2017 17:53:54 hadoop/node1@HADOOP.COM (des3-cbc-sha1)
1 09/06/2017 17:53:54 hadoop/node1@HADOOP.COM (arcfour-hmac)
1 09/06/2017 17:53:54 hadoop/node1@HADOOP.COM (camellia256-cts-cmac)
1 09/06/2017 17:53:54 hadoop/node1@HADOOP.COM (camellia128-cts-cmac)
1 09/06/2017 17:53:54 hadoop/node1@HADOOP.COM (des-hmac-sha1)
1 09/06/2017 17:53:54 hadoop/node1@HADOOP.COM (des-cbc-md5)
1 09/06/2017 17:53:54 hadoop/node2@HADOOP.COM (des3-cbc-sha1)
1 09/06/2017 17:53:54 hadoop/node2@HADOOP.COM (arcfour-hmac)
1 09/06/2017 17:53:54 hadoop/node2@HADOOP.COM (camellia256-cts-cmac)
1 09/06/2017 17:53:54 hadoop/node2@HADOOP.COM (camellia128-cts-cmac)
1 09/06/2017 17:53:54 hadoop/node2@HADOOP.COM (des-hmac-sha1)
1 09/06/2017 17:53:54 hadoop/node2@HADOOP.COM (des-cbc-md5)
1 09/06/2017 17:53:54 hadoop/node3@HADOOP.COM (des3-cbc-sha1)
1 09/06/2017 17:53:54 hadoop/node3@HADOOP.COM (arcfour-hmac)
1 09/06/2017 17:53:54 hadoop/node3@HADOOP.COM (camellia256-cts-cmac)
1 09/06/2017 17:53:54 hadoop/node3@HADOOP.COM (camellia128-cts-cmac)
1 09/06/2017 17:53:54 hadoop/node3@HADOOP.COM (des-hmac-sha1)
1 09/06/2017 17:53:54 hadoop/node3@HADOOP.COM (des-cbc-md5)
1 09/06/2017 17:53:54 HTTP/node1@HADOOP.COM (des3-cbc-sha1)
1 09/06/2017 17:53:54 HTTP/node1@HADOOP.COM (arcfour-hmac)
1 09/06/2017 17:53:54 HTTP/node1@HADOOP.COM (camellia256-cts-cmac)
1 09/06/2017 17:53:54 HTTP/node1@HADOOP.COM (camellia128-cts-cmac)
1 09/06/2017 17:53:54 HTTP/node1@HADOOP.COM (des-hmac-sha1)
1 09/06/2017 17:53:54 HTTP/node1@HADOOP.COM (des-cbc-md5)
1 09/06/2017 17:53:54 HTTP/node2@HADOOP.COM (des3-cbc-sha1)
1 09/06/2017 17:53:54 HTTP/node2@HADOOP.COM (arcfour-hmac)
1 09/06/2017 17:53:54 HTTP/node2@HADOOP.COM (camellia256-cts-cmac)
1 09/06/2017 17:53:54 HTTP/node2@HADOOP.COM (camellia128-cts-cmac)
1 09/06/2017 17:53:54 HTTP/node2@HADOOP.COM (des-hmac-sha1)
1 09/06/2017 17:53:54 HTTP/node2@HADOOP.COM (des-cbc-md5)
1 09/06/2017 17:53:54 HTTP/node3@HADOOP.COM (des3-cbc-sha1)
1 09/06/2017 17:53:54 HTTP/node3@HADOOP.COM (arcfour-hmac)
1 09/06/2017 17:53:54 HTTP/node3@HADOOP.COM (camellia256-cts-cmac)
1 09/06/2017 17:53:54 HTTP/node3@HADOOP.COM (camellia128-cts-cmac)
1 09/06/2017 17:53:54 HTTP/node3@HADOOP.COM (des-hmac-sha1)
1 09/06/2017 17:53:54 HTTP/node3@HADOOP.COM (des-cbc-md5)
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;方法二（未使用）：&lt;br /&gt;
在node1节点，即KDC server节点上执行下面命令，分别创建keytab，名字为hdfs.keytab：
    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ cd /var/kerberos/krb5kdc/  
$ kadmin.local -q &quot;xst  -k hdfs-unmerged.keytab hadoop/node1@HADOOP.COM&quot;  
$ kadmin.local -q &quot;xst  -k hdfs-unmerged.keytab hadoop/node2@HADOOP.COM&quot;  
$ kadmin.local -q &quot;xst  -k hdfs-unmerged.keytab hadoop/node3@HADOOP.COM&quot;  
$ kadmin.local -q &quot;xst  -k HTTP.keytab  HTTP/node1@HADOOP.COM&quot;  
$ kadmin.local -q &quot;xst  -k HTTP.keytab  HTTP/node2@HADOOP.COM&quot;  
$ kadmin.local -q &quot;xst  -k HTTP.keytab  HTTP/node3@HADOOP.COM&quot;  
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
    &lt;p&gt;这样，就会在/var/kerberos/krb5kdc/（当前）目录下生成hdfs-unmerged.keytab和HTTP.keytab两个文件，接下来使用ktutil合并者两个文件为hdfs.keytab。&lt;/p&gt;
    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ cd /var/kerberos/krb5kdc/   
$ ktutil  
ktutil: rkt hdfs-unmerged.keytab  
ktutil: rkt HTTP.keytab  
ktutil: wkt hdfs.keytab
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
    &lt;p&gt;使用klist显示hdfs.keytab文件列表：&lt;/p&gt;
    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ klist -ket  hdfs.keytab
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;测试：&lt;br /&gt;
验证是否正确合并了key，使用合并后的keytab，分别使用hadoop和HTTP principals来获取证书。
    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ kinit -k -t hdfs.keytab hadoop/node1@HADOOP.COM
$ kinit -k -t hdfs.keytab HTTP/node1@HADOOP.COM
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
    &lt;p&gt;如果出现错误：kinit: Key table entry not found while getting initial credentials，则上面的（生成）合并有问题，重新执行前面的操作。&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;部署kerberos-keytabhdfs&quot;&gt;部署Kerberos Keytab（hdfs）&lt;/h2&gt;
&lt;p&gt;拷贝生成的hdfs.keytab文件到其他节点的/etc/hadoop/conf目录【可以自己定义目录，后续需要在hdfs配置文件中使用此目录】&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ cd /var/kerberos/krb5kdc/  【刚刚生成keytab文件所在目录】
$ scp hdfs.keytab node1:/etc/hadoop/conf  
$ scp hdfs.keytab node2:/etc/hadoop/conf  
$ scp hdfs.keytab node3:/etc/hadoop/conf
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;p&gt;并设置权限，分别在node1、node2、node3上执行更改文件属主和权限命令：&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ ssh node1 &quot;chown hadoop:hadoop /etc/hadoop/conf/hdfs.keytab ;chmod 400 /etc/hadoop/conf/hdfs.keytab&quot;
$ ssh node2 &quot;chown hadoop:hadoop /etc/hadoop/conf/hdfs.keytab ;chmod 400 /etc/hadoop/conf/hdfs.keytab&quot;
$ ssh node3 &quot;chown hadoop:hadoop /etc/hadoop/conf/hdfs.keytab ;chmod 400 /etc/hadoop/conf/hdfs.keytab&quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;blockquote&gt;
  &lt;p&gt;注意：由于keytab相当于有了永久凭证，不需要提供密码(如果修改kdc中的principal的密码，则该keytab就会失效)，所以其他用户如果对该文件有读权限，就可以冒充 keytab中指定的用户身份访问hadoop，所以keytab文件需要确保只对owner有读权限(0400)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;hdfs配置修改&quot;&gt;HDFS配置修改&lt;/h2&gt;
&lt;p&gt;关于HDFS集群的部署配置就不在此文中说明，以下直接进行说明Kerberos整合HDFS之时所做的修改操作。&lt;/p&gt;
&lt;h3 id=&quot;修改core-sitexml配置文件&quot;&gt;修改core-site.xml配置文件&lt;/h3&gt;
&lt;p&gt;在集群中所有节点的core-site.xml文件中添加下面的配置:&lt;/p&gt;
&lt;div class=&quot;language-xml highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;hadoop.security.authentication&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;kerberos&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;

&lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;hadoop.security.authorization&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;true&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;h3 id=&quot;修改hdfs-sitexml配置文件&quot;&gt;修改hdfs-site.xml配置文件&lt;/h3&gt;
&lt;p&gt;在集群中所有节点的hdfs-site.xml文件中添加下面的配置：&lt;/p&gt;
&lt;div class=&quot;language-xml highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c&quot;&gt;&amp;lt;!-- General HDFS security config --&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;dfs.block.access.token.enable&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;true&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;&amp;lt;!-- NameNode security config --&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;dfs.namenode.keytab.file&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;/opt/hadoop_krb5/conf/hdfs.keytab&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt; &lt;span class=&quot;c&quot;&gt;&amp;lt;!-- HDFS keytab的目录 --&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;dfs.namenode.kerberos.principal&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;hadoop/_HOST@HADOOP.COM&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;dfs.namenode.kerberos.internal.spnego.principal&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;HTTP/_HOST@HADOOP.COM&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;&amp;lt;!-- DataNode security config --&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;dfs.datanode.data.dir.perm&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;700&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;dfs.datanode.address&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;0.0.0.0:61004&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;dfs.datanode.http.address&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;0.0.0.0:61006&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;dfs.datanode.keytab.file&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;/opt/hadoop_krb5/conf/hdfs.keytab&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt; &lt;span class=&quot;c&quot;&gt;&amp;lt;!-- HDFS keytab的目录 --&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;dfs.datanode.kerberos.principal&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;hadoop/_HOST@HADOOP.COM&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;dfs.datanode.kerberos.https.principal&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;HTTP/_HOST@HADOOP.COM&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;&amp;lt;!-- 开启SSL(jsvc时可不配置；可选，详见下属总结以及启动datanode部分) --&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;dfs.http.policy&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;HTTPS_ONLY&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;&amp;lt;!-- SASL 模式--&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;dfs.data.transfer.protection&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;integrity&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;&amp;lt;!-- Web Authentication config --&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;dfs.webhdfs.enabled&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;true&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;dfs.web.authentication.kerberos.keytab&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;/opt/hadoop_krb5/conf/hdfs.keytab&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt; &lt;span class=&quot;c&quot;&gt;&amp;lt;!-- HDFS keytab的目录 --&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;dfs.web.authentication.kerberos.principal&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;HTTP/_HOST@HADOOP.COM&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
 &lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;&amp;lt;!--- HDFS QJM HA：如果HDFS配置了QJM HA，则需要添加；另外，你还要在zookeeper上配置kerberos（详见后续文章说明） --&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;dfs.journalnode.keytab.file&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;/opt/hadoop_krb5/conf/hdfs.keytab&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;dfs.journalnode.kerberos.principal&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;hadoop/_HOST@HADOOP.COM&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;dfs.journalnode.kerberos.internal.spnego.principal&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;HTTP/_HOST@HADOOP.COM&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;h3 id=&quot;修改hadoop-envsh配置文件&quot;&gt;修改hadoop-env.sh配置文件&lt;/h3&gt;
&lt;p&gt;在hadoop-env.sh文件中，需要修改HADOOP_SECURE_DN_USER的值，其依据datanode启动方式不同，有不同的设置。&lt;br /&gt;
注意的关键点如下：&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;jsvc模式启动datanode：HADOOP_SECURE_DN_USER有值&lt;/li&gt;
  &lt;li&gt;SASL模式启动datanode：HADOOP_SECURE_DN_USER没值，要注释掉。&lt;/li&gt;
&lt;/ol&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;#export HADOOP_SECURE_DN_USER=${HADOOP_SECURE_DN_USER}
#export HADOOP_SECURE_DN_USER=hadoop
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;p&gt;具体配置方式，见下述启动datanode的部分，以不同的启动方式来详细说明。&lt;/p&gt;

&lt;p&gt;配置中有几点要注意的：&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;如果不进行SSL配置，则hadoop需要使用jsvc来启动（如下条解释）。&lt;/li&gt;
  &lt;li&gt;dfs.datanode.address、dfs.datanode.http.address表示data transceiver RPC server所绑定的hostname或IP地址，此部分配置与datanode的启动方式有关（本条内容目前是靠个人理解，由于目前还是菜鸟学习阶段，所以理解可能问题，请大家指出并告诉我，谢谢啦～我的邮箱leafming@foxmail.com），这部分的端口值有两种设置情况；
    &lt;ul&gt;
      &lt;li&gt;一定小于1024-jsvc:如果开启security，并且使用jsvc模式启动datanode（不配置SSL），dfs.datanode.address、dfs.datanode.http.address的端口一定要小于1024（privileged端口），否则的话启动datanode时候会报Cannot start secure cluster without privileged resources错误。CDH官网说明如下（详见&lt;a href=&quot;https://www.cloudera.com/documentation/enterprise/5-11-x/topics/cdh_sg_secure_hdfs_config.html#concept_nsy_21z_xn&quot;&gt;Configure Secure HDFS&lt;/a&gt;）：
        &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; The dfs.datanode.address and dfs.datanode.http.address port numbers for the DataNode must be below 1024,because this provides part of the security mechanism to make it impossible for a user to run a map task which impersonates a DataNode. 
 The port numbers for the NameNode and Secondary NameNode can be anything you want, but the default port numbers are good ones to use.
&lt;/code&gt;&lt;/pre&gt;
        &lt;/div&gt;
      &lt;/li&gt;
      &lt;li&gt;一定大于1024-SASL:如果使用在2.6之前的版本，安全模式的hadoop只能使用jsvc，即先以root用户来启动datanode，然后再切到普通用户。而在2.6.0之后的版本，SASL可以用来验证数据传输。在使用SASL的配置下，不再需要root用jsvc来启动安全模式的集群，并且也不在需要使用特权端口。如果启用SASL模式，需要在hdfs-site.xml中设置dfs.data.transfer.protection，并且dfs.datanode.address的端口要大于1024（non-privileged端口），并且设置dfs.http.policy为HTTPS_ONLY，而且保证HADOOP_SECURE_DN_USER环境变量值没有设置。一定要注意的是，dfs.datanode.address若设置成了特权端口，则SASL无法使用，这是向后兼容性原因所必需的。官网说明如下&lt;a href=&quot;http://hadoop.apache.org/docs/stable/hadoop-project-dist/hadoop-common/SecureMode.html&quot;&gt;Hadoop in Secure Mode-Secure DataNode&lt;/a&gt; ：
        &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; As of version 2.6.0, SASL can be used to authenticate the data transfer protocol. 
 In this configuration, it is no longer required for secured clusters to start the DataNode as root using jsvc and bind to privileged ports. To enable SASL on data transfer protocol, set dfs.data.transfer.
 protection in hdfs-site.xml, set a non-privileged port for dfs.datanode.address, set dfs.http.policy to HTTPS_ONLY and make sure the HADOOP_SECURE_DN_USER environment variable is not defined. 
 Note that it is not possible to use SASL on data transfer protocol if dfs.datanode.address is set to a privileged port. This is required for backwards-compatibility reasons.
&lt;/code&gt;&lt;/pre&gt;
        &lt;/div&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;principal中的instance部分可以使用_HOST标记，系统会自动替换它为全称域名。&lt;/li&gt;
  &lt;li&gt;如果开启了security, hadoop会对hdfs block data(由dfs.data.dir指定)做permission check，方式用户的代码不是调用hdfs api而是直接本地读block data，这样就绕过了kerberos和文件权限验证，管理员可以通过设置dfs.datanode.data.dir.perm 来修改datanode 文件权限，这里我们设置为700。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;本次集群配置示例：&lt;/p&gt;

&lt;div class=&quot;language-xml highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;core-site.xml  
-----------------------------------------------------------------
&lt;span class=&quot;nt&quot;&gt;&amp;lt;configuration&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;fs.defaultFS&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;hdfs://ns1&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;ha.zookeeper.quorum&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;node1:2181,node2:2181,node3:2181&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;io.compression.codecs&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;org.apache.hadoop.io.compress.SnappyCodec&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;hadoop.tmp.dir&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;/opt/hadoop-dir&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;hadoop.security.authentication&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;kerberos&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;hadoop.security.authorization&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;true&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;/configuration&amp;gt;&lt;/span&gt;
-----------------------------------------------------------------
hdfs-site.xml
-----------------------------------------------------------------
&lt;span class=&quot;nt&quot;&gt;&amp;lt;configuration&amp;gt;&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;&amp;lt;!-- General HDFS security config --&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;dfs.block.access.token.enable&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;true&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;dfs.nameservices&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;ns1&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;dfs.ha.namenodes.ns1&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;node1,node2&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;dfs.namenode.rpc-address.ns1.node1&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;node1:8020&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;dfs.namenode.rpc-address.ns1.node2&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;node2:8020&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;dfs.namenode.http-address.ns1.node1&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;node1:8570&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;dfs.namenode.http-address.ns1.node2&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;node2:8570&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;&amp;lt;!-- NameNode security config --&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;dfs.namenode.keytab.file&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;/opt/hadoop_krb5/conf/hdfs.keytab&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt; &lt;span class=&quot;c&quot;&gt;&amp;lt;!-- path to the HDFS keytab --&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;dfs.namenode.kerberos.principal&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;hadoop/_HOST@HADOOP.COM&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;dfs.namenode.kerberos.internal.spnego.principal&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;HTTP/_HOST@HADOOP.COM&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;&amp;lt;!-- DataNode security config --&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;dfs.datanode.data.dir.perm&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;700&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;dfs.datanode.address&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;0.0.0.0:61004&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;dfs.datanode.http.address&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;0.0.0.0:61006&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;dfs.datanode.keytab.file&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;/opt/hadoop_krb5/conf/hdfs.keytab&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt; &lt;span class=&quot;c&quot;&gt;&amp;lt;!-- path to the HDFS keytab --&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;dfs.datanode.kerberos.principal&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;hadoop/_HOST@HADOOP.COM&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;dfs.datanode.kerberos.https.principal&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;HTTP/_HOST@HADOOP.COM&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;dfs.http.policy&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;HTTPS_ONLY&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;dfs.data.transfer.protection&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;integrity&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;&amp;lt;!-- Web Authentication config --&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;dfs.webhdfs.enabled&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;true&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;dfs.web.authentication.kerberos.keytab&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;/opt/hadoop_krb5/conf/hdfs.keytab&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt; &lt;span class=&quot;c&quot;&gt;&amp;lt;!-- path to the HTTP keytab --&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;dfs.web.authentication.kerberos.principal&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;HTTP/_HOST@HADOOP.COM&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;&amp;lt;!-- HDFS QJM HA--&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;dfs.journalnode.keytab.file&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;/opt/hadoop_krb5/conf/hdfs.keytab&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;dfs.journalnode.kerberos.principal&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;hadoop/_HOST@HADOOP.COM&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;dfs.journalnode.kerberos.internal.spnego.principal&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;HTTP/_HOST@HADOOP.COM&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;dfs.namenode.shared.edits.dir&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;qjournal://node1:8485;node2:8485;node3:8485/ns1&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;dfs.journalnode.edits.dir&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;/opt/hadoop-dir/journal&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;dfs.ha.fencing.methods&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;sshfence&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;dfs.ha.fencing.ssh.private-key-files&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;/home/hadoop/.ssh/id_rsa&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;dfs.permissions.enabled&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;true&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;dfs.namenode.acls.enabled&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;true&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;dfs.permissions.superusergroup&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;cgroup&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;dfs.replication&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;3&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;final&amp;gt;&lt;/span&gt;true&lt;span class=&quot;nt&quot;&gt;&amp;lt;/final&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;dfs.namenode.name.dir&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;file:///opt/hadoop-dir/hadoop_data/nn&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;dfs.datanode.data.dir&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;file:///opt/hadoop-dir/hadoop_data/dn&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;ha.zookeeper.session-timeout.ms&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;5000&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;dfs.ha.automatic-failover.enabled&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;true&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;dfs.client.failover.proxy.provider.ns1&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;  
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;dfs.socket.timeout&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;90000&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;dfs.balance.bandwidthPerSec&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;10485760&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;/configuration&amp;gt;&lt;/span&gt;
-----------------------------------------------------------------
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;h2 id=&quot;检查集群上的hdfs和本地文件的权限未尝试hdfs配置kerberos认证-文章中写需要此操作&quot;&gt;检查集群上的HDFS和本地文件的权限（未尝试，&lt;a href=&quot;https://yq.aliyun.com/articles/25636?spm=5176.100240.searchblog.8.wbY2wv&quot;&gt;HDFS配置Kerberos认证&lt;/a&gt; 文章中写需要此操作）&lt;/h2&gt;
&lt;p&gt;请参考&lt;a href=&quot;https://www.cloudera.com/documentation/enterprise/latest/topics/cdh_sg_users_groups_verify.html?spm=5176.100239.blogcont25636.6.wkeCKj&quot;&gt;Verify User Accounts and Groups in CDH 5 Due to Security&lt;/a&gt;或者&lt;a href=&quot;http://hadoop.apache.org/docs/r2.5.2/hadoop-project-dist/hadoop-common/SecureMode.html?spm=5176.100239.blogcont25636.7.wkeCKj&quot;&gt;Hadoop in Secure Mode&lt;/a&gt;。&lt;/p&gt;

&lt;h1 id=&quot;hdfs整合kerberos启动&quot;&gt;HDFS整合Kerberos（启动）&lt;/h1&gt;
&lt;p&gt;启动之前，请确认JCE jar已经替换，即若master_key_type和supported_enctypes使用aes256-cts（klist -e 命令查看采用了什么encryption），则需要替换JCE jar，请参考前面的说明。否则可能出现问题，可参考&lt;a href=&quot;https://www.cloudera.com/documentation/enterprise/5-11-x/topics/cm_sg_sec_troubleshooting.html#topic_17_1_5&quot;&gt;The NameNode starts but clients cannot connect to it and error message contains enctype code 18&lt;/a&gt;。
而本次操作中，没有使用aes256-cts，所以不用进行替换。&lt;/p&gt;

&lt;h2 id=&quot;kerberoskdc已经启动&quot;&gt;KerberosKDC已经启动&lt;/h2&gt;
&lt;h2 id=&quot;启动namenode可不单独做这个操作直接配置好之后启动但可优先测试&quot;&gt;启动NameNode（可不单独做这个操作，直接配置好之后启动，但可优先测试）&lt;/h2&gt;
&lt;h3 id=&quot;启动操作&quot;&gt;启动操作&lt;/h3&gt;
&lt;p&gt;上述更改配置文件的时候，已经停掉了全部hdfs服务，现在进行启动操作。&lt;br /&gt;
在每个节点上获取root用户的ticket，这里root为之前创建的root/admin的密码。&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ ssh cdh1 &quot;echo root@1234|kinit root/admin&quot;
$ ssh cdh2 &quot;echo root@1234|kinit root/admin&quot;
$ ssh cdh3 &quot;echo root@1234|kinit root/admin&quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;p&gt;关闭selinux&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;setenforce 0
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;获取node1的启动namenode的ticket：&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;kinit -k -t /opt/hadoop_krb5/conf/hdfs.keytab hadoop/node1@HADOOP.COM
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;p&gt;如果出现下面异常kinit: Password incorrect while getting initial credentials，则重新导出keytab再试试。&lt;/p&gt;

&lt;p&gt;然后启动服务，观察日志： 
在node1启动namenode&lt;br /&gt;
hadoop-daemon.sh start namenode&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;待全部配置好之后，hdfs ha启动可参看&lt;a href=&quot;http://www.cnblogs.com/raphael5200/p/5154325.html&quot;&gt;配置HDFS HA(高可用)&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;测试启动&quot;&gt;测试启动&lt;/h3&gt;
&lt;p&gt;在本次操作中，未直接进行测试，是在namenode和datanode全部启动之后才进行测试，但是，验证NameNode是否启动可参照下属操作：&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;打开 web 界面查看启动状态&lt;/li&gt;
  &lt;li&gt;运行下面命令查看 hdfs（hadoop fs -ls /）：
    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; $ hadoop fs -ls /
 Found 4 items
 drwxrwxrwx   - yarn hadoop          0 2014-06-26 15:24 /logroot
 drwxrwxrwt   - hdfs hadoop          0 2014-11-04 10:44 /tmp
 drwxr-xr-x   - hdfs hadoop          0 2014-08-10 10:53 /user
 drwxr-xr-x   - hdfs hadoop          0 2013-05-20 22:52 /var
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;问题总结&quot;&gt;问题总结&lt;/h3&gt;
&lt;p&gt;采用此种方式过程中，可能遇到以下问题运行问题：&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;一个用户如果在你的凭据缓存中没有有效的kerberos ticket，执行上面命令将会失败，将会出现下面的错误：
    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;     11/01/04 12:08:12 WARN ipc.Client: Exception encountered while connecting to the server : javax.security.sasl.SaslException:
     GSS initiate failed [Caused by GSSException: No valid credentials provided (Mechanism level: Failed to find any Kerberos tgt)]
     Bad connection to FS. command aborted. exception: Call to nn-host/10.0.0.2:8020 failed on local exception: java.io.IOException:
     javax.security.sasl.SaslException: GSS initiate failed [Caused by GSSException: No valid credentials provided (Mechanism level: Failed to find any Kerberos tgt)]
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
    &lt;p&gt;解决方法：可通过klist来查看缓存状态，或重新kinit更新缓存。&lt;/p&gt;
    &lt;blockquote&gt;
      &lt;p&gt;此问题官网说明参考&lt;a href=&quot;https://www.cloudera.com/documentation/enterprise/5-11-x/topics/cm_sg_sec_troubleshooting.html#topic_17_1_0&quot;&gt;Running any Hadoop command fails after enabling security.&lt;/a&gt;&lt;/p&gt;
    &lt;/blockquote&gt;
  &lt;/li&gt;
  &lt;li&gt;但是，如果使用的是MIT kerberos 1.8.1或更高版本、并且Oracle JDK 6 Update 26或更低版本，即使成功的使用kinit获取了ticket，java仍然无法读取kerberos票据缓存，可能出现如下错误：
    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;     11/01/04 12:08:12 WARN ipc.Client: Exception encountered while connecting to the server : javax.security.sasl.SaslException:
     GSS initiate failed [Caused by GSSException: No valid credentials provided (Mechanism level: Failed to find any Kerberos tgt)]
     Bad connection to FS. command aborted. exception: Call to nn-host/10.0.0.2:8020 failed on local exception: java.io.IOException:
     javax.security.sasl.SaslException: GSS initiate failed [Caused by GSSException: No valid credentials provided (Mechanism level: Failed to find any Kerberos tgt)]
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
    &lt;p&gt;问题原因：这个问题是因为MIT kerberos 1.8.1或更高版本在写凭证缓存的时候做了一个更改（change参考&lt;a href=&quot;http://krbdev.mit.edu/rt/Ticket/Display.html?id=6206&quot;&gt;MIT Kerberos Change&lt;/a&gt;），如果使用是Oracle JDK 6 Update 26或更低版本，会遇到一个bug（bug参考&lt;a href=&quot;http://bugs.sun.com/bugdatabase/view_bug.do?bug_id=6979329&quot;&gt;Report of bug in Oracle JDK 6 Update 26 and lower&lt;/a&gt;），这个bug导致了在MIT kerberos 1.8.1或更高版中，java无法去读取Kerberos的票据缓存。而需要额外说明的是，Kerberos 1.8.1在Ubuntu Lucid或更高版本、 Debian Squeeze或更高版本中是默认Kerberos，会出现这个问题；但是在RHEL或CentOS中,默认的Kerberos是较老的版本，所以目前不会出现此问题。&lt;br /&gt;
解决方法：在使用kinit获取ticket之后使用&lt;strong&gt;&lt;em&gt;kinit -R&lt;/em&gt;&lt;/strong&gt;来renew ticket。这样，将重写票据缓存中的ticket为java可读的格式，如下：&lt;/p&gt;
    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;     $ klist
     klist: No credentials cache found (ticket cache FILE:/tmp/krb5cc_1000)
     $ hadoop fs -ls
     11/01/04 13:15:51 WARN ipc.Client: Exception encountered while connecting to the server : javax.security.sasl.SaslException:
     GSS initiate failed [Caused by GSSException: No valid credentials provided (Mechanism level: Failed to find any Kerberos tgt)]
     Bad connection to FS. command aborted. exception: Call to nn-host/10.0.0.2:8020 failed on local exception: java.io.IOException:
     javax.security.sasl.SaslException: GSS initiate failed [Caused by GSSException: No valid credentials provided (Mechanism level: Failed to find any Kerberos tgt)]
     $ kinit
     Password for atm@YOUR-REALM.COM: 
     $ klist
     Ticket cache: FILE:/tmp/krb5cc_1000
     Default principal: atm@YOUR-REALM.COM
        
     Valid starting     Expires            Service principal
     01/04/11 13:19:31  01/04/11 23:19:31  krbtgt/YOUR-REALM.COM@YOUR-REALM.COM
        
     renew until 01/05/11 13:19:30
     $ hadoop fs -ls
     11/01/04 13:15:59 WARN ipc.Client: Exception encountered while connecting to the server : javax.security.sasl.SaslException:
     GSS initiate failed [Caused by GSSException: No valid credentials provided (Mechanism level: Failed to find any Kerberos tgt)]
     Bad connection to FS. command aborted. exception: Call to nn-host/10.0.0.2:8020 failed on local exception: java.io.IOException:
     javax.security.sasl.SaslException: GSS initiate failed [Caused by GSSException: No valid credentials provided (Mechanism level: Failed to find any Kerberos tgt)]
     $ kinit -R
     $ hadoop fs -ls
     Found 6 items
     drwx------   - atm atm          0 2011-01-02 16:16 /user/atm/.staging
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;在上述问题2中，也有kinit -R 问题：&lt;br /&gt;
     但是，需要注意的是使用2这种方法，要求的是ticket是可renew的。而能否获取renewable tickets依赖于KDC的设置和每一个principal的设置（包括realm中有问题的principal和TGT service端的principal）。&lt;br /&gt;
     如果，一个ticker不可renew，那么它的”valid starting”和”renew until”的值是相同的时间。这时，使用kinit -R就会遇到下面的问题：
    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;     kinit: Ticket expired while renewing credentials
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
    &lt;blockquote&gt;
      &lt;p&gt;此问题官网说明参考&lt;a href=&quot;https://www.cloudera.com/documentation/enterprise/5-11-x/topics/cm_sg_sec_troubleshooting.html#topic_17_1_1&quot;&gt;Java is unable to read the Kerberos credentials cache created by versions of MIT Kerberos 1.8.1 or higher.&lt;/a&gt;&lt;/p&gt;
    &lt;/blockquote&gt;

    &lt;p&gt;所以为了获取可renew的ticket，可尝试使用以下方法-未彻底测试，若有问题，还需要大家自行解决下，并希望大家告诉我一下啦～（以下解决方法部分参考其他文章，&lt;a href=&quot;http://blog.csdn.net/wulantian/article/details/42173095&quot;&gt;CDH的Kerberos认证配置&lt;/a&gt;，时间过去挺久了，有些遗忘，待有时间再重新测试下）：&lt;br /&gt;
a.在kdc.conf中添加默认flag&lt;/p&gt;
    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;     default_principal_flags = +forwardable,+renewable
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
    &lt;p&gt;但是实际没有起作用，因为查看资料，默认的principal_flags就包含了renewable，所以问题不是出在这里。另外需要说明一点，default_principal_flags只对这个flags生效以后创建的principal生效，之前创建的不生效，需要使用modprinc来使之前的principal生效。&lt;br /&gt;
b.在kdc.conf中添加，并加大该参数：&lt;/p&gt;
    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;     max_renewable_life = 10d
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
    &lt;p&gt;修改之后重启kdc，重新kinit，再重新执行kinit -R则可以正常renew了。&lt;br /&gt;
为了进行验证，再次将参数修改为“max_renewable_life = 0s”，再重新kinit后执行kinit -R则再次不能renew，则说明是否可以获取renew的ticket中，默认是可以获取renew的ticket的，但是，可以renw的最长时间是0s，所以造成无法renew，解决的办法是在kdc.conf中增大该参数。&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;blockquote&gt;
  &lt;p&gt;另外补充：&lt;br /&gt;
1」关于krb5.conf中的renew_lifetime = 7d参数，该参数设置该服务器上的使用kinit -R时renew的时间。&lt;br /&gt;
2」可以通过modprinc来修改max_renewable_life的值，使用modprinc修改的值比kdc.conf中的配置有更高的优先级，例如，使用modprinc设置了为7天，kdc.conf中设置了为10天，使用getprinc可以看出，实际生效的是7天。需要注意的是，既要修改krbtgt/for_hadoop@for_hadoop，也要修改类似于hdfs/hadoop.local@for_hadoop这样的prinicials。使用modprinc来修改max_renewable_life，即kadmin.local进入kerberos的shell之后，执行：&lt;/p&gt;
  &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;modprinc -maxrenewlife 7days krbtgt/for_hadoop@for_hadoop  
getprinc krbtgt/for_hadoop@for_hadoop
&lt;/code&gt;&lt;/pre&gt;
  &lt;/div&gt;
&lt;/blockquote&gt;

&lt;p&gt;到这里，kinit -R的问题解决，可以成功的执行hadoop fs -ls了。&lt;br /&gt;
其他问题参考官网&lt;a href=&quot;https://www.cloudera.com/documentation/enterprise/5-11-x/topics/cm_sg_sec_troubleshooting.html#topic_17_1_0&quot;&gt;Troubleshooting Authentication Issues&lt;/a&gt;。&lt;/p&gt;

&lt;h2 id=&quot;启动datanode&quot;&gt;启动datanode&lt;/h2&gt;
&lt;p&gt;根据hdfs配置的区别，有两种启动datanode的方式，一种是使用jscv，一种是开启SASL。&lt;/p&gt;
&lt;h3 id=&quot;方式一jsvc启动datanode-目前此种方式测试有些问题能成功启动并正常使用但是启动后通过jps查看发现datanode处有进程号但无进程名字datanode原因未知待解决&quot;&gt;方式一：jsvc启动datanode-目前此种方式测试有些问题，能成功启动并正常使用，但是启动后通过jps查看，发现datanode处有进程号，但无进程名字“datanode”，原因未知，待解决。&lt;/h3&gt;
&lt;p&gt;如果没有配置TLS/SSL for HDFS（hdfs-site.xml里的dfs.http.policy），则datanode需要通过JSVC启动（只能root用户）。&lt;/p&gt;

&lt;p&gt;关于Datanode+jsvc：&lt;br /&gt;
在2.6版本前，启用hadoop安全模式，因为DataNode的数据传输协议没有使用HadoopRPC框架，DataNodes必须使用被dfs.datanode.address和dfs.datanode.http.address指定的特权端口来认证他们自己，该认证使基于假设攻击者无法获取在DataNode主机上的root特权。启动datanode的时候，必须用root用户，而当你使用root执行hdfs datanode命令时，服务器进程首先绑定特权端口，随后销毁特权并使用被HADOOP_SECURE_DN_USER指定的用户账号运行。这个启动进程使用被安装在JSVC_HOME的jsvc program。因此必须在启动项中hadoop-env.sh指定HADOOP_SECURE_DN_USER和JSVC_HOME做为环境变量。&lt;/p&gt;

&lt;p&gt;jsvc模式启动datanode关键点先说明：&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;hdfs-site.xml中没有开启TLS/SSL HDFS配置；&lt;/li&gt;
  &lt;li&gt;hdfs-site.xml中dfs.datanode.address、dfs.datanode.http.address的端口一定小于1024（特权端口）；&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;hadoop-env.sh设置HADOOP_SECURE_DN_USER为实际启动用户；&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  export HADOOP_SECURE_DN_USER=hadoop
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;安装jsvc，在hdfs-site.xml下加入安装目录JSVC_HOME，jsvc相关jar包替换；&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  export JSVC_HOME=/opt/hadoop/sbin/Linux/bigtop-jsvc-1.0.10-cdh5.11.0
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;启动服务前，先获取ticket再运行相关命令，要使用root用户启动datanode。&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;ijsvc环境部署hdfs集群的所有节点都要进行此操作&quot;&gt;i.jsvc环境部署（hdfs集群的所有节点都要进行此操作）&lt;/h4&gt;
&lt;p&gt;使用jsvc模式，hdfs-site.xml中去掉ssl配置，并且相关端口号使用特权端口，之后需要部署jsvc环境。
因为系统里未安装jsvc，则首先进行安装操作，安装参考&lt;a href=&quot;http://blog.csdn.net/shuchangwen/article/details/45242549&quot;&gt;jscv安装&lt;/a&gt;。&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;下载安装包
因为我的hdoop版本是2.6.0-cdh5.11.0，因此我在&lt;a href=&quot;http://archive.cloudera.com/cdh5/cdh/5/&quot;&gt;CDH组件下载&lt;/a&gt;处下载了bigtop-jsvc-1.0.10-cdh5.11.0.tar.gz。
    &lt;blockquote&gt;
      &lt;p&gt;补充：有些文章说明，apache hadoop可去&lt;a href=&quot;http://archive.apache.org/dist/commons/daemon/binaries/&quot;&gt;apache网站&lt;/a&gt;下载源代码和bin包。并且，关于JSVC，默认指向hadoop安装目录的libexec下，但libexec下并没有jsvc文件（hadoop是直接下载的tar.gz包，不是rpm安装），如下载commons-daemon-1.0.15-src.tar.gz及commons-daemon-1.0.15-bin.tar.gz，先解压src包后进入src/native/unix目录依次(可能需要先yum install gcc make sdk autoconf，再执行)执行./configure命令，make命令，这样会在当前目录下生成一个叫jsvc的文件，之后把它拷贝到hadoop目录下的libexec下，或更改环境变量如3。&lt;/p&gt;
    &lt;/blockquote&gt;
  &lt;/li&gt;
  &lt;li&gt;安装操作&lt;br /&gt;
把安装包放到了HADOOP_HOME家目录”/sbin/Linux/”目录下，直接解压即可。&lt;br /&gt;
解压成bigtop-jsvc-1.0.10-cdh5.11.0后，进入到$HADOOP_HOME/sbin/Linux/bigtop-jsvc-1.0.10-cdh5.11.0目录下，可以看到jsvc，使用“./jsvc -help”命令测试jsvc能否使用（注意修改整个文件的权限drwxr-xr-x. 5 hadoop root   4096 Sep  8 13:54 bigtop-jsvc-1.0.10-cdh5.11.0）。&lt;/li&gt;
  &lt;li&gt;配置环境变量&lt;br /&gt;
在hadoop-env.sh文件中加入以下内容：
    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;export HADOOP_SECURE_DN_USER=hadoop
export JSVC_HOME=/opt/hadoop/sbin/Linux/bigtop-jsvc-1.0.10-cdh5.11.0
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
    &lt;blockquote&gt;
      &lt;p&gt;说明：设置了HADOOP_SECURE_DN_USER的环境变量后，start-dfs.sh的启动脚本将会自动跳过DATANODE的启动。&lt;/p&gt;
    &lt;/blockquote&gt;
  &lt;/li&gt;
  &lt;li&gt;替换jar包&lt;br /&gt;
之前是没有进行替换jar包的操作，之后启动过程中出现错误，之后查阅资料得知，JSVC运行还需要一个commons-daemon-xxx.jar包，因此发现需要进行jar包替换，通过查阅资料得知，需要替换$HADOOP_HOME/share/hadoop/hdfs/lib下的commons-daemon-xxx.jar。&lt;br /&gt;
因为我下载的是bigtop-jsvc-1.0.10-cdh5.11.0.tar.gz，而在HADOOP_HOME家目录的/share/hadoop/hdfs/lib下的是commons-daemon-1.0.13.jar，因此从&lt;a href=&quot;http://archive.apache.org/dist/commons/daemon/binaries/&quot;&gt;commons／daemon&lt;/a&gt;下下载了commons-daemon-1.0.10.jar，然后把得到的commons-daemon-1.0.10.jar文件拷贝到hadoop安装目录下share/hadoop/hdfs/lib下（有文章说明要同时删除自带版本的commons-daemon-xxx.jar包，但我没有删除也可以使用）并更改了权限和其它内容保持一致(如-rwxr-xr-x. 1 hadoop root    24242 Sep  8 14:13 commons-daemon-1.0.10.jar)。&lt;/li&gt;
&lt;/ol&gt;

&lt;blockquote&gt;
  &lt;p&gt;接1补充：如果下载的是apache commons，即可解压bin包，然后把得到的commons-daemon-**.jar文件拷贝到hadoop安装目录下share/hadoop/hdfs/lib下，同时删除自带版本的commons-daemon-xxx.jar包。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;将上述操作在集群中的所有节点重复一遍（node1、node2、node3）。&lt;br /&gt;
至此，jsvc的安装结束，注意hdfs的所有节点都要进行以上安装操作。&lt;/p&gt;
&lt;h4 id=&quot;ii启动集群datanode&quot;&gt;ii.启动（集群）datanode&lt;/h4&gt;
&lt;h5 id=&quot;启动操作-1&quot;&gt;启动操作&lt;/h5&gt;
&lt;p&gt;设置了Security后，NameNode、QJM、ZKFC可以通过start-dfs.sh启动，DataNode需要使用（jsvc）root权限启动。&lt;br /&gt;
并且因为设置了HADOOP_SECURE_DN_USER的环境变量后，执行start-dfs.sh的启动脚本将会自动跳过DATANODE的启动。&lt;br /&gt;
所以使用jsvc模式，启动集群的时候需要两个步骤：&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;启动NameNode、QJM、ZKFC（详细参考上述启动namenode）（若不是第一次启动，第一次配置好了hadoop的启动需要参考&lt;a href=&quot;http://www.cnblogs.com/raphael5200/p/5154325.html&quot;&gt;配置HDFS HA(高可用)&lt;/a&gt; ）
    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;#每台机器上（kinit启动的用户）
kinit -k -t /opt/hadoop_krb5/conf/hdfs.keytab hadoop/node1@HADOOP.COM
#node1上
start-dfs.sh
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
    &lt;p&gt;使用start-dfs.sh之后查看QJM的日志和ZKFC的日志（QJM的报错不会有明显的提示）检查有无exception；如果启动不成功则仍需进行排查（keytab、zk的kerberos等）。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;启动Datanode &lt;br /&gt;
因为Datanode需要通过jsvc启动进程，当你使用root执行启动脚本（如hdfs datanode）命令时，服务器进程首先绑定特权端口，随后销毁特权并使用被HADOOP_SECURE_DN_USER指定的用户账号运行。&lt;br /&gt;
所以先需要在集群中的每台机器上都获取原启动用户（hadoop）ticket（现在登陆的是root用户,时间有点长了，有些遗忘好像也需要kinitroot的），然后再启动服务。&lt;br /&gt;
kinit并启动服务：
    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; # ssh node1 &quot;kinit -k -t /opt/hadoop_krb5/conf/hdfs.keytab hadoop/node1@HADOOP.COM; ./opt/hadoop/sbin/hadoop-daemon.sh start datanode&quot;
 # ssh node2 &quot;kinit -k -t /opt/hadoop_krb5/conf/hdfs.keytab hadoop/node2@HADOOP.COM; ./opt/hadoop/sbin/hadoop-daemon.sh start datanode&quot;
 # ssh node3 &quot;kinit -k -t /opt/hadoop_krb5/conf/hdfs.keytab hadoop/node3@HADOOP.COM; ./opt/hadoop/sbin/hadoop-daemon.sh start datanode&quot;
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
    &lt;p&gt;补充，或在kinit后每台机器上使用命令启动：&lt;/p&gt;
    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; HADOOP_DATANODE_USER=hadoop sudo -E /opt/hadoop/bin/hdfs datanode
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
    &lt;p&gt;或：&lt;/p&gt;
    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; [root@node1 ~]# kinit -k -t /opt/hadoop_krb5/conf/hdfs.keytab hadoop/node1@HADOOP.COM
 [root@node1 ~]# start-secure-dns.sh
 node3: starting datanode, logging to /app/dcos/hadoop_logs//hadoop-hadoop-datanode-node3.out
 node1: starting datanode, logging to /app/dcos/hadoop_logs//hadoop-hadoop-datanode-node1.out
 node2: starting datanode, logging to /app/dcos/hadoop_logs//hadoop-hadoop-datanode-node2.out
    
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;验证datanode启动情况：观看node1上NameNode日志，出现下面日志表示DataNode启动成功：
    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;2017-09-11 10:06:27,667 INFO org.apache.hadoop.security.UserGroupInformation: Login successful for user hadoop/node1@HADOOP.COM using keytab file /opt/hadoop_krb5/conf/hdfs.keytab
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h5 id=&quot;遇到问题&quot;&gt;遇到问题&lt;/h5&gt;
&lt;p&gt;通过此方法启动datanode之后，通过jps查看，发现进程名字无法显示，但是hadoop集群运行正常。&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;[root@node1 sbin]# jps
6912 QuorumPeerMain
8785 NameNode
9251 DFSZKFailoverController
27156 Jps
10456
19929 Main
9033 JournalNode
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;p&gt;排查问题补充相关：&lt;br /&gt;
jps(Java Virtual Machine Process Status Tool)是提供的一个显示当前所有java进程pid的命令，而jvm运行时会生成一个目录hsperfdata_$USER(其中user是启动java进程的用户)，默认的是生成在 java.io.tmpdir目录下，在linux中默认是/tmp，目录下会有些pid文件,存放jvm进程信息可以利用strings查看里面的文件内容，一般就是jvm的进程信息而已。&lt;br /&gt;
以上问题是只有进程号，没有进程名字，就思考是不是pid文件问题，于是去/tmp/hsperfdata_hadoop/和/tmp/hsperfdata_root/下看看是否有相关进程信息，发现datanode虽然是用jsvc方式用root用户启动的，而“10456”进程在/tmp/hsperfdata_hadoop/下。&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;[root@node1 tmp]# cd hsperfdata_
hsperfdata_apple1/  hsperfdata_apple2/  hsperfdata_hadoop/  hsperfdata_root/    hsperfdata_sitech1/ hsperfdata_sitech2/
[root@node1 tmp]# cd hsperfdata_hadoop/
[root@node1 hsperfdata_hadoop]# ls
10456  6912  8785  9033  9251
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;p&gt;之后就去尝试使用SASL方式启动datanode了，这个问题就没有继续解决。怀疑是不是上面部署步骤出现问题了，有时间回来再看看是什么问题，再进行修改@TODO，希望大家有消息告诉我下，非常感谢！邮箱：leafming@foxmail.com。&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;此文“&lt;a href=&quot;http://blog.csdn.net/xiao_jun_0820/article/details/39375819&quot;&gt;Hadoop的kerberos的实践部署&lt;/a&gt;”和“&lt;a href=&quot;http://blog.csdn.net/wulantian/article/details/42173095&quot;&gt;CDH的Kerberos认证&lt;/a&gt;”内有关于datanode使用jsvc启动内容，但未完全参照。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;补充其他问题（好像这个问题没啥关系，不是这么解决，就先放这放着吧）：有人说，有时候端口问题服务无法正常启动，如：“WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: node2/10.211.55.11:8020”，使用“netstat -an|grep 8020”命令查看端口状态，如果不正常，映射为127.0.0.1:8020，则可尝试修改/etc/hosts文件中，去掉“127.0.0.1 localhost”，添加自己ip和主机名的映射，重新启动。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h5 id=&quot;小总结&quot;&gt;小总结&lt;/h5&gt;
&lt;p&gt;加强理解，再次重复总结：jsvc模式启动datanode关键点：&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;hdfs-site.xml中没有开启TLS/SSL HDFS配置；&lt;/li&gt;
  &lt;li&gt;hdfs-site.xml中dfs.datanode.address、dfs.datanode.http.address的端口一定小于1024（特权端口）；&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;hadoop-env.sh设置HADOOP_SECURE_DN_USER为实际启动用户；&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  export HADOOP_SECURE_DN_USER=hadoop
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;安装jsvc，在hdfs-site.xml下加入安装目录JSVC_HOME，jsvc相关jar包替换；&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  export JSVC_HOME=/opt/hadoop/sbin/Linux/bigtop-jsvc-1.0.10-cdh5.11.0
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;启动服务前，先获取ticket再运行相关命令，要使用root用户启动datanode，其它正常用hadoop用户即可。&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;方式二hfds中开启sasl整体配置&quot;&gt;方式二：Hfds中开启SASL整体配置&lt;/h3&gt;

&lt;blockquote&gt;
  &lt;p&gt;过渡说明：关于迁移一个使用root验证的hdfs集群为SASL方式，官方网站（&lt;a href=&quot;http://hadoop.apache.org/docs/stable/hadoop-project-dist/hadoop-common/SecureMode.html&quot;&gt;Hadoop in Secure Mode-Secure DataNode&lt;/a&gt; ）上有如下说明：&lt;/p&gt;

  &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;In order to migrate an existing cluster that used root authentication to start using SASL instead, first ensure that version 2.6.0 or later has been deployed to all cluster nodes as well as any external applications that need to connect to the cluster. Only versions 2.6.0 and later of the HDFS client can connect to a DataNode that uses SASL for authentication of data transfer protocol, so it is vital that all callers have the correct version before migrating. After version 2.6.0 or later has been deployed everywhere, update configuration of any external applications to enable SASL. If an HDFS client is enabled for SASL, then it can connect successfully to a DataNode running with either root authentication or SASL authentication. Changing configuration for all clients guarantees that subsequent configuration changes on DataNodes will not disrupt the applications. Finally, each individual DataNode can be migrated by changing its configuration and restarting. It is acceptable to have a mix of some DataNodes running with root authentication and some DataNodes running with SASL authentication temporarily during this migration period, because an HDFS client enabled for SASL can connect to both.
&lt;/code&gt;&lt;/pre&gt;
  &lt;/div&gt;
&lt;/blockquote&gt;

&lt;p&gt;方式一介绍了使用jsvc启动datanode（稍有问题），下面开始介绍使用SASL的方式。&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;有文章写了sasl in hdfs的配置方式相关操作，参考&lt;a href=&quot;http://blog.csdn.net/dxl342/article/details/55510659&quot;&gt;HDFS使用Kerberos&lt;/a&gt;。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;关于SASL模式的配置关键主要有以下几点，文章上面配置hadoop部分也有部分说明：&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;hdfs-site.xml中开启TLS/SSL HDFS配置；&lt;/li&gt;
  &lt;li&gt;hdfs-site.xml中dfs.datanode.address、dfs.datanode.http.address的端口一定大于1024（非特权端口）；&lt;/li&gt;
  &lt;li&gt;hadoop-env.sh中的HADOOP_SECURE_DN_USER内容一定为空，并且和jsvc模式不同，不需要进行jsvc的环境部署；&lt;/li&gt;
  &lt;li&gt;https配置；&lt;/li&gt;
  &lt;li&gt;正常启动hdfs集群。&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;ihdfs配置1基础配置&quot;&gt;i.hdfs配置（1基础配置）&lt;/h4&gt;
&lt;p&gt;虽然上面配置地方已经提过了，不过这次还是再重复写一遍吧，保持操作完整性嘛，大家配置过的可以去检查一次。&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;hdfs-site.xml中开启TLS/SSL HDFS配置，即在hdfs-site.xml中定义dfs.http.policy，指定要在HDFS的守护进程启动HTTPS服务器。增加如下内容：
    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; &amp;lt;!-- 开启SSL(jsvc时可不配置；可选，详见下属总结以及启动datanode部分) --&amp;gt;
 &amp;lt;property&amp;gt;
  	&amp;lt;name&amp;gt;dfs.http.policy&amp;lt;/name&amp;gt;
  	&amp;lt;value&amp;gt;HTTPS_ONLY&amp;lt;/value&amp;gt;
 &amp;lt;/property&amp;gt;
 &amp;lt;!-- SASL 模式--&amp;gt;
 &amp;lt;property&amp;gt;
  	&amp;lt;name&amp;gt;dfs.data.transfer.protection&amp;lt;/name&amp;gt;
 	 &amp;lt;value&amp;gt;integrity&amp;lt;/value&amp;gt;
 &amp;lt;/property&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
    &lt;p&gt;说明，这里可以使用三个参数：  &lt;br /&gt;
HTTP_ONLY: Only HTTP server is started&lt;br /&gt;
HTTPS_ONLY: Only HTTPS server is started&lt;br /&gt;
HTTP_AND_HTTPS: Both HTTP and HTTPS server are started  &lt;br /&gt;
值得一提的是，如果dfs.http.policy设置了https_only，则普通的WebHDFS不再可用。您将需要使用WebHDFS基于HTTPS，在这种结构中，它能保护你通过WebHDFS的数据。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;检查hdfs-site.xml中dfs.datanode.address、dfs.datanode.http.address的端口一定大于1024（非特权端口）；hadoop-env.sh中的HADOOP_SECURE_DN_USER内容一定为空。&lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&quot;iihttps配置&quot;&gt;ii.https配置&lt;/h4&gt;
&lt;p&gt;经过以上操作后，尝试启动hdfs，会发现namenode报错后退出，如下：&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;2017-09-13 14:12:37,273 INFO org.apache.hadoop.http.HttpServer2: HttpServer.start() threw a non Bind IOException
java.io.FileNotFoundException: /home/dtdream/.keystore (No such file or directory)
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;p&gt;发现没有keystore文件，这个问题跟hadoop、Kerberos没什么关系，纯粹是https的配置了。&lt;br /&gt;
简单说明https相关原理：https要求集群中有一个CA，它会生成ca_key和ca_cert，想要加入这个集群的节点，需要拿到这2个文件，然后经过一连串的动作生成keystore，并在hadoop的ssl-server.xml和ssl-client.xml中指定这个keystore的路径和密码，这样各个节点间就可以使用https进行通信了。
因此若要继续使用此模式，后续需要进行hdfs中的https配置。详细hdfs的https配置，可参考&lt;a href=&quot;https://zh.hortonworks.com/blog/deploying-https-hdfs/&quot;&gt;DEPLOYING HTTPS IN HDFS&lt;/a&gt;，下面直接帖命令简单说明下过程。&lt;/p&gt;

&lt;p&gt;注：在每台（node1、node2、node3）机器上都创建了/opt/ca 这个目录，存放ca相关文件，以下命令均在集群中各个机器的此目录下执行。&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;生成每个机器的密钥和证书&lt;br /&gt;
首先需要在集群里面的每个机器上创建keyhecertificate，可以使用keytool命令来创建，如：
    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ keytool -keystore {keystore} -alias localhost -validity {validity} -genkey
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
    &lt;p&gt;即通过此命令定义两个关键参数：&lt;br /&gt;
keystore：keystore文件负责存储certificate，里面包括certificate的私钥，因此需要好好保存；&lt;br /&gt;
validity：定义certificate的有效时间。&lt;br /&gt;
keytool命令会设置certificate的一些相关细节，如CN、OU、O、L、ST、C；其中CN要和节点全域名（FQDN）保持一致，通常情况下，在有部署DNS的情况下，客户端将cn与DNS域名进行比较，以确保它确实连接到所需服务器，而不是恶意服务器。&lt;br /&gt;
此操作命令示例（注意密码）：&lt;/p&gt;
    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;#node1  ／opt／ca目录下
keytool -keystore keystore -alias node1 -validity 9999 -genkey -keyalg RSA -keysize 2048 -dname &quot;CN=node1, OU=security, O=hadoop, L=beijing, ST=beijing, C=CN&quot;  
#node2  ／opt／ca目录下
keytool -keystore keystore -alias node2 -validity 9999 -genkey -keyalg RSA -keysize 2048 -dname &quot;CN=node1, OU=security, O=hadoop, L=beijing, ST=beijing, C=CN&quot;  
#node3  ／opt／ca目录下
keytool -keystore keystore -alias node3 -validity 9999 -genkey -keyalg RSA -keysize 2048 -dname &quot;CN=node1, OU=security, O=hadoop, L=beijing, ST=beijing, C=CN&quot;
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
    &lt;p&gt;执行完上述命令，会在当前目录下生成keystore文件。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;创建自己的CA  &lt;br /&gt;
经过第一步之后，集群的每个机器中有个自己的公私密钥对以及一个标识机器的证书。但是，证书是没有注册的，这意味着攻击者可以创建这样的证书冒充任何机器。&lt;br /&gt;
因此，为了防止伪造证书，要为注册签名集群中的每台机器的证书。证书颁发机构（CA）负责签署证书。CA的工作就像一个政府签发护照，政府印章（标志）每个护照，使护照变得难以伪造。其他政府核实这些邮票以确保护照是真实的。类似地，CA在证书上签名，加密保证了签名证书难以伪造。因此，只要CA是一个真正可信的权威，客户就保证他们连接到真正的机器。&lt;br /&gt;
下面，使用openssl命令去生成一个新的CA证书，生成的CA仅仅是一个公私密钥对和证书，可以用它签署其他证书。
我们这里将node1作为CA，在node1上执行如下命令（注意密码）：
    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;#node1  ／opt／ca目录下
openssl req -new -x509 -keyout test_ca_key -out test_ca_cert -days 9999 -subj '/C=CN/ST=beijing/L=beijing/O=hadoop/OU=security/CN=node1'
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
    &lt;p&gt;说明：这里cn是CA服务器的地址。&lt;br /&gt;
执行完以上命令，会在当前目录下生成test_ca_cert、test_ca_key文件。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;添加CA到客户机器的信任库&lt;br /&gt;
在生成了CA之后，需要添加CA到每个客户端的信任库中，使客户可以信任这个CA，使用命令：
    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ keytool -keystore {truststore} -alias CARoot -import -file {ca-cert}
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
    &lt;p&gt;此步骤操作命令示例： 
即，首先在node1上，将上面生成的test_ca_key和test_ca_cert拷贝到集群中的所有机器上。&lt;/p&gt;
    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;#node1  ／opt／ca目录下
scp test_ca_cert node2:/opt/ca/  
scp test_ca_cert node3:/opt/ca/  
scp test_ca_key node3:/opt/ca/  
scp test_ca_key node2:/opt/ca/
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
    &lt;p&gt;在集群中每台机器上执行如下命令（注意密码）：&lt;/p&gt;
    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;#node1  ／opt／ca目录下  
keytool -keystore truststore -alias CARoot -import -file test_ca_cert
#node2  ／opt／ca目录下  
keytool -keystore truststore -alias CARoot -import -file test_ca_cert
#node3  ／opt／ca目录下  
keytool -keystore truststore -alias CARoot -import -file test_ca_cert
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
    &lt;p&gt;执行完以上命令，会在当前目录下生成truststore文件。&lt;br /&gt;
在步骤1中的ketstore存储的是每一台机器自己的身份，而客户机的truststore存储的是客户端信任的所有证书。导入证书到一个truststore中意味着信任那个证书签名的其它所有证书。如以上所述，信任政府（CA）也意味着信任它签发的所有护照（证书）。这个属性称为信任链，它在大型Hadoop集群上部署HTTPS时特别有用。你可以在集群中用一个CA签名所有认证，然后每个机器就能使用一个相同信任了CA的truststore，通过这种方式，所有的机器可以验证所有其他机器。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;签名证书&lt;br /&gt;
下一步就是要使用步骤2生成的CA来签名步骤1中生成的所有证书。
    &lt;ol&gt;
      &lt;li&gt;首先，你需要从密钥库中导出的证书，使用如下命令：
        &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; $ keytool -keystore -alias localhost -certreq -file {cert-file}
&lt;/code&gt;&lt;/pre&gt;
        &lt;/div&gt;
        &lt;p&gt;即在node1、node2、node3上执行（注意密码）：&lt;/p&gt;

        &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; #node1  ／opt／ca目录下
 keytool -certreq -alias node1 -keystore keystore -file cert  
 #node2  ／opt／ca目录下
 keytool -certreq -alias node2 -keystore keystore -file cert
 #node3  ／opt／ca目录下
 keytool -certreq -alias node3 -keystore keystore -file cert
&lt;/code&gt;&lt;/pre&gt;
        &lt;/div&gt;
        &lt;p&gt;执行完以上命令，会在当前目录下生成cert文件。&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;之后，使用CA进行签名，使用如下命令：
        &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; $ openssl x509 -req -CA {ca-cert} -CAkey {ca-key} -in {cert-file} -out {cert-signed} -days {validity} -CAcreateserial -passin pass:{ca-password}
&lt;/code&gt;&lt;/pre&gt;
        &lt;/div&gt;
        &lt;p&gt;即在node1、node2、node3上执行（注意密码）：&lt;/p&gt;
        &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; #node1  ／opt／ca目录下
 openssl x509 -req -CA test_ca_cert -CAkey test_ca_key -in cert -out cert_signed -days 9999 -CAcreateserial -passin pass:hadoop@1234
 #这个pass是CA的密码，即Then sign it with the CA。
 #node2  ／opt／ca目录下
 openssl x509 -req -CA test_ca_cert -CAkey test_ca_key -in cert -out cert_signed -days 9999 -CAcreateserial -passin pass:hadoop@1234
 #node3  ／opt／ca目录下
 openssl x509 -req -CA test_ca_cert -CAkey test_ca_key -in cert -out cert_signed -days 9999 -CAcreateserial -passin pass:hadoop@1234
&lt;/code&gt;&lt;/pre&gt;
        &lt;/div&gt;
        &lt;p&gt;执行完以上命令，会在当前目录下生成cert_signed文件。&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;最后，将CA正式和被签名的证书都导入keystore中，使用如下命令：
        &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; $ keytool -keystore -alias CARoot -import -file {ca-cert}
 $ keytool -keystore -alias localhost -import -file {cert-signed}
&lt;/code&gt;&lt;/pre&gt;
        &lt;/div&gt;
        &lt;p&gt;即在node1、node2、node3上执行（注意密码）：&lt;/p&gt;

        &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; #node1  ／opt／ca目录下
 keytool -keystore keystore -alias CARoot -import -file test_ca_cert
 keytool -keystore keystore -alias node1 -import -file cert_signed
 #node2  ／opt／ca目录下
 keytool -keystore keystore -alias CARoot -import -file test_ca_cert
 keytool -keystore keystore -alias node2 -import -file cert_signed
 #node3  ／opt／ca目录下
 keytool -keystore keystore -alias CARoot -import -file test_ca_cert
 keytool -keystore keystore -alias node3 -import -file cert_signed
&lt;/code&gt;&lt;/pre&gt;
        &lt;/div&gt;
      &lt;/li&gt;
      &lt;li&gt;补充：以上命令参数说明：&lt;br /&gt;
 keystore:keystore的位置&lt;br /&gt;
 ca-cert:CA证书&lt;br /&gt;
 ca-key:CA私钥&lt;br /&gt;
 ca-password:CA密码&lt;br /&gt;
 cert-file:导出的服务器的未签名证书&lt;br /&gt;
 cert-signed:服务器的签名的证书&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&quot;iiihdfs配置2整合https&quot;&gt;iii.hdfs配置（2整合https）&lt;/h4&gt;
&lt;p&gt;最后需要去配置HDFS中的HTTPs。&lt;br /&gt;
其次，需要配置在$HADOOP_HOME/etc/hadoop目录下的ssl-server.xml和ssl-client.xml，告诉HDFS的密钥库和信任存储区。&lt;br /&gt;
在所有节点上均进行此配置，现在node1上配置好，之后拷贝到其他节点（因为文件设置的都是在一样的路径）。&lt;br /&gt;
说明：这里没来得及深究，有些配置可以省略。以后又时间再补充。@TODO&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;ssl-client.xml&lt;br /&gt;
本次操作配置文件示例：
    &lt;div class=&quot;language-xml highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; &lt;span class=&quot;nt&quot;&gt;&amp;lt;configuration&amp;gt;&lt;/span&gt;
 &lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
   &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;ssl.client.truststore.location&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
   &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;/opt/ca/truststore&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
   &lt;span class=&quot;nt&quot;&gt;&amp;lt;description&amp;gt;&lt;/span&gt;Truststore to be used by clients like distcp. Must be specified.
   &lt;span class=&quot;nt&quot;&gt;&amp;lt;/description&amp;gt;&lt;/span&gt;
 &lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
 &lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
   &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;ssl.client.truststore.password&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
   &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;hadoop@1234&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
   &lt;span class=&quot;nt&quot;&gt;&amp;lt;description&amp;gt;&lt;/span&gt;Optional. Default value is &quot;&quot;.
   &lt;span class=&quot;nt&quot;&gt;&amp;lt;/description&amp;gt;&lt;/span&gt;
 &lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
 &lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
   &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;ssl.client.truststore.type&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
   &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;jks&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
   &lt;span class=&quot;nt&quot;&gt;&amp;lt;description&amp;gt;&lt;/span&gt;Optional. The keystore file format, default value is &quot;jks&quot;.
   &lt;span class=&quot;nt&quot;&gt;&amp;lt;/description&amp;gt;&lt;/span&gt;
 &lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
 &lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
   &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;ssl.client.truststore.reload.interval&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
   &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;10000&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
   &lt;span class=&quot;nt&quot;&gt;&amp;lt;description&amp;gt;&lt;/span&gt;Truststore reload check interval, in milliseconds.
   Default value is 10000 (10 seconds).
   &lt;span class=&quot;nt&quot;&gt;&amp;lt;/description&amp;gt;&lt;/span&gt;
 &lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
 &lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
   &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;ssl.client.keystore.location&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
   &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;/opt/ca/keystore&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
   &lt;span class=&quot;nt&quot;&gt;&amp;lt;description&amp;gt;&lt;/span&gt;Keystore to be used by clients like distcp. Must be specified.
   &lt;span class=&quot;nt&quot;&gt;&amp;lt;/description&amp;gt;&lt;/span&gt;
 &lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
 &lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
   &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;ssl.client.keystore.password&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
   &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;hadoop@1234&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
   &lt;span class=&quot;nt&quot;&gt;&amp;lt;description&amp;gt;&lt;/span&gt;Optional. Default value is &quot;&quot;.
   &lt;span class=&quot;nt&quot;&gt;&amp;lt;/description&amp;gt;&lt;/span&gt;
 &lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
 &lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
   &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;ssl.client.keystore.keypassword&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
   &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;hadoop@1234&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
   &lt;span class=&quot;nt&quot;&gt;&amp;lt;description&amp;gt;&lt;/span&gt;Optional. Default value is &quot;&quot;.
   &lt;span class=&quot;nt&quot;&gt;&amp;lt;/description&amp;gt;&lt;/span&gt;
 &lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
 &lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
   &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;ssl.client.keystore.type&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
   &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;jks&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
   &lt;span class=&quot;nt&quot;&gt;&amp;lt;description&amp;gt;&lt;/span&gt;Optional. The keystore file format, default value is &quot;jks&quot;.
   &lt;span class=&quot;nt&quot;&gt;&amp;lt;/description&amp;gt;&lt;/span&gt;
 &lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
 &lt;span class=&quot;nt&quot;&gt;&amp;lt;/configuration&amp;gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;ssl-server.xml&lt;br /&gt;
本次操作配置文件示例：
    &lt;div class=&quot;language-xml highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; &lt;span class=&quot;nt&quot;&gt;&amp;lt;configuration&amp;gt;&lt;/span&gt;
 &lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
   &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;ssl.server.truststore.location&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
   &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;/opt/ca/truststore&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
   &lt;span class=&quot;nt&quot;&gt;&amp;lt;description&amp;gt;&lt;/span&gt;Truststore to be used by NN and DN. Must be specified.
   &lt;span class=&quot;nt&quot;&gt;&amp;lt;/description&amp;gt;&lt;/span&gt;
 &lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
 &lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
   &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;ssl.server.truststore.password&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
   &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;hadoop@1234&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
   &lt;span class=&quot;nt&quot;&gt;&amp;lt;description&amp;gt;&lt;/span&gt;Optional. Default value is &quot;&quot;.
   &lt;span class=&quot;nt&quot;&gt;&amp;lt;/description&amp;gt;&lt;/span&gt;
 &lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
 &lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
   &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;ssl.server.truststore.type&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
   &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;jks&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
   &lt;span class=&quot;nt&quot;&gt;&amp;lt;description&amp;gt;&lt;/span&gt;Optional. The keystore file format, default value is &quot;jks&quot;.
   &lt;span class=&quot;nt&quot;&gt;&amp;lt;/description&amp;gt;&lt;/span&gt;
 &lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
 &lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
   &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;ssl.server.truststore.reload.interval&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
   &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;10000&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
   &lt;span class=&quot;nt&quot;&gt;&amp;lt;description&amp;gt;&lt;/span&gt;Truststore reload check interval, in milliseconds.
   Default value is 10000 (10 seconds).
   &lt;span class=&quot;nt&quot;&gt;&amp;lt;/description&amp;gt;&lt;/span&gt;
 &lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
 &lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
   &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;ssl.server.keystore.location&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
   &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;/opt/ca/keystore&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
   &lt;span class=&quot;nt&quot;&gt;&amp;lt;description&amp;gt;&lt;/span&gt;Keystore to be used by NN and DN. Must be specified.
   &lt;span class=&quot;nt&quot;&gt;&amp;lt;/description&amp;gt;&lt;/span&gt;
 &lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
 &lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
   &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;ssl.server.keystore.password&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
   &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;hadoop@1234&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
   &lt;span class=&quot;nt&quot;&gt;&amp;lt;description&amp;gt;&lt;/span&gt;Must be specified.
   &lt;span class=&quot;nt&quot;&gt;&amp;lt;/description&amp;gt;&lt;/span&gt;
 &lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
 &lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
   &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;ssl.server.keystore.keypassword&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
   &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;hadoop@1234&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
   &lt;span class=&quot;nt&quot;&gt;&amp;lt;description&amp;gt;&lt;/span&gt;Must be specified.
   &lt;span class=&quot;nt&quot;&gt;&amp;lt;/description&amp;gt;&lt;/span&gt;
 &lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
 &lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
   &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;ssl.server.keystore.type&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
   &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;jks&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
   &lt;span class=&quot;nt&quot;&gt;&amp;lt;description&amp;gt;&lt;/span&gt;Optional. The keystore file format, default value is &quot;jks&quot;.
   &lt;span class=&quot;nt&quot;&gt;&amp;lt;/description&amp;gt;&lt;/span&gt;
 &lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
 &lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
   &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;ssl.server.exclude.cipher.list&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
   &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;TLS_ECDHE_RSA_WITH_RC4_128_SHA,SSL_DHE_RSA_EXPORT_WITH_DES40_CBC_SHA,SSL_RSA_WITH_DES_CBC_SHA,SSL_DHE_RSA_WITH_DES_CBC_SHA,SSL_RSA_EXPORT_WITH_RC4_40_MD5,SSL_RSA_EXPORT_WITH_DES40_CBC_SHA,SSL_RSA_WITH_RC4_128_MD5&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
   &lt;span class=&quot;nt&quot;&gt;&amp;lt;description&amp;gt;&lt;/span&gt;Optional. The weak security cipher suites that you want excluded from SSL communication.&lt;span class=&quot;nt&quot;&gt;&amp;lt;/description&amp;gt;&lt;/span&gt;
 &lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
 &lt;span class=&quot;nt&quot;&gt;&amp;lt;/configuration&amp;gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
    &lt;p&gt;以上，关于Hfds中开启SASL整体配置说明完毕。&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;下面总结一下都做了什么：&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;hdfs-site.xml中开启TLS/SSL HDFS配置；&lt;/li&gt;
  &lt;li&gt;hdfs-site.xml中dfs.datanode.address、dfs.datanode.http.address的端口一定大于1024（非特权端口）；&lt;/li&gt;
  &lt;li&gt;hadoop-env.sh中的HADOOP_SECURE_DN_USER内容一定为空，并且和jsvc模式不同，不需要进行jsvc的环境部署；&lt;/li&gt;
  &lt;li&gt;配置https：生成每个机器的密钥和证书；创建自己的CA；添加CA到客户机器的信任库；签名证书；&lt;/li&gt;
  &lt;li&gt;hdfs中整合https：配置ssl-server.xml和ssl-client.xml。&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;iv测试启动集群&quot;&gt;iv.测试启动（集群）&lt;/h4&gt;
&lt;p&gt;以上，关于hdfs中开启SASL的整体配置完毕，下面即可直接进行集群的启动。&lt;br /&gt;
补充：此处作为补充完整描述下全新集群的启动过程，通常情况下，直接启动即可。&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;全新HA集群启动过程：
    &lt;ol&gt;
      &lt;li&gt;kinit验证&lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;分别启动zookeeper&lt;/p&gt;

        &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; zkServer.sh start
&lt;/code&gt;&lt;/pre&gt;
        &lt;/div&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;启动三台JournalNode：node1、node2、node3&lt;/p&gt;

        &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; hadoop-daemon.sh start journalnode
&lt;/code&gt;&lt;/pre&gt;
        &lt;/div&gt;
      &lt;/li&gt;
      &lt;li&gt;在其中一个NameNode上格式化hadoop.tmp.dir并初始化(格式化完成之后，将会在&lt;script type=&quot;math/tex&quot;&gt;\$\{dfs.namenode.name.dir\}/current&lt;/script&gt;目录下生成元数据，&lt;script type=&quot;math/tex&quot;&gt;\$\{dfs.namenode.name.dir\}&lt;/script&gt;是在hdfs-site.xml中配置的，默认值是&lt;script type=&quot;math/tex&quot;&gt;file://\$\{hadoop.tmp.dir\}/dfs/name&lt;/script&gt;，dfs.namenode.name.dir属性可配多个目录，如 /data1/dfs/name，/data2/dfs/name，/data3/dfs/name等。各个目录存储的文件结构和内容都完全一样，相当于备份，这样做的好处是当其中一个目录损坏了，也不会影响到Hadoop的元数据，特别是当其中一个目录是NFS（网络文件系统 Network File System，NFS）之上，即使你这台机器损坏了，元数据也得到保存；&lt;script type=&quot;math/tex&quot;&gt;\$\{hadoop.tmp.dir\}&lt;/script&gt;是在core-si te.xml文件内配置的）
        &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; #node1
 hdfs namenode -format
&lt;/code&gt;&lt;/pre&gt;
        &lt;/div&gt;
      &lt;/li&gt;
      &lt;li&gt;把格式化后的元数据拷备到另一台NameNode节点上
        &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; #node1
 $ scp -r ${hadoop.tmp.dir} root@node2:${hadoop.tmp.dir}
&lt;/code&gt;&lt;/pre&gt;
        &lt;/div&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;启动NameNode&lt;/p&gt;

        &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; #node1
 hadoop-daemon.sh start namenode
 #node2
 hdfs namenode -bootstrapStandby（Y/N？）
 hadoop-daemon.sh start namenode
&lt;/code&gt;&lt;/pre&gt;
        &lt;/div&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;初始化zkfc&lt;/p&gt;

        &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; #Node1:
 hdfs zkfc -formatZK
&lt;/code&gt;&lt;/pre&gt;
        &lt;/div&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;全面停止并全面启动&lt;/p&gt;

        &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; #Node1:
 stop-dfs.sh
 start-dfs.sh
&lt;/code&gt;&lt;/pre&gt;
        &lt;/div&gt;
      &lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;因为启动过程中用到了hadoopHA，因此，可测试namenode的HA切换。
    &lt;ol&gt;
      &lt;li&gt;
        &lt;p&gt;用命令查看namenode的状态（两台namenode，在hdfs-si te.xml中配置的名字和主机名保持了一直，也是node1，所以这里测试写node1）：&lt;/p&gt;

        &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; hdfs haadmin -getServiceState node1
&lt;/code&gt;&lt;/pre&gt;
        &lt;/div&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;通过使用上述命令，有时候出现两台namenode都是standby的情况，则可以使用如下命令进行强制切换：&lt;/p&gt;

        &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; hdfs haadmin -transitionToActive --forcemanual node1
&lt;/code&gt;&lt;/pre&gt;
        &lt;/div&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;再次使用上述命令查看切换状态。&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;至此，本篇内容完成。以上内容基本上是完全关于HDFS中的Kerberos部署，HDFS结合Kerberos的整体部署完毕，若配置中使用了HA，则需要进行下文ZK配置之后才能完成完整部署。&lt;/p&gt;

&lt;p&gt;如有问题，请发送邮件至leafming@foxmail.com联系我，谢谢～&lt;br /&gt;
©商业转载请联系作者获得授权，非商业转载请注明出处。&lt;/p&gt;</content><author><name>Liv Yeh</name></author><category term="Kerberos" /><summary type="html">本文属于Kerberos具体实践整理的第二部分，主要涉及kerberos与HDFS的整合操作。</summary></entry><entry><title type="html">Docker+Mesos+Marathon监控方法使用总结</title><link href="http://localhost:4000/cloud/2018/06/15/Docker+Mesos+Marathon%E7%9B%91%E6%8E%A7%E6%96%B9%E6%B3%95%E4%BD%BF%E7%94%A8%E6%80%BB%E7%BB%93/" rel="alternate" type="text/html" title="Docker+Mesos+Marathon监控方法使用总结" /><published>2018-06-15T00:00:00+08:00</published><updated>2018-06-15T00:00:00+08:00</updated><id>http://localhost:4000/cloud/2018/06/15/Docker+Mesos+Marathon%E7%9B%91%E6%8E%A7%E6%96%B9%E6%B3%95%E4%BD%BF%E7%94%A8%E6%80%BB%E7%BB%93</id><content type="html" xml:base="http://localhost:4000/cloud/2018/06/15/Docker+Mesos+Marathon%E7%9B%91%E6%8E%A7%E6%96%B9%E6%B3%95%E4%BD%BF%E7%94%A8%E6%80%BB%E7%BB%93/">&lt;blockquote&gt;
  &lt;p&gt;本文主要关于Docker、Mesos、Marathon的监控方法的总结。&lt;br /&gt;
&lt;strong&gt;注意: 本文中使用的版本是Docker1.12.6、Mesos1.3.0、Marathon1.4.5。&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Docker+Mesos+Marathon所搭建的平台监控所用到的后台方法已经基本上写完了，现在用一些时间总结下相关监控方法，满满用心总结的，不过用到的不止这些，还差很多以后再另开文章补充。在总结过程中也重新梳理了很多东西，现在分享出来，希望对大家有用啦，也省的自己以后忘了～哈哈。&lt;/p&gt;

&lt;h1 id=&quot;docker管理-容器相关&quot;&gt;Docker管理-容器相关&lt;/h1&gt;
&lt;h2 id=&quot;前期准备开启docker远程访问&quot;&gt;前期准备：开启Docker远程访问&lt;/h2&gt;
&lt;p&gt;Docker daemon可以有3种远程访问方式的socket：unix、tcp和fd。&lt;br /&gt;
其中Docker支持使用restful api远程获取信息，但是需要提前开启一个Tcp Socket，这样才能实现远程通信。&lt;br /&gt;
默认情况下，Docker守护进程Unix socket（/var/run/docker.sock）来进行本地进程通信，而不会监听任何端口，因此只能在本地使用docker客户端或者使用Docker API进行操作,并且需要root权限或者是docker group成员。如果想在其他主机上操作Docker主机，就需要让Docker守护进程打开一个Tcp Socket，这样才能实现远程通信。&lt;br /&gt;
补充说明：可以使用HTTPs方式，不过目前没有进行配置，可以后续更改。但是，如果你用和Https的socket，需要注意的是只支持TLS1.0及以上的协议，SSLv3或者更低的是不支持的。&lt;br /&gt;
官方网站描述如下&lt;a href=&quot;https://docs.docker.com/v1.12/engine/reference/commandline/dockerd/&quot;&gt;Daemon socket option&lt;/a&gt;。&lt;br /&gt;
我们来使用开启TCP Socket的方式。&lt;br /&gt;
需要更改docker配置文件，修改OPTIONS，具体方式如下：&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;如果找不到docker配置文件，可以以下述方式查找：&lt;br /&gt;
找到docker.service文件：&lt;br /&gt;
systemctl show –property=FragmentPath docker
    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;---@---[~]$systemctl show --property=FragmentPath docker 
FragmentPath=/usr/lib/systemd/system/docker.service
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
    &lt;p&gt;找到docker.service文件并查看，发现docker文件位置：/etc/sysconfig/docker&lt;br /&gt;
&lt;img src=&quot;https://github.com/leafming/bak/blob/master/images/cloud/2018-06-11-dockerservice内容.png?raw=true&quot; alt=&quot;DockerService内容&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;找到文件后编辑文件docker&lt;br /&gt;
在OPTIONS=后加上 -H=unix:///var/run/docker.sock -H=tcp://0.0.0.0:端口&lt;br /&gt;
说明：&lt;br /&gt;
1、确定sock文件位置：/var/run/docker.sock&lt;br /&gt;
2、可用指定ip：指定端口&lt;br /&gt;
3、重启docker&lt;br /&gt;
&lt;img src=&quot;https://github.com/leafming/bak/blob/master/images/cloud/2018-06-11-dockertcpSocket配置.png?raw=true&quot; alt=&quot;DockerService内容&quot; /&gt;&lt;br /&gt;
说明：&lt;br /&gt;
有资料表述，一般情况下执行以下操作即可：&lt;br /&gt;
1、vim /etc/sysconfig/docker（更改docker文件）&lt;br /&gt;
2、在OPTIONS=后加上 -H=unix:///var/run/docker.sock -H=tcp://0.0.0.0:端口即可&lt;br /&gt;
如若不成功，可尝试下述操作：&lt;br /&gt;
1、vim /usr/lib/systemd/system/docker.service （更改docker.service文件）&lt;br /&gt;
2、直接在ExecStart=/user/bin/dockerd后添加-H=tcp://0.0.0.0:端口 -H=unix:///var/run/docker.sock(注意顺序)  &lt;br /&gt;
3、执行命令：systemctl daemon-reload 、systemctl restart docker&lt;/li&gt;
  &lt;li&gt;测试使用：&lt;br /&gt;
配置之后，尝试使用docker restful api来获取信息。&lt;br /&gt;
&lt;img src=&quot;https://github.com/leafming/bak/blob/master/images/cloud/2018-06-11-dockerrestful获取尝试.png?raw=true&quot; alt=&quot;2018-06-11-dockerrestful获取尝试&quot; /&gt;&lt;br /&gt;
或者直接在机器上尝试查询：“sudo docker -H IP:端口 命令”来测试是否能够取到内容。&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;docker-client的选择&quot;&gt;Docker-Client的选择&lt;/h2&gt;
&lt;p&gt;Docker-client的前期准备已经完毕，下面进行DockerAPI的使用。&lt;/p&gt;
&lt;h3 id=&quot;docker版本与docker-api的对应关系-和-相关library&quot;&gt;Docker版本与Docker API的对应关系 和 相关Library&lt;/h3&gt;
&lt;p&gt;Docker提供了Docker Engine API 去连接Docker daemon 来进行Docker的管理。Docker Engine API是Restful API，可以通过http客户端，比如说wget或者curl等来使用。&lt;br /&gt;
Docker官方提供Python和Go的SDK，可以直接使用。而在我们这里使用的是java语言，所以可以直接使用restful API的方式来获取相关信息或者直接使用他人封装好的Library。&lt;/p&gt;
&lt;h4 id=&quot;docker版本和api版本对应&quot;&gt;Docker版本和API版本对应&lt;/h4&gt;
&lt;p&gt;Docker的不同版本对用不同版本的API。具体以一个表格的形式列了出来，具体可以参考官方网站所写的内容:&lt;a href=&quot;https://docs.docker.com/develop/sdk/#docker-ee-and-ce-api-mismatch&quot;&gt;Docker版本和API对应表-API version matrix&lt;/a&gt;。&lt;br /&gt;
通过查看这个表，我们知道，我现在用的docker版本是1.12.6，所以来说，所对应的API版本为1.24。&lt;br /&gt;
关于Docker Engine API 1.24的使用，可以参考官网&lt;a href=&quot;https://docs.docker.com/engine/api/v1.24/&quot;&gt;Docker Engine API 1.24&lt;/a&gt;。&lt;/p&gt;
&lt;h4 id=&quot;docker-unofficial-libraries&quot;&gt;Docker unofficial libraries&lt;/h4&gt;
&lt;p&gt;Docker中出了官方提供的Python和Go的SDK之外，仍然有一些非官方的libraries可以使用，并且可使用的语言类型更加的广泛。关于可以使用的Library，官方在官网上也有所推荐，见&lt;a href=&quot;https://docs.docker.com/develop/sdk/#unofficial-libraries&quot;&gt;官网Unofficial libraries&lt;/a&gt;所示。&lt;br /&gt;
目前，项目里面并没有直接使用Docker Engine API，而是使用Java的第三方Library,第三方Library也是对Docker Engine API的一个封装。关于Java的Library，Docker官方推荐有三种，docker-client、docker-java、docker-java-api，而这次在项目中，使用的是&lt;a href=&quot;https://github.com/spotify/docker-client&quot;&gt;spotify/docker-client&lt;/a&gt;，在下面会将部分所用Library中的方法和Docker Engine API对应着介绍一下。&lt;/p&gt;

&lt;h2 id=&quot;docker-client的使用&quot;&gt;Docker-Client的使用&lt;/h2&gt;
&lt;p&gt;我们使用的是&lt;a href=&quot;https://github.com/spotify/docker-client/blob/master/docs/user_manual.md&quot;&gt;spotify/docker-client&lt;/a&gt;，在github上有详细的使用说明，直接点击链接即可。所以就不详细介绍了，下面就直接列出来使用的几个方法记录一下。&lt;/p&gt;
&lt;h3 id=&quot;引入jar包&quot;&gt;引入jar包&lt;/h3&gt;
&lt;p&gt;我们使用的是spotify/docker-client，可以直接通过maven或者jar包的方式引入，maven如下：&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&amp;lt;dependency&amp;gt;
  &amp;lt;groupId&amp;gt;com.spotify&amp;lt;/groupId&amp;gt;
  &amp;lt;artifactId&amp;gt;docker-client&amp;lt;/artifactId&amp;gt;
  &amp;lt;version&amp;gt;LATEST-VERSION&amp;lt;/version&amp;gt;
&amp;lt;/dependency&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;p&gt;针对Docker1.12.6，选择的是8.9.1版本。&lt;/p&gt;

&lt;h3 id=&quot;开始使用&quot;&gt;开始使用&lt;/h3&gt;
&lt;p&gt;因为项目中主要用到的是监控，所以基本上都是从服务器上查询的方法，关于对于创建容器、删除容器等操作，因为容器直接归于marathon管理，所以不在Docker这里进行容器创建、删除等操作了。&lt;/p&gt;

&lt;h4 id=&quot;创建和关闭docker连接&quot;&gt;创建和关闭Docker连接&lt;/h4&gt;
&lt;h5 id=&quot;创建连接&quot;&gt;创建连接&lt;/h5&gt;
&lt;p&gt;在之前的操作，开启了Docker RPC端口之后，可以在其他机器上创建远程Docker连接。&lt;br /&gt;
而且我们也没有开启https，所以可以直接使用如下方式：&lt;br /&gt;
传入容器宿主机IP+端口构成的uri，建立和宿主机的连接。&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;// use the builder
String dockerUri =&quot;http://&quot;+hostIp+&quot;:&quot;+port;
final DockerClient docker = DefaultDockerClient.builder().uri(URI.create(dockerUri)).build();
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;p&gt;除了这种方式，还有其它几种方式创建docker连接，详细参考&lt;a href=&quot;https://github.com/spotify/docker-client/blob/master/docs/user_manual.md#creating-a-docker-client&quot;&gt;Creating a docker-client&lt;/a&gt;。&lt;/p&gt;
&lt;h5 id=&quot;关闭docker连接&quot;&gt;关闭Docker连接&lt;/h5&gt;
&lt;p&gt;关闭连接直接通过创建的DockerClient docker连接对象，调用close方法即可。&lt;/p&gt;
&lt;div class=&quot;language-java highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;// Close the docker client&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;docker&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;close&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;();&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;h4 id=&quot;docker操作&quot;&gt;Docker操作&lt;/h4&gt;
&lt;h5 id=&quot;容器列表&quot;&gt;容器列表&lt;/h5&gt;
&lt;p&gt;获取宿主机上的容器列表，方法如下：&lt;br /&gt;
这个方法能够列出宿主机上全部&lt;strong&gt;正在运行&lt;/strong&gt;的容器的列表。&lt;/p&gt;
&lt;div class=&quot;language-java highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;List&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Container&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;containers&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;docker&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;listContainers&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;DockerClient&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;ListContainersParam&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;allContainers&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;());&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;p&gt;通过这个方法，可以返回List&lt;Container&gt;，其中的Container对象，可以取到的容器的id、名称、镜像信息、网络信息、状态等内容。&lt;/Container&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://github.com/leafming/bak/blob/master/images/cloud/2018-06-13-container属性.png?raw=true&quot; alt=&quot;container属性&quot; /&gt;&lt;/p&gt;

&lt;p&gt;并且，其中包括网络信息可以通过networkSettings取到，包括内容如下：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://github.com/leafming/bak/blob/master/images/cloud/2018-06-13-networkSettings属性.png?raw=true&quot; alt=&quot;networkSettings&quot; /&gt;&lt;/p&gt;

&lt;h5 id=&quot;容器详情&quot;&gt;容器详情&lt;/h5&gt;
&lt;p&gt;上述获取容器列表的过程中取到的容器信息并不详细，如果想看容器的详细信息可使用inspect方法,需要传入的内容是容器的id，不过通过测试，不需要传入全部的完整id，部分。&lt;/p&gt;
&lt;div class=&quot;language-java highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;ContainerInfo&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;info&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;docker&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;inspectContainer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;containerID&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;p&gt;通过这个方法可以获取到ContainerInfo对象，其中包括容器的详细信息，如下：&lt;br /&gt;
&lt;img src=&quot;https://github.com/leafming/bak/blob/master/images/cloud/2018-06-13-containerInfo属性.png?raw=true&quot; alt=&quot;containerInfo&quot; /&gt;&lt;/p&gt;
&lt;h6 id=&quot;容器状态对象&quot;&gt;容器状态对象&lt;/h6&gt;
&lt;p&gt;通过 ContainerState state = info.state();可以取到容器的状态对象ContainerState，其中属性如下。&lt;br /&gt;
&lt;img src=&quot;https://github.com/leafming/bak/blob/master/images/cloud/2018-06-13-ContainerState.png?raw=true&quot; alt=&quot;ContainerState&quot; /&gt;&lt;br /&gt;
取对象的state.status()，可以取到当前容器的状态，容器状态总共包括：created、restarting、running、paused、exited、dead共5种。&lt;/p&gt;
&lt;h6 id=&quot;容器配置信息&quot;&gt;容器配置信息&lt;/h6&gt;
&lt;p&gt;通过 ContainerConfig config = containerInfo.config();取到容器的配置信息，其中属性包括如下。&lt;br /&gt;
&lt;img src=&quot;https://github.com/leafming/bak/blob/master/images/cloud/2018-06-13-ContainerConfig属性.png?raw=true&quot; alt=&quot;ContainerConfig&quot; /&gt;&lt;br /&gt;
通过ContainerConfig可以获取到容器的hostname、env配置、启动容器的命令、所用镜像、工作目录、labels等信息。&lt;/p&gt;
&lt;h6 id=&quot;容器hostconfig&quot;&gt;容器HostConfig&lt;/h6&gt;
&lt;p&gt;通过 HostConfig hostConfig = containerInfo.hostConfig();可以取到容器的host配置信息，其中属性如下。&lt;br /&gt;
&lt;img src=&quot;https://github.com/leafming/bak/blob/master/images/cloud/2018-06-13-HostConfig.png?raw=true&quot; alt=&quot;HostConfig&quot; /&gt;&lt;br /&gt;
通过HostConfig对象，可以获取到容器和宿主机之间映射的目录、端口等信息，以及所给容器分配的cpu core数量（hostConfig.cpuShares()取到的数值除以1024）、memory（hostConfig.memory()）、swap的大小（hostConfig.memorySwap()-hostConfig.memory()）等信息。&lt;/p&gt;
&lt;h6 id=&quot;容器网络信息&quot;&gt;容器网络信息&lt;/h6&gt;
&lt;p&gt;通过NetworkSettings networkSettings = containerInfo.networkSettings();可以取到容器的网络信息，此对象和容器列表中取到的内容一致。通过它可以取到容器的网络模式、网关、ip、mac等信息。&lt;/p&gt;
&lt;h5 id=&quot;容器内进程&quot;&gt;容器内进程&lt;/h5&gt;
&lt;p&gt;上述操作均是获取容器的基本信息，如果获取容器内当时的进程信息，可以使用如下方法：&lt;br /&gt;
传入的ps_args为aux，和在容器内执行“ps aux”命令取到的数据一致，即“[USER, PID, %CPU, %MEM, VSZ, RSS, TTY, STAT, START, TIME, COMMAND]”等内容。&lt;br /&gt;
通过如下方法能取到TopResults对象，此对象内包括属性为process和titles，通过获取其中的process，可得到容器内的进程情况。&lt;/p&gt;
&lt;div class=&quot;language-java highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;//例子&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;//final TopResults topResults = docker.topContainer(&quot;containerID&quot;, &quot;ps_args&quot;);&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;TopResults&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;topResults&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;docker&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;topContainer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;containerID&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;aux&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;ImmutableList&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ImmutableList&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;processes&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;topResults&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;processes&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;();&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;h5 id=&quot;容器资源使用情况&quot;&gt;容器资源使用情况&lt;/h5&gt;
&lt;p&gt;在命令行中，我们可以通过docker stats来查看docker容器资源使用情况的信息，通过命令行能查询到如下内容：&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;CONTAINER    CPU %    MEM USAGE / LIMIT    MEM %    NET I/O    BLOCK I/O
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;p&gt;docker-client也提供了方法，来通过如下方式获取docker stats信息：&lt;/p&gt;
&lt;div class=&quot;language-java highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;ContainerStats&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;stats&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;docker&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;stats&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;containerID&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;p&gt;通过此方法，能够取到ContainerStats对象，其中包含内容如下：&lt;br /&gt;
&lt;img src=&quot;https://github.com/leafming/bak/blob/master/images/cloud/2018-06-13-ContainerStats.png?raw=true&quot; alt=&quot;ContainerStats&quot; /&gt;&lt;br /&gt;
但是，我们取到的数据并不能直接使用，而需要通过计算，来得到更加直观的数据，下面进行一下详细说明。&lt;br /&gt;
而计算的过程，主要参考&lt;a href=&quot;https://www.2cto.com/net/201701/582048.html&quot;&gt;“dockerstats命令源码分析结果”&lt;/a&gt;文章中，对于docker stats源码的分析。&lt;/p&gt;
&lt;h6 id=&quot;cpu利用率计算&quot;&gt;CPU利用率计算&lt;/h6&gt;
&lt;ol&gt;
  &lt;li&gt;计算分析&lt;br /&gt;
在上述参考文章中提到:
    &lt;blockquote&gt;
      &lt;p&gt;docker daemon会记录这次读取/sys/fs/cgroup/cpuacct/docker/[containerId]/cpuacct.usage的值，作为cpu_total_usage；并记录了上一次读取的该值为pre_cpu_total_usage；读取/proc/stat中cpu field value，并进行累加，得到system_usage;并记录上一次的值为pre_system_usage；读取/sys/fs/cgroup/cpuacct/docker/[containerId]/cpuacct.usage_percpu中的记录，组成数组per_cpu_usage_array。&lt;/p&gt;
    &lt;/blockquote&gt;

    &lt;p&gt;因此，可以得到docker stats计算Cpu Percent的算法如下：&lt;/p&gt;
    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;cpu_delta = cpu_total_usage - pre_cpu_total_usage;
system_delta = system_usage - pre_system_usage;
CPU % = ((cpu_delta / system_delta) * length(per_cpu_usage_array) ) * 100.0
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;代码实现&lt;br /&gt;
所以说，将上述内容中得到的公式所需数据与我们通过取到的数据相对应，通过已经得到的stats对象，用方法可以取到两个CpuStats对象：
    &lt;div class=&quot;language-java highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;CpuStats&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cpuStats&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;stats&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;cpuStats&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;();&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;CpuStats&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;precpuStats&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;stats&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;precpuStats&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;();&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
    &lt;p&gt;然后我们计算cpu利用率，就可以这样来计算：&lt;/p&gt;
    &lt;div class=&quot;language-java highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;String&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cpuPercent&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;---&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;null&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;!=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cpuStats&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;null&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;!=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;precpuStats&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;){&lt;/span&gt;
 &lt;span class=&quot;cm&quot;&gt;/**
 	* 计算cpu利用率 %
 	* cpuDelta = cpuTotalUsage - preCpuTotalUsage;
   	* systemDelta = systemUsage - preSystemUsage;
   	* CPU % = ((cpuDelta / systemDelta) * length(per_cpu_usage_array) ) * 100.0
 	*/&lt;/span&gt;
 	&lt;span class=&quot;n&quot;&gt;Long&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cpuTotalUsage&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cpuStats&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;cpuUsage&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;().&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;totalUsage&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;();&lt;/span&gt;
 	&lt;span class=&quot;n&quot;&gt;Long&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;preCpuTotalUsage&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;precpuStats&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;cpuUsage&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;().&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;totalUsage&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;();&lt;/span&gt;
 	&lt;span class=&quot;n&quot;&gt;Long&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cpuDelta&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cpuTotalUsage&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;preCpuTotalUsage&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;
 	&lt;span class=&quot;n&quot;&gt;Long&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;systemUsage&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cpuStats&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;systemCpuUsage&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;();&lt;/span&gt;
 	&lt;span class=&quot;n&quot;&gt;Long&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;preSystemUsage&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;precpuStats&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;systemCpuUsage&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;();&lt;/span&gt;
 	&lt;span class=&quot;n&quot;&gt;Long&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;systemDelta&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;systemUsage&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;preSystemUsage&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;
 	&lt;span class=&quot;n&quot;&gt;Integer&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;percpuUsageListSize&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cpuStats&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;cpuUsage&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;().&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;percpuUsage&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;().&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;();&lt;/span&gt;
 	&lt;span class=&quot;n&quot;&gt;cpuPercent&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cpuDelta&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;floatValue&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;systemDelta&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;floatValue&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;())&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;percpuUsageListSize&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;floatValue&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;())&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;%&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;
 &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h6 id=&quot;memory利用率计算&quot;&gt;memory利用率计算&lt;/h6&gt;
&lt;ol&gt;
  &lt;li&gt;计算分析&lt;br /&gt;
在上述参考文章中提到:
    &lt;blockquote&gt;
      &lt;p&gt;读取/sys/fs/cgroup/memory/docker/[containerId]/memory.usage_in_bytes的值，作为mem_usage；如果容器限制了内存，则读取/sys/fs/cgroup/memory/docker/[id]/memory.limit_in_bytes作为mem_limit，否则mem_limit = machine_mem。&lt;/p&gt;
    &lt;/blockquote&gt;

    &lt;p&gt;因此可以得到docker stats计算Memory数据的算法如下：&lt;/p&gt;
    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;MEM USAGE = mem_usage
MEM LIMIT = mem_limit
MEM % = (mem_usage / mem_limit) * 100.0
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;代码实现&lt;br /&gt;
通过已经得到的stats对象，用方法可以取到MemoryStats对象。
    &lt;div class=&quot;language-java highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;MemoryStats&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;memoryStats&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;stats&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;memoryStats&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;();&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
    &lt;p&gt;然后根据公式来计算memory利用率：&lt;/p&gt;
    &lt;div class=&quot;language-java highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; &lt;span class=&quot;n&quot;&gt;String&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;memUsageFormat&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;---&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;
 &lt;span class=&quot;n&quot;&gt;String&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;memLimitFormat&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;---&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;
 &lt;span class=&quot;n&quot;&gt;String&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;memPercent&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;---&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;
 &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;null&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;!=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;memoryStats&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;){&lt;/span&gt;
 	&lt;span class=&quot;cm&quot;&gt;/**
      * 计算memory利用率 %
      * MEM USAGE = mem_usage
        MEM LIMIT = mem_limit
        MEM % = (mem_usage / mem_limit) * 100.0
      */&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;Long&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;memUsage&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;memoryStats&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;usage&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;();&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;Long&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;memLimit&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;memoryStats&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;limit&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;();&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;memUsageFormat&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Utils&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;getDynamicSizeUnit&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;memUsage&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;memLimitFormat&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Utils&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;getDynamicSizeUnit&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;memLimit&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;memPercent&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;memUsage&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;floatValue&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;memLimit&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;floatValue&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;())*&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;%&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;
 &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h6 id=&quot;network-io计算&quot;&gt;Network IO计算&lt;/h6&gt;
&lt;ol&gt;
  &lt;li&gt;计算分析&lt;br /&gt;
在上述参考文章中提到:
    &lt;blockquote&gt;
      &lt;p&gt;network stats的计算可以根据“获取属于该容器network namespace veth pairs在主机中对应的veth*虚拟网卡EthInterface数组，然后循环数组中每个网卡设备，读取/sys/class/net//statistics/rx_bytes得到rx_bytes, 读取/sys/class/net//statistics/tx_bytes得到对应的tx_bytes。将所有这些虚拟网卡对应的rx_bytes累加得到该容器的rx_bytes。将所有这些虚拟网卡对应的tx_bytes累加得到该容器的tx_bytes。&lt;/p&gt;
    &lt;/blockquote&gt;

    &lt;p&gt;因此我们可以得到network stats的计算算法如下：&lt;/p&gt;
    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;NET I = rx_bytes
NET O = tx_bytes
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;代码实现&lt;br /&gt;
通过已经得到的stats对象，可以取到 ImmutableMap&amp;lt;String, NetworkStats&amp;gt;。
    &lt;div class=&quot;language-java highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;ImmutableMap&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;NetworkStats&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;networks&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;stats&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;networks&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;();&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
    &lt;p&gt;然后根据公式来计算network io：&lt;/p&gt;
    &lt;div class=&quot;language-java highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; &lt;span class=&quot;n&quot;&gt;String&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rxBytesSumFormat&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;---&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;
 &lt;span class=&quot;n&quot;&gt;String&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;txBytesSumFormat&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;---&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;
 &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;null&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;!=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;networks&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;){&lt;/span&gt;
 	&lt;span class=&quot;cm&quot;&gt;/**
      * docker stats计算Network IO数据的算法：
        NET I = rx_bytes(所有网卡累加)
        NET O = tx_bytes（所有网卡累加）
      */&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;Long&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rxBytesSum&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0L&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;Long&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;txBytesSum&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0L&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Map&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;Entry&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;NetworkStats&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;nl&quot;&gt;entry:&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;networks&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;entrySet&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()){&lt;/span&gt;
  	      &lt;span class=&quot;n&quot;&gt;rxBytesSum&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;entry&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;getValue&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;().&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;rxBytes&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;();&lt;/span&gt;
           &lt;span class=&quot;n&quot;&gt;txBytesSum&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;entry&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;getValue&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;().&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;txBytes&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;();&lt;/span&gt;
        &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
   &lt;span class=&quot;c1&quot;&gt;//Utils.getDynamicSizeUnit()是一个动态单位转换的方法&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;rxBytesSumFormat&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Utils&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;getDynamicSizeUnit&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;rxBytesSum&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;txBytesSumFormat&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Utils&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;getDynamicSizeUnit&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;txBytesSum&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
 &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h6 id=&quot;blk-io计算&quot;&gt;Blk IO计算&lt;/h6&gt;
&lt;ol&gt;
  &lt;li&gt;计算分析&lt;br /&gt;
在上述参考文章中提到:
    &lt;blockquote&gt;
      &lt;p&gt;Blk IO计算可以根据“获取每个块设备的IoServiceBytesRecursive数据：先去读取/sys/fs/cgroup/blkio/docker/[containerId]/blkio.io_serviced_recursive中是否有有效值，如果有，则读取/sys/fs/cgroup/blkio/docker/[containerId]/blkio.io_service_bytes_recursive的值返回； 如果没有，就去读取/sys/fs/cgroup/blkio/docker/[containerId]/blkio.throttle.io_service_bytes中的值返回；将每个块设备的IoServiceBytesRecursive数据中所有read field对应value进行累加，得到该容器的blk_read值；将每个块设备的IoServiceBytesRecursive数据中所有write field对应value进行累加，得到该容器的blk_write值。&lt;/p&gt;
    &lt;/blockquote&gt;

    &lt;p&gt;因此，我们可以得到Blk IO计算算法如下：&lt;/p&gt;
    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;BLOCK I = blk_read
BLOCK O = blk_write
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;代码实现
    &lt;div class=&quot;language-java highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; &lt;span class=&quot;n&quot;&gt;String&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;blkReadFormat&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;---&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;
 &lt;span class=&quot;n&quot;&gt;String&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;blkWriteFormat&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;---&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;
 &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;null&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;!=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;blockIoStats&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;){&lt;/span&gt;
 	&lt;span class=&quot;cm&quot;&gt;/**
      * docker stats计算Block IO数据的算法：
        BLOCK I = blkRead
        BLOCK O = blkWrite
      */&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;ImmutableList&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Object&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;objects&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;blockIoStats&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;ioServiceBytesRecursive&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;();&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;Long&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;blkRead&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0L&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;Long&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;blkWrite&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0L&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;
        &lt;span class=&quot;c1&quot;&gt;//因为是Object，不好遍历，所以转变成了jsonobj遍历&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Object&lt;/span&gt; &lt;span class=&quot;nl&quot;&gt;obj:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;objects&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
        	&lt;span class=&quot;n&quot;&gt;String&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;jsonString&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;JSON&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;toJSONString&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;obj&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
             &lt;span class=&quot;n&quot;&gt;JSONObject&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;jsonObj&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;JSON&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;parseObject&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;jsonString&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
             &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Read&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;equals&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;jsonObj&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;getString&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;op&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;))){&lt;/span&gt;
         	    &lt;span class=&quot;n&quot;&gt;blkRead&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;jsonObj&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;getLong&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;value&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
             &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Write&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;equals&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;jsonObj&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;getString&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;op&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;))){&lt;/span&gt;
         &lt;span class=&quot;n&quot;&gt;blkWrite&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;jsonObj&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;getLong&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;value&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
             &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
        &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;blkReadFormat&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Utils&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;getDynamicSizeUnit&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;blkRead&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;blkWriteFormat&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Utils&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;getDynamicSizeUnit&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;blkWrite&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
 &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h6 id=&quot;获取时间&quot;&gt;获取时间&lt;/h6&gt;
&lt;p&gt;至此，以上将docker stats所需要的数据均计算出来了，之后我们只需获取下当前的采集时间即可。&lt;/p&gt;
&lt;div class=&quot;language-java highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; &lt;span class=&quot;n&quot;&gt;Date&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;read&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;stats&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;read&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;();&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h5 id=&quot;容器其他&quot;&gt;容器其他&lt;/h5&gt;
&lt;p&gt;上面说的基本上是关于docker容器监控所用的方法，剩下的都是直接操作容器的工具，先不写出来了，有需要的可以直接参考官方说明&lt;a href=&quot;https://github.com/spotify/docker-client/blob/master/docs/user_manual.md#creating-a-docker-client&quot;&gt;spotify/docker-client&lt;/a&gt;。&lt;/p&gt;

&lt;h4 id=&quot;容器宿主机监控&quot;&gt;容器宿主机监控&lt;/h4&gt;
&lt;p&gt;以上说明了容器的基础监控，我们在应用中，如果需要监控容器所在宿主机的情况，也可以使用下述方法：&lt;/p&gt;
&lt;div class=&quot;language-java highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;Info&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;info&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;docker&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;info&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;();&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;p&gt;获取到了Info对象，通过此对象可以取到宿主机上运行的容器状态、资源情况等，具体可获取到的如下。&lt;br /&gt;
&lt;img src=&quot;https://github.com/leafming/bak/blob/master/images/cloud/2018-06-14-dockerhostInfo.png?raw=true&quot; alt=&quot;Info&quot; /&gt;&lt;/p&gt;

&lt;h4 id=&quot;其他&quot;&gt;其他&lt;/h4&gt;
&lt;p&gt;除了以上说的那些，还可以获取、操作Networks、Images等。因为我们这里自己创建的一个镜像库，所以不直接使用docker-client的方法获取镜像信息，下面会统一再说明镜像库的搭建和列表的获取。&lt;br /&gt;
至此，docker-client所用到的方法都说明完毕了，其他没提到的还是直接去看官方说明吧&lt;a href=&quot;https://github.com/spotify/docker-client/blob/master/docs/user_manual.md#creating-a-docker-client&quot;&gt;spotify/docker-client&lt;/a&gt;。&lt;/p&gt;

&lt;h2 id=&quot;engine-api的使用&quot;&gt;Engine API的使用&lt;/h2&gt;
&lt;p&gt;上述进行说明了Docker-client的使用，我们也可以直接通过Engine API v1.24来进行Docker的操作。&lt;br /&gt;
也是开启TCP端口之后，直接发送request到宿主机地址：端口，然后会收到json格式的response。&lt;br /&gt;
这里直接使用工具测试，获取到容器的列表信息，如下图。&lt;br /&gt;
&lt;img src=&quot;https://github.com/leafming/bak/blob/master/images/cloud/2018-06-14-restful获取容器列表.png?raw=true&quot; alt=&quot;2018-06-14-restful获取容器列表&quot; /&gt;&lt;br /&gt;
此后，如果需要，可以直接参考官方说明&lt;a href=&quot;https://docs.docker.com/engine/api/v1.24/&quot;&gt;Engine API v1.24&lt;/a&gt;，不过需要注意的是，我这里使用的docker对应的是v1.24的，其他版本的要选择不同对应版本的api哦，在本文最开始也选择docker-client的“Docker版本和API版本对应”处也说明了，忘记了的话回过头去看哦。&lt;/p&gt;

&lt;h1 id=&quot;docker管理-docker镜像仓库&quot;&gt;Docker管理-Docker镜像仓库&lt;/h1&gt;
&lt;p&gt;我们上述说明了使用Docker-Client获取Docker容器的一些基础信息，而镜像我们是单独部署了一个镜像服务器，因此，不直接使用docker-client来获取镜像列表。下面会先说明镜像服务器的部署，之后说下如何获取镜像服务器中的镜像列表。&lt;/p&gt;
&lt;h2 id=&quot;简单说明镜像服务器的部署&quot;&gt;简单说明镜像服务器的部署&lt;/h2&gt;
&lt;p&gt;Docke官方提供了Docker Hub网站来作为一个公开的集中仓库。然而，本地访问Docker Hub速度往往很慢，并且很多时候我们需要一个本地的私有仓库只供网内使用。&lt;br /&gt;
Docker仓库实际上提供两方面的功能，一个是镜像管理，一个是认证。前者主要由docker-registry项目来实现，通过http服务来上传下载；后者可以通过docker-index（闭源）项目或者利用现成认证方案（如nginx）实现http请求管理。&lt;br /&gt;
目前来说，我们只需要在内网建立一个存储镜像的地方，因此只使用docker registry来搭建一个私有镜像库。&lt;br /&gt;
下面简单说明下仓库搭建过程，也可以直接参考官方部署&lt;a href=&quot;https://docs.docker.com/registry/deploying/&quot;&gt;“Deploy a registry server”&lt;/a&gt;。&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;官方提供了registry镜像，我们直接下载：
    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;docker pull registry
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;默认情况下，会将仓库存放于容器内,这样的话如果容器被删除，则存放于容器中的镜像也会丢失，所以我们需要指定一个本地目录挂载到容器内的存放镜像的目录下。所以，我们以如下命令来启动一个docker容器：
    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;docker run --privileged=true -d -v /datacenter02/registry:/var/lib/registry -p 5000:5000 --restart=always --name registry registry
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;查看启动的容器
    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;---@---[~]#docker ps -a
CONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS              PORTS                    NAMES
458a9e2301a6        registry            &quot;/entrypoint.sh /etc/&quot;   7 months ago        Up 7 months         0.0.0.0:5000-&amp;gt;5000/tcp   registry
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;测试使用&lt;br /&gt;
创建一个小的镜像，然后测试push
    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;docker push 132.-.-.-:5000/busybox（这里的ip没写全，用-代替了，自己写的时候写全）
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
    &lt;p&gt;可以看到push失败，报关于https的错误类似如下。&lt;/p&gt;
    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Error response from daemon: invalid registry endpoint https://132.-.-.-:5000/v1/: Get https://132.-.-.-:5000/v1/_ping: http: server gave HTTP response to HTTPS client. If this private registry supports only HTTP or HTTPS with an unknown CA certificate, please add `--insecure-registry 132.-.-.-:5000` to the daemon's arguments. In the case of HTTPS, if you have access to the registry's CA certificate, no need for the flag; simply place the CA certificate at /etc/docker/certs.d/132.-.-.-:5000/ca.crt
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;配置http访问&lt;br /&gt;
因为Docker从1.3.X之后，与docker registry交互默认使用的是https，然而此处搭建的私有仓库只提供http服务，所以当与私有仓库交互时就会报上面的错误。为了解决这个问题需要在启动docker server时增加启动参数为默认使用http访问。&lt;br /&gt;
我们需要修改docker配置文件，在docker配置文件中增加“–insecure-registry 132.-.-.-:5000”，其中IP为了不泄露用-代替了，自己写的时候需要写全：
    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;# If you have a registry secured with https but do not have proper certs
# distributed, you can tell docker to not look for full authorization by
# adding the registry to the INSECURE_REGISTRY line and uncommenting it.
# INSECURE_REGISTRY='--insecure-registry'
INSECURE_REGISTRY='--insecure-registry 132.-.-.-:5000'
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
    &lt;p&gt;之后重启docker服务。&lt;br /&gt;
之后再次测试，可以发现没有报错啦，push成功。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;命令行仓库管理&lt;br /&gt;
有文章说，查询私有仓库中的所有镜像，使用docker search命令，但是我这里经过尝试，发现会报错：“Error response from daemon: Unexpected status code 404”。&lt;br /&gt;
后来发现，docker search是v1版本的API，我们现在的是v2版本，所以不能使用。&lt;br /&gt;
如果需要查询，则也是直接curl使用v2版本的API：
    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;---@---[~]#curl 132.90.130.13:5000/v2/_catalog
{&quot;repositories&quot;:[&quot;alluxio&quot;,&quot;basic&quot;,&quot;go&quot;,&quot;go1.10&quot;,&quot;go_zhzj&quot;,&quot;hdfs_datanode&quot;,&quot;hello-mine&quot;,&quot;hiveonspark&quot;,&quot;hiveonspark-gx&quot;,&quot;hivespark&quot;,&quot;jdk&quot;,&quot;jtwspark1.6.3&quot;,&quot;kafka&quot;,&quot;ninecon&quot;,&quot;nm&quot;,&quot;rm1&quot;,&quot;rm2&quot;,&quot;spark-2.3.0&quot;,&quot;spark2&quot;,&quot;spark2.2.1&quot;,&quot;spark2.2.1-gx&quot;,&quot;spark2.2.1-jtw&quot;,&quot;spark2.2.1-rx-demo&quot;,&quot;sparkdemo&quot;,&quot;sparkrx1.6.3&quot;,&quot;sparkrx2.2.1&quot;,&quot;tensorflow&quot;]}
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
    &lt;p&gt;详细的将在下面说明。&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;镜像仓库器管理&quot;&gt;镜像仓库器管理&lt;/h2&gt;
&lt;p&gt;对于Docker Registry，Docker官方提供了HTTP API V2用于与其交互，用来管理docker images。对于此，在官方网站上也有说明：&lt;a href=&quot;https://docs.docker.com/registry/spec/api/&quot;&gt;HTTP API V2&lt;/a&gt;。&lt;br /&gt;
因为我们只用到了镜像管理功能，所以下面只是用到的说明获取仓库内的镜像列表以及tags的方法，其他的需要自己参考官网啦。&lt;/p&gt;
&lt;h3 id=&quot;镜像列表&quot;&gt;镜像列表&lt;/h3&gt;
&lt;p&gt;我们使用下述方式来获取仓库里面的镜像列表，获取也是请求之后来获取一个包含信息（仓库、镜像名称）的json串，官方给出的request和response例子如下：&lt;br /&gt;
request:&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;GET /v2/_catalog
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;p&gt;response:&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;200 OK
Content-Type: application/json

{
  &quot;repositories&quot;: [
    &amp;lt;name&amp;gt;,
    ...
  ]
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;p&gt;我这里直接使用json工具，获取到我们仓库中的镜像列表：&lt;br /&gt;
&lt;img src=&quot;https://github.com/leafming/bak/blob/master/images/cloud/2018-06-14-仓库镜像列表.png?raw=true&quot; alt=&quot;镜像列表&quot; /&gt;&lt;/p&gt;
&lt;h3 id=&quot;镜像tags&quot;&gt;镜像tags&lt;/h3&gt;
&lt;p&gt;但是，对于一个镜像来说，有不同的tags来标明它的版本，所以单单靠上述方法获取镜像的名称还是不够的，还需获取到tags。官方也给出了相关的例子：&lt;br /&gt;
request:&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;GET /v2/&amp;lt;name&amp;gt;/tags/list
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;p&gt;response:&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;200 OK
Content-Type: application/json

{
    &quot;name&quot;: &amp;lt;name&amp;gt;,
    &quot;tags&quot;: [
        &amp;lt;tag&amp;gt;,
        ...
    ]
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;p&gt;之后，我也使用json工具，获取了仓库中“spark2.2.1”的tags信息如下：&lt;br /&gt;
&lt;img src=&quot;https://github.com/leafming/bak/blob/master/images/cloud/2018-06-14-镜像tags获取.png?raw=true&quot; alt=&quot;镜像tags获取&quot; /&gt;&lt;/p&gt;

&lt;p&gt;至此，我们就可以得到仓库里面镜像对我们来说的有用的信息了。&lt;/p&gt;

&lt;h3 id=&quot;代码实现&quot;&gt;代码实现&lt;/h3&gt;
&lt;p&gt;而在后台程序里，直接使用了最原始的httpclient写了restful工具类，直接获取镜像名称和相关tags信息，后来封装成一个对象放到list中返回直接使用，也可以直接使用restful的相关框架就比较方便了，就不详细说明了。&lt;/p&gt;
&lt;div class=&quot;language-java highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  &lt;span class=&quot;cm&quot;&gt;/**
     * 获取镜像服务器内的镜像列表
     * http://..../v2/_catalog
     * @throws IOException
     */&lt;/span&gt;
    &lt;span class=&quot;kd&quot;&gt;public&lt;/span&gt;  &lt;span class=&quot;kd&quot;&gt;static&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;List&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;   &lt;span class=&quot;nf&quot;&gt;getImagesList&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;kd&quot;&gt;throws&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;IOException&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;String&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;url&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;http://&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ConstantOp&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;IMAGES_REPOSITORIES_IP&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;:&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ConstantOp&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;IMAGES_REPOSITORIES_PORT&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;/v2/_catalog&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;List&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;images&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ArrayList&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;gt;();&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;RestfulHttpCli&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;HttpResponse&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;response&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;RestfulHttpCli&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;getClient&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;url&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
                &lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;get&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt;              &lt;span class=&quot;c1&quot;&gt;//设置post请求&lt;/span&gt;
                &lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;addHeader&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Content-Type&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;application/json&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
                &lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;addHeader&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Accept&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;application/json&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
                &lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;addHeader&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;charset&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;utf-8&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
                &lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;request&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;();&lt;/span&gt;         &lt;span class=&quot;c1&quot;&gt;//发起请求&lt;/span&gt;
        &lt;span class=&quot;c1&quot;&gt;//响应状态码&lt;/span&gt;
        &lt;span class=&quot;c1&quot;&gt;//  System.out.println(response.getCode());&lt;/span&gt;
        &lt;span class=&quot;c1&quot;&gt;//最终发起请求的地址&lt;/span&gt;
        &lt;span class=&quot;c1&quot;&gt;//  System.out.println(response.getRequestUrl());&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;response&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;getCode&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;200&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;){&lt;/span&gt;
            &lt;span class=&quot;c1&quot;&gt;//请求成功&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;String&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;content&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;response&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;getContent&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;();&lt;/span&gt;
            &lt;span class=&quot;c1&quot;&gt;//格式化json&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;JSONObject&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;jsonObject&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;JSON&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;parseObject&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;content&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;JSONArray&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;repositories&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;jsonObject&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;getJSONArray&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;repositories&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;images&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;repositories&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;toJavaList&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;class&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
        &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;images&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;

    &lt;span class=&quot;cm&quot;&gt;/**
     * 获取镜像服务器内的镜像tags
     * 如http://..../v2/_catalog
     * @throws IOException
     */&lt;/span&gt;
    &lt;span class=&quot;kd&quot;&gt;public&lt;/span&gt;  &lt;span class=&quot;kd&quot;&gt;static&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;String&lt;/span&gt;  &lt;span class=&quot;nf&quot;&gt;getTagsList&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;String&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;image_name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;kd&quot;&gt;throws&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;IOException&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;String&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;url&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;http://&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ConstantOp&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;IMAGES_REPOSITORIES_IP&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;:&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ConstantOp&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;IMAGES_REPOSITORIES_PORT&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;/v2/{image_name}/tags/list&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;String&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tags_str&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;---&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;RestfulHttpCli&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;HttpResponse&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;response&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;RestfulHttpCli&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;getClient&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;url&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
                &lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;get&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt;              &lt;span class=&quot;c1&quot;&gt;//设置post请求&lt;/span&gt;
                &lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;addHeader&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Content-Type&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;application/json&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
                &lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;addHeader&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Accept&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;application/json&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
                &lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;addHeader&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;charset&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;utf-8&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
                &lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;addPathParam&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;image_name&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;image_name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
                &lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;request&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;();&lt;/span&gt;         &lt;span class=&quot;c1&quot;&gt;//发起请求&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;response&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;getCode&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;200&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;){&lt;/span&gt;
            &lt;span class=&quot;c1&quot;&gt;//请求成功&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;String&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;content&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;response&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;getContent&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;();&lt;/span&gt;
            &lt;span class=&quot;c1&quot;&gt;//格式化json&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;JSONObject&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;jsonObject&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;JSON&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;parseObject&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;content&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;JSONArray&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tags&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;jsonObject&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;getJSONArray&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;tags&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;tags_str&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;StringUtils&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;join&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tags&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;,&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
        &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tags_str&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
    
    &lt;span class=&quot;cm&quot;&gt;/**
     * 获取镜像服务器中的image列表，返回 List&amp;lt;ImagesDetails&amp;gt;
     * @return
     * @throws IOException
     */&lt;/span&gt;
    &lt;span class=&quot;kd&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;kd&quot;&gt;static&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;List&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ImagesDetails&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;   &lt;span class=&quot;nf&quot;&gt;getImagesDetailsList&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;kd&quot;&gt;throws&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;IOException&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;List&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ImagesDetails&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;  &lt;span class=&quot;n&quot;&gt;imagesDetailsList&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ArrayList&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;gt;();&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;List&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;imagesList&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;getImagesList&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;();&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;null&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;!=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;imagesList&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;){&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;String&lt;/span&gt; &lt;span class=&quot;nl&quot;&gt;image_name:&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;imagesList&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;ImagesDetails&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;imagesDetails&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ImagesDetails&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;();&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;imagesDetails&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;setName&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;image_name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;imagesDetails&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;setTags&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;getTagsList&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;image_name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;));&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;imagesDetailsList&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;add&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;imagesDetails&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
            &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
        &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;imagesDetailsList&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;p&gt;至此，完成了镜像仓库列表获取的全部工具类。&lt;/p&gt;

&lt;p&gt;以上也将Docker监控的总结暂时告一段落，下面进行Mesos的说明。&lt;/p&gt;

&lt;h1 id=&quot;mesos管理&quot;&gt;Mesos管理&lt;/h1&gt;
&lt;p&gt;对于Mesos管理，官方提供2中方式：HTTP Endpoints和Operator HTTP API。&lt;/p&gt;
&lt;h2 id=&quot;http-endpoints&quot;&gt;HTTP Endpoints&lt;/h2&gt;
&lt;p&gt;对于Mesos master和Mesos agent均可以直接使用HTTP Endpoints，而且使用方式很简单，如下：&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;http://ip:port/endpoint
如：
http://masterIp:5050/metrics/snapshot
http://slaveIp:5050/metrics/snapshot
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;p&gt;具体使用可以参考官方网站说明：&lt;a href=&quot;http://mesos.apache.org/documentation/latest/endpoints/#http-endpoints&quot;&gt;HTTP Endpoints&lt;/a&gt;。&lt;br /&gt;
通过观察，发现mesos原生监控页面中，是使用的这种方式，直接在前台进行调用的此api，所以，如果端口没开，当终端访问页面的时候，会无法获取数据。&lt;br /&gt;
下面就是从前台控制台看到的获取的内容，会调用定时获取snapshot和state2个内容。&lt;br /&gt;
&lt;img src=&quot;https://github.com/leafming/bak/blob/master/images/cloud/2018-06-15-mesos监控页面截图.png?raw=true&quot; alt=&quot;2018-06-15-mesos监控页面截图&quot; /&gt; &lt;br /&gt;
不过需要注意的是，如果使用的是Mesos1.1或之后的版本，不建议使用此种方式，可以使用下面说的新的&lt;a href=&quot;http://mesos.apache.org/documentation/latest/operator-http-api/&quot;&gt;v1 Operator HTTP API&lt;/a&gt;。&lt;/p&gt;

&lt;h2 id=&quot;operator-http-api&quot;&gt;Operator HTTP API&lt;/h2&gt;
&lt;p&gt;对于Mesos master和agents均支持/api/v1 endpoint。不过这个api仅支持post请求。并且请求内容需要是json格式（Content-Type: application/json）或者protobuf格式（Content-Type: application/x-protobuf）。&lt;br /&gt;
对于&lt;a href=&quot;http://mesos.apache.org/documentation/latest/operator-http-api/#master-api&quot;&gt;Master&lt;/a&gt;和&lt;a href=&quot;http://mesos.apache.org/documentation/latest/operator-http-api/#agent-api&quot;&gt;Agent&lt;/a&gt;均提供了丰富的api，直接点击连接即可查看官方的说明，我就不在这里一一列出来了，直接说一下用到的一个方法。&lt;/p&gt;
&lt;h3 id=&quot;使用mesos-api&quot;&gt;使用mesos api&lt;/h3&gt;
&lt;p&gt;对于mesos的api，我这里只使用了master的GET_METRICS方法，目的是想自己做一个监控，能监控到mesos中的全部的资源使用情况，如下图mesos原生监控页面里面所示：&lt;br /&gt;
&lt;img src=&quot;https://github.com/leafming/bak/blob/master/images/cloud/2018-06-15-mesos原生监控页面资源情况.png?raw=true&quot; alt=&quot;2018-06-15-mesos原生监控页面资源情况&quot; /&gt;&lt;br /&gt;
所以，为了获取这些内容，可以直接选择官方的master的&lt;a href=&quot;http://mesos.apache.org/documentation/latest/operator-http-api/#get_metrics&quot;&gt;GET_METRICS&lt;/a&gt;方法，官方给出的请求例子如下：&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;GET_METRICS HTTP Request (JSON):

POST /api/v1  HTTP/1.1

Host: masterhost:5050
Content-Type: application/json
Accept: application/json

{
  &quot;type&quot;: &quot;GET_METRICS&quot;,
  &quot;get_metrics&quot;: {
    &quot;timeout&quot;: {
      &quot;nanoseconds&quot;: 5000000000
    }
  }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;p&gt;然后我们可以直接使用工具进行获取测试：&lt;br /&gt;
&lt;img src=&quot;https://github.com/leafming/bak/blob/master/images/cloud/2018-06-15-mesosRestfulPost工具截图.png?raw=true&quot; alt=&quot;2018-06-15-mesosRestfulPost工具截图&quot; /&gt;&lt;br /&gt;
通过post方式发送对应json到“http://masterIP:5050/api/v1”即可取到了相应json格式的监控数据。&lt;br /&gt;
而在程序中，也是用了最原始的方法直接使用的httpclient写的restful工具类，通过提交post请求后，获取到对应的响应内容，也可以直接使用restful的框架会比较方便，其他的具体就不详细说了，直接贴下代码：&lt;br /&gt;
不过这里因为取到的json不是全部使用了，所以json解析是对应取到的数据提取自己有用的东西，使用了最笨的方法，求别嫌弃(,,• . •̀,) 。&lt;/p&gt;
&lt;div class=&quot;language-java highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;cm&quot;&gt;/**
     * 生成mesos的访问连接
     * @param hostIp
     * @return
     */&lt;/span&gt;
    &lt;span class=&quot;kd&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;String&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;generateUrl&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;String&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;hostIp&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;){&lt;/span&gt;
        &lt;span class=&quot;c1&quot;&gt;//格式如：http://-.-.-.-:5050/api/v1&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;http://&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;hostIp&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;:&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ConstantOp&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;MESOS_PORT&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;/api/v1&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;

    &lt;span class=&quot;kd&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;MasterMesosMetrics&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;getMasterMetrics&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;String&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mesosMasterIp&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;kd&quot;&gt;throws&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;IOException&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;String&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;url&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;generateUrl&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mesosMasterIp&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;MasterMesosMetrics&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;masterMesosMetrics&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;MasterMesosMetrics&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;();&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;RestfulHttpCli&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;HttpResponse&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;request&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kc&quot;&gt;null&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;request&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;RestfulHttpCli&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;getClient&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;url&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
                &lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;post&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt;   
                &lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;addHeader&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Content-Type&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;application/json&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
                &lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;addHeader&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Accept&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;application/json&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
                &lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;addHeader&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;charset&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;utf-8&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
                &lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;body&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;{\n&quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;
                        &lt;span class=&quot;s&quot;&gt;&quot;  \&quot;type\&quot;: \&quot;GET_METRICS\&quot;,\n&quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;
                        &lt;span class=&quot;s&quot;&gt;&quot;  \&quot;get_metrics\&quot;: {\n&quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;
                        &lt;span class=&quot;s&quot;&gt;&quot;    \&quot;timeout\&quot;: {\n&quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;
                        &lt;span class=&quot;s&quot;&gt;&quot;      \&quot;nanoseconds\&quot;: 5\n&quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;
                        &lt;span class=&quot;s&quot;&gt;&quot;    }\n&quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;
                        &lt;span class=&quot;s&quot;&gt;&quot;  }\n&quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;
                        &lt;span class=&quot;s&quot;&gt;&quot;}&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;request&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;();&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;//        System.out.println(request.getCode());&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;//        System.out.println(request.getRequestUrl());&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;200&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;request&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;getCode&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;())&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;String&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;content&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;request&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;getContent&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;();&lt;/span&gt;
            &lt;span class=&quot;c1&quot;&gt;//格式化json&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;JSONObject&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;contentObject&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;JSON&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;parseObject&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;content&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;JSONObject&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;get_metrics&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;contentObject&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;getJSONObject&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;get_metrics&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;JSONArray&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;metrics&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;get_metrics&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;getJSONArray&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;metrics&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;metrics&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
                &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;metrics&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;();&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;++)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
                    &lt;span class=&quot;c1&quot;&gt;// 遍历 jsonarray 数组，把每一个对象转成 json 对象&lt;/span&gt;
                    &lt;span class=&quot;n&quot;&gt;JSONObject&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;job&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;metrics&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;getJSONObject&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
                    &lt;span class=&quot;n&quot;&gt;Object&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;name&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;job&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;get&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;name&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
                    &lt;span class=&quot;c1&quot;&gt;//agents&lt;/span&gt;
                    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;master/slaves_active&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;equals&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)){&lt;/span&gt;
                        &lt;span class=&quot;n&quot;&gt;masterMesosMetrics&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;setSlavesActive&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;job&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;getInteger&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;value&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;));&lt;/span&gt;
                    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;master/slaves_inactive&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;equals&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)){&lt;/span&gt;
                        &lt;span class=&quot;n&quot;&gt;masterMesosMetrics&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;setSlavesInactive&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;job&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;getInteger&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;value&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;));&lt;/span&gt;
                    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;master/slaves_disconnected&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;equals&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)){&lt;/span&gt;
                        &lt;span class=&quot;n&quot;&gt;masterMesosMetrics&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;setSlavesDisconnected&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;job&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;getInteger&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;value&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;));&lt;/span&gt;
                        &lt;span class=&quot;c1&quot;&gt;//tasks&lt;/span&gt;
                    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;master/tasks_staging&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;equals&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)){&lt;/span&gt;
                        &lt;span class=&quot;n&quot;&gt;masterMesosMetrics&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;setTasksStaging&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;job&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;getInteger&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;value&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;));&lt;/span&gt;
                    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;master/tasks_starting&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;equals&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)){&lt;/span&gt;
                        &lt;span class=&quot;n&quot;&gt;masterMesosMetrics&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;setTasksStarting&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;job&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;getInteger&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;value&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;));&lt;/span&gt;
                    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;master/tasks_running&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;equals&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)){&lt;/span&gt;
                        &lt;span class=&quot;n&quot;&gt;masterMesosMetrics&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;setTasksRunning&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;job&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;getInteger&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;value&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;));&lt;/span&gt;
                    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;master/tasks_unreachable&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;equals&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)){&lt;/span&gt;
                        &lt;span class=&quot;n&quot;&gt;masterMesosMetrics&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;setTasksUnreachable&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;job&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;getInteger&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;value&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;));&lt;/span&gt;
                    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;master/tasks_killing&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;equals&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)){&lt;/span&gt;
                        &lt;span class=&quot;n&quot;&gt;masterMesosMetrics&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;setTasksKilling&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;job&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;getInteger&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;value&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;));&lt;/span&gt;
                    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;master/tasks_finished&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;equals&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)){&lt;/span&gt;
                        &lt;span class=&quot;n&quot;&gt;masterMesosMetrics&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;setTasksFinished&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;job&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;getInteger&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;value&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;));&lt;/span&gt;
                    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;master/tasks_killed&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;equals&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)){&lt;/span&gt;
                        &lt;span class=&quot;n&quot;&gt;masterMesosMetrics&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;setTasksKilled&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;job&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;getInteger&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;value&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;));&lt;/span&gt;
                    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;master/tasks_failed&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;equals&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)){&lt;/span&gt;
                        &lt;span class=&quot;n&quot;&gt;masterMesosMetrics&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;setTasksFailed&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;job&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;getInteger&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;value&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;));&lt;/span&gt;
                    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;master/tasks_lost&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;equals&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)){&lt;/span&gt;
                        &lt;span class=&quot;n&quot;&gt;masterMesosMetrics&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;setTasksLost&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;job&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;getInteger&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;value&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;));&lt;/span&gt;
                        &lt;span class=&quot;c1&quot;&gt;//resources&lt;/span&gt;
                        &lt;span class=&quot;c1&quot;&gt;//cpus&lt;/span&gt;
                    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;master/cpus_total&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;equals&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)){&lt;/span&gt;
                        &lt;span class=&quot;n&quot;&gt;masterMesosMetrics&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;setCpusTotal&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;job&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;getInteger&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;value&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;));&lt;/span&gt;
                    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;master/cpus_used&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;equals&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)){&lt;/span&gt;
                        &lt;span class=&quot;n&quot;&gt;masterMesosMetrics&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;setCpusUsed&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;job&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;getInteger&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;value&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;));&lt;/span&gt;
                    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;master/cpus_percent&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;equals&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)){&lt;/span&gt;
                        &lt;span class=&quot;c1&quot;&gt;//cpuused/cputotal&lt;/span&gt;
                        &lt;span class=&quot;n&quot;&gt;masterMesosMetrics&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;setCpusPercent&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;job&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;getDouble&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;value&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;));&lt;/span&gt;
                        &lt;span class=&quot;c1&quot;&gt;//gpu&lt;/span&gt;
                    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;master/gpus_total&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;equals&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)){&lt;/span&gt;
                        &lt;span class=&quot;n&quot;&gt;masterMesosMetrics&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;setGpusTotal&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;job&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;getInteger&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;value&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;));&lt;/span&gt;
                    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;master/gpus_used&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;equals&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)){&lt;/span&gt;
                        &lt;span class=&quot;n&quot;&gt;masterMesosMetrics&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;setGpusUsed&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;job&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;getInteger&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;value&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;));&lt;/span&gt;
                    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;master/gpus_percent&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;equals&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)){&lt;/span&gt;
                        &lt;span class=&quot;n&quot;&gt;masterMesosMetrics&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;setGpusPercent&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;job&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;getDouble&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;value&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;));&lt;/span&gt;
                        &lt;span class=&quot;c1&quot;&gt;//mem&lt;/span&gt;
                    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;master/mem_total&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;equals&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)){&lt;/span&gt;
                       &lt;span class=&quot;n&quot;&gt;masterMesosMetrics&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;setMemTotal&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;job&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;getInteger&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;value&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;));&lt;/span&gt;
                    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;master/mem_used&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;equals&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)){&lt;/span&gt;
                      &lt;span class=&quot;n&quot;&gt;masterMesosMetrics&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;setMemUsed&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;job&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;getInteger&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;value&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;));&lt;/span&gt;
                    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;master/mem_percent&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;equals&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)){&lt;/span&gt;
                        &lt;span class=&quot;n&quot;&gt;masterMesosMetrics&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;setMemPercent&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;job&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;getDouble&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;value&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;));&lt;/span&gt;
                        &lt;span class=&quot;c1&quot;&gt;//disk&lt;/span&gt;
                    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;master/disk_total&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;equals&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)){&lt;/span&gt;
                        &lt;span class=&quot;n&quot;&gt;masterMesosMetrics&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;setDiskTotal&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;job&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;getInteger&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;value&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;));&lt;/span&gt;
                    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;master/disk_used&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;equals&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)){&lt;/span&gt;
                        &lt;span class=&quot;n&quot;&gt;masterMesosMetrics&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;setDiskUsed&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;job&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;getInteger&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;value&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;));&lt;/span&gt;
                    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;master/disk_percent&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;equals&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)){&lt;/span&gt;
                        &lt;span class=&quot;n&quot;&gt;masterMesosMetrics&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;setDiskPercent&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;job&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;getDouble&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;value&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;));&lt;/span&gt;
                    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;master/uptime_secs&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;equals&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)){&lt;/span&gt;
                        &lt;span class=&quot;n&quot;&gt;masterMesosMetrics&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;setUptimeSecs&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;job&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;getInteger&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;value&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;));&lt;/span&gt;
                    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
                &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
            &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
        &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;masterMesosMetrics&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;p&gt;至此，关于mesos的监控就这么多了，都是直接使用的httpApi官网都列明白了就不复制过来了，再贴一遍官网连接，有需要的直接去查吧：&lt;a href=&quot;http://mesos.apache.org/documentation/latest/endpoints/#http-endpoints&quot;&gt;HTTP Endpoints&lt;/a&gt;和&lt;a href=&quot;http://mesos.apache.org/documentation/latest/operator-http-api/#operator-http-api&quot;&gt;Operator HTTP API&lt;/a&gt;。&lt;/p&gt;

&lt;h1 id=&quot;marathon管理&quot;&gt;Marathon管理&lt;/h1&gt;
&lt;p&gt;对于Marathon的管理，官方也提供了2种方式，1为直接使用marathon的restful api；2是官方也提供了封装好的方法，直接使用就可以啦。&lt;/p&gt;
&lt;h2 id=&quot;marathon-client&quot;&gt;Marathon-client&lt;/h2&gt;
&lt;p&gt;对于marathon-client，也是对于restful api的一种封装，官方也给出的详细的使用说明:&lt;a href=&quot;https://github.com/mesosphere/marathon-client&quot;&gt;marathon-client&lt;/a&gt;。&lt;br /&gt;
我们使用的marathon版本是Marathon1.4.5，所以来说，可以使用下列依赖：&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&amp;lt;dependency&amp;gt;
  &amp;lt;groupId&amp;gt;com.mesosphere&amp;lt;/groupId&amp;gt;
  &amp;lt;artifactId&amp;gt;marathon-client&amp;lt;/artifactId&amp;gt;
  &amp;lt;version&amp;gt;0.6.0&amp;lt;/version&amp;gt;
&amp;lt;/dependency&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;p&gt;导入依赖之后，我们就可以直接使用了。&lt;br /&gt;
首先，使用&lt;strong&gt;MarathonClient.getInstance()&lt;/strong&gt;创建Marathon实例对象，之后就可以直接使用其对应的各种方法了，在这里就不和docker-client似的详细说明了，因为这里没有参与过多就不贴详细使用代码啦，官方使用说明挺好的（&lt;a href=&quot;https://github.com/mesosphere/marathon-client&quot;&gt;marathon-client&lt;/a&gt;），所以直接放上来一个小例子来参考吧(IP全用-.-.-.-代替了)。&lt;/p&gt;
&lt;div class=&quot;language-java highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kd&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;kd&quot;&gt;static&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;main&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;String&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;args&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[])&lt;/span&gt; &lt;span class=&quot;kd&quot;&gt;throws&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Exception&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;String&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;endpoint&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;http://-.-.-.-:8080&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;Marathon&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;marathon&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;MarathonClient&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;getInstance&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;endpoint&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;

        &lt;span class=&quot;n&quot;&gt;App&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;app&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;App&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;();&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;app&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;setId&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;spark-with-api&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;app&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;setCmd&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;/bin/bash  /usr/tools/demo.sh user1 user1234&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;app&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;setCpus&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Double&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;));&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;app&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;setMem&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Double&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4096&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;));&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;app&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;setInstances&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Integer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;));&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;Container&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;container&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Container&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;();&lt;/span&gt;

        &lt;span class=&quot;c1&quot;&gt;//设置docker镜像配置&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;Docker&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;docker&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Docker&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;();&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;docker&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;setImage&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;-.-.-.-:5000/sparkwithhadoop_1.6.3:2.2&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;docker&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;setNetwork&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;BRIDGE&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;docker&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;setPrivileged&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;true&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;

        &lt;span class=&quot;c1&quot;&gt;//设置容器的参数&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;Collection&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Parameter&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ArrayList&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Parameter&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;();&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;add&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Parameter&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;net&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;pub_net&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;));&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;add&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Parameter&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;ip&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;-.-.-.-&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;));&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;add&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Parameter&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;hostname&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;master1&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;));&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;docker&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;setParameters&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;

        &lt;span class=&quot;c1&quot;&gt;//设置端口映射&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;Collection&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Port&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;portMappings&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ArrayList&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Port&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;();&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;Port&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;port22&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Port&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;();&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;port22&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;setContainerPort&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;22&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;port22&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;setProtocol&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;tcp&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;portMappings&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;add&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;port22&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
        
        &lt;span class=&quot;n&quot;&gt;Port&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;port7077&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Port&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;();&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;port7077&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;setContainerPort&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;7077&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;port7077&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;setProtocol&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;tcp&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;portMappings&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;add&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;port7077&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
        
        &lt;span class=&quot;n&quot;&gt;Port&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;port7070&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Port&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;();&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;port7070&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;setContainerPort&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;7070&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;port7070&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;setProtocol&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;tcp&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;portMappings&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;add&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;port7070&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;docker&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;setPortMappings&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;portMappings&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
        
        &lt;span class=&quot;n&quot;&gt;container&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;setDocker&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;docker&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;container&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;setType&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;DOCKER&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;//设置容器的挂载目录&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;Collection&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Volume&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;volumes&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ArrayList&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Volume&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;();&lt;/span&gt; 
        &lt;span class=&quot;n&quot;&gt;LocalVolume&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;v1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;LocalVolume&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;();&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;v1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;setContainerPath&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;/usr/tools/hd&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;v1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;setHostPath&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;/app/dcos/&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;v1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;setMode&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;RW&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;volumes&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;add&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;v1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;container&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;setVolumes&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;volumes&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
        
        &lt;span class=&quot;n&quot;&gt;app&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;setContainer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;container&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;//设置健康检查&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;List&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;HealthCheck&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;healthChecks&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ArrayList&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;HealthCheck&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;();&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;HealthCheck&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;h1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;HealthCheck&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;();&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;h1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;setProtocol&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;MESOS_HTTP&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;h1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;setGracePeriodSeconds&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;300&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;h1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;setIntervalSeconds&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;60&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;h1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;setTimeoutSeconds&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;60&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;h1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;setMaxConsecutiveFailures&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;h1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;setPortIndex&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;healthChecks&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;add&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;h1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;app&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;setHealthChecks&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;healthChecks&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;marathon&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;createApp&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;app&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h2 id=&quot;marathon-restful-api&quot;&gt;Marathon restful api&lt;/h2&gt;
&lt;p&gt;另外一种管理marathon的方式就是直接使用其&lt;a href=&quot;http://mesosphere.github.io/marathon/api-console/index.html&quot;&gt;Marathon REST API&lt;/a&gt;。&lt;br /&gt;
不过它和docker和mesos的有所不同，他们是只有get或post请求，而在marathon中，是正常的restful api使用方式，不同的请求操作有不同的含义。&lt;br /&gt;
拿/v2/apps来举例：&lt;br /&gt;
如果是GET，则可以获取到对应的正在运行的applications的列表。&lt;br /&gt;
如果是POST的话，则是创建或者开启一个新的application，提交的请求将创建的application所需要的参数带着就可以啦。&lt;br /&gt;
具体的这里的restful api的使用方式就不细说了，直接看官方说明之后按照restful api正常使用方式使用就可以啦。&lt;br /&gt;
再贴一遍，官方的详细说明如下：&lt;a href=&quot;http://mesosphere.github.io/marathon/api-console/index.html&quot;&gt;Marathon REST API&lt;/a&gt;。&lt;/p&gt;

&lt;p&gt;好了，marathon的管理方式也说明到这里。&lt;/p&gt;

&lt;hr /&gt;
&lt;p&gt;至此，本篇内容完成。&lt;br /&gt;
本文由2018-06-11开始整理，于2018-06-15整理完成。&lt;br /&gt;
如有问题，请发送邮件至leafming@foxmail.com联系我，谢谢～&lt;br /&gt;
©商业转载请联系作者获得授权，非商业转载请注明出处。&lt;/p&gt;</content><author><name>Liv Yeh</name></author><category term="Docker" /><category term="Mesos" /><category term="Marathon" /><summary type="html">本文主要关于Docker、Mesos、Marathon的监控方法的总结。 注意: 本文中使用的版本是Docker1.12.6、Mesos1.3.0、Marathon1.4.5。 Docker+Mesos+Marathon所搭建的平台监控所用到的后台方法已经基本上写完了，现在用一些时间总结下相关监控方法，满满用心总结的，不过用到的不止这些，还差很多以后再另开文章补充。在总结过程中也重新梳理了很多东西，现在分享出来，希望对大家有用啦，也省的自己以后忘了～哈哈。 Docker管理-容器相关 前期准备：开启Docker远程访问 Docker daemon可以有3种远程访问方式的socket：unix、tcp和fd。 其中Docker支持使用restful api远程获取信息，但是需要提前开启一个Tcp Socket，这样才能实现远程通信。 默认情况下，Docker守护进程Unix socket（/var/run/docker.sock）来进行本地进程通信，而不会监听任何端口，因此只能在本地使用docker客户端或者使用Docker API进行操作,并且需要root权限或者是docker group成员。如果想在其他主机上操作Docker主机，就需要让Docker守护进程打开一个Tcp Socket，这样才能实现远程通信。 补充说明：可以使用HTTPs方式，不过目前没有进行配置，可以后续更改。但是，如果你用和Https的socket，需要注意的是只支持TLS1.0及以上的协议，SSLv3或者更低的是不支持的。 官方网站描述如下Daemon socket option。 我们来使用开启TCP Socket的方式。 需要更改docker配置文件，修改OPTIONS，具体方式如下： 如果找不到docker配置文件，可以以下述方式查找： 找到docker.service文件： systemctl show –property=FragmentPath docker ---@---[~]$systemctl show --property=FragmentPath docker FragmentPath=/usr/lib/systemd/system/docker.service 找到docker.service文件并查看，发现docker文件位置：/etc/sysconfig/docker 找到文件后编辑文件docker 在OPTIONS=后加上 -H=unix:///var/run/docker.sock -H=tcp://0.0.0.0:端口 说明： 1、确定sock文件位置：/var/run/docker.sock 2、可用指定ip：指定端口 3、重启docker 说明： 有资料表述，一般情况下执行以下操作即可： 1、vim /etc/sysconfig/docker（更改docker文件） 2、在OPTIONS=后加上 -H=unix:///var/run/docker.sock -H=tcp://0.0.0.0:端口即可 如若不成功，可尝试下述操作： 1、vim /usr/lib/systemd/system/docker.service （更改docker.service文件） 2、直接在ExecStart=/user/bin/dockerd后添加-H=tcp://0.0.0.0:端口 -H=unix:///var/run/docker.sock(注意顺序) 3、执行命令：systemctl daemon-reload 、systemctl restart docker 测试使用： 配置之后，尝试使用docker restful api来获取信息。 或者直接在机器上尝试查询：“sudo docker -H IP:端口 命令”来测试是否能够取到内容。 Docker-Client的选择 Docker-client的前期准备已经完毕，下面进行DockerAPI的使用。 Docker版本与Docker API的对应关系 和 相关Library Docker提供了Docker Engine API 去连接Docker daemon 来进行Docker的管理。Docker Engine API是Restful API，可以通过http客户端，比如说wget或者curl等来使用。 Docker官方提供Python和Go的SDK，可以直接使用。而在我们这里使用的是java语言，所以可以直接使用restful API的方式来获取相关信息或者直接使用他人封装好的Library。 Docker版本和API版本对应 Docker的不同版本对用不同版本的API。具体以一个表格的形式列了出来，具体可以参考官方网站所写的内容:Docker版本和API对应表-API version matrix。 通过查看这个表，我们知道，我现在用的docker版本是1.12.6，所以来说，所对应的API版本为1.24。 关于Docker Engine API 1.24的使用，可以参考官网Docker Engine API 1.24。 Docker unofficial libraries Docker中出了官方提供的Python和Go的SDK之外，仍然有一些非官方的libraries可以使用，并且可使用的语言类型更加的广泛。关于可以使用的Library，官方在官网上也有所推荐，见官网Unofficial libraries所示。 目前，项目里面并没有直接使用Docker Engine API，而是使用Java的第三方Library,第三方Library也是对Docker Engine API的一个封装。关于Java的Library，Docker官方推荐有三种，docker-client、docker-java、docker-java-api，而这次在项目中，使用的是spotify/docker-client，在下面会将部分所用Library中的方法和Docker Engine API对应着介绍一下。 Docker-Client的使用 我们使用的是spotify/docker-client，在github上有详细的使用说明，直接点击链接即可。所以就不详细介绍了，下面就直接列出来使用的几个方法记录一下。 引入jar包 我们使用的是spotify/docker-client，可以直接通过maven或者jar包的方式引入，maven如下： &amp;lt;dependency&amp;gt; &amp;lt;groupId&amp;gt;com.spotify&amp;lt;/groupId&amp;gt; &amp;lt;artifactId&amp;gt;docker-client&amp;lt;/artifactId&amp;gt; &amp;lt;version&amp;gt;LATEST-VERSION&amp;lt;/version&amp;gt; &amp;lt;/dependency&amp;gt; 针对Docker1.12.6，选择的是8.9.1版本。 开始使用 因为项目中主要用到的是监控，所以基本上都是从服务器上查询的方法，关于对于创建容器、删除容器等操作，因为容器直接归于marathon管理，所以不在Docker这里进行容器创建、删除等操作了。 创建和关闭Docker连接 创建连接 在之前的操作，开启了Docker RPC端口之后，可以在其他机器上创建远程Docker连接。 而且我们也没有开启https，所以可以直接使用如下方式： 传入容器宿主机IP+端口构成的uri，建立和宿主机的连接。 // use the builder String dockerUri =&quot;http://&quot;+hostIp+&quot;:&quot;+port; final DockerClient docker = DefaultDockerClient.builder().uri(URI.create(dockerUri)).build(); 除了这种方式，还有其它几种方式创建docker连接，详细参考Creating a docker-client。 关闭Docker连接 关闭连接直接通过创建的DockerClient docker连接对象，调用close方法即可。 // Close the docker client docker.close(); Docker操作 容器列表 获取宿主机上的容器列表，方法如下： 这个方法能够列出宿主机上全部正在运行的容器的列表。 List&amp;lt;Container&amp;gt; containers = docker.listContainers(DockerClient.ListContainersParam.allContainers()); 通过这个方法，可以返回List，其中的Container对象，可以取到的容器的id、名称、镜像信息、网络信息、状态等内容。 并且，其中包括网络信息可以通过networkSettings取到，包括内容如下： 容器详情 上述获取容器列表的过程中取到的容器信息并不详细，如果想看容器的详细信息可使用inspect方法,需要传入的内容是容器的id，不过通过测试，不需要传入全部的完整id，部分。 ContainerInfo info = docker.inspectContainer(&quot;containerID&quot;); 通过这个方法可以获取到ContainerInfo对象，其中包括容器的详细信息，如下： 容器状态对象 通过 ContainerState state = info.state();可以取到容器的状态对象ContainerState，其中属性如下。 取对象的state.status()，可以取到当前容器的状态，容器状态总共包括：created、restarting、running、paused、exited、dead共5种。 容器配置信息 通过 ContainerConfig config = containerInfo.config();取到容器的配置信息，其中属性包括如下。 通过ContainerConfig可以获取到容器的hostname、env配置、启动容器的命令、所用镜像、工作目录、labels等信息。 容器HostConfig 通过 HostConfig hostConfig = containerInfo.hostConfig();可以取到容器的host配置信息，其中属性如下。 通过HostConfig对象，可以获取到容器和宿主机之间映射的目录、端口等信息，以及所给容器分配的cpu core数量（hostConfig.cpuShares()取到的数值除以1024）、memory（hostConfig.memory()）、swap的大小（hostConfig.memorySwap()-hostConfig.memory()）等信息。 容器网络信息 通过NetworkSettings networkSettings = containerInfo.networkSettings();可以取到容器的网络信息，此对象和容器列表中取到的内容一致。通过它可以取到容器的网络模式、网关、ip、mac等信息。 容器内进程 上述操作均是获取容器的基本信息，如果获取容器内当时的进程信息，可以使用如下方法： 传入的ps_args为aux，和在容器内执行“ps aux”命令取到的数据一致，即“[USER, PID, %CPU, %MEM, VSZ, RSS, TTY, STAT, START, TIME, COMMAND]”等内容。 通过如下方法能取到TopResults对象，此对象内包括属性为process和titles，通过获取其中的process，可得到容器内的进程情况。 //例子 //final TopResults topResults = docker.topContainer(&quot;containerID&quot;, &quot;ps_args&quot;); TopResults topResults = docker.topContainer(&quot;containerID&quot;, &quot;aux&quot;); ImmutableList&amp;lt;ImmutableList&amp;lt;String&amp;gt;&amp;gt; processes = topResults.processes(); 容器资源使用情况 在命令行中，我们可以通过docker stats来查看docker容器资源使用情况的信息，通过命令行能查询到如下内容： CONTAINER CPU % MEM USAGE / LIMIT MEM % NET I/O BLOCK I/O docker-client也提供了方法，来通过如下方式获取docker stats信息： ContainerStats stats = docker.stats(&quot;containerID&quot;); 通过此方法，能够取到ContainerStats对象，其中包含内容如下： 但是，我们取到的数据并不能直接使用，而需要通过计算，来得到更加直观的数据，下面进行一下详细说明。 而计算的过程，主要参考“dockerstats命令源码分析结果”文章中，对于docker stats源码的分析。 CPU利用率计算 计算分析 在上述参考文章中提到: docker daemon会记录这次读取/sys/fs/cgroup/cpuacct/docker/[containerId]/cpuacct.usage的值，作为cpu_total_usage；并记录了上一次读取的该值为pre_cpu_total_usage；读取/proc/stat中cpu field value，并进行累加，得到system_usage;并记录上一次的值为pre_system_usage；读取/sys/fs/cgroup/cpuacct/docker/[containerId]/cpuacct.usage_percpu中的记录，组成数组per_cpu_usage_array。 因此，可以得到docker stats计算Cpu Percent的算法如下： cpu_delta = cpu_total_usage - pre_cpu_total_usage; system_delta = system_usage - pre_system_usage; CPU % = ((cpu_delta / system_delta) * length(per_cpu_usage_array) ) * 100.0 代码实现 所以说，将上述内容中得到的公式所需数据与我们通过取到的数据相对应，通过已经得到的stats对象，用方法可以取到两个CpuStats对象： CpuStats cpuStats = stats.cpuStats(); CpuStats precpuStats = stats.precpuStats(); 然后我们计算cpu利用率，就可以这样来计算： String cpuPercent=&quot;---&quot;; if (null!=cpuStats&amp;amp;&amp;amp;null!=precpuStats){ /** * 计算cpu利用率 % * cpuDelta = cpuTotalUsage - preCpuTotalUsage; * systemDelta = systemUsage - preSystemUsage; * CPU % = ((cpuDelta / systemDelta) * length(per_cpu_usage_array) ) * 100.0 */ Long cpuTotalUsage=cpuStats.cpuUsage().totalUsage(); Long preCpuTotalUsage =precpuStats.cpuUsage().totalUsage(); Long cpuDelta =cpuTotalUsage - preCpuTotalUsage; Long systemUsage =cpuStats.systemCpuUsage(); Long preSystemUsage =precpuStats.systemCpuUsage(); Long systemDelta =systemUsage-preSystemUsage; Integer percpuUsageListSize = cpuStats.cpuUsage().percpuUsage().size(); cpuPercent = ((cpuDelta.floatValue() / systemDelta.floatValue()) * percpuUsageListSize.floatValue()) * 100+&quot;%&quot;; } memory利用率计算 计算分析 在上述参考文章中提到: 读取/sys/fs/cgroup/memory/docker/[containerId]/memory.usage_in_bytes的值，作为mem_usage；如果容器限制了内存，则读取/sys/fs/cgroup/memory/docker/[id]/memory.limit_in_bytes作为mem_limit，否则mem_limit = machine_mem。 因此可以得到docker stats计算Memory数据的算法如下： MEM USAGE = mem_usage MEM LIMIT = mem_limit MEM % = (mem_usage / mem_limit) * 100.0 代码实现 通过已经得到的stats对象，用方法可以取到MemoryStats对象。 MemoryStats memoryStats = stats.memoryStats(); 然后根据公式来计算memory利用率： String memUsageFormat=&quot;---&quot;; String memLimitFormat=&quot;---&quot;; String memPercent=&quot;---&quot;; if (null!=memoryStats){ /** * 计算memory利用率 % * MEM USAGE = mem_usage MEM LIMIT = mem_limit MEM % = (mem_usage / mem_limit) * 100.0 */ Long memUsage= memoryStats.usage(); Long memLimit=memoryStats.limit(); memUsageFormat= Utils.getDynamicSizeUnit(memUsage); memLimitFormat=Utils.getDynamicSizeUnit(memLimit); memPercent=(memUsage.floatValue()/memLimit.floatValue())*100+&quot;%&quot;; } Network IO计算 计算分析 在上述参考文章中提到: network stats的计算可以根据“获取属于该容器network namespace veth pairs在主机中对应的veth*虚拟网卡EthInterface数组，然后循环数组中每个网卡设备，读取/sys/class/net//statistics/rx_bytes得到rx_bytes, 读取/sys/class/net//statistics/tx_bytes得到对应的tx_bytes。将所有这些虚拟网卡对应的rx_bytes累加得到该容器的rx_bytes。将所有这些虚拟网卡对应的tx_bytes累加得到该容器的tx_bytes。 因此我们可以得到network stats的计算算法如下： NET I = rx_bytes NET O = tx_bytes 代码实现 通过已经得到的stats对象，可以取到 ImmutableMap&amp;lt;String, NetworkStats&amp;gt;。 ImmutableMap&amp;lt;String, NetworkStats&amp;gt; networks = stats.networks(); 然后根据公式来计算network io： String rxBytesSumFormat=&quot;---&quot;; String txBytesSumFormat=&quot;---&quot;; if (null!=networks){ /** * docker stats计算Network IO数据的算法： NET I = rx_bytes(所有网卡累加) NET O = tx_bytes（所有网卡累加） */ Long rxBytesSum=0L; Long txBytesSum=0L; for (Map.Entry&amp;lt;String, NetworkStats&amp;gt; entry:networks.entrySet()){ rxBytesSum+=entry.getValue().rxBytes(); txBytesSum+=entry.getValue().txBytes(); } //Utils.getDynamicSizeUnit()是一个动态单位转换的方法 rxBytesSumFormat=Utils.getDynamicSizeUnit(rxBytesSum); txBytesSumFormat=Utils.getDynamicSizeUnit(txBytesSum); } Blk IO计算 计算分析 在上述参考文章中提到: Blk IO计算可以根据“获取每个块设备的IoServiceBytesRecursive数据：先去读取/sys/fs/cgroup/blkio/docker/[containerId]/blkio.io_serviced_recursive中是否有有效值，如果有，则读取/sys/fs/cgroup/blkio/docker/[containerId]/blkio.io_service_bytes_recursive的值返回； 如果没有，就去读取/sys/fs/cgroup/blkio/docker/[containerId]/blkio.throttle.io_service_bytes中的值返回；将每个块设备的IoServiceBytesRecursive数据中所有read field对应value进行累加，得到该容器的blk_read值；将每个块设备的IoServiceBytesRecursive数据中所有write field对应value进行累加，得到该容器的blk_write值。 因此，我们可以得到Blk IO计算算法如下： BLOCK I = blk_read BLOCK O = blk_write 代码实现 String blkReadFormat=&quot;---&quot;; String blkWriteFormat=&quot;---&quot;; if (null!=blockIoStats){ /** * docker stats计算Block IO数据的算法： BLOCK I = blkRead BLOCK O = blkWrite */ ImmutableList&amp;lt;Object&amp;gt; objects = blockIoStats.ioServiceBytesRecursive(); Long blkRead =0L; Long blkWrite =0L; //因为是Object，不好遍历，所以转变成了jsonobj遍历 for (Object obj: objects) { String jsonString= JSON.toJSONString(obj); JSONObject jsonObj = JSON.parseObject(jsonString); if (&quot;Read&quot;.equals(jsonObj.getString(&quot;op&quot;))){ blkRead+=jsonObj.getLong(&quot;value&quot;); }else if (&quot;Write&quot;.equals(jsonObj.getString(&quot;op&quot;))){ blkWrite+=jsonObj.getLong(&quot;value&quot;); } } blkReadFormat=Utils.getDynamicSizeUnit(blkRead); blkWriteFormat=Utils.getDynamicSizeUnit(blkWrite); } 获取时间 至此，以上将docker stats所需要的数据均计算出来了，之后我们只需获取下当前的采集时间即可。 Date read = stats.read(); 容器其他 上面说的基本上是关于docker容器监控所用的方法，剩下的都是直接操作容器的工具，先不写出来了，有需要的可以直接参考官方说明spotify/docker-client。 容器宿主机监控 以上说明了容器的基础监控，我们在应用中，如果需要监控容器所在宿主机的情况，也可以使用下述方法： Info info = docker.info(); 获取到了Info对象，通过此对象可以取到宿主机上运行的容器状态、资源情况等，具体可获取到的如下。 其他 除了以上说的那些，还可以获取、操作Networks、Images等。因为我们这里自己创建的一个镜像库，所以不直接使用docker-client的方法获取镜像信息，下面会统一再说明镜像库的搭建和列表的获取。 至此，docker-client所用到的方法都说明完毕了，其他没提到的还是直接去看官方说明吧spotify/docker-client。 Engine API的使用 上述进行说明了Docker-client的使用，我们也可以直接通过Engine API v1.24来进行Docker的操作。 也是开启TCP端口之后，直接发送request到宿主机地址：端口，然后会收到json格式的response。 这里直接使用工具测试，获取到容器的列表信息，如下图。 此后，如果需要，可以直接参考官方说明Engine API v1.24，不过需要注意的是，我这里使用的docker对应的是v1.24的，其他版本的要选择不同对应版本的api哦，在本文最开始也选择docker-client的“Docker版本和API版本对应”处也说明了，忘记了的话回过头去看哦。 Docker管理-Docker镜像仓库 我们上述说明了使用Docker-Client获取Docker容器的一些基础信息，而镜像我们是单独部署了一个镜像服务器，因此，不直接使用docker-client来获取镜像列表。下面会先说明镜像服务器的部署，之后说下如何获取镜像服务器中的镜像列表。 简单说明镜像服务器的部署 Docke官方提供了Docker Hub网站来作为一个公开的集中仓库。然而，本地访问Docker Hub速度往往很慢，并且很多时候我们需要一个本地的私有仓库只供网内使用。 Docker仓库实际上提供两方面的功能，一个是镜像管理，一个是认证。前者主要由docker-registry项目来实现，通过http服务来上传下载；后者可以通过docker-index（闭源）项目或者利用现成认证方案（如nginx）实现http请求管理。 目前来说，我们只需要在内网建立一个存储镜像的地方，因此只使用docker registry来搭建一个私有镜像库。 下面简单说明下仓库搭建过程，也可以直接参考官方部署“Deploy a registry server”。 官方提供了registry镜像，我们直接下载： docker pull registry 默认情况下，会将仓库存放于容器内,这样的话如果容器被删除，则存放于容器中的镜像也会丢失，所以我们需要指定一个本地目录挂载到容器内的存放镜像的目录下。所以，我们以如下命令来启动一个docker容器： docker run --privileged=true -d -v /datacenter02/registry:/var/lib/registry -p 5000:5000 --restart=always --name registry registry 查看启动的容器 ---@---[~]#docker ps -a CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 458a9e2301a6 registry &quot;/entrypoint.sh /etc/&quot; 7 months ago Up 7 months 0.0.0.0:5000-&amp;gt;5000/tcp registry 测试使用 创建一个小的镜像，然后测试push docker push 132.-.-.-:5000/busybox（这里的ip没写全，用-代替了，自己写的时候写全） 可以看到push失败，报关于https的错误类似如下。 Error response from daemon: invalid registry endpoint https://132.-.-.-:5000/v1/: Get https://132.-.-.-:5000/v1/_ping: http: server gave HTTP response to HTTPS client. If this private registry supports only HTTP or HTTPS with an unknown CA certificate, please add `--insecure-registry 132.-.-.-:5000` to the daemon's arguments. In the case of HTTPS, if you have access to the registry's CA certificate, no need for the flag; simply place the CA certificate at /etc/docker/certs.d/132.-.-.-:5000/ca.crt 配置http访问 因为Docker从1.3.X之后，与docker registry交互默认使用的是https，然而此处搭建的私有仓库只提供http服务，所以当与私有仓库交互时就会报上面的错误。为了解决这个问题需要在启动docker server时增加启动参数为默认使用http访问。 我们需要修改docker配置文件，在docker配置文件中增加“–insecure-registry 132.-.-.-:5000”，其中IP为了不泄露用-代替了，自己写的时候需要写全： # If you have a registry secured with https but do not have proper certs # distributed, you can tell docker to not look for full authorization by # adding the registry to the INSECURE_REGISTRY line and uncommenting it. # INSECURE_REGISTRY='--insecure-registry' INSECURE_REGISTRY='--insecure-registry 132.-.-.-:5000' 之后重启docker服务。 之后再次测试，可以发现没有报错啦，push成功。 命令行仓库管理 有文章说，查询私有仓库中的所有镜像，使用docker search命令，但是我这里经过尝试，发现会报错：“Error response from daemon: Unexpected status code 404”。 后来发现，docker search是v1版本的API，我们现在的是v2版本，所以不能使用。 如果需要查询，则也是直接curl使用v2版本的API： ---@---[~]#curl 132.90.130.13:5000/v2/_catalog {&quot;repositories&quot;:[&quot;alluxio&quot;,&quot;basic&quot;,&quot;go&quot;,&quot;go1.10&quot;,&quot;go_zhzj&quot;,&quot;hdfs_datanode&quot;,&quot;hello-mine&quot;,&quot;hiveonspark&quot;,&quot;hiveonspark-gx&quot;,&quot;hivespark&quot;,&quot;jdk&quot;,&quot;jtwspark1.6.3&quot;,&quot;kafka&quot;,&quot;ninecon&quot;,&quot;nm&quot;,&quot;rm1&quot;,&quot;rm2&quot;,&quot;spark-2.3.0&quot;,&quot;spark2&quot;,&quot;spark2.2.1&quot;,&quot;spark2.2.1-gx&quot;,&quot;spark2.2.1-jtw&quot;,&quot;spark2.2.1-rx-demo&quot;,&quot;sparkdemo&quot;,&quot;sparkrx1.6.3&quot;,&quot;sparkrx2.2.1&quot;,&quot;tensorflow&quot;]} 详细的将在下面说明。 镜像仓库器管理 对于Docker Registry，Docker官方提供了HTTP API V2用于与其交互，用来管理docker images。对于此，在官方网站上也有说明：HTTP API V2。 因为我们只用到了镜像管理功能，所以下面只是用到的说明获取仓库内的镜像列表以及tags的方法，其他的需要自己参考官网啦。 镜像列表 我们使用下述方式来获取仓库里面的镜像列表，获取也是请求之后来获取一个包含信息（仓库、镜像名称）的json串，官方给出的request和response例子如下： request: GET /v2/_catalog response: ``` 200 OK Content-Type: application/json</summary></entry><entry><title type="html">lintcode算法练习打卡</title><link href="http://localhost:4000/base/2018/06/06/lintcode%E7%AE%97%E6%B3%95%E7%BB%83%E4%B9%A0%E6%89%93%E5%8D%A1/" rel="alternate" type="text/html" title="lintcode算法练习打卡" /><published>2018-06-06T00:00:00+08:00</published><updated>2018-06-06T00:00:00+08:00</updated><id>http://localhost:4000/base/2018/06/06/lintcode%E7%AE%97%E6%B3%95%E7%BB%83%E4%B9%A0%E6%89%93%E5%8D%A1</id><content type="html" xml:base="http://localhost:4000/base/2018/06/06/lintcode%E7%AE%97%E6%B3%95%E7%BB%83%E4%B9%A0%E6%89%93%E5%8D%A1/">&lt;blockquote&gt;
  &lt;p&gt;本文主要关于&lt;a href=&quot;https://www.lintcode.com/problem/&quot;&gt;lintcode&lt;/a&gt; 中的算法练习,以后有时间无聊了就来记录一道算法题目，以后随着更新吧，更新时间不定哦～&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h1 id=&quot;2018-06-06-1-ab问题&quot;&gt;2018-06-06-1-A+B问题&lt;/h1&gt;
&lt;h2 id=&quot;题目&quot;&gt;题目&lt;/h2&gt;
&lt;p&gt;给出两个整数a和b, 求他们的和, 但不能使用+等数学运算符。&lt;br /&gt;
&lt;strong&gt;说明&lt;/strong&gt;&lt;br /&gt;
a和b都是32位整数么？-是&lt;br /&gt;
我可以使用位运算符么？-当然可以&lt;br /&gt;
&lt;strong&gt;样例&lt;/strong&gt;&lt;br /&gt;
如果a=1并且b=2，返回3。&lt;/p&gt;
&lt;h2 id=&quot;解答&quot;&gt;解答&lt;/h2&gt;
&lt;h3 id=&quot;所用知识点-java位运算&quot;&gt;所用知识点-java位运算&lt;/h3&gt;
&lt;p&gt;java里int型是4个字节，即32位，用二进制表示java里的1即000……0001，且都是有符号的数，最高位代表符号位，即32位能表示的最大整数是2的32次方-1。&lt;br /&gt;
&amp;amp; 与运算符 ：按位与，当且仅当两个对应的位置都是1，结果才是1，否则结果为0。(有0则0)&lt;br /&gt;
| 或运算符 ：按位或，当且仅当两个对应的位置都是0，结果才是0，否则结果是1。(有1则1)&lt;br /&gt;
~ 非运算符 ：按位取反。&lt;br /&gt;
^异或运算符 ：当运算符两边不同的时候结果为1，两边相同的时候结果为0。&lt;br /&gt;
&lt;script type=&quot;math/tex&quot;&gt;&gt;&gt;&lt;/script&gt;位移运算符（&lt;script type=&quot;math/tex&quot;&gt;% &lt;![CDATA[
&lt;&lt; %]]&gt;&lt;/script&gt;同理）：位移运算符可以简单的理解为乘除法，像左移是除法，向右移是乘法。左移：在低位补0；右移：正数右移高位补0，负数右移高位补1。num&lt;script type=&quot;math/tex&quot;&gt;% &lt;![CDATA[
&lt;&lt; %]]&gt;&lt;/script&gt;1,相当于num乘以2;num&lt;script type=&quot;math/tex&quot;&gt;&gt;&gt;&lt;/script&gt;1,相当于num除以2。8&lt;script type=&quot;math/tex&quot;&gt;&gt;&gt;&lt;/script&gt;2不要理解为8/2，位移两位就是除以2的2次方也就是8/4；注意9&lt;script type=&quot;math/tex&quot;&gt;&gt;&gt;&lt;/script&gt;1的结果是4，即最低位的1会移没了。&lt;br /&gt;
&lt;script type=&quot;math/tex&quot;&gt;&gt;&gt;&gt;&lt;/script&gt;无符号右移 ：忽略符号位，空位都以0补齐。使用了“零扩展”：无论正负，都在高位插入0。value&lt;script type=&quot;math/tex&quot;&gt;&gt;&gt;&gt;&lt;/script&gt;num–num 指定要移位值value 移动的位数。无符号右移运算符&lt;script type=&quot;math/tex&quot;&gt;&gt;&gt;&gt;&lt;/script&gt;只是对32位和64位的值有意义。&lt;/p&gt;
&lt;h3 id=&quot;位运算加法分析&quot;&gt;位运算加法分析&lt;/h3&gt;
&lt;p&gt;本题目下述分析均参考或学习文章&lt;a href=&quot;https://blog.csdn.net/surp2011/article/details/51149828&quot;&gt;位运算-加法运算、交换两个数值&lt;/a&gt;。&lt;/p&gt;
&lt;h4 id=&quot;思路分析&quot;&gt;思路分析&lt;/h4&gt;
&lt;p&gt;参考上述文章，是从最熟悉的十进制分析。&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;思路1:十进制加法计算过程从末尾到高位进行计算，基本上是同位数字相加，有进位的情况再加上进位，即每次计算的时候是某一位的2个数字相加，最多3个数字即再多加一个进位。如15+9，个位5+9=14，结果末尾数为4，进位1；十位即1+0+1（进位）=2，因此结果为24。&lt;/li&gt;
  &lt;li&gt;思路2:加法过程分为对应位数字相加结果和进位数字相加结果，再求2个结果的和，直到没有进位即为最终结果。再如15+9，5+9=4（个位），进位为1；1+0=1（十位），进位为0；即本位结果位14，进位为10；因此15+9即可转化为，14+10，即个位4+0=4，进位为0；十位1+1=2，进位为0；所以结果为24，进位结果是0，所以不用再计算，即可得出最终结果24。总结上诉，即将加法分为了对应位相加（不进位）和进位值2部分，再求2个结果和，并且之后重复计算，直到进位值为0。因此，可以发现停止计算的条件可以设置为进位值为0。&lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&quot;位运算分析&quot;&gt;位运算分析&lt;/h4&gt;
&lt;p&gt;下面在二进制位运算层面实现。&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;二进制和十进制差别：逢十进一和逢二进一。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h5 id=&quot;对应位相加不进位-sum&quot;&gt;对应位相加，不进位-sum&lt;/h5&gt;
&lt;p&gt;在二进制中，则1位数相加，思考结果为：&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;0 + 0 = 0
0 + 1 = 1
1 + 0 = 1
1 + 1 = 0（不进位）
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;p&gt;可以发现相同为0，不同为1，则当二进制的不进位加法，可以用异或^来表示。&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;0 ^ 0 = 0
0 ^ 1 = 1
1 ^ 0 = 1
1 ^ 1 = 0
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;p&gt;因此，在二进制中，对应位置相加（本位操作）可以使用异或^符号来实现，即a^b。&lt;/p&gt;
&lt;h5 id=&quot;进位-carry&quot;&gt;进位-carry&lt;/h5&gt;
&lt;p&gt;如果进行情况下，如果获取进位，只得到进位值，进位值的结果，思考如下：&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;注意这里是只得到进位值
0 + 0 = 0
0 + 1 = 0
1 + 0 = 0
1 + 1 = 1
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;p&gt;由此可看出，有0就为0，因此可以用位运算&amp;amp;来代替。&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;0 &amp;amp; 0 = 0
0 &amp;amp; 1 = 0
1 &amp;amp; 0 = 0
1 &amp;amp; 1 = 1
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;p&gt;但是进位应该是进到高位，因此可以使用左移操作符将进位的1左进一位。&lt;br /&gt;
在位运算中，我们用“«”表示向左移动一位，也就是“进位”。&lt;br /&gt;
0«1 = 0，值还是0，1«1 = 10，值为2。&lt;br /&gt;
因此，进位可以如下表示：&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;(x&amp;amp;y)&amp;lt;&amp;lt;1
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;blockquote&gt;
  &lt;p&gt;tips：左移一位在二进制的意义可以理解为x2，对应于十进制即为x10，也就实现了进位。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h5 id=&quot;小总结&quot;&gt;小总结&lt;/h5&gt;
&lt;p&gt;因此总结一下：&lt;br /&gt;
到这里，我们基本上拥有了这样两个表达式：&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;x^y //执行加法
(x&amp;amp;y)&amp;lt;&amp;lt;1 //进位操作
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;p&gt;因此，应我们上面的思路2，可以得到加法表达公式抽象为：&lt;strong&gt;a+b = a^b + (a&amp;amp;b)«1&lt;/strong&gt;，之后迭代或循环实现重复性操作即可。&lt;strong&gt;当进位为0的时候，+操作的某一个值就会是0，也就不用再重复计算了，算法停止。&lt;/strong&gt;&lt;br /&gt;
&lt;strong&gt;因此可以通过进位是0来判断结束。&lt;/strong&gt;&lt;br /&gt;
下面测试一下：&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;计算11+01=100，用推算的表达式：a^b=11^01=10，a&amp;amp;b=11&amp;amp;01=01，(a&amp;amp;b)&amp;lt;&amp;lt;1=01&amp;lt;&amp;lt;1=10，所以下述需要做的是10+10，但是我们不用普通的加法，即可以再执行一下**a+b = a^b + (a&amp;amp;b)&amp;lt;&amp;lt;1**，即a^b=10^10=00,a&amp;amp;b=10&amp;amp;10=10,(a&amp;amp;b)&amp;lt;&amp;lt;1=10&amp;lt;&amp;lt;1=100,加法操作的某一个值已经是0了，但是进位值为100，可以看看一会继续计算，进位会不会变成0，00+100，即00^100=100,000&amp;amp;100=000,000&amp;lt;&amp;lt;1=000,因此现在进位为0了，因此不用再计算了，即结果为100。
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;h3 id=&quot;代码&quot;&gt;代码&lt;/h3&gt;
&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;递归&lt;/p&gt;

    &lt;div class=&quot;language-java highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kd&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;kd&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Solution&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
 &lt;span class=&quot;cm&quot;&gt;/**
  * @param a: An integer
  * @param b: An integer
  * @return: The sum of a and b 
  */&lt;/span&gt;
 &lt;span class=&quot;kd&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;aplusb&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
     &lt;span class=&quot;c1&quot;&gt;// write your code here&lt;/span&gt;
     &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;==&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;){&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;
 &lt;span class=&quot;c1&quot;&gt;//没有进位的时候完成运算&lt;/span&gt;
         &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;
     &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
 &lt;span class=&quot;c1&quot;&gt;//加法、进位左移，传入参数完成递归&lt;/span&gt;
     &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;aplusb&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;^&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&amp;lt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;   
 &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;

    &lt;p&gt;一行递归:&lt;/p&gt;
    &lt;div class=&quot;language-java highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kd&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;kd&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Solution&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
 &lt;span class=&quot;cm&quot;&gt;/**
  * @param a: An integer
  * @param b: An integer
  * @return: The sum of a and b 
  */&lt;/span&gt;
 &lt;span class=&quot;kd&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;aplusb&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;==&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;?&lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;a:&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;aplusb&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;^&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&amp;lt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
 &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;while&lt;/p&gt;

    &lt;div class=&quot;language-java highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kd&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;kd&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Solution&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
 &lt;span class=&quot;cm&quot;&gt;/**
  * @param a: An integer
  * @param b: An integer
  * @return: The sum of a and b 
  */&lt;/span&gt;
 &lt;span class=&quot;kd&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;aplusb&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
     &lt;span class=&quot;c1&quot;&gt;// write your code here&lt;/span&gt;
   &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;^&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;
   &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;carry&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&amp;lt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;
   &lt;span class=&quot;k&quot;&gt;while&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;carry&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;!=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;){&lt;/span&gt;
       &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;
       &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;carry&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;
       &lt;span class=&quot;n&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;^&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;
       &lt;span class=&quot;n&quot;&gt;carry&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&amp;lt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;
   &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
   &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;
 &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;\\错误答案&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;四不像，不要&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;while&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;加递归，死循环了&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;：&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;\\&lt;/span&gt;&lt;span class=&quot;kd&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;kd&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Solution&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;\\&lt;/span&gt;    &lt;span class=&quot;kd&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;aplusb&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;\\&lt;/span&gt;        &lt;span class=&quot;c1&quot;&gt;// write your code here&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;\\&lt;/span&gt;        &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;^&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;\\&lt;/span&gt;        &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;carry&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&amp;lt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;\\&lt;/span&gt;        &lt;span class=&quot;k&quot;&gt;while&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;!=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;carry&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;){&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;\\&lt;/span&gt;            &lt;span class=&quot;n&quot;&gt;aplusb&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;carry&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;\\&lt;/span&gt;        &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;\\&lt;/span&gt;        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;\\&lt;/span&gt;    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;\\&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;do-while&lt;/p&gt;

    &lt;div class=&quot;language-java highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kd&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;kd&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Solution&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
 &lt;span class=&quot;cm&quot;&gt;/**
  * @param a: An integer
  * @param b: An integer
  * @return: The sum of a and b 
  */&lt;/span&gt;
 &lt;span class=&quot;kd&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;aplusb&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
     &lt;span class=&quot;c1&quot;&gt;// write your code here&lt;/span&gt;
     &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;
     &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;carry&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;
     &lt;span class=&quot;k&quot;&gt;do&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
         &lt;span class=&quot;n&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;^&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;
         &lt;span class=&quot;n&quot;&gt;carry&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&amp;lt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;
         &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;
         &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;carry&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;
     &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;while&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;carry&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;!=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
     &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;
 &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;拓展-交换2个数的值&quot;&gt;拓展-交换2个数的值&lt;/h2&gt;
&lt;div class=&quot;language-java highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kd&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;kd&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Test&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;kd&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;kd&quot;&gt;static&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;main&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;String&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;args&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[]){&lt;/span&gt;
        &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;20&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;^&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;^&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;^&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;System&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;out&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;println&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;\t&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h1 id=&quot;2018-06-11-169-汉诺塔问题&quot;&gt;2018-06-11-169-汉诺塔问题&lt;/h1&gt;
&lt;h2 id=&quot;题目-1&quot;&gt;题目&lt;/h2&gt;
&lt;p&gt;题目：汉诺塔问题（又称为河内塔问题），是一个大家熟知的问题。在A，B，C三根柱子上，有n个不同大小的圆盘（假设半径分别为1-n吧），一开始他们都叠在A上，你的目标是在最少的合法移动步数内将所有盘子从A塔移动到C塔。&lt;br /&gt;
游戏中的每一步规则如下：&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;每一步只允许移动一个盘子（从一根柱子最上方到另一个柱子的最上方）&lt;/li&gt;
  &lt;li&gt;移动的过程中，你必须保证大的盘子不能在小的盘子上方（小的可以放在大的上面，最大盘子下面不能有任何其他大小的盘子)&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;解答-1&quot;&gt;解答&lt;/h2&gt;
&lt;p&gt;递归实现:&lt;br /&gt;
三个位置，其中有一个时缓冲期，在这个题目里，从A移动到C，B是缓冲区。
当n=0时不用做任何动作；&lt;br /&gt;
当n&amp;gt;0时，&lt;br /&gt;
首先，将n-1个圆盘从A经C移动到B（移动到缓冲区）；&lt;br /&gt;
然后，即那个1个圆盘从A移动到C（起点到终点）；&lt;br /&gt;
最后，将n-1个圆盘从B经A移动到C（缓冲区到终点）。&lt;/p&gt;

&lt;div class=&quot;language-java highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kd&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;kd&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Solution&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;List&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;hanoi&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ArrayList&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;();&lt;/span&gt;
    &lt;span class=&quot;cm&quot;&gt;/**
     * @param n: the number of disks
     * @return: the order of moves
     */&lt;/span&gt;
    &lt;span class=&quot;kd&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;List&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;towerOfHanoi&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;c1&quot;&gt;// write your code here&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;move&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;A&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;B&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;C&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;hanoi&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
    
    &lt;span class=&quot;kd&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;move&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;String&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;start&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;String&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tmp&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;String&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;to&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;){&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;==&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;){&lt;/span&gt;
            
        &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;else&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;move&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;start&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;to&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tmp&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;String&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;moving&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;from &quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;start&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot; to &quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;to&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;hanoi&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;add&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;moving&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;move&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tmp&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;start&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;to&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
        &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
    
    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;至此，本篇内容暂时完成，以后随着更新。&lt;br /&gt;
如有问题，请发送邮件至leafming@foxmail.com联系我，谢谢～&lt;br /&gt;
©商业转载请联系作者获得授权，非商业转载请注明出处。&lt;/p&gt;</content><author><name>Liv Yeh</name></author><category term="Algorithm" /><summary type="html">本文主要关于lintcode 中的算法练习,以后有时间无聊了就来记录一道算法题目，以后随着更新吧，更新时间不定哦～ 2018-06-06-1-A+B问题 题目 给出两个整数a和b, 求他们的和, 但不能使用+等数学运算符。 说明 a和b都是32位整数么？-是 我可以使用位运算符么？-当然可以 样例 如果a=1并且b=2，返回3。 解答 所用知识点-java位运算 java里int型是4个字节，即32位，用二进制表示java里的1即000……0001，且都是有符号的数，最高位代表符号位，即32位能表示的最大整数是2的32次方-1。 &amp;amp; 与运算符 ：按位与，当且仅当两个对应的位置都是1，结果才是1，否则结果为0。(有0则0) | 或运算符 ：按位或，当且仅当两个对应的位置都是0，结果才是0，否则结果是1。(有1则1) ~ 非运算符 ：按位取反。 ^异或运算符 ：当运算符两边不同的时候结果为1，两边相同的时候结果为0。 位移运算符（同理）：位移运算符可以简单的理解为乘除法，像左移是除法，向右移是乘法。左移：在低位补0；右移：正数右移高位补0，负数右移高位补1。num1,相当于num乘以2;num1,相当于num除以2。82不要理解为8/2，位移两位就是除以2的2次方也就是8/4；注意91的结果是4，即最低位的1会移没了。 无符号右移 ：忽略符号位，空位都以0补齐。使用了“零扩展”：无论正负，都在高位插入0。valuenum–num 指定要移位值value 移动的位数。无符号右移运算符只是对32位和64位的值有意义。 位运算加法分析 本题目下述分析均参考或学习文章位运算-加法运算、交换两个数值。 思路分析 参考上述文章，是从最熟悉的十进制分析。 思路1:十进制加法计算过程从末尾到高位进行计算，基本上是同位数字相加，有进位的情况再加上进位，即每次计算的时候是某一位的2个数字相加，最多3个数字即再多加一个进位。如15+9，个位5+9=14，结果末尾数为4，进位1；十位即1+0+1（进位）=2，因此结果为24。 思路2:加法过程分为对应位数字相加结果和进位数字相加结果，再求2个结果的和，直到没有进位即为最终结果。再如15+9，5+9=4（个位），进位为1；1+0=1（十位），进位为0；即本位结果位14，进位为10；因此15+9即可转化为，14+10，即个位4+0=4，进位为0；十位1+1=2，进位为0；所以结果为24，进位结果是0，所以不用再计算，即可得出最终结果24。总结上诉，即将加法分为了对应位相加（不进位）和进位值2部分，再求2个结果和，并且之后重复计算，直到进位值为0。因此，可以发现停止计算的条件可以设置为进位值为0。 位运算分析 下面在二进制位运算层面实现。 二进制和十进制差别：逢十进一和逢二进一。 对应位相加，不进位-sum 在二进制中，则1位数相加，思考结果为： 0 + 0 = 0 0 + 1 = 1 1 + 0 = 1 1 + 1 = 0（不进位） 可以发现相同为0，不同为1，则当二进制的不进位加法，可以用异或^来表示。 0 ^ 0 = 0 0 ^ 1 = 1 1 ^ 0 = 1 1 ^ 1 = 0 因此，在二进制中，对应位置相加（本位操作）可以使用异或^符号来实现，即a^b。 进位-carry 如果进行情况下，如果获取进位，只得到进位值，进位值的结果，思考如下： 注意这里是只得到进位值 0 + 0 = 0 0 + 1 = 0 1 + 0 = 0 1 + 1 = 1 由此可看出，有0就为0，因此可以用位运算&amp;amp;来代替。 0 &amp;amp; 0 = 0 0 &amp;amp; 1 = 0 1 &amp;amp; 0 = 0 1 &amp;amp; 1 = 1 但是进位应该是进到高位，因此可以使用左移操作符将进位的1左进一位。 在位运算中，我们用“«”表示向左移动一位，也就是“进位”。 0«1 = 0，值还是0，1«1 = 10，值为2。 因此，进位可以如下表示： (x&amp;amp;y)&amp;lt;&amp;lt;1 tips：左移一位在二进制的意义可以理解为x2，对应于十进制即为x10，也就实现了进位。 小总结 因此总结一下： 到这里，我们基本上拥有了这样两个表达式： x^y //执行加法 (x&amp;amp;y)&amp;lt;&amp;lt;1 //进位操作 因此，应我们上面的思路2，可以得到加法表达公式抽象为：a+b = a^b + (a&amp;amp;b)«1，之后迭代或循环实现重复性操作即可。当进位为0的时候，+操作的某一个值就会是0，也就不用再重复计算了，算法停止。 因此可以通过进位是0来判断结束。 下面测试一下： 计算11+01=100，用推算的表达式：a^b=11^01=10，a&amp;amp;b=11&amp;amp;01=01，(a&amp;amp;b)&amp;lt;&amp;lt;1=01&amp;lt;&amp;lt;1=10，所以下述需要做的是10+10，但是我们不用普通的加法，即可以再执行一下**a+b = a^b + (a&amp;amp;b)&amp;lt;&amp;lt;1**，即a^b=10^10=00,a&amp;amp;b=10&amp;amp;10=10,(a&amp;amp;b)&amp;lt;&amp;lt;1=10&amp;lt;&amp;lt;1=100,加法操作的某一个值已经是0了，但是进位值为100，可以看看一会继续计算，进位会不会变成0，00+100，即00^100=100,000&amp;amp;100=000,000&amp;lt;&amp;lt;1=000,因此现在进位为0了，因此不用再计算了，即结果为100。 代码 递归 public class Solution { /** * @param a: An integer * @param b: An integer * @return: The sum of a and b */ public int aplusb(int a, int b) { // write your code here if(0==b){a //没有进位的时候完成运算 return a; } //加法、进位左移，传入参数完成递归 return aplusb(a^b,(a&amp;amp;b)&amp;lt;&amp;lt;1); } } 一行递归: public class Solution { /** * @param a: An integer * @param b: An integer * @return: The sum of a and b */ public int aplusb(int a, int b) { return b==0?a:aplusb(a^b,(a&amp;amp;b)&amp;lt;&amp;lt;1); } } while public class Solution { /** * @param a: An integer * @param b: An integer * @return: The sum of a and b */ public int aplusb(int a, int b) { // write your code here int sum=a^b; int carry=(a&amp;amp;b)&amp;lt;&amp;lt;1; while(carry!=0){ a=sum; b=carry; sum=a^b; carry=(a&amp;amp;b)&amp;lt;&amp;lt;1; } return sum; } } \\错误答案(四不像，不要while加递归，死循环了)： \\public class Solution { \\ public int aplusb(int a, int b) { \\ // write your code here \\ int sum=a^b; \\ int carry=(a&amp;amp;b)&amp;lt;&amp;lt;1; \\ while(0!=carry){ \\ aplusb(sum,carry); \\ } \\ return sum; \\ } \\} do-while public class Solution { /** * @param a: An integer * @param b: An integer * @return: The sum of a and b */ public int aplusb(int a, int b) { // write your code here int sum=0; int carry=0; do { sum=a^b; carry=(a&amp;amp;b)&amp;lt;&amp;lt;1; a=sum; b=carry; } while (carry!=0); return sum; } } 拓展-交换2个数的值 public class Test{ public static void main(String args[]){ int a=10;int b=20; a=a^b; b=b^a; a=a^b; System.out.println(a+&quot;\t&quot;+b); } } 2018-06-11-169-汉诺塔问题 题目 题目：汉诺塔问题（又称为河内塔问题），是一个大家熟知的问题。在A，B，C三根柱子上，有n个不同大小的圆盘（假设半径分别为1-n吧），一开始他们都叠在A上，你的目标是在最少的合法移动步数内将所有盘子从A塔移动到C塔。 游戏中的每一步规则如下： 每一步只允许移动一个盘子（从一根柱子最上方到另一个柱子的最上方） 移动的过程中，你必须保证大的盘子不能在小的盘子上方（小的可以放在大的上面，最大盘子下面不能有任何其他大小的盘子) 解答 递归实现: 三个位置，其中有一个时缓冲期，在这个题目里，从A移动到C，B是缓冲区。 当n=0时不用做任何动作； 当n&amp;gt;0时， 首先，将n-1个圆盘从A经C移动到B（移动到缓冲区）； 然后，即那个1个圆盘从A移动到C（起点到终点）； 最后，将n-1个圆盘从B经A移动到C（缓冲区到终点）。 public class Solution { List &amp;lt;String&amp;gt; hanoi=new ArrayList(); /** * @param n: the number of disks * @return: the order of moves */ public List&amp;lt;String&amp;gt; towerOfHanoi(int n) { // write your code here move(n,&quot;A&quot;,&quot;B&quot;,&quot;C&quot;); return hanoi; } public void move(int n,String start, String tmp,String to){ if (n==0){ }else{ move(n-1,start,to,tmp); String moving=&quot;from &quot;+start+&quot; to &quot;+to; hanoi.add(moving); move(n-1,tmp,start,to); } } }</summary></entry><entry><title type="html">HDFS权限以及目录限额相关</title><link href="http://localhost:4000/bigdata/2018/06/04/HDFS%E6%9D%83%E9%99%90%E4%BB%A5%E5%8F%8A%E7%9B%AE%E5%BD%95%E9%99%90%E9%A2%9D%E7%9B%B8%E5%85%B3/" rel="alternate" type="text/html" title="HDFS权限以及目录限额相关" /><published>2018-06-04T00:00:00+08:00</published><updated>2018-06-04T00:00:00+08:00</updated><id>http://localhost:4000/bigdata/2018/06/04/HDFS%E6%9D%83%E9%99%90%E4%BB%A5%E5%8F%8A%E7%9B%AE%E5%BD%95%E9%99%90%E9%A2%9D%E7%9B%B8%E5%85%B3</id><content type="html" xml:base="http://localhost:4000/bigdata/2018/06/04/HDFS%E6%9D%83%E9%99%90%E4%BB%A5%E5%8F%8A%E7%9B%AE%E5%BD%95%E9%99%90%E9%A2%9D%E7%9B%B8%E5%85%B3/">&lt;blockquote&gt;
  &lt;p&gt;本文主要关于HDFS的用户权限设置以及目录的限额控制的总结。本文主要分3部分进行总结，1为HDFS的用户权限设置，2为目录的限额控制，最后简单说明一下单纯使用HDFS ACL可能造成的安全隐患。&lt;br /&gt;
&lt;strong&gt;注意: 本文中使用的版本是Hadoop 2.6.0-cdh5.11.0&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;平台中需要对于使用租户的权限以及所用文件空间进行控制，所以查找了关于HDFS用户权限以及目录限额控制的相关方法和权限控制JAVA API，并且翻阅源码的时候也找到了相关HDFS存储限额控制的JAVA API，过了这么长时间今天终于想起来要总结一下。不过有点需要注明，目前为止单纯的使用HDFS ACL控制权限有用户伪造的隐患，此种隐患会在本文最后进行说明。&lt;/p&gt;

&lt;p&gt;#&lt;/p&gt;

&lt;p&gt;至此，本篇内容完成。&lt;br /&gt;
如有问题，请发送邮件至leafming@foxmail.com联系我，谢谢～&lt;br /&gt;
©商业转载请联系作者获得授权，非商业转载请注明出处。&lt;/p&gt;</content><author><name>Liv Yeh</name></author><category term="Hadoop" /><summary type="html">本文主要关于HDFS的用户权限设置以及目录的限额控制的总结。本文主要分3部分进行总结，1为HDFS的用户权限设置，2为目录的限额控制，最后简单说明一下单纯使用HDFS ACL可能造成的安全隐患。 注意: 本文中使用的版本是Hadoop 2.6.0-cdh5.11.0 平台中需要对于使用租户的权限以及所用文件空间进行控制，所以查找了关于HDFS用户权限以及目录限额控制的相关方法和权限控制JAVA API，并且翻阅源码的时候也找到了相关HDFS存储限额控制的JAVA API，过了这么长时间今天终于想起来要总结一下。不过有点需要注明，目前为止单纯的使用HDFS ACL控制权限有用户伪造的隐患，此种隐患会在本文最后进行说明。 # 至此，本篇内容完成。 如有问题，请发送邮件至leafming@foxmail.com联系我，谢谢～ ©商业转载请联系作者获得授权，非商业转载请注明出处。</summary></entry><entry><title type="html">spark日志相关内容</title><link href="http://localhost:4000/bigdata/2018/05/21/spark%E6%97%A5%E5%BF%97%E7%9B%B8%E5%85%B3%E5%86%85%E5%AE%B9/" rel="alternate" type="text/html" title="spark日志相关内容" /><published>2018-05-21T00:00:00+08:00</published><updated>2018-05-21T00:00:00+08:00</updated><id>http://localhost:4000/bigdata/2018/05/21/spark%E6%97%A5%E5%BF%97%E7%9B%B8%E5%85%B3%E5%86%85%E5%AE%B9</id><content type="html" xml:base="http://localhost:4000/bigdata/2018/05/21/spark%E6%97%A5%E5%BF%97%E7%9B%B8%E5%85%B3%E5%86%85%E5%AE%B9/">&lt;blockquote&gt;
  &lt;p&gt;本文主要关于spark日志相关的部分内容，包括spark日志位置以及其中一种&amp;gt;日志配置方法，后续可再对本文进行其他配置方法的补充。&lt;br /&gt;
&lt;strong&gt;注意: 本文中使用的版本是spark2.2.1&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;最近平台中某租户使用的容器化集群spark集群，提交的spark  streaming任务的日志没有进行级别控制，疯狂的刷日志，导致会占满宿主机的存储空间，并且集群均使用的是standalone模式，没有配置删除日志，所以日志太多会影响同一个宿主机下其他租户spark的使用。因此，在今天进行了一下集群的全局配置，直接将日志级别进行了更改，并且也趁这个时间，总结下对于spark日志相关的部分内容，后续有时间再进行其他补充。&lt;/p&gt;

&lt;h1 id=&quot;spark应用程序运行日志的存放&quot;&gt;Spark应用程序运行日志的存放&lt;/h1&gt;
&lt;p&gt;在很多情况下，我们需要查看driver和executor在运行spark程序时候产生的日志，以便于我们调试和查找问题。&lt;/p&gt;
&lt;h2 id=&quot;driver端日志&quot;&gt;Driver端日志&lt;/h2&gt;
&lt;p&gt;Spark Driver端的日志在默认情况下是直接输出在控制台的，driver本身没有stderr和stdout文件，所以只能在控制台输出。不过可以通过配置，将日志打印到文件中，具体配置方式后续再进行说明。&lt;/p&gt;
&lt;h2 id=&quot;executor端日志&quot;&gt;Executor端日志&lt;/h2&gt;
&lt;p&gt;Spark Executor日志的存放位置，是与Spark的部署模式相关的；Spark目前3种部署方式：Spark Standalone、Mesos、YARN。&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;Spark Standalone模式：在spark standalone的部署模式下，可以直接在Master UI界面查看到相应的应用程序的日志，如下图。其中可以看到是有stderr和stdout两种日志，区别就是如果你在程序中使用了println(….)输出语句，并且位置是在executor端执行的，这些信息会在stdout文件里面显示，而在driver端执行的会直接在控制台输出；其余的Spark运行日志会在stderr文件里面显示。&lt;br /&gt;
&lt;img src=&quot;https://github.com/leafming/bak/blob/master/images/spark/2018-05-21-sparkStandaloneLogUI.png?raw=true&quot; alt=&quot;standaloneUI日志&quot; /&gt;&lt;br /&gt;
通常，每个job的详细日志输出是在每个worker（slave）节点的work目录下，这个目录可以通过spark-env.sh下配置SPARK_WORKER_DIR参数（Directory to run applications in, which will include both logs and scratch space，默认情况下是SPARK_HOME/work）设置。&lt;br /&gt;
&lt;img src=&quot;https://github.com/leafming/bak/blob/master/images/spark/2018-05-23-work目录下内容.png?raw=true&quot; alt=&quot;work目录下内容&quot; /&gt;&lt;br /&gt;
此部分，可以进行worker配置使日志自动删除，详情见后续“配置日志”部分。&lt;/li&gt;
  &lt;li&gt;Mesos模式：在Mesos模式下，也可以通过Mesos的Master UI界面上看到相关的应用程序日志，这些日志是存储在Mesos Slave的work目录下的，通常情况下通过修改mesos-slave-env.sh或mesos-master-env.sh文件下的MESOS_log_dir参数和MESOS_work_dir参数可以设置slave或master的日志目录和工作目录，默认情况下是master和slave的logs都在/var/log/mesos下。&lt;/li&gt;
  &lt;li&gt;YARN模式：在yarn模式下，executor和application master都运行在“containers”内。&lt;br /&gt;
YARN在一个application结束后，有2种处理容器内日志的方式。
    &lt;ol&gt;
      &lt;li&gt;其中在yarn模式下，最简单的收集日志的方式是使用Yarn的日志收集工具(yarn logs -applicationId &lt;app ID=&quot;&quot;&gt;)，这个工具可以收集应用程序的相关日志，但是要求:a.开启了日志聚合功能（yarn.log-aggregation-enable，默认情况下这参数是false）；b.application必须运行完，因为yarn必须先聚合这些日志。这种情况下，容器日志将被复制到HDFS，并删除本地日志，从而腾出更多空间。这样的话，这些日志可以在集群任何节点上用yarn logs命令查看：yarn logs -applicationId &lt;app ID=&quot;&quot;&gt;，用这个命令会打印出指定应用的所有日志文件的内容，或者也可以直接在HDFS上查看这些日志（HDFS shell或者HDFS API）。这个目录的配置可以在YARN配置中指定（yarn.nodemanager.remote-app-log-dir和yarn.nodemanager.remote-app-log-dir-suffix）。这些日志同样还可以在Spark Web UI上Executors页查看，但是也有前提，需要启动Spark history server和MapReduce history server，再在yarn-site.xml中配置好yarn.log.server.url。Spark history server UI将把你重定向到MapReduce history server以查看这些聚合日志。&lt;/app&gt;&lt;/app&gt;&lt;/li&gt;
      &lt;li&gt;如果日志聚合没有开启，那么日志文件将在每台机器上的YARN_APP_LOGS_DIR目录保留，通常这个目录指向NodeManager节点(ResourceManager节点下没输出)的/tmp/logs或者$HADOOP_HOME/log/userlogs（这取决于Hadoop版本和安全方式）。查看日志的话，需要到每台机器上查看这些目录。子目录是按application ID和container ID来组织的。这些日志同样可以在 Spark Web UI上Executors页查看，而且这时你不需要运行MapReduce history server。这里还有一个需要注意的地方，在没有开启日志聚合的时候，有一个参数yarn.nodemanager.log.retain-seconds，这个参数指应用程序输入出日志的保存时间，默认是10800，单位s，也就是3个小时，所以有可能超过时间再去查看日志的时候，原来的运行日志就自动删除了。&lt;br /&gt;
额外补充：在yarn模式下，kill掉某个job（直接在UI界面或者是终端kill掉任务都是不对的，该任务可能还会继续执行下去，所以要用如下命令才算完全停止该job的执行），yarn application -kill &lt;app ID=&quot;&quot;&gt;。&lt;/app&gt;&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h1 id=&quot;配置日志&quot;&gt;配置日志&lt;/h1&gt;
&lt;h2 id=&quot;standalone日志自动删除配置&quot;&gt;Standalone日志自动删除配置&lt;/h2&gt;
&lt;p&gt;目前，在使用中，平台中的容器化的spark集群因为资源已经由docker+mesos+marathon控制了，一个集群只有一个租户使用，因此均是standalone模式部署的，不过在使用过程中，应用程序日志不会自动删除会占很大空间，因此进行了worker配置，使日志自动删除。&lt;br /&gt;
其中，更改了conf/spark-env.sh，设置SPARK_WORKER_OPTS，即在文件内增加：&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;export SPARK_WORKER_OPTS=&quot;-Dspark.worker.cleanup.enabled=true -Dspark.worker.cleanup.interval=3600 -Dspark.worker.cleanup.appDataTtl=604800 -Dspark.worker.ui.compressedLogFileLengthCacheSize=100&quot;  
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;p&gt;参数解释：&lt;br /&gt;
(1)spark.worker.cleanup.enabled（默认false）：仅在standalone模式下生效，开启后定期清理worker节点的worker目录下的应用程序日志，并且仅会清理已经停止的application日志。Enable periodic cleanup of worker / application directories. Note that this only affects standalone mode, as YARN works differently. Only the directories of stopped applications are cleaned up.&lt;br /&gt;
(2)spark.worker.cleanup.interval（默认1800）：清理频率。Controls the interval, in seconds, at which the worker cleans up old application work dirs on the local machine.&lt;br /&gt;
(3)spark.worker.cleanup.appDataTtl（604800(7days,7&lt;em&gt;24&lt;/em&gt;3600)）：The number of seconds to retain application work directories on each worker. This is a Time To Live and should depend on the amount of available disk space you have. Application logs and jars are downloaded to each application work dir. Over time, the work dirs can quickly fill up disk space, especially if you run jobs very frequently.&lt;br /&gt;
(4)spark.worker.ui.compressedLogFileLengthCacheSize（默认100）：For compressed log files, the uncompressed file can only be computed by uncompressing the files. Spark caches the uncompressed file size of compressed log files. This property controls the cache size.&lt;/p&gt;

&lt;h2 id=&quot;调试屏蔽日志&quot;&gt;调试屏蔽日志&lt;/h2&gt;
&lt;p&gt;我们通常会使用IDE（例如Intellij IDEA）开发Spark应用，而程序调试运行时会在控制台中打印出所有的日志信息。它描述了（伪）集群运行、程序执行的所有行为。在很多情况下，这些信息对于我们来说是无关紧要的，我们更关心的是最终结果，无论是正常输出还是异常停止。我们可以通过log4j主动控制日志输出的级别。引入log4j.Logger和log4j.Level，并在对象中设置Logger.getLogger(“org”).setLevel(Level.ERROR)，其中getLogger(class)的参数用途是追踪产生此日志的类。&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;import org.apache.log4j.{Level, Logger}
Logger.getLogger(&quot;org.apache.spark&quot;).setLevel(Level.WARN)
Logger.getLogger(&quot;org.eclipse.jetty.server&quot;).setLevel(Level.OFF)
Logger.getLogger(&quot;kafka.utils.VerifiableProperties&quot;).setLevel(Level.WARN)
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;p&gt;这样的话，就可以看到我们关心的信息了。&lt;br /&gt;
补充说明参考：&lt;a href=&quot;https://blog.csdn.net/lixwjava/article/details/45950559&quot;&gt;使用一个类Log4jUtils来专门处理Logger对象的声明等操作&lt;/a&gt;。&lt;/p&gt;
&lt;h2 id=&quot;spark日志级别设置-log4j&quot;&gt;spark日志级别设置-log4j&lt;/h2&gt;
&lt;p&gt;在默认情况下，Spark应用程序的日志级别是INFO的，我们可以自定义Spark应用程序的日志输出级别，其中可以有多种方式：&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;局部应用设置：&lt;br /&gt;
针对SparkContext应用，Spark有专门的api设置日志级别，即sc.setLogLevel(级别)，但是此方法只针对SparkContext相关的应用，而对Spark-streaming等应用无效果。&lt;/li&gt;
  &lt;li&gt;局部应用设置：&lt;br /&gt;
自己写一个log4j.properties文件，在里面设置日志级别，如：
    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;# Set everything to be logged to the console
log4j.rootCategory=WARN, console
log4j.appender.console=org.apache.log4j.ConsoleAppender
log4j.appender.console.target=System.err
log4j.appender.console.layout=org.apache.log4j.PatternLayout
log4j.appender.console.layout.ConversionPattern=%d{yy/MM/dd HH:mm:ss} %p %c{1}: %m%n
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
    &lt;p&gt;这个文件设置了Spark应用程序在运行的时候会打出WARN级别的日志，然后在spark-submit提交应用程序的时候，通过–files参数，指定上述log4j.properties的文件路径，上传后即可即可使用这个配置打印应用程序的日志。&lt;br /&gt;
问题：Note that for the first option, both executors and the application master will share the same log4j configuration, which may cause issues when they run on the same node (e.g. trying to write to the same log file).&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;局部应用设置：&lt;br /&gt;
在spark-submit的时候，在spark.driver.extraJavaOptions（对Spark Driver）或者spark.executor.extraJavaOptions（对SparkExecutor）增加 -Dlog4j.configuration=&lt;location of=&quot;&quot; configuration=&quot;&quot; file=&quot;&quot;&gt;。但是在这里需要注意2个问题：如果使用了文件，需要protocol should be explicitly provided；并且这个文件需要存在在所有的节点上（and the file needs to exist locally on all the nodes）。&lt;/location&gt;&lt;/li&gt;
  &lt;li&gt;集群全局配置：&lt;br /&gt;
针对集群的log级别更改，可以到$SPARK_HOME/conf/log4j.properties文件里面进行修改，比如：
    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;# Set everything to be logged to the console
log4j.rootCategory=WARN, console
log4j.appender.console=org.apache.log4j.ConsoleAppender
log4j.appender.console.target=System.err
log4j.appender.console.layout=org.apache.log4j.PatternLayout
log4j.appender.console.layout.ConversionPattern=%d{yy/MM/dd HH:mm:ss} %p %c{1}: %m%n
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
    &lt;p&gt;这样设置，即进行了全局日志的设置。&lt;br /&gt;
在standalone模式下，如果不进行配置，集群默认使用的是org/apache/spark/log4j-defaults.properties配置，配置的话则如上操作。但是，如果在全局设置了之后，会同时生效Driver端和Executor端的日志级别。&lt;br /&gt;
这次我在更改容器内集群的配置日志级别配置的时候，就是用的此种方式，但是在集群中运行的程序，会通过driver端输出Info日志来表示程序运行的状态，而executor端确实是不需要关注Info日志的内容，因此需要进行driver端和executor端日志分离的情况操作，详情见下下述“Spark Streaming中应用日志的切分”的操作。&lt;/p&gt;
    &lt;h2 id=&quot;log4j其他配置&quot;&gt;log4j其他配置&lt;/h2&gt;
    &lt;p&gt;在yarn模式下：&lt;br /&gt;
If you need a reference to the proper location to put log files in the YARN so that YARN can properly display and aggregate them, use spark.yarn.app.container.log.dir in your log4j.properties. For example,&lt;/p&gt;
    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; log4j.appender.file_appender.File=${spark.yarn.app.container.log.dir}/spark.log
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
    &lt;p&gt;For streaming applications, configuring RollingFileAppender and setting file location to YARN’s log directory will avoid disk overflow caused by large log files, and logs can be accessed using YARN’s log utility.&lt;br /&gt;
翻译：&lt;br /&gt;
如果你需要引用YARN放置日志文件的路径，以便YARN可以正确地展示和聚合日志，请在log4j.properties文件中使用spark.yarn.app.container.log.dir。例如，&lt;/p&gt;
    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;log4j.appender.file_appender.File=${spark.yarn.app.container.log.dir}/spark.log
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
    &lt;p&gt;对于流式应用，可以配置RollingFileAppender，并将文件路径设置为YARN日志目录，以避免磁盘打满，而且这些日志还可以利用YARN的日志工具访问和查看。&lt;/p&gt;
    &lt;h2 id=&quot;spark-streaming中应用的日志切分&quot;&gt;Spark Streaming中应用的日志切分&lt;/h2&gt;
    &lt;p&gt;目前我们所用的集群是standalone模式，在Spark Standalone模式下，spark默认使用org/apache/spark/log4j-defaults.properties配置，所有的日志都记录在stderr里面，由于Spark Streaming应用程序是一直运行的，时间长了以后stderr文件会非常大，占用空间的同时难以让我们调试和定位问题，所以我们需要切分日志，spark原生提供了对Executor日志的切分，Driver日志需要我们单独配置log4j。&lt;/p&gt;
    &lt;h3 id=&quot;executor端日志切分在spark应用环境变量中配置&quot;&gt;Executor端日志切分，在spark应用环境变量中配置：&lt;/h3&gt;
    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;spark.executor.logs.rolling.strategy  time  //可以按日期（time）和日志大小(size)来切分日志
spark.executor.logs.rolling.time.interval daily  //可以按天、小时、分钟切分
spark.executor.logs.rolling.maxRetainedFiles 7  //保留多少个日志文件，旧的日志自动删除
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
    &lt;p&gt;或者也可以自定义日志生成方式，同上述3方法，只要配置参数spark.executor.extraJavaOptions，指定log4j配置。&lt;/p&gt;
    &lt;h3 id=&quot;driver日志切分&quot;&gt;Driver日志切分&lt;/h3&gt;
    &lt;p&gt;spark-submit的时候自定义log4j，–driver-java-options “-Dlog4j.configuration=file:/路径/log4j-driver.properties -Dapp.logging.name=NAME” ，app.logging.name在log4j文件里面配置了，用NAME去区分不同spark应用。&lt;/p&gt;
    &lt;h4 id=&quot;使用示例-driver端单独设置log4j配置并且设置额外输出日志到文件中&quot;&gt;使用示例-Driver端单独设置log4j配置，并且设置额外输出日志到文件中：&lt;/h4&gt;
    &lt;p&gt;背景：&lt;br /&gt;
集群中的日志级别设置的是WRAN，但是程序中Driver端的日志需要输出INFO级别的日志并且显示在控制台上，因此使用此方法进行了Driver端的日志级别单独设置。并且对于Driver端的日志，如果不进行设置的话，均会输出到控制台中，因此通过设置，尝试将日志输出到文件（&lt;strong&gt;这里需要注意的是，log4j的控制仅仅针对于的是日志，对于在程序里执行的print语句，仍然会输出到控制台中，并不会输出到定义的日志文件&lt;/strong&gt;）。  &lt;br /&gt;
log4j文件设置：&lt;/p&gt;
    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;#
# Licensed to the Apache Software Foundation (ASF) under one or more
# contributor license agreements.  See the NOTICE file distributed with
# this work for additional information regarding copyright ownership.
# The ASF licenses this file to You under the Apache License, Version 2.0
# (the &quot;License&quot;); you may not use this file except in compliance with
# the License.  You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
log4j.rootCategory=INFO, console,FILE
# 针对控制台设置：Set everything to be logged to the console
log4j.appender.console=org.apache.log4j.ConsoleAppender
log4j.appender.console.target=System.err
log4j.appender.console.layout=org.apache.log4j.PatternLayout
log4j.appender.console.layout.ConversionPattern=%d{yy/MM/dd HH:mm:ss} %p %c{1}: %m%n
# 针对日志输出到FILE
log4j.appender.FILE=org.apache.log4j.FileAppender
log4j.appender.FILE.Threshold=DEBUG
# 输出到的日志路径：${app.logging.name}为外部引入的应用名称来定义日志文件的名字
log4j.appender.FILE.file=/usr/tools/logs/${app.logging.name}-driver.log
log4j.appender.FILE.layout=org.apache.log4j.PatternLayout
log4j.appender.FILE.layout.ConversionPattern=%d{yy/MM/dd HH:mm:ss} %p %c{1}: %m%n
# Set the default spark-shell log level to WARN. When running the spark-shell, the
# log level for this class is used to overwrite the root logger's log level, so that
# the user can have different defaults for the shell and regular Spark apps.
log4j.logger.org.apache.spark.repl.Main=WARN
# Settings to quiet third party logs that are too verbose
log4j.logger.org.spark_project.jetty=WARN
log4j.logger.org.spark_project.jetty.util.component.AbstractLifeCycle=ERROR
log4j.logger.org.apache.spark.repl.SparkIMain$exprTyper=WARN
log4j.logger.org.apache.spark.repl.SparkILoop$SparkILoopInterpreter=WARN
log4j.logger.org.apache.parquet=ERROR
log4j.logger.parquet=ERROR
# SPARK-9183: Settings to avoid annoying messages when looking up nonexistent UDFs in SparkSQL with Hive support
log4j.logger.org.apache.hadoop.hive.metastore.RetryingHMSHandler=FATAL
log4j.logger.org.apache.hadoop.hive.ql.exec.FunctionRegistry=ERROR
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
    &lt;p&gt;提交命令：&lt;/p&gt;
    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;spark-submit --master spark://master01:7077,master02:7077 --jars /usr/tools/spark_234gsignalling/sparkStreamingKafka0.8-0.10Jars/spark-streaming-kafka-0-8_2.11-2.2.1.jar,/usr/tools/spark_234gsignalling/sparkStreamingKafka0.8-0.10Jars/kafka_2.11-0.8.2.1.jar,/usr/tools/spark_234gsignalling/sparkStreamingKafka0.8-0.10Jars/metrics-core-2.2.0.jar,/usr/tools/spark_234gsignalling/sparkStreamingKafka0.8-0.10Jars/kafka-clients-0.10.1.1.jar --files &quot;/usr/tools/spark_234gsignalling/kafka_client_jaas.conf&quot; --driver-java-options &quot;-Dlog4j.configuration=file:/usr/tools/spark_234gsignalling/log4j4g.properties -Dapp.logging.name=NAME&quot; --driver-memory 2g --total-executor-cores 36 --executor-cores 2 --executor-memory 10g --class com.sitech.signallingStreaming.Signalling234gMask 4gsignallingSpark-0.10kafka-c60.jar skhconf_4g hdfs://dcoshdfs/spark_log/4g_info_c60log
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
    &lt;p&gt;提交命令中对于此次日志设置的主要是：&lt;/p&gt;
    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;--driver-java-options &quot;-Dlog4j.configuration=file:/usr/tools/spark_234gsignalling/log4j4g.properties -Dapp.logging.name=NAME&quot;
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;参考文章：&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.iteblog.com/archives/1353.html&quot;&gt;Spark应用程序运行的日志存在哪里&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://blog.csdn.net/dylanzhouz/article/details/53098508&quot;&gt;sparkstreaming日志切分配置&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://bit1129.iteye.com/blog/2186358&quot;&gt;spark日志log4j配置-控制台+文件同时输出&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.cnblogs.com/sorco/p/7070922.html&quot;&gt;spark深入：配置文件与日志(yarn)&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.cnblogs.com/likui360/p/7992982.html&quot;&gt;log4j配置1&lt;/a&gt;,&lt;a href=&quot;https://blog.csdn.net/sinat_30185177/article/details/73550377&quot;&gt;log4j配置2&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://spark.apache.org/docs/2.2.1/running-on-yarn.html&quot;&gt;spark2.2-yarn&lt;/a&gt;,&lt;a href=&quot;http://spark.apache.org/docs/2.2.1/spark-standalone.html&quot;&gt;spark2.2-standalone&lt;/a&gt;,&lt;a href=&quot;http://spark.apache.org/docs/2.2.1/running-on-mesos.html&quot;&gt;spark2.2-mesos&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;至此，本篇内容完成。&lt;br /&gt;
如有问题，请发送邮件至leafming@foxmail.com联系我，谢谢～&lt;br /&gt;
©商业转载请联系作者获得授权，非商业转载请注明出处。&lt;/p&gt;</content><author><name>Liv Yeh</name></author><category term="Spark" /><summary type="html">本文主要关于spark日志相关的部分内容，包括spark日志位置以及其中一种&amp;gt;日志配置方法，后续可再对本文进行其他配置方法的补充。 注意: 本文中使用的版本是spark2.2.1 最近平台中某租户使用的容器化集群spark集群，提交的spark streaming任务的日志没有进行级别控制，疯狂的刷日志，导致会占满宿主机的存储空间，并且集群均使用的是standalone模式，没有配置删除日志，所以日志太多会影响同一个宿主机下其他租户spark的使用。因此，在今天进行了一下集群的全局配置，直接将日志级别进行了更改，并且也趁这个时间，总结下对于spark日志相关的部分内容，后续有时间再进行其他补充。 Spark应用程序运行日志的存放 在很多情况下，我们需要查看driver和executor在运行spark程序时候产生的日志，以便于我们调试和查找问题。 Driver端日志 Spark Driver端的日志在默认情况下是直接输出在控制台的，driver本身没有stderr和stdout文件，所以只能在控制台输出。不过可以通过配置，将日志打印到文件中，具体配置方式后续再进行说明。 Executor端日志 Spark Executor日志的存放位置，是与Spark的部署模式相关的；Spark目前3种部署方式：Spark Standalone、Mesos、YARN。 Spark Standalone模式：在spark standalone的部署模式下，可以直接在Master UI界面查看到相应的应用程序的日志，如下图。其中可以看到是有stderr和stdout两种日志，区别就是如果你在程序中使用了println(….)输出语句，并且位置是在executor端执行的，这些信息会在stdout文件里面显示，而在driver端执行的会直接在控制台输出；其余的Spark运行日志会在stderr文件里面显示。 通常，每个job的详细日志输出是在每个worker（slave）节点的work目录下，这个目录可以通过spark-env.sh下配置SPARK_WORKER_DIR参数（Directory to run applications in, which will include both logs and scratch space，默认情况下是SPARK_HOME/work）设置。 此部分，可以进行worker配置使日志自动删除，详情见后续“配置日志”部分。 Mesos模式：在Mesos模式下，也可以通过Mesos的Master UI界面上看到相关的应用程序日志，这些日志是存储在Mesos Slave的work目录下的，通常情况下通过修改mesos-slave-env.sh或mesos-master-env.sh文件下的MESOS_log_dir参数和MESOS_work_dir参数可以设置slave或master的日志目录和工作目录，默认情况下是master和slave的logs都在/var/log/mesos下。 YARN模式：在yarn模式下，executor和application master都运行在“containers”内。 YARN在一个application结束后，有2种处理容器内日志的方式。 其中在yarn模式下，最简单的收集日志的方式是使用Yarn的日志收集工具(yarn logs -applicationId )，这个工具可以收集应用程序的相关日志，但是要求:a.开启了日志聚合功能（yarn.log-aggregation-enable，默认情况下这参数是false）；b.application必须运行完，因为yarn必须先聚合这些日志。这种情况下，容器日志将被复制到HDFS，并删除本地日志，从而腾出更多空间。这样的话，这些日志可以在集群任何节点上用yarn logs命令查看：yarn logs -applicationId ，用这个命令会打印出指定应用的所有日志文件的内容，或者也可以直接在HDFS上查看这些日志（HDFS shell或者HDFS API）。这个目录的配置可以在YARN配置中指定（yarn.nodemanager.remote-app-log-dir和yarn.nodemanager.remote-app-log-dir-suffix）。这些日志同样还可以在Spark Web UI上Executors页查看，但是也有前提，需要启动Spark history server和MapReduce history server，再在yarn-site.xml中配置好yarn.log.server.url。Spark history server UI将把你重定向到MapReduce history server以查看这些聚合日志。 如果日志聚合没有开启，那么日志文件将在每台机器上的YARN_APP_LOGS_DIR目录保留，通常这个目录指向NodeManager节点(ResourceManager节点下没输出)的/tmp/logs或者$HADOOP_HOME/log/userlogs（这取决于Hadoop版本和安全方式）。查看日志的话，需要到每台机器上查看这些目录。子目录是按application ID和container ID来组织的。这些日志同样可以在 Spark Web UI上Executors页查看，而且这时你不需要运行MapReduce history server。这里还有一个需要注意的地方，在没有开启日志聚合的时候，有一个参数yarn.nodemanager.log.retain-seconds，这个参数指应用程序输入出日志的保存时间，默认是10800，单位s，也就是3个小时，所以有可能超过时间再去查看日志的时候，原来的运行日志就自动删除了。 额外补充：在yarn模式下，kill掉某个job（直接在UI界面或者是终端kill掉任务都是不对的，该任务可能还会继续执行下去，所以要用如下命令才算完全停止该job的执行），yarn application -kill 。 配置日志 Standalone日志自动删除配置 目前，在使用中，平台中的容器化的spark集群因为资源已经由docker+mesos+marathon控制了，一个集群只有一个租户使用，因此均是standalone模式部署的，不过在使用过程中，应用程序日志不会自动删除会占很大空间，因此进行了worker配置，使日志自动删除。 其中，更改了conf/spark-env.sh，设置SPARK_WORKER_OPTS，即在文件内增加： export SPARK_WORKER_OPTS=&quot;-Dspark.worker.cleanup.enabled=true -Dspark.worker.cleanup.interval=3600 -Dspark.worker.cleanup.appDataTtl=604800 -Dspark.worker.ui.compressedLogFileLengthCacheSize=100&quot; 参数解释： (1)spark.worker.cleanup.enabled（默认false）：仅在standalone模式下生效，开启后定期清理worker节点的worker目录下的应用程序日志，并且仅会清理已经停止的application日志。Enable periodic cleanup of worker / application directories. Note that this only affects standalone mode, as YARN works differently. Only the directories of stopped applications are cleaned up. (2)spark.worker.cleanup.interval（默认1800）：清理频率。Controls the interval, in seconds, at which the worker cleans up old application work dirs on the local machine. (3)spark.worker.cleanup.appDataTtl（604800(7days,7243600)）：The number of seconds to retain application work directories on each worker. This is a Time To Live and should depend on the amount of available disk space you have. Application logs and jars are downloaded to each application work dir. Over time, the work dirs can quickly fill up disk space, especially if you run jobs very frequently. (4)spark.worker.ui.compressedLogFileLengthCacheSize（默认100）：For compressed log files, the uncompressed file can only be computed by uncompressing the files. Spark caches the uncompressed file size of compressed log files. This property controls the cache size.</summary></entry><entry><title type="html">机器学习入门自学-描述统计学入门2</title><link href="http://localhost:4000/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/2018/05/16/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%E8%87%AA%E5%AD%A6-%E6%8F%8F%E8%BF%B0%E7%BB%9F%E8%AE%A1%E5%AD%A6%E5%85%A5%E9%97%A82/" rel="alternate" type="text/html" title="机器学习入门自学-描述统计学入门2" /><published>2018-05-16T00:00:00+08:00</published><updated>2018-05-16T00:00:00+08:00</updated><id>http://localhost:4000/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/2018/05/16/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%E8%87%AA%E5%AD%A6-%E6%8F%8F%E8%BF%B0%E7%BB%9F%E8%AE%A1%E5%AD%A6%E5%85%A5%E9%97%A82</id><content type="html" xml:base="http://localhost:4000/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/2018/05/16/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%E8%87%AA%E5%AD%A6-%E6%8F%8F%E8%BF%B0%E7%BB%9F%E8%AE%A1%E5%AD%A6%E5%85%A5%E9%97%A82/">&lt;blockquote&gt;
  &lt;p&gt;本文关于自学udacity机器学习课程的自学笔记，为第一部分，描述统计学入门(2)。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h1 id=&quot;2018-05-16-可变性&quot;&gt;2018-05-16-可变性&lt;/h1&gt;
&lt;p&gt;&lt;strong&gt;范围(值域)&lt;/strong&gt;是观察到的最大值和最小值之间的差。&lt;br /&gt;
值域不包括细节信息，因为值域是仅仅在2个数据的基础上得出的。&lt;br /&gt;
异常数值增大差异性，值域作为度量标准时，有异常数值，值域不可能准确的代表数据的差异性。&lt;/p&gt;

&lt;h2 id=&quot;忽略尾部&quot;&gt;忽略尾部&lt;/h2&gt;
&lt;p&gt;处理异常数值：处理异常数值的一种方法就是忽略分布中的上尾和下尾。习惯上，统计学家会忽略较低的25%和较高的25%。
虽然建议去除上下各25%的数据点，但我们在去除数据点时还需要特别谨慎，特别是在数据量不大的情况下，去除一半的数据点&amp;gt;会让我们丢失大量数据的信息。&lt;br /&gt;
一般来说，在去除数据点前，我们建议首先将数据点通过图像表述出来（直方图、散点图、箱线图等），这样可以帮助你获得对数据整理分析的了解。然后，基于项目的背景，判断你更关心数据的哪一部分（大多数正常数据，还是小部分异常数据），因为在一些项目背景下，你可能更关心那些异常值。最后，是基于现有的数据量作出决定，究竟是直接丢弃部分数据还是对部分作出调整，亦或是有保留地接受所有数据。特别记住一点，没有一种分析方法100%正确，但我们总可以尝试根据不同的需求找到一种最合理的方法。&lt;/p&gt;

&lt;h2 id=&quot;四分位差&quot;&gt;四分位差&lt;/h2&gt;
&lt;p&gt;找出方法：排序的数据集，从中间分成2半，再找一半的中位数。&lt;br /&gt;
第一个四分位数：称为总体的&lt;strong&gt;Q1&lt;/strong&gt;&lt;br /&gt;
中位数：Q2&lt;br /&gt;
第三个四分位：称为总体的&lt;strong&gt;Q3&lt;/strong&gt;&lt;br /&gt;
&lt;strong&gt;四分位差(IQR)&lt;/strong&gt;：Q3-Q1 能表示图的差异性。&lt;br /&gt;
几乎50%的数据在IQR间。&lt;br /&gt;
IQR不受异常值的影响。&lt;br /&gt;
The Interquartile range (IQR) is the distance be- tween the 1st quartile and 3rd quartile and gives us the range of the middle 50% of our data. The IQR is easily found by computing: Q3-Q1.&lt;/p&gt;

&lt;h2 id=&quot;异常值&quot;&gt;异常值&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;异常值&lt;/strong&gt;：如果一个值小于Q1减去1.5倍的IQR或者大于Q3加上1.5倍IQR，则这个数就被认为是异常数值。&lt;br /&gt;
Lower Outliers &amp;lt; Q1-1.5(IQR)&lt;br /&gt;
Upper Outliers &amp;gt; Q3+1.5(IQR)&lt;/p&gt;

&lt;h2 id=&quot;箱线图&quot;&gt;箱线图&lt;/h2&gt;
&lt;p&gt;表示中位数、四分位差、最小值和最大值有效。&lt;br /&gt;
&lt;strong&gt;箱线图（盒须图）&lt;/strong&gt;：直观的表示四分位数和异常数值。箱线图外面的点表示异常值，在此上下文中，“min”和“max”是指样本中不包括异常值在内的最小值和最大值。箱线图的方向可以有不同。&lt;br /&gt;
&lt;img src=&quot;https://github.com/leafming/bak/blob/master/images/machineLearning/2018-05-16-箱线图.png?raw=true&quot; alt=&quot;普通箱线图例子&quot; /&gt;&lt;br /&gt;
箱线图的对比，箱线图与直方图连线对应：&lt;br /&gt;
&lt;img src=&quot;https://github.com/leafming/bak/blob/master/images/machineLearning/2018-05-16-箱线图与分布图连线对应.png?raw=true&quot; alt=&quot;箱线图和直方图对应连线例子&quot; /&gt;&lt;br /&gt;
值域和IQR都无法将所有数据集考虑进来，完全不相同的两个数据集也可能有相同的IQR，不同的图可能有相同的箱线图。&lt;br /&gt;
&lt;img src=&quot;https://github.com/leafming/bak/blob/master/images/machineLearning/2018-05-16-不同图IQR相同.png?raw=true&quot; alt=&quot;不同图相同IQR&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;基础概念&quot;&gt;基础概念&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;离均差&lt;/strong&gt;(Deviation from Mean)：用每个值减去平均值 &lt;script type=&quot;math/tex&quot;&gt;x_{i}-\overline{x}&lt;/script&gt; （减的顺序保持一致）。&lt;br /&gt;
&lt;strong&gt;平均偏差&lt;/strong&gt;：计算离均差的平均值。&lt;script type=&quot;math/tex&quot;&gt;\frac{\sum(x_{i}-\overline{x}) }{n}&lt;/script&gt;&lt;br /&gt;
&lt;strong&gt;绝对偏差&lt;/strong&gt;(Absolute Deviations)：&lt;script type=&quot;math/tex&quot;&gt;|x_{i}-\overline{x}|&lt;/script&gt;&lt;br /&gt;
&lt;strong&gt;平均绝对偏差&lt;/strong&gt;(Average Absolute Deviation)：各次测量值的绝对偏差绝对值的平均值。 &lt;script type=&quot;math/tex&quot;&gt;\overline{d}=\frac{\sum_{i=1}^{n}|x_{i}-\overline{x}|}{n}=\sum (\frac{|x_{i}-\overline{x}|}{n})&lt;/script&gt;&lt;br /&gt;
&lt;strong&gt;相对平均偏差&lt;/strong&gt;：指平均偏差占平均值的百分率。&lt;script type=&quot;math/tex&quot;&gt;R\overline{d}=\frac{\overline{d}}{ \overline{x}}&lt;/script&gt;*100%&lt;br /&gt;
&lt;strong&gt;平方偏差&lt;/strong&gt;(Squared Deviation)：&lt;script type=&quot;math/tex&quot;&gt;\left ( x_{i}-\overline{x} \right )^{2}&lt;/script&gt;&lt;br /&gt;
&lt;strong&gt;平方和&lt;/strong&gt;SS(sum of squares)：&lt;script type=&quot;math/tex&quot;&gt;\sum_{i=1}^{n} \left ( x_{i}-\overline{x} \right )^{2}&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;因为抽样往往是总体居于中间的值，因此抽样中的差异性将少于整个总体的差异性，所以使用贝塞尔校正系数：将除以n换为除以n-1。&lt;br /&gt;
&lt;strong&gt;平均平方偏差&lt;/strong&gt;（Arerage Square Deviation）-&lt;strong&gt;方差&lt;/strong&gt;：平方偏差的均值 &lt;script type=&quot;math/tex&quot;&gt;\frac{\sum_{i=1}^{n} \left ( x_{i}-\overline{x} \right )^{2}}{n}&lt;/script&gt;，贝塞尔校正后的方差(样本方差)&lt;script type=&quot;math/tex&quot;&gt;s^{2}=\frac{\sum_{i=1}^{n} \left ( x_{i}-\overline{x} \right )^{2}}{n-1}&lt;/script&gt;&lt;br /&gt;
&lt;strong&gt;标准偏差（标准差）(standard deviation)&lt;/strong&gt;：最常用的分布测量方法,平均平方偏差的平方根;方差的平方根(平方偏差的和除以n，再开平方)。&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;样本标准差&lt;/strong&gt;(standard deviation of sample): &lt;script type=&quot;math/tex&quot;&gt;s=\sqrt{\frac{\sum_{i=1}^{n}\left ( x_{i}-\overline{x} \right )^{2}}{n-1}}&lt;/script&gt;,&lt;script type=&quot;math/tex&quot;&gt;\overline{x}&lt;/script&gt;代表样本的X1,X2,…,Xn的均值。-估算总体标准差。&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;总体标准差&lt;/strong&gt;(standard deviation of population): &lt;script type=&quot;math/tex&quot;&gt;\sigma=\sqrt{\frac{\sum_{i=1}^{n}\left ( x_{i}-\mu \right )^{2}}{n}}&lt;/script&gt;,&lt;script type=&quot;math/tex&quot;&gt;\sigma&lt;/script&gt;代表总体X的均值。-计算数据集自己的标准差。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;strong&gt;如果使用这个数据集估算此样本所属的较大型总体的标准差，要除以n-1，即使用样本标准差公式。如果这个数据集较小，计算这个数据集自己的标准差，则除以n，即使用总体标准差公式。&lt;/strong&gt;&lt;br /&gt;
计算过程：求平均值、求离均差、再求每个偏差
的平方、再取平均值、在取平方根。  &lt;br /&gt;
&lt;img src=&quot;https://github.com/leafming/bak/blob/master/images/machineLearning/2018-05-16-方差到标准方差.png?raw=true&quot; alt=&quot;方差到标准方差&quot; /&gt; &lt;br /&gt;
&lt;strong&gt;相对标准偏差&lt;/strong&gt;：指标准偏差占平均值的百分率，又称为变异系数(CV)，通常用RSD表示。&lt;script type=&quot;math/tex&quot;&gt;RSD=\frac{s}{\overline{x}}&lt;/script&gt;*100%&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;平均绝对离差&lt;/strong&gt;：平均绝对离差(mean absolute deviation)是用样本数据相对于其平均值的绝对距离来度量数据的离散程度。平均绝对离差也称为平均离差(mean deviation)。平均绝对离差定义为各数据与平均值的离差的绝对值的平均数。&lt;br /&gt;
设样本的n个观测值为x1,x2..xn，平均绝对离差为：&lt;br /&gt;
&lt;script type=&quot;math/tex&quot;&gt;M_{D}=\frac{1}{n}\sum_{i=1}^{n}|x_{i}-\overline{x}|&lt;/script&gt;&lt;br /&gt;
对于分组数据，平均绝对离差为：&lt;br /&gt;
&lt;script type=&quot;math/tex&quot;&gt;M_{D}=\frac{\sum_{i=1}^{k}f_{i}\left|x_{i} -\overline{x}\right|}{\sum_{i=1}^{k}f_{i}}&lt;/script&gt;&lt;br /&gt;
其中&lt;script type=&quot;math/tex&quot;&gt;f_{i}&lt;/script&gt;,&lt;script type=&quot;math/tex&quot;&gt;x_{i}&lt;/script&gt;分别为第i(i=1,2…,k)组数据的频数及组中值，k为数据分组的组数。&lt;/p&gt;

&lt;h2 id=&quot;标准差重要性&quot;&gt;标准差重要性&lt;/h2&gt;
&lt;p&gt;在正态分布中，数据均匀分布，平均值=中位数=众数，并且位于分布的中心。&lt;strong&gt;大约68%的数据与平均值的偏差不超过1个标准差；95%的数据与平均值的偏差不超过2个标准差。&lt;/strong&gt;&lt;br /&gt;
&lt;img src=&quot;https://github.com/leafming/bak/blob/master/images/machineLearning/2018-05-17-正态分布与标准差.png?raw=true&quot; alt=&quot;正态分布与标准差&quot; /&gt;&lt;/p&gt;

&lt;h1 id=&quot;2018-05-17-归一化&quot;&gt;2018-05-17 归一化&lt;/h1&gt;
&lt;h2 id=&quot;标准化分布图&quot;&gt;标准化分布图&lt;/h2&gt;
&lt;p&gt;正态分布类型：宽扁型、瘦高型、或者介于2者之间，但曲线下面积始终为1或100%。&lt;strong&gt;大约68%的数据与平均值的偏差不超过1个标准差；95%的数据与平均值的偏差不超过2个标准差。&lt;/strong&gt;   &lt;br /&gt;
&lt;strong&gt;特定值在x轴上的位置通常用标准偏差来描述&lt;/strong&gt;。与平均值的距离多少个标准差的值，称为&lt;strong&gt;z&lt;/strong&gt;。通过将正态分布中的值转换为这个特殊数字z，就可以知道小于或大于该值的百分比。&lt;br /&gt;
&lt;img src=&quot;https://github.com/leafming/bak/blob/master/images/machineLearning/2018-05-17-正态分布的z值.png?raw=true&quot; alt=&quot;正态分布的z值&quot; /&gt;&lt;br /&gt;
&lt;strong&gt;标准差数量&lt;/strong&gt;z公式：计算某个值与平均值之间相差多少个标准差，即&lt;script type=&quot;math/tex&quot;&gt;z=\frac{x-\mu}{\sigma }&lt;/script&gt;。始终用x减去平均值。&lt;br /&gt;
当某个值小于平均值是，是负的z值；z值是指任何值距离平均值的标准偏差数；如果一个值与均值相等，它的Z值为0。&lt;br /&gt;
&lt;strong&gt;标准化（归一化）分布图&lt;/strong&gt;：将正态分布图中的任意值转化称z值，则标准化了分布图。&lt;br /&gt;
如果我们将数据归一化处理为z值，该归一化分布的新平均值会是多少？-0&lt;br /&gt;
如果我们将数据归一化处理为z值，该归一化分布的新标准偏差会是多少？-1&lt;/p&gt;

&lt;p&gt;总结：对于任何正态分布，都可以通过以下方式归一化该分布：&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;减去平均值，将其平移到0处&lt;/li&gt;
  &lt;li&gt;除以标准偏差，使标准偏差=1&lt;br /&gt;
这就叫做&lt;strong&gt;标准正态分布&lt;/strong&gt;。&lt;br /&gt;
&lt;img src=&quot;https://github.com/leafming/bak/blob/master/images/machineLearning/2018-05-17-标准正态分布.png?raw=true&quot; alt=&quot;标准正态分布&quot; /&gt; &lt;br /&gt;
&lt;img src=&quot;https://github.com/leafming/bak/blob/master/images/machineLearning/2018-06-04-标准正态分布.png?raw=true&quot; alt=&quot;标准正态分布2&quot; /&gt;&lt;br /&gt;
可以将任意正态分布转成任意正态分布：即通过转成标准正态分布，再转换成其他正态分布。&lt;/li&gt;
&lt;/ol&gt;

&lt;h1 id=&quot;2018-05-21-概率密度函数&quot;&gt;2018-05-21-概率密度函数&lt;/h1&gt;
&lt;h2 id=&quot;概率密度函数&quot;&gt;概率密度函数&lt;/h2&gt;
&lt;p&gt;在正态分布中，通过查看某个值在x轴上的位置即标准偏差，能改确定大于或小于任何值的百分比，下面学习如何计算这些百分比。&lt;br /&gt;
我们使用理论曲线来绘制数据模型，曲线下的面积是1 ，因为它是用分布数据的相对频率（即比例）来绘制数据模型，该曲线叫做&lt;strong&gt;概率密度函数&lt;/strong&gt;，通常缩写为PDF。&lt;br /&gt;
概率密度函数曲线下的面积表示概率。&lt;br /&gt;
&lt;img src=&quot;https://github.com/leafming/bak/blob/master/images/machineLearning/2018-05-21-概率密度函数.png?raw=true&quot; alt=&quot;概率密度函数&quot; /&gt;&lt;br /&gt;
绘制概率密度函数时，绝对频率（absolute frequency）变成相对频率（relative frequency）。&lt;br /&gt;
&lt;img src=&quot;https://github.com/leafming/bak/blob/master/images/machineLearning/2018-05-21-直方图-概率密度函数.png?raw=true&quot; alt=&quot;直方图-概率密度函数&quot; /&gt;&lt;/p&gt;
&lt;h2 id=&quot;正态概率密度函数&quot;&gt;正态概率密度函数&lt;/h2&gt;
&lt;p&gt;曲线的末端实际上不会接触到x轴，只是越来越接近x轴，x轴是水平渐进线，该理论模型的曲线末端不能接触到x轴是因为我们永远都不能100%确定某件事；&lt;br /&gt;
假设有某个值（x），从负无穷到x之间的曲线下的面积，等于随机地从样本中选择一个小于x的受试者对应的概率，也就等于样本或总体中值小于x的比例。如果这个概率是80%，可以说x是第80个百分位。&lt;br /&gt;
&lt;img src=&quot;https://github.com/leafming/bak/blob/master/images/machineLearning/2018-06-04-认识概率密度函数.png?raw=true&quot; alt=&quot;认识概率密度函数&quot; /&gt;&lt;br /&gt;
概率密度函数公式见百科：&lt;a href=&quot;https://baike.baidu.com/item/概率密度函数/5021996?fr=aladdin&quot;&gt;概率密度函数&lt;/a&gt;。&lt;br /&gt;
正态概率密度函数公式（一维正态分布）：&lt;br /&gt;
若随机变量X服从一个位置参数为&lt;script type=&quot;math/tex&quot;&gt;\mu&lt;/script&gt;、尺度参数为&lt;script type=&quot;math/tex&quot;&gt;\sigma&lt;/script&gt;的概率分布，其概率密度函数为&lt;script type=&quot;math/tex&quot;&gt;f\left ( x \right )=\frac{1}{\sqrt{2\pi }\sigma }e^{\left ( -\frac{\left ( x-\mu \right )^{2}}{2\sigma^{2}} \right )}&lt;/script&gt;，则这个随机变量就称为正态随机变量，正态随机变量服从的正态分布就称为正态分布，记作&lt;script type=&quot;math/tex&quot;&gt;&lt;/script&gt;，读作X服从&lt;script type=&quot;math/tex&quot;&gt;&lt;/script&gt;，或X服从正态分布。  &lt;br /&gt;
μ维随机向量具有类似的概率规律时，称此随机向量遵从多维正态分布。多元正态分布有很好的性质，例如，多元正态分布的边缘分布仍为正态分布，它经任何线性变换得到的随机向量仍为多维正态分布，特别它的线性组合为一元正态分布。&lt;br /&gt;
标准正态分布：&lt;br /&gt;
当μ=0，&lt;script type=&quot;math/tex&quot;&gt;\sigma&lt;/script&gt;=1时，正态分布就成为标准正态分布：&lt;script type=&quot;math/tex&quot;&gt;f(x)=\frac{1}{\sqrt{2\pi }}e^{(-\frac{x^{2}}{2})}&lt;/script&gt;&lt;/p&gt;</content><author><name>Liv Yeh</name></author><category term="机器学习" /><category term="描述统计学" /><summary type="html">本文关于自学udacity机器学习课程的自学笔记，为第一部分，描述统计学入门(2)。 2018-05-16-可变性 范围(值域)是观察到的最大值和最小值之间的差。 值域不包括细节信息，因为值域是仅仅在2个数据的基础上得出的。 异常数值增大差异性，值域作为度量标准时，有异常数值，值域不可能准确的代表数据的差异性。 忽略尾部 处理异常数值：处理异常数值的一种方法就是忽略分布中的上尾和下尾。习惯上，统计学家会忽略较低的25%和较高的25%。 虽然建议去除上下各25%的数据点，但我们在去除数据点时还需要特别谨慎，特别是在数据量不大的情况下，去除一半的数据点&amp;gt;会让我们丢失大量数据的信息。 一般来说，在去除数据点前，我们建议首先将数据点通过图像表述出来（直方图、散点图、箱线图等），这样可以帮助你获得对数据整理分析的了解。然后，基于项目的背景，判断你更关心数据的哪一部分（大多数正常数据，还是小部分异常数据），因为在一些项目背景下，你可能更关心那些异常值。最后，是基于现有的数据量作出决定，究竟是直接丢弃部分数据还是对部分作出调整，亦或是有保留地接受所有数据。特别记住一点，没有一种分析方法100%正确，但我们总可以尝试根据不同的需求找到一种最合理的方法。 四分位差 找出方法：排序的数据集，从中间分成2半，再找一半的中位数。 第一个四分位数：称为总体的Q1 中位数：Q2 第三个四分位：称为总体的Q3 四分位差(IQR)：Q3-Q1 能表示图的差异性。 几乎50%的数据在IQR间。 IQR不受异常值的影响。 The Interquartile range (IQR) is the distance be- tween the 1st quartile and 3rd quartile and gives us the range of the middle 50% of our data. The IQR is easily found by computing: Q3-Q1. 异常值 异常值：如果一个值小于Q1减去1.5倍的IQR或者大于Q3加上1.5倍IQR，则这个数就被认为是异常数值。 Lower Outliers &amp;lt; Q1-1.5(IQR) Upper Outliers &amp;gt; Q3+1.5(IQR) 箱线图 表示中位数、四分位差、最小值和最大值有效。 箱线图（盒须图）：直观的表示四分位数和异常数值。箱线图外面的点表示异常值，在此上下文中，“min”和“max”是指样本中不包括异常值在内的最小值和最大值。箱线图的方向可以有不同。 箱线图的对比，箱线图与直方图连线对应： 值域和IQR都无法将所有数据集考虑进来，完全不相同的两个数据集也可能有相同的IQR，不同的图可能有相同的箱线图。 基础概念 离均差(Deviation from Mean)：用每个值减去平均值 （减的顺序保持一致）。 平均偏差：计算离均差的平均值。 绝对偏差(Absolute Deviations)： 平均绝对偏差(Average Absolute Deviation)：各次测量值的绝对偏差绝对值的平均值。 相对平均偏差：指平均偏差占平均值的百分率。*100% 平方偏差(Squared Deviation)： 平方和SS(sum of squares)： 因为抽样往往是总体居于中间的值，因此抽样中的差异性将少于整个总体的差异性，所以使用贝塞尔校正系数：将除以n换为除以n-1。 平均平方偏差（Arerage Square Deviation）-方差：平方偏差的均值 ，贝塞尔校正后的方差(样本方差) 标准偏差（标准差）(standard deviation)：最常用的分布测量方法,平均平方偏差的平方根;方差的平方根(平方偏差的和除以n，再开平方)。 样本标准差(standard deviation of sample): ,代表样本的X1,X2,…,Xn的均值。-估算总体标准差。 总体标准差(standard deviation of population): ,代表总体X的均值。-计算数据集自己的标准差。 如果使用这个数据集估算此样本所属的较大型总体的标准差，要除以n-1，即使用样本标准差公式。如果这个数据集较小，计算这个数据集自己的标准差，则除以n，即使用总体标准差公式。 计算过程：求平均值、求离均差、再求每个偏差 的平方、再取平均值、在取平方根。 相对标准偏差：指标准偏差占平均值的百分率，又称为变异系数(CV)，通常用RSD表示。*100% 平均绝对离差：平均绝对离差(mean absolute deviation)是用样本数据相对于其平均值的绝对距离来度量数据的离散程度。平均绝对离差也称为平均离差(mean deviation)。平均绝对离差定义为各数据与平均值的离差的绝对值的平均数。 设样本的n个观测值为x1,x2..xn，平均绝对离差为： 对于分组数据，平均绝对离差为： 其中,分别为第i(i=1,2…,k)组数据的频数及组中值，k为数据分组的组数。 标准差重要性 在正态分布中，数据均匀分布，平均值=中位数=众数，并且位于分布的中心。大约68%的数据与平均值的偏差不超过1个标准差；95%的数据与平均值的偏差不超过2个标准差。 2018-05-17 归一化 标准化分布图 正态分布类型：宽扁型、瘦高型、或者介于2者之间，但曲线下面积始终为1或100%。大约68%的数据与平均值的偏差不超过1个标准差；95%的数据与平均值的偏差不超过2个标准差。 特定值在x轴上的位置通常用标准偏差来描述。与平均值的距离多少个标准差的值，称为z。通过将正态分布中的值转换为这个特殊数字z，就可以知道小于或大于该值的百分比。 标准差数量z公式：计算某个值与平均值之间相差多少个标准差，即。始终用x减去平均值。 当某个值小于平均值是，是负的z值；z值是指任何值距离平均值的标准偏差数；如果一个值与均值相等，它的Z值为0。 标准化（归一化）分布图：将正态分布图中的任意值转化称z值，则标准化了分布图。 如果我们将数据归一化处理为z值，该归一化分布的新平均值会是多少？-0 如果我们将数据归一化处理为z值，该归一化分布的新标准偏差会是多少？-1 总结：对于任何正态分布，都可以通过以下方式归一化该分布： 减去平均值，将其平移到0处 除以标准偏差，使标准偏差=1 这就叫做标准正态分布。 可以将任意正态分布转成任意正态分布：即通过转成标准正态分布，再转换成其他正态分布。 2018-05-21-概率密度函数 概率密度函数 在正态分布中，通过查看某个值在x轴上的位置即标准偏差，能改确定大于或小于任何值的百分比，下面学习如何计算这些百分比。 我们使用理论曲线来绘制数据模型，曲线下的面积是1 ，因为它是用分布数据的相对频率（即比例）来绘制数据模型，该曲线叫做概率密度函数，通常缩写为PDF。 概率密度函数曲线下的面积表示概率。 绘制概率密度函数时，绝对频率（absolute frequency）变成相对频率（relative frequency）。 正态概率密度函数 曲线的末端实际上不会接触到x轴，只是越来越接近x轴，x轴是水平渐进线，该理论模型的曲线末端不能接触到x轴是因为我们永远都不能100%确定某件事； 假设有某个值（x），从负无穷到x之间的曲线下的面积，等于随机地从样本中选择一个小于x的受试者对应的概率，也就等于样本或总体中值小于x的比例。如果这个概率是80%，可以说x是第80个百分位。 概率密度函数公式见百科：概率密度函数。 正态概率密度函数公式（一维正态分布）： 若随机变量X服从一个位置参数为、尺度参数为的概率分布，其概率密度函数为，则这个随机变量就称为正态随机变量，正态随机变量服从的正态分布就称为正态分布，记作，读作X服从，或X服从正态分布。 μ维随机向量具有类似的概率规律时，称此随机向量遵从多维正态分布。多元正态分布有很好的性质，例如，多元正态分布的边缘分布仍为正态分布，它经任何线性变换得到的随机向量仍为多维正态分布，特别它的线性组合为一元正态分布。 标准正态分布： 当μ=0，=1时，正态分布就成为标准正态分布：</summary></entry><entry><title type="html">机器学习入门自学-描述统计学入门1</title><link href="http://localhost:4000/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/2018/05/10/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%E8%87%AA%E5%AD%A6-%E6%8F%8F%E8%BF%B0%E7%BB%9F%E8%AE%A1%E5%AD%A6%E5%85%A5%E9%97%A81/" rel="alternate" type="text/html" title="机器学习入门自学-描述统计学入门1" /><published>2018-05-10T00:00:00+08:00</published><updated>2018-05-10T00:00:00+08:00</updated><id>http://localhost:4000/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/2018/05/10/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%E8%87%AA%E5%AD%A6-%E6%8F%8F%E8%BF%B0%E7%BB%9F%E8%AE%A1%E5%AD%A6%E5%85%A5%E9%97%A81</id><content type="html" xml:base="http://localhost:4000/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/2018/05/10/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%E8%87%AA%E5%AD%A6-%E6%8F%8F%E8%BF%B0%E7%BB%9F%E8%AE%A1%E5%AD%A6%E5%85%A5%E9%97%A81/">&lt;blockquote&gt;
  &lt;p&gt;本文关于自学udacity机器学习课程的自学笔记，为第一部分，描述统计学入门(1)。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h1 id=&quot;2018-05-08-研究方法入门&quot;&gt;2018-05-08-研究方法入门&lt;/h1&gt;
&lt;h2 id=&quot;基本概念&quot;&gt;基本概念&lt;/h2&gt;
&lt;p&gt;抽象概念（constructs）  &lt;br /&gt;
&lt;strong&gt;操作性定义：&lt;/strong&gt;一种将构造（constructs）转变为我们可衡量的变量的方式；一种用我们衡量它的方式描述变量的方式。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;总体参数&lt;/strong&gt;μ：描述整个总体的平均值&lt;br /&gt;
&lt;strong&gt;样本统计量&lt;/strong&gt;&lt;script type=&quot;math/tex&quot;&gt;\bar{x}&lt;/script&gt;：样本的平均值&lt;br /&gt;
&lt;strong&gt;样本大小&lt;/strong&gt;n&lt;br /&gt;
&lt;strong&gt;抽样误差&lt;/strong&gt;μ-&lt;script type=&quot;math/tex&quot;&gt;\bar{x}&lt;/script&gt;：样本平均值和总体平均值之间的差异。在使用一个样本对一个总体进行推理时，样本的平均值可能不会完全等于总体的平均值。 &lt;br /&gt;
用&lt;script type=&quot;math/tex&quot;&gt;\bar{x}&lt;/script&gt;来估计μ，估计值是对μ的最佳猜测。&lt;/p&gt;

&lt;p&gt;好样本：大、随机无偏差&lt;br /&gt;
&lt;strong&gt;随机样本：&lt;/strong&gt;每个对象被选中的概率都是一样的。&lt;br /&gt;
可视化关系-eg 散点图&lt;br /&gt;
&lt;strong&gt;散点图：&lt;/strong&gt;&lt;br /&gt;
1.x轴上变量：自变量（independent variable）或预测变量（predictor variable）&lt;br /&gt;
2.y轴上变量：因变量（dependent variable）即结果（outcome）&lt;/p&gt;

&lt;h2 id=&quot;基本概念-变量&quot;&gt;基本概念-变量&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;在试验中，研究人员操纵 (自) 变量，测量 (因) 变量的变化，然后尝试控制(潜伏)变量。&lt;/strong&gt;&lt;br /&gt;
简单点说，自变量是“原因”，而因变量就是“结果”。在实验中，自变量是由实验者操纵、掌握的变量。因变量是因为自变量的变化而产生的现象变化或结果。因此自变量和因变量的相互依存的，没有自变量就无所谓因变量，没有因变量也无所谓自变量。&lt;br /&gt;
1.&lt;strong&gt;自变量&lt;/strong&gt;:&lt;br /&gt;
自变量（Independent variable）一词来自数学。在数学中，y=f(x)。在这一方程中自变量是x，因变量是y。将这个方程运用到心理学的研究中，自变量是指研究者主动操纵，而引起因变量发生变化的因素或条件，因此自变量被看作是因变量的原因。自变量有连续变量和类别变量之分。如果实验者操纵的自变量是连续变量，则实验是函数型实验。如实验者操纵的自变量是类别变量，则实验是因素型的。在心理学实验中，一个明显的问题是要有一个有机体作为被试对刺激作反应。显然，这里刺激变量就是自变量。&lt;br /&gt;
2.&lt;strong&gt;因变量:&lt;/strong&gt;&lt;br /&gt;
因变量（dependent variable）函数中的专业名词，也叫函数值。函数关系式中，某些特定的数会随另一个（或另几个）会变动的数的变动而变动，就称为因变量。如：Y=f(X)。此式表示为：Y随X的变化而变化。Y是因变量，X是自变量。另外“因变量”也特指心理实验中的专业名词。&lt;br /&gt;
3.&lt;strong&gt;潜在变量（外部因素）&lt;/strong&gt;:&lt;br /&gt;
a.可为变量之间观察到的关系提供可能的另一种解释&lt;br /&gt;
b.是会影响我们衡量的两个或多个变量之间关系的因素&lt;br /&gt;
c.在我们做出确定的因果声明之前，必须在试验中加以控制&lt;br /&gt;
d.使从观察性研究的数据中确定因果关系变得困难&lt;/p&gt;

&lt;h2 id=&quot;相关并不代表因果&quot;&gt;相关并不代表因果&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;correlation does not imply causation. - 相关并不代表因果&lt;/strong&gt;  &lt;br /&gt;
show releation（关系） =&amp;gt; observational studies surveys（观察性研究）  &lt;br /&gt;
show causation（因果关系 即特定因素） =&amp;gt; controued experiment（对照实验，实验性研究）&lt;/p&gt;

&lt;h2 id=&quot;实验性研究和观察性研究&quot;&gt;实验性研究和观察性研究&lt;/h2&gt;
&lt;p&gt;实验性研究和观察性研究的区别:&lt;br /&gt;
&lt;strong&gt;观察性研究&lt;/strong&gt;：是非随机化的研究,在自然状态下对研究对象的特征进行观查、记录，并对结果进行描述和对比分析的研究。&lt;br /&gt;
&lt;strong&gt;实验性研究&lt;/strong&gt;：就是人为地进行干预措施，而收集到结果的分析性研究。&lt;br /&gt;
实验性研究是人为研究，观察性研究是自然研究。&lt;br /&gt;
拓展：&lt;br /&gt;
（1）观察性研究中的基本要素：一个是研究对象，另一个是研究因素。在描述性研究中，研究因素是影响因素；在分析性研究中，研究因素称为危险因素或暴露因素。&lt;br /&gt;
（2）观察性研究的特征概括：在研究中，不向研究对象施加任何实验因素（干预因素），可以将观察对象按某种特征分组，但不需随机分组。&lt;br /&gt;
（3）实验性研究是在控制的条件下系统的操纵某种变量的变化，来研究这种变量的变化对其他变量所产生的影响。&lt;/p&gt;

&lt;p&gt;调查方式：调查问卷&lt;br /&gt;
1.不理解内容 =&amp;gt; &lt;strong&gt;应答偏差&lt;/strong&gt;&lt;br /&gt;
2.拒绝回答 =&amp;gt; &lt;strong&gt;无应答偏差&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;控制因素：盲法&lt;br /&gt;
安慰剂（无效药）&lt;br /&gt;
1.单盲：参与者不知道自己是无效药&lt;br /&gt;
2.双盲：都不知道&lt;/p&gt;

&lt;h2 id=&quot;小习题&quot;&gt;小习题&lt;/h2&gt;
&lt;p&gt;假设我们将患有失眠症的人随机分配到两个治疗方法中。在一个方法中，被试获得 20 毫克唑吡旦（安比恩）。在另一种方法中，被试获得了一个安慰剂药片。被试不知道他们服用的是哪种类型的药片。服药后，被试在睡眠实验室入睡以帮助控制潜在变量。第二天早上，在与心理学家的对话中，他们对自己的睡眠质量进行了从 1 到 10 的评分（1 表示“非常差”，10 表示“非常好”）。心理学家同样不知道他们各自服用了哪种药物。唑吡旦组的被试报告的睡眠质量（均值 = 8）优于安慰剂组（均值 = 5）。&lt;br /&gt;
关于这个情景以下哪个说法是正确的？选择所有适用项。&lt;br /&gt;
A这是一项观察性研究示例，因此我们无法对唑吡旦的有效性得出因果结论。&lt;br /&gt;
B参与者可以看出他们服用的是什么药片。&lt;br /&gt;
C药片类型（唑吡旦或安慰剂）为因变量。&lt;br /&gt;
D此研究为实验性研究，我们可以对唑吡旦的有效性得出因果结论。&lt;br /&gt;
E该实验使用了双盲对照组，因为参与者和心理学家都不知道每个人服用的药片类型。&lt;br /&gt;
F唑吡旦组与安慰剂组报告的睡眠质量之间的差异，可能不是由唑吡旦引起的。&lt;br /&gt;
G睡眠质量的操作定义使用一个满分为100分的度量表。&lt;br /&gt;
H药丸类型（唑吡旦或安慰剂）是自变量。&lt;br /&gt;
I治疗成果的操作定义使用一个满分为10分的度量表。&lt;br /&gt;
J心理学家不知道被试服用的是那种药丸。&lt;br /&gt;
K这项研究表明，在其他条件相同的情况下，唑吡旦比安慰剂更能改善睡眠质量。&lt;/p&gt;

&lt;p&gt;答案:DEHJK&lt;/p&gt;

&lt;p&gt;习题解释:&lt;br /&gt;
此研究为实验性研究，我们可以对唑吡旦的有效性得出因果结论;该实验使用了双盲对照组，因为参与者和心理学家都不知道每个人服用的药片类型。&lt;br /&gt;
The independent variable is whatever differed between the experiment group and control group. What was the independent variable in this experiment?&lt;br /&gt;
药丸类型（唑吡旦或安慰剂）是自变量。&lt;br /&gt;
In an experimental study, unlike an observational study, it is valid to make causal conclusions since randomization minimizes the effect of lurking variables.What conclusions can you draw from the results of this experimental study?&lt;br /&gt;
这项研究表明，在其他条件相同的情况下，唑吡旦比安慰剂更能改善睡眠质量。&lt;br /&gt;
Note that while the operational definition of quality of sleep is the 10-point scale, the way we actually measure success comes from the difference in quality between groups.&lt;br /&gt;
治疗成果的操作定义不是使用一个满分为10分的度量表。而是参与者的睡眠质量。&lt;/p&gt;

&lt;h1 id=&quot;2018-05-11-数据可视化&quot;&gt;2018-05-11-数据可视化&lt;/h1&gt;
&lt;p&gt;&lt;strong&gt;Σ&lt;/strong&gt;号表示总和，它是希腊字母大写西格玛。&lt;br /&gt;
&lt;strong&gt;f&lt;/strong&gt;代表频率（计数），&lt;strong&gt;p&lt;/strong&gt;代表比例。&lt;br /&gt;
在此情况下，n（样本中的数字）等于此次研究中的总人数。&lt;/p&gt;
&lt;h2 id=&quot;频率表&quot;&gt;频率表&lt;/h2&gt;
&lt;p&gt;frequency 在中文中指频数，而relative frequency指的是频率（相对频数）&lt;br /&gt;
&lt;strong&gt;频数&lt;/strong&gt;（频率）：个数&lt;br /&gt;
&lt;strong&gt;相对频数&lt;/strong&gt;（相对频率）：比例或百分比,频数除以样本数&lt;br /&gt;
1.展示方式1:用比例(小数)表示：0&amp;lt;=比例&amp;lt;=1 ,如0.23&lt;br /&gt;
2.展示方式2:百分比表示：0%&amp;lt;=百分比&amp;lt;=100% ,如23%&lt;br /&gt;
&lt;img src=&quot;https://github.com/leafming/bak/blob/master/images/machineLearning/2018-05-10-频率表.png?raw=true&quot; alt=&quot;table&quot; /&gt;&lt;br /&gt;
对于任何频率表，所有相对频率之和应当等于1。&lt;br /&gt;
表格的行数,取决于你如何去整理数据。&lt;br /&gt;
&lt;strong&gt;区间&lt;/strong&gt;（interval）、&lt;strong&gt;容器&lt;/strong&gt;（bin）、桶（bucket）:每行选择一个范围，如0-19、20-39&lt;br /&gt;
&lt;strong&gt;组距&lt;/strong&gt;：是指对频率进行计数的区间，如为20 &lt;br /&gt;
一组混乱无章的数据，可以通过频率表描述数据可视化。&lt;/p&gt;
&lt;h2 id=&quot;直方图&quot;&gt;直方图&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;X轴&lt;/strong&gt;上：变量，是可以量化的值，可划分组距（如年龄、价格（元）、长度（米）的值）-区分柱状图 &lt;br /&gt;
&lt;strong&gt;Y轴&lt;/strong&gt;上：只是频率&lt;br /&gt;
Frequency is on the y-axis; countries and colors are categorical data. With histograms, the x-axis should be numerical.&lt;br /&gt;
直方图两个轴的交叉点是&lt;strong&gt;原点&lt;/strong&gt;，&lt;strong&gt;笛卡尔坐标是(0,0)&lt;/strong&gt;。 &lt;br /&gt;
&lt;img src=&quot;https://github.com/leafming/bak/blob/master/images/machineLearning/2018-05-10-直方图.png?raw=true&quot; alt=&quot;histogram&quot; /&gt; &lt;br /&gt;
组距大小（区间大小），可以创建任何组距大小的直方图，Interactivate直方图软件。&lt;br /&gt;
组距越大，每个区间内观察值越多。&lt;br /&gt;
组距大小取决于需要多大的分组、回答什么养的问题、需要多少详细信息。选择的组距大小在某些情况下可能会牺牲一些信息。&lt;br /&gt;
每个长条上的数字可代表其频率。 
通常，当我们使用直方图做数据可视化时，如果我们&lt;strong&gt;增大组距&lt;/strong&gt;，频率会怎样？–&lt;strong&gt;变大&lt;/strong&gt;：As we make the bin size bigger, more values will fall inside that bin.&lt;/p&gt;

&lt;h2 id=&quot;直方图和柱状图区别&quot;&gt;直方图和柱状图区别&lt;/h2&gt;
&lt;p&gt;&lt;img src=&quot;https://github.com/leafming/bak/blob/master/images/machineLearning/2018-05-10-直方图与柱状图.png?raw=true&quot; alt=&quot;different&quot; /&gt;&lt;br /&gt;
&lt;strong&gt;柱状图（BAR GRAPH）&lt;/strong&gt;：&lt;br /&gt;
柱之间的空间表示每个柱都是独特的类别，无法更改组距；柱状图可能会根据需要回答的问题，按照一定顺序排列柱状物，这样可以轻松的从x轴寻找到任何内容；柱状图的形状是任意的，取决于如何在x轴上排列各个类别；x轴上的变量通常是分类或者定性的(categorical/qualitative)；注意y轴上的值，划分可能不同。&lt;br /&gt;
&lt;strong&gt;直方图（Histogram）&lt;/strong&gt;：&lt;br /&gt;
是同一个类别，可以选择任何区间或组距；直方图的形状非常重要；对于直方图来说x轴上的变量是值（numerical/quantitative），是可以量化的。&lt;/p&gt;
&lt;h2 id=&quot;基础概念&quot;&gt;基础概念&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;正态分布&lt;/strong&gt;：&lt;br /&gt;
&lt;a href=&quot;https://baike.baidu.com/item/正态分布/829892?fr=aladdin&quot;&gt;正态分布百度百科&lt;/a&gt; &lt;br /&gt;
&lt;img src=&quot;https://github.com/leafming/bak/blob/master/images/machineLearning/2018-05-10-正态分布.png?raw=true&quot; alt=&quot;正态分布&quot; /&gt;&lt;/p&gt;

&lt;p&gt;正态分布峰值：众数；形状大致对称；大多数都在中间位置&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;偏斜分布&lt;/strong&gt;：&lt;br /&gt;
当多数数据集中在曲线的一端，而少数数据在曲线的另一端，数据分布的形态就产生了偏斜。当偏斜的一边的趋向正数的方向，叫正偏态。当偏斜的一边的趋向负数的方向叫负偏态。&lt;br /&gt;
&lt;img src=&quot;https://github.com/leafming/bak/blob/master/images/machineLearning/2018-05-10-偏斜分布.png?raw=true&quot; alt=&quot;偏斜分布&quot; /&gt;&lt;br /&gt;
负偏斜分布&lt;br /&gt;
&lt;img src=&quot;https://github.com/leafming/bak/blob/master/images/machineLearning/2018-05-14-负偏斜分布.png?raw=true&quot; alt=&quot;负偏斜分布&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;小习题-1&quot;&gt;小习题&lt;/h2&gt;
&lt;p&gt;1.图判断&lt;br /&gt;
&lt;img src=&quot;https://github.com/leafming/bak/blob/master/images/machineLearning/2018-05-14-2小习题.png?raw=true&quot; alt=&quot;test&quot; /&gt;&lt;br /&gt;
X轴上的数据是什么类型？&lt;br /&gt;
A数值型&lt;br /&gt;
B类别型&lt;br /&gt;
选择 B&lt;br /&gt;
图中柱的高度代表相对频率吗？&lt;br /&gt;
A是&lt;br /&gt;
B不是&lt;br /&gt;
选择 B&lt;br /&gt;
These are overall percentages. To be relative, they would have to add to 100%.&lt;/p&gt;

&lt;p&gt;2.以下哪个更适合用来计算 n ？&lt;br /&gt;
A频率表&lt;br /&gt;
B直方图&lt;br /&gt;
选择 A&lt;br /&gt;
以下哪个更适合用来分析分布的形状？&lt;br /&gt;
A频率表&lt;br /&gt;
B直方图&lt;br /&gt;
选择 B&lt;/p&gt;

&lt;h1 id=&quot;2018-05-14-google-spreadsheet&quot;&gt;2018-05-14-Google Spreadsheet&lt;/h1&gt;
&lt;p&gt;execel的使用。&lt;/p&gt;

&lt;h1 id=&quot;2018-05-14-集中趋势&quot;&gt;2018-05-14-集中趋势&lt;/h1&gt;
&lt;h2 id=&quot;基础概念-1&quot;&gt;基础概念&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;中心测量方法&lt;/strong&gt;，描述分布中心的情况:&lt;br /&gt;
&lt;strong&gt;众数&lt;/strong&gt;：出现频率最高的值或范围。  &lt;br /&gt;
&lt;strong&gt;中位数&lt;/strong&gt;：刚好分布在中间的值。&lt;br /&gt;
&lt;strong&gt;平均值&lt;/strong&gt;：位于分布中间特定位置的统计值。&lt;/p&gt;

&lt;h2 id=&quot;众数讨论&quot;&gt;众数讨论&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;众数可用于描述任何数据类型，数值型和类别型都可以。&lt;/strong&gt;&lt;br /&gt;
&lt;strong&gt;出现频率最高的值或范围。&lt;/strong&gt;&lt;br /&gt;
&lt;strong&gt;不是数据集中的每个数据都影响众数。&lt;/strong&gt;&lt;br /&gt;
&lt;strong&gt;众数可能随着样本的不同而不同。&lt;/strong&gt;&lt;br /&gt;
&lt;strong&gt;直方图中，众数随着组距的改变而改变。众数与呈现数据的方式有很大关系。&lt;/strong&gt;&lt;br /&gt;
&lt;strong&gt;众数没有计算公式。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;均匀分布&lt;/strong&gt;-没有众数。&lt;br /&gt;
&lt;img src=&quot;https://github.com/leafming/bak/blob/master/images/machineLearning/2018-05-14-均匀分布.png?raw=true&quot; alt=&quot;均匀分布&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;多峰分布&lt;/strong&gt;:存在两个或多个明显清晰的趋势的分布。-不只一个众数。&lt;br /&gt;
&lt;img src=&quot;https://github.com/leafming/bak/blob/master/images/machineLearning/2018-05-14-多峰分布.png?raw=true&quot; alt=&quot;多峰分布&quot; /&gt;&lt;/p&gt;

&lt;p&gt;练习：这个分布图的众数是什么？&lt;br /&gt;
&lt;img src=&quot;https://github.com/leafming/bak/blob/master/images/machineLearning/2018-05-14-众数小练习.png?raw=true&quot; alt=&quot;众数练习&quot; /&gt;&lt;br /&gt;
AMale  BFemale  C1000  D7000&lt;br /&gt;
答案 A&lt;/p&gt;

&lt;h2 id=&quot;平均值讨论&quot;&gt;平均值讨论&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;算数平均值&lt;/strong&gt;(样本平均值)：&lt;script type=&quot;math/tex&quot;&gt;\overline{x} = \frac{x_{1}+ x_{2}+...+x_{n}}{n}=\frac{\sum_{i=1}^{n}x_{i}}{n}&lt;/script&gt;&lt;br /&gt;
&lt;strong&gt;总体的均值μ&lt;/strong&gt;：&lt;script type=&quot;math/tex&quot;&gt;\mu=\frac{\sum x}{N}&lt;/script&gt; N为总体的数量&lt;br /&gt;
均值特性：&lt;br /&gt;
&lt;strong&gt;分布中的所有值都影响平均值。&lt;/strong&gt;&lt;br /&gt;
&lt;strong&gt;平均值可用公式来描述。&lt;/strong&gt;&lt;br /&gt;
&lt;strong&gt;同一个总体中的多个样本会有相似的平均值。&lt;/strong&gt;&lt;br /&gt;
&lt;strong&gt;一个样本的平均值可以用来推论其所在的总体。&lt;/strong&gt;&lt;br /&gt;
&lt;strong&gt;如果向数据集中添加一个极值，它的平均值会发生改变。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;当出现异常数值（outlier）时，平均值会有误导性；异常数值会将平均值拉向异常方向，造成偏斜分布，使得平均值难以具备数据中位数的代表性。&lt;/p&gt;

&lt;p&gt;众数不受异常数值影响，而平均值会受到很大影响。&lt;/p&gt;

&lt;h2 id=&quot;中位数讨论&quot;&gt;中位数讨论&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;中位数&lt;/strong&gt;是位于“中间”的数据，意味着有一半数据值小于它，而另一半大于它。&lt;br /&gt;
如何让中位数更加有用？-按顺序排列数据。&lt;br /&gt;
如何找出中位数？1.按顺序排列数据，找到最中间的一个。2.按顺序排列数据，如果数据量为偶数的数据集中查找中位数时，求中间2个数字的平均数。&lt;br /&gt;
&lt;strong&gt;中位数公式&lt;/strong&gt;：n个值的数据集的中位数,排序后：&lt;br /&gt;
1.n为&lt;strong&gt;偶数&lt;/strong&gt;：&lt;script type=&quot;math/tex&quot;&gt;\frac{x_{\frac{n}{2}}+x_{\frac{n}{2}+1}}{2}&lt;/script&gt;&lt;br /&gt;
2.n为&lt;strong&gt;奇数&lt;/strong&gt;：&lt;script type=&quot;math/tex&quot;&gt;x_{\frac{n+1}{2}}&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;在含异常值的数据中统计中位数，发现中位数的变化并不大，中位数的这一趋势非常稳健，稳健即强大且稳定，即使偏离了基准也不会受到很大的影响。&lt;/p&gt;

&lt;h2 id=&quot;小总结&quot;&gt;小总结&lt;/h2&gt;
&lt;p&gt;有些时候由于存在异常数值，均值无法描述分布中心；在有些情况下，众数也无法描述分布中心；中位数不会考虑到所有数据点；在处理高偏斜分布时，中位数通常能更好的反映出集中趋势。&lt;/p&gt;

&lt;p&gt;在正向偏斜分布中，如下图：众数&amp;lt;中位数&amp;lt;均值&lt;br /&gt;
&lt;img src=&quot;https://github.com/leafming/bak/blob/master/images/machineLearning/2018-05-14-正偏斜分布中心情况.jpeg?raw=true&quot; alt=&quot;正向偏斜分布分布中心&quot; /&gt;&lt;/p&gt;

&lt;p&gt;在正态分布中，如下图：均值=中位数=众数&lt;br /&gt;
&lt;img src=&quot;https://github.com/leafming/bak/blob/master/images/machineLearning/2018-05-14-正态中心分布情况.png?raw=true&quot; alt=&quot;正态分布分布中心&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;中心测量方法总结&quot;&gt;中心测量方法总结&lt;/h2&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt; &lt;/th&gt;
      &lt;th&gt;有一个简单的公式&lt;/th&gt;
      &lt;th&gt;如果数据集中有数据的值变化，它也一定会变化&lt;/th&gt;
      &lt;th&gt;不受组距变化的影响&lt;/th&gt;
      &lt;th&gt;不易受到异常值的影响&lt;/th&gt;
      &lt;th&gt;容易在直方图上找到&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;mean均值&lt;/td&gt;
      &lt;td&gt;V&lt;/td&gt;
      &lt;td&gt;V&lt;/td&gt;
      &lt;td&gt;V&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;median中位数&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;V&lt;/td&gt;
      &lt;td&gt;V&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;mode众数&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;V&lt;/td&gt;
      &lt;td&gt;V&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h2 id=&quot;小练习&quot;&gt;小练习&lt;/h2&gt;
&lt;p&gt;&lt;img src=&quot;https://github.com/leafming/bak/blob/master/images/machineLearning/2018-05-14-小习题.png?raw=true&quot; alt=&quot;小练习2&quot; /&gt;&lt;br /&gt;
此图中众数1=众数2，均值1=均值2，中间数1=中间数2&lt;br /&gt;
众数均为40000-50000&lt;br /&gt;
平均值50000&lt;br /&gt;
中间数也差不多在中间&lt;/p&gt;

&lt;p&gt;如有问题，请发送邮件至leafming@foxmail.com联系我，谢谢～&lt;br /&gt;
©商业转载请联系作者获得授权，非商业转载请注明出处。&lt;/p&gt;</content><author><name>Liv Yeh</name></author><category term="机器学习" /><category term="描述统计学" /><summary type="html">本文关于自学udacity机器学习课程的自学笔记，为第一部分，描述统计学入门(1)。 2018-05-08-研究方法入门 基本概念 抽象概念（constructs） 操作性定义：一种将构造（constructs）转变为我们可衡量的变量的方式；一种用我们衡量它的方式描述变量的方式。 总体参数μ：描述整个总体的平均值 样本统计量：样本的平均值 样本大小n 抽样误差μ-：样本平均值和总体平均值之间的差异。在使用一个样本对一个总体进行推理时，样本的平均值可能不会完全等于总体的平均值。 用来估计μ，估计值是对μ的最佳猜测。 好样本：大、随机无偏差 随机样本：每个对象被选中的概率都是一样的。 可视化关系-eg 散点图 散点图： 1.x轴上变量：自变量（independent variable）或预测变量（predictor variable） 2.y轴上变量：因变量（dependent variable）即结果（outcome）</summary></entry><entry><title type="html">Kerberos具体实践1-Kerberos环境准备及安装</title><link href="http://localhost:4000/bigdata/2018/05/05/Kerberos%E5%85%B7%E4%BD%93%E5%AE%9E%E8%B7%B51-Kerberos%E7%8E%AF%E5%A2%83%E5%87%86%E5%A4%87%E5%8F%8A%E5%AE%89%E8%A3%85/" rel="alternate" type="text/html" title="Kerberos具体实践1-Kerberos环境准备及安装" /><published>2018-05-05T00:00:00+08:00</published><updated>2018-05-05T00:00:00+08:00</updated><id>http://localhost:4000/bigdata/2018/05/05/Kerberos%E5%85%B7%E4%BD%93%E5%AE%9E%E8%B7%B51-Kerberos%E7%8E%AF%E5%A2%83%E5%87%86%E5%A4%87%E5%8F%8A%E5%AE%89%E8%A3%85</id><content type="html" xml:base="http://localhost:4000/bigdata/2018/05/05/Kerberos%E5%85%B7%E4%BD%93%E5%AE%9E%E8%B7%B51-Kerberos%E7%8E%AF%E5%A2%83%E5%87%86%E5%A4%87%E5%8F%8A%E5%AE%89%E8%A3%85/">&lt;blockquote&gt;
  &lt;p&gt;本文属于Kerberos具体实践整理的第一部分，主要涉及到Kerberos集群的安装以及基本命令的使用。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h1 id=&quot;概述&quot;&gt;概述&lt;/h1&gt;
&lt;h2 id=&quot;为什么要将hdfs和kerberos整合&quot;&gt;为什么要将HDFS和Kerberos整合&lt;/h2&gt;
&lt;p&gt;HDFS权限控制过于简单，直接使用hadoop的acl进行权限控制，可能会出现在程序中使用&lt;strong&gt;System.setProperty(“HADOOP_USER_NAME”,”root”);&lt;/strong&gt;直接更改用户，伪装成任意用户使用。因此，需要加强HDFS权限控制，则采用进行kerberos认证的方式。&lt;br /&gt;
hadoop的用户鉴权是基于JAAS的，其中hadoop.security.authentication属性有simple 和kerberos 等方式。如果hadoop.security.authentication等于”kerberos”,那么是“hadoop-user-kerberos”或者“hadoop-keytab-kerberos”，否则是“hadoop-simple”。在使用了kerberos的情况下，从javax.security.auth.kerberos.KerberosPrincipal的实例获取username。在没有使用kerberos时，首先读取hadoop的系统环境变量，如果没有的话，对于windows 从com.sun.security.auth.NTUserPrincipal获取用户名，对于类unix 从com.sun.security.auth.UnixPrincipal中获得用户名，然后再看该用户属于哪个group，从而完成登陆认证。&lt;/p&gt;
&lt;h2 id=&quot;kerberos原理&quot;&gt;Kerberos原理&lt;/h2&gt;
&lt;h3 id=&quot;术语说明&quot;&gt;术语说明&lt;/h3&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;术语&lt;/th&gt;
      &lt;th&gt;简述&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;KDC&lt;/td&gt;
      &lt;td&gt;在启用Kerberos的环境中，KDC用于验证各个模块&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Kerberos KDC Server&lt;/td&gt;
      &lt;td&gt;KDC所在的机器&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Kerberos Client&lt;/td&gt;
      &lt;td&gt;任何一个需要通过KDC认证的机器（或模块）&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Principal&lt;/td&gt;
      &lt;td&gt;用于验证一个用户或者一个Service的唯一的标识，相当于一个账号，需要为其设置密码（这个密码也被称之为Key）&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Keytab&lt;/td&gt;
      &lt;td&gt;包含有一个或多个Principal以及其密码的文件&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Relam&lt;/td&gt;
      &lt;td&gt;由KDC以及多个Kerberos Client组成的网络&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;KDC Admin Account&lt;/td&gt;
      &lt;td&gt;KDC中拥有管理权限的账户（例如添加、修改、删除Principal）&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Authentication Server (AS)&lt;/td&gt;
      &lt;td&gt;用于初始化认证，并生成Ticket Granting Ticket (TGT)&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Ticket Granting Server (TGS)&lt;/td&gt;
      &lt;td&gt;在TGT的基础上生成Service Ticket。一般情况下AS和TGS都在KDC的Server上&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;Kerberos原理则不在此处进行说明，以后再做补充@TODO。本文直接先说明测试部署过程。&lt;/p&gt;
&lt;h1 id=&quot;部署操作&quot;&gt;部署操作&lt;/h1&gt;
&lt;p&gt;本文中部署操作首先先进行Kerberos单节点KDC部署，之后将单节点KDC的基础上结合HDFS进行配置，最后对整体集群进行优化，部署主从KDC防止Kerberos单点故障。&lt;br /&gt;
全部部署过程均在RHEL 7.1系统上进行。&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;参考链接：&lt;br /&gt;
&lt;a href=&quot;https://ieevee.com/tech/2016/06/07/kerberos-1.html&quot;&gt;Kerberos从入门到放弃（一）：HDFS使用kerberos&lt;/a&gt;&lt;br /&gt;
&lt;a href=&quot;https://yq.aliyun.com/articles/25636?spm=5176.100240.searchblog.8.wbY2wv&quot;&gt;HDFS配置Kerberos认证&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;环境说明&quot;&gt;环境说明&lt;/h2&gt;
&lt;p&gt;系统环境：&lt;br /&gt;
操作系统：RHEL 7.1
Hadoop版本：2.6.0-cdh5.11.0
JDK版本：jdk1.8.0&lt;br /&gt;
运行用户：hadoop&lt;/p&gt;
&lt;h2 id=&quot;kerberos单节点kdc部署&quot;&gt;Kerberos单节点KDC部署&lt;/h2&gt;
&lt;p&gt;节点规划:&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;hosts&lt;/th&gt;
      &lt;th&gt;角色&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;node1&lt;/td&gt;
      &lt;td&gt;kerberos server、AS、TGS、agent、namenode、datanode、zk&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;node2&lt;/td&gt;
      &lt;td&gt;kerberos client、SecondaryNameNode 、datanode、zk&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;node3&lt;/td&gt;
      &lt;td&gt;kerberos client、datanode、zk&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h3 id=&quot;1添加主机名解析到etchosts文件或配置dns&quot;&gt;(1)添加主机名解析到/etc/hosts文件或配置DNS&lt;/h3&gt;
&lt;p&gt;在Kerberos中，Principal中需各主机的FQDN名，所以集群中需要有DNS。&lt;br /&gt;
但在本次测试中，未进行DNS配置，直接使用配置hosts进行测试。&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;[root@node1 ~]# cat /etc/hosts
::1         localhost localhost.localdomain localhost6 localhost6.localdomain6
10.211.55.10 node1
10.211.55.11 node2
10.211.55.12 node3
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;注意：hostname 请使用小写，要不然在集成 kerberos 时会出现一些错误。&lt;/strong&gt;&lt;/p&gt;
&lt;h3 id=&quot;2配置ntp&quot;&gt;(2)配置NTP&lt;/h3&gt;
&lt;p&gt;Kerberos集群对时间同步敏感度较高，默认时间相差超过5分钟就会出现问题，所以最好是在集群中增加NTP服务器。不过我的集群机器比较少，先跳过NTP吧。&lt;/p&gt;
&lt;h3 id=&quot;3安装kerberos&quot;&gt;(3)安装Kerberos&lt;/h3&gt;
&lt;p&gt;Kerberos有不同的实现，如MIT KDC、Microsoft Active Directory等。我这里采用的是MIT KDC。&lt;br /&gt;
在 KDC (这里是 node1 ) 上安装包 krb5、krb5-server 和 krb5-client：&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ yum install krb5-server krb5-libs krb5-workstation  -y 
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;p&gt;在其他节点（node1、node2、node3）安装 krb5-devel、krb5-workstation：&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ yum install krb5-libs krb5-workstation  -y
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;h3 id=&quot;4修改配置文件&quot;&gt;(4).修改配置文件&lt;/h3&gt;
&lt;p&gt;kdc 服务器涉及到三个配置文件：&lt;br /&gt;
/etc/krb5.conf&lt;br /&gt;
/var/kerberos/krb5kdc/kdc.conf&lt;br /&gt;
/var/kerberos/krb5kdc/kadm5.acl&lt;/p&gt;
&lt;h4 id=&quot;akrb5conf配置&quot;&gt;a).krb5.conf配置&lt;/h4&gt;
&lt;p&gt;/etc/krb5.conf:包含Kerberos的配置信息。例如，KDC的位置，Kerberos的admin的realms 等。需要所有使用的Kerberos的机器上的配置文件都同步。这里仅列举需要的基本配置。详细参考&lt;a href=&quot;http://web.mit.edu/kerberos/krb5-latest/doc/admin/conf_files/krb5_conf.html&quot;&gt;krb5.conf&lt;/a&gt;&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;[root@node1 etc]# cat krb5.conf
# Configuration snippets may be placed in this directory as well
includedir /etc/krb5.conf.d/
[logging] #[logging]：表示 server 端的日志的打印位置
 default = FILE:/var/log/krb5libs.log
 kdc = FILE:/var/log/krb5kdc.log
 admin_server = FILE:/var/log/kadmind.log

[libdefaults] #[libdefaults]：每种连接的默认配置，需要注意以下几个关键的小配置
 default_realm = HADOOP.COM #设置Kerberos应用程序的默认领域。如果您有多个领域，只需向[realms]节添加其他的语句
 dns_lookup_realm = false
 #clockskew = 120 #时钟偏差是不完全符合主机系统时钟的票据时戳的容差，超过此容差将不接受此票据。通常，将时钟扭斜设置为 300 秒（5 分钟）。这意味着从服务器的角度看，票证的时间戳与它的偏差可以是在前后 5 分钟内。~~
 ticket_lifetime = 24h #表明凭证生效的时限，一般为24小时
 renew_lifetime = 7d #表明凭证最长可以被延期的时限，一般为一个礼拜。当凭证过期之后，对安全认证的服务的后续访问则会失败
 forwardable = true #允许转发解析请求  
 rdns = false
 udp_preference_limit = 1 #禁止使用udp可以防止一个Hadoop中的错误

[realms] #列举使用的realm
HADOOP.COM = {
  kdc = node1:88 #代表要kdc的位置。格式是机器:端口。测试过程中也可不加端口。
  admin_server = node1:749 #代表admin的位置。格式是机器:端口。测试过程中也可不加端口。
  default_domain = HADOOP.COM #代表默认的域名。
 }

[kdc]
 profile=/var/kerberos/krb5kdc/kdc.conf
 
#[domain_realm] 
#.hadoop.com = HADOOP.COM
#hadoop.com = HADOOP.COM
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;p&gt;总结：&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;这个文件可以用include和includedir引入其他文件或文件夹，但必须是绝对路径&lt;/li&gt;
  &lt;li&gt;realms:包含kerberos realm的名字（部分键控），显示关于realm的特殊信息，包括该realm内的主机要从哪里寻找kerberos的server。&lt;/li&gt;
  &lt;li&gt;domain realm：将domain名和子domain名映射到realm名上&lt;/li&gt;
  &lt;li&gt;必须填的有以下几项：&lt;/li&gt;
  &lt;li&gt;default-realm：在libdefault部分&lt;/li&gt;
  &lt;li&gt;admin_server：在realm部分&lt;/li&gt;
  &lt;li&gt;domain_realm：当domain名和realm名不同的时候要设置&lt;/li&gt;
  &lt;li&gt;logging：当该机器作为KDC时要设置&lt;/li&gt;
  &lt;li&gt;[appdefaults]：可以设定一些针对特定应用的配置，覆盖默认配置。&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;bkdcconf配置&quot;&gt;b).kdc.conf配置&lt;/h4&gt;
&lt;p&gt;/var/kerberos/krb5kdc/kdc.conf:包括KDC的配置信息。默认放在 /usr/local/var/krb5kdc。或者通过覆盖KRB5_KDC_PROFILE环境变量修改配置文件位置。详细参考&lt;a href=&quot;http://web.mit.edu/kerberos/krb5-latest/doc/admin/conf_files/kdc_conf.html&quot;&gt;kdc.conf&lt;/a&gt;。&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;[root@node1 ~]# cat /var/kerberos/krb5kdc/kdc.conf
[kdcdefaults]
 kdc_ports = 88
 kdc_tcp_ports = 88

[realms]
 HADOOP.COM = { #是设定的 realms。名字随意。Kerberos 可以支持多个 realms，会增加复杂度。大小写敏感，一般为了识别使用全部大写。这个realms跟机器的host没有大关系。
  #master_key_type = aes256-cts
  #和supported_enctypes默认使用aes256-cts。由于，JAVA使用aes256-cts验证方式需要安装额外的jar包（后面再做说明）。推荐不使用，并且删除aes256-cts。
  kadmind_port = 749
  acl_file = /var/kerberos/krb5kdc/kadm5.acl #标注了admin的用户权限，需要用户自己创建。文件格式是：Kerberos_principal permissions [target_principal] [restrictions] 支持通配符等。最简单的写法是*/admin@HADOOP.COM *,代表名称匹配*/admin@HADOOP.COM 都认为是admin，权限是 *。代表全部权限。
  dict_file = /usr/share/dict/words
  database_name = /var/kerberos/krb5kdc/principal
  key_stash_file =  /var/kerberos/krb5kdc/.k5.HADOOP.COM
  admin_keytab = /var/kerberos/krb5kdc/kadm5.keytab #KDC 进行校验的 keytab
  max_life = 24h
  max_renewable_life = 10d #涉及到是否能进行ticket的renwe必须配置
  default_principal_flags = +renewable, +forwardable
  supported_enctypes = des3-hmac-sha1:normal arcfour-hmac:normal camellia256-cts:normal camellia128-cts:normal des-hmac-sha1:normal des-cbc-md5:normal des-cbc-crc:normal #支持的校验方式.注意把aes256-cts去掉
 }
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;p&gt;总结：&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;HADOOP.COM： 是设定的 realms。名字随意。Kerberos可以支持多个。&lt;/li&gt;
  &lt;li&gt;realms，会增加复杂度。大小写敏感，一般为了识别使用全部大写。这个 realms 跟机器的 host 没有大关系。&lt;/li&gt;
  &lt;li&gt;master_key_type：和 supported_enctypes 默认使用 aes256-cts。JAVA 使用 aes256-cts 验证方式需要安装 JCE 包，见下面的说明。为了简便，你可以不使用aes256-cts 算法，这样就不需要安装 JCE 。&lt;/li&gt;
  &lt;li&gt;acl_file：标注了 admin 的用户权限，需要用户自己创建。文件格式是：Kerberos_principal permissions [target_principal] [restrictions]&lt;/li&gt;
  &lt;li&gt;supported_enctypes：支持的校验方式。&lt;/li&gt;
  &lt;li&gt;admin_keytab：KDC 进行校验的 keytab。&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;补充说明-关于AES-256加密（未测试，参考&lt;a href=&quot;https://yq.aliyun.com/articles/25636?spm=5176.100240.searchblog.8.wbY2wv&quot;&gt;HDFS配置Kerberos认证&lt;/a&gt;）： &lt;br /&gt;
对于使用 centos5. 6 及以上的系统，默认使用 AES-256 来加密的。这就需要集群中的所有节点上安装 JCE，如果你使用的是 JDK1.6 ，则到 Java Cryptography Extension (JCE) Unlimited Strength Jurisdiction Policy Files for JDK/JRE 6 页面下载，如果是 JDK1.7，则到 Java Cryptography Extension (JCE) Unlimited Strength Jurisdiction Policy Files for JDK/JRE 7 下载。下载的文件是一个 zip 包，解开后，将里面的两个文件放到下面的目录中：$JAVA_HOME/jre/lib/security&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h4 id=&quot;ckadm5acl配置&quot;&gt;c).kadm5.acl配置&lt;/h4&gt;
&lt;p&gt;为了能够不直接访问KDC控制台而从Kerberos数据库添加和删除主体，请对Kerberos管理服务器指示允许哪些主体执行哪些操作。通过编辑文件 /var/kerberos/krb5kdc/kadm5.acl完成此操作。ACL（访问控制列表）允许您精确指定特权。&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;[root@node1 ~]# cat /var/kerberos/krb5kdc/kadm5.acl
*/admin@HADOOP.COM	*
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h3 id=&quot;5同步配置文件&quot;&gt;(5)同步配置文件&lt;/h3&gt;
&lt;p&gt;将 kdc 中的 /etc/krb5.conf 拷贝到集群中其他服务器即可。&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ scp /etc/krb5.conf node2:/etc/krb5.conf
$ scp /etc/krb5.conf node3:/etc/krb5.conf
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;p&gt;请确认集群如果关闭了 selinux。&lt;/p&gt;

&lt;h3 id=&quot;6创建数据库&quot;&gt;(6)创建数据库&lt;/h3&gt;
&lt;p&gt;在node1上运行初始化数据库命令。其中 -r 指定对应 realm。&lt;br /&gt;
该命令会在 /var/kerberos/krb5kdc/ 目录下创建 principal 数据库。&lt;br /&gt;
如果遇到数据库已经存在的提示，可以把/var/kerberos/krb5kdc/目录下的principal的相关文件都删除掉。默认的数据库名字都是 principal。可以使用 -d 指定数据库名字。&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ kdb5_util create -r JAVACHEN.COM -s
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;blockquote&gt;
  &lt;p&gt;补充小技巧-（未测试，其他帖子看到的）：出现Loading random data的时候另开个终端执行点消耗CPU的命令如cat /dev/sda &amp;gt; /dev/urandom 可以加快随机数采集。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;操作结果小例子：&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;[root@node1 etc]# kdb5_util create -r HADOOP.COM -s
Loading random data
Initializing database '/var/kerberos/krb5kdc/principal' for realm 'HADOOP.COM',
master key name 'K/M@HADOOP.COM'
You will be prompted for the database Master Password.    #在此处输入的是root@1234
It is important that you NOT FORGET this password.
Enter KDC database master key:
Re-enter KDC database master key to verify:
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h3 id=&quot;7启动服务&quot;&gt;(7)启动服务&lt;/h3&gt;
&lt;p&gt;在node1节点上运行：&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;[root@node1 etc]# service krb5kdc start
Redirecting to /bin/systemctl start krb5kdc.service
[root@node1 etc]# service kadmin start
Redirecting to /bin/systemctl start kadmin.service
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;p&gt;至此kerberos，搭建完毕。&lt;/p&gt;

&lt;h2 id=&quot;kerberos基本环境创建及简单命令测试&quot;&gt;Kerberos基本环境创建及简单命令测试&lt;/h2&gt;
&lt;h3 id=&quot;1创建kerberos管理员&quot;&gt;(1)创建Kerberos管理员&lt;/h3&gt;
&lt;p&gt;关于 kerberos 的管理，可以使用 kadmin.local 或 kadmin，至于使用哪个，取决于账户和访问权限：&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;如果有访问 kdc 服务器的 root 权限，但是没有 kerberos admin 账户，使用 kadmin.local&lt;/li&gt;
  &lt;li&gt;如果没有访问 kdc 服务器的 root 权限，但是用 kerberos admin 账户，使用 kadmin&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;在node1上创建远程管理的管理员，系统会提示输入密码，密码不能为空，且需妥善保存。：&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;#手动输入两次密码，这里密码为 root
$ kadmin.local -q &quot;addprinc root/admin&quot;
# 也可以不用手动输入密码，通过echo将密码引入
$ echo -e &quot;root\nroot&quot; | kadmin.local -q &quot;addprinc root/admin&quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;p&gt;建议：&lt;br /&gt;
最好把username设为root，会提示输入密码，可以输入一个密码。&lt;br /&gt;
创建第一个principal，必须在KDC自身的终端上进行，而且需要以root登录，这样才可以执行kadmin.local命令。&lt;/p&gt;

&lt;p&gt;操作结果小例子：&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;[root@node1 etc]# kadmin.local -q &quot;addprinc root/admin&quot;
Authenticating as principal root/admin@HADOOP.COM with password.
WARNING: no policy specified for root/admin@HADOOP.COM; defaulting to no policy
Enter password for principal &quot;root/admin@HADOOP.COM&quot;:
Re-enter password for principal &quot;root/admin@HADOOP.COM&quot;:
Principal &quot;root/admin@HADOOP.COM&quot; created.
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h3 id=&quot;2添加更多主体-创建host主体并将自己的host主题添加到自己密钥表文件&quot;&gt;(2)添加更多主体-创建host主体并将自己的host主题添加到自己密钥表文件&lt;/h3&gt;
&lt;h4 id=&quot;a基于kerberos-的应用程序例如-kprop将使用主机主体将变更传播到从kdc服务器也可以通过该主体提供对使用应用程序如ssh的kdc服务器的安全远程访问&quot;&gt;a).基于Kerberos 的应用程序(例如 kprop)将使用主机主体将变更传播到从KDC服务器。也可以通过该主体提供对使用应用程序(如ssh)的KDC服务器的安全远程访问。&lt;/h4&gt;
&lt;p&gt;请注意，当主体实例为主机名时，无论名称服务中的域名是大写还是小写，都必须以小写字母指定FQDN。&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;kadmin: addprinc -randkey host/node1
Principal &quot;host/node1@HADOOP.COM&quot; created. 
kadmin:
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;p&gt;或用命令（创建了node1、node2、node3的host主体）：&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;kadmin.local -q &quot;addprinc -randkey host/node1@HADOOP.COM&quot;
kadmin.local -q &quot;addprinc -randkey host/node2@HADOOP.COM&quot;
kadmin.local -q &quot;addprinc -randkey host/node3@HADOOP.COM&quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;h4 id=&quot;b将kdc服务器的host主体添加到kdc服务器的密钥表文件&quot;&gt;b).将KDC服务器的host主体添加到KDC服务器的密钥表文件。&lt;/h4&gt;
&lt;p&gt;通过将主机主体添加到密钥表文件，允许应用服务器(如sshd)自动使用该主体。&lt;br /&gt;
&lt;strong&gt;注意：将自己的host主体添加到自己的密钥表文件。&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;#在node1上执行
kadmin: ktadd host/node1
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h3 id=&quot;3kerberos简单命令测试&quot;&gt;(3)Kerberos简单命令测试&lt;/h3&gt;
&lt;p&gt;输入kadmin或者kadmin.local命令进入kerberos的shell(登录到管理员账户:如果在本机上，可以通过kadmin.local直接登录。其它机器的，先使用kinit进行验证)，如下：&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;1、其他机器上先使用kinit进行验证：
echo root@1234|kinit root/admin  
2、之后再使用kadmin或者kadmin.local命令进入kerberos的shell
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;h4 id=&quot;aprincipals操作&quot;&gt;a).principals操作&lt;/h4&gt;
&lt;p&gt;查看principals&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ kadmin: list_principals
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;p&gt;添加一个新的 principal&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ kadmin:  addprinc user1  
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;p&gt;删除 principal&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ kadmin:  delprinc user1  
$ kadmin: exit
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;p&gt;也可以直接通过下面的命令来执行：&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;#提示需要输入密码
$ kadmin -p root/admin -q &quot;list_principals&quot;
$ kadmin -p root/admin -q &quot;addprinc user2&quot;
$ kadmin -p root/admin -q &quot;delprinc user2&quot;

#不用输入密码
$ kadmin.local -q &quot;list_principals&quot;
$ kadmin.local -q &quot;addprinc user2&quot;
$ kadmin.local -q &quot;delprinc user2&quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h4 id=&quot;bticket操作创建一个测试用户test密码设置为test&quot;&gt;b).ticket操作:创建一个测试用户test，密码设置为test&lt;/h4&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ echo -e &quot;test\ntest&quot; | kadmin.local -q &quot;addprinc test&quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;p&gt;获取 test 用户的 ticket：&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;#通过用户名和密码进行登录
[root@node2 ~]# kinit test
Password for test@HADOOP.COM:
[root@node2 ~]# klist  -e
Ticket cache: KEYRING:persistent:0:krb_ccache_CGo77JQ
Default principal: test@HADOOP.COM
Valid starting       Expires              Service principal
09/06/2017 16:06:57  09/07/2017 16:06:57  krbtgt/HADOOP.COM@HADOOP.COM
	renew until 09/13/2017 16:06:57, Etype (skey, tkt): des3-cbc-sha1, des3-cbc-sha1
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;p&gt;销毁该 test 用户的 ticket:&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;[root@node2 ~]# kdestroy
Other credential caches present, use -A to destroy all
[root@node2 ~]# kdestroy -A
[root@node2 ~]# klist  -e
klist: Credentials cache keyring 'persistent:0:krb_ccache_CGo77JQ' not found
[root@node2 ~]# klist
klist: Credentials cache keyring 'persistent:0:krb_ccache_CGo77JQ' not found
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;p&gt;更新 ticket:&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ kinit root/admin
  Password for root/admin@HADOOP.COM:
$  klist
  Ticket cache: FILE:/tmp/krb5cc_0
  Default principal: root/admin@JAVACHEN.COM
  Valid starting     Expires            Service principal
  11/07/14 15:33:57  11/08/14 15:33:57  krbtgt/JAVACHEN.COM@JAVACHEN.COM
    renew until 11/17/14 15:33:57
  Kerberos 4 ticket cache: /tmp/tkt0
  klist: You have no tickets cached
$ kinit -R
$ klist
  Ticket cache: FILE:/tmp/krb5cc_0
  Default principal: root/admin@JAVACHEN.COM
  Valid starting     Expires            Service principal
  11/07/14 15:34:05  11/08/14 15:34:05  krbtgt/JAVACHEN.COM@JAVACHEN.COM
    renew until 11/17/14 15:33:57
  Kerberos 4 ticket cache: /tmp/tkt0
  klist: You have no tickets cached
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;h4 id=&quot;c-抽取密钥到在本地keytab文件&quot;&gt;c). 抽取密钥到在本地keytab文件&lt;/h4&gt;
&lt;p&gt;抽取密钥并将其储存在本地keytab文件/etc/krb5.keytab中。这个文件由超级用户拥有，所以您必须是root用户才能在kadmin shell 中执行以下命令:&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ kadmin.local -q &quot;ktadd kadmin/admin&quot;
$ klist -k /etc/krb5.keytab
  Keytab name: FILE:/etc/krb5.keytab
  KVNO Principal
  ---- ----------------------------------------------------------------------
     3 kadmin/admin@LASHOU-INC.COM
     3 kadmin/admin@LASHOU-INC.COM
     3 kadmin/admin@LASHOU-INC.COM
     3 kadmin/admin@LASHOU-INC.COM
     3 kadmin/admin@LASHOU-INC.COM
   -----------------
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;至此，本篇内容完成。以上为Kerberos单KDC版搭建过程，下篇文章进行HDFS和Kerberos整合操作的整理。&lt;br /&gt;
如有问题，请发送邮件至leafming@foxmail.com联系我，谢谢～&lt;br /&gt;
©商业转载请联系作者获得授权，非商业转载请注明出处。&lt;/p&gt;</content><author><name>Liv Yeh</name></author><category term="Kerberos" /><summary type="html">本文属于Kerberos具体实践整理的第一部分，主要涉及到Kerberos集群的安装以及基本命令的使用。</summary></entry><entry><title type="html">SparkStreaming程序中checkpoint与广播变量兼容处理</title><link href="http://localhost:4000/bigdata/2018/04/04/SparkStreaming%E7%A8%8B%E5%BA%8F%E4%B8%ADcheckpoint%E4%B8%8E%E5%B9%BF%E6%92%AD%E5%8F%98%E9%87%8F%E5%85%BC%E5%AE%B9%E5%A4%84%E7%90%86/" rel="alternate" type="text/html" title="SparkStreaming程序中checkpoint与广播变量兼容处理" /><published>2018-04-04T00:00:00+08:00</published><updated>2018-04-04T00:00:00+08:00</updated><id>http://localhost:4000/bigdata/2018/04/04/SparkStreaming%E7%A8%8B%E5%BA%8F%E4%B8%ADcheckpoint%E4%B8%8E%E5%B9%BF%E6%92%AD%E5%8F%98%E9%87%8F%E5%85%BC%E5%AE%B9%E5%A4%84%E7%90%86</id><content type="html" xml:base="http://localhost:4000/bigdata/2018/04/04/SparkStreaming%E7%A8%8B%E5%BA%8F%E4%B8%ADcheckpoint%E4%B8%8E%E5%B9%BF%E6%92%AD%E5%8F%98%E9%87%8F%E5%85%BC%E5%AE%B9%E5%A4%84%E7%90%86/">&lt;blockquote&gt;
  &lt;p&gt;上文中说明了如何使用kafka连接池来优化程序，但是在上文中预留了一个问题，就是当使用上文的方式下发KafkaPool广播变量时，如果Spark Streaming程序中也使用了checkpoint，则如果程序中断而重启程序，广播变量无法从checkpoint中恢复，会出现“java.lang.ClassCastException:B cannot be cast to KafkaPool”问题，所以在此篇文章中，对此问题进行解决。&lt;br /&gt;
&lt;strong&gt;注意: 本文中使用的版本是spark2.2.1和kafka0.10.1.1&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h1 id=&quot;背景&quot;&gt;背景&lt;/h1&gt;
&lt;p&gt;在spark信令处理程序中使用checkpoint主要是因为从源头读取kafka数据的时候记录offset，防止数据丢失；并且目前是做的是容器化的集群，如果集群down了，会自动重启容器并且也能把程序恢复。&lt;br /&gt;
不过对于Spark Streaming中防止数据丢失可以有两种方式:&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;使用Spark Streaming的checkpoint机制&lt;/li&gt;
  &lt;li&gt;自己维护kafka offset&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;但是，有人说checkpoint有弊端，并且我也遇到了序列化的这个问题。在查资料的过程中，看到有评论说checkpoint与广播变量就是不能同时使用（这是不对的），所以也思考过要不要改成自己手动维护offset，而且发现有好多人也这么做了。不过我们代码更新迭代并不频繁，不会被checkpoint影响太大，所以还是决定再试试使用checkpoint，终于好不容易也让我找到了解决方法，真是巨开心,下面就说下怎么解决的。&lt;/p&gt;

&lt;h1 id=&quot;解决-示例说明&quot;&gt;解决-示例说明&lt;/h1&gt;
&lt;h2 id=&quot;参考例子&quot;&gt;参考例子&lt;/h2&gt;
&lt;p&gt;在Spark Streaming中，目前为止累加器和广播变量确实是无法从checkpoint恢复的。但是如果在程序中既使用到checkpoint又使用了累加器和广播变量的话，最好对累加器和广播变量做懒实例化操作，这样可以使累加器和广播变量在driver失败重启时能够重新实例化。&lt;br /&gt;
解决方法其实就在spark官方的项目的examples中，访问请戳: &lt;a href=&quot;https://github.com/apache/spark/blob/master/examples/src/main/scala/org/apache/spark/examples/streaming/RecoverableNetworkWordCount.scala&quot;&gt;RecoverableNetworkWordCount&lt;/a&gt; ，它是广播变量和累加器与checkpoint兼容的一个例子。下面我就把代码摘出来记录一下。&lt;/p&gt;
&lt;h3 id=&quot;第一步用单例模式来获取或生成广播变量和累加器&quot;&gt;第一步：用单例模式来获取或生成广播变量和累加器&lt;/h3&gt;
&lt;div class=&quot;language-scala highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;cm&quot;&gt;/**
 * Use this singleton to get or register a Broadcast variable.
 * 单例模式获取广播变量wordBlacklist
 */&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;object&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;WordBlacklist&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;nd&quot;&gt;@volatile&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;private&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;var&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;instance&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Broadcast&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;Seq&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;]]&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kc&quot;&gt;null&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;getInstance&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sc&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;SparkContext&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Broadcast&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;Seq&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;]]&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;instance&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;kc&quot;&gt;null&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;synchronized&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;instance&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;kc&quot;&gt;null&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
          &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;wordBlacklist&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Seq&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;a&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;b&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;c&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
          &lt;span class=&quot;n&quot;&gt;instance&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sc&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;broadcast&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;wordBlacklist&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
      &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;instance&lt;/span&gt;
  &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;cm&quot;&gt;/**
 * Use this singleton to get or register an Accumulator.
 * 累加器
 */&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;object&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;DroppedWordsCounter&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;nd&quot;&gt;@volatile&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;private&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;var&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;instance&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;LongAccumulator&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kc&quot;&gt;null&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;getInstance&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sc&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;SparkContext&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;LongAccumulator&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;instance&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;kc&quot;&gt;null&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;synchronized&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;instance&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;kc&quot;&gt;null&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
          &lt;span class=&quot;n&quot;&gt;instance&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sc&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;longAccumulator&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;WordsInBlacklistCounter&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
      &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;instance&lt;/span&gt;
  &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;h3 id=&quot;第二步在spark主程序中使用&quot;&gt;第二步：在Spark主程序中使用&lt;/h3&gt;
&lt;p&gt;在主程序的driver端位置使用，懒实例化操作，这样可以使累加器和广播变量在driver失败重启时能够重新实例化。&lt;/p&gt;
&lt;div class=&quot;language-scala highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;object&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;RecoverableNetworkWordCount&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;c1&quot;&gt;// 这个是用来生成StreamingContext对象的用户自定义的方法
&lt;/span&gt;  &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;createContext&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ip&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;port&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Int&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;outputPath&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;checkpointDirectory&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;StreamingContext&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;// If you do not see this printed, that means the StreamingContext has been loaded from the new checkpoint
&lt;/span&gt;    &lt;span class=&quot;c1&quot;&gt;// 如果没有打印出这句话，说明是使用检查点元数据恢复一个StreamingContext
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;println&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Creating new context&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;outputFile&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;File&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;outputPath&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;outputFile&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;exists&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;())&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;outputFile&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;delete&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sparkConf&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;SparkConf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;().&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;setAppName&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;RecoverableNetworkWordCount&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;// 创建sparkContext，1秒一个批次
&lt;/span&gt;    &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ssc&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;StreamingContext&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sparkConf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Seconds&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;))&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;// 设置checkpoint
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;ssc&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;checkpoint&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;checkpointDirectory&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;// Create a socket stream on target ip:port and count the words in input stream of \n delimited text (eg. generated by 'nc')
&lt;/span&gt;    &lt;span class=&quot;c1&quot;&gt;// 这里是测试的socket stream
&lt;/span&gt;    &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lines&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ssc&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;socketTextStream&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ip&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;port&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;words&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lines&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;flatMap&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;_&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;split&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot; &quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;))&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;wordCounts&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;words&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;map&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;_&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;reduceByKey&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;_&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;_&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;wordCounts&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;foreachRDD&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;rdd&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;RDD&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;String&lt;/span&gt;, &lt;span class=&quot;kt&quot;&gt;Int&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;time&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Time&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&amp;gt;&lt;/span&gt;
      &lt;span class=&quot;c1&quot;&gt;// Get or register the blacklist Broadcast 广播变量
&lt;/span&gt;      &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;blacklist&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;WordBlacklist&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;getInstance&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;rdd&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sparkContext&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
      &lt;span class=&quot;c1&quot;&gt;// Get or register the droppedWordsCounter Accumulator 累加器
&lt;/span&gt;      &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;droppedWordsCounter&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;DroppedWordsCounter&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;getInstance&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;rdd&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sparkContext&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
      &lt;span class=&quot;c1&quot;&gt;// Use blacklist to drop words and use droppedWordsCounter to count them 使用广播变量和累加器
&lt;/span&gt;      &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;counts&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rdd&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;filter&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;word&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;count&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&amp;gt;&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;blacklist&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;value&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;contains&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;word&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
          &lt;span class=&quot;n&quot;&gt;droppedWordsCounter&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;add&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;count&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
          &lt;span class=&quot;kc&quot;&gt;false&lt;/span&gt;
        &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
          &lt;span class=&quot;kc&quot;&gt;true&lt;/span&gt;
        &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
      &lt;span class=&quot;o&quot;&gt;}.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;collect&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;().&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mkString&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;[&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;, &quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;]&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
      &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;output&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Counts at time $time $counts&quot;&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;println&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;output&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;println&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Dropped ${droppedWordsCounter.value} word(s) totally&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;println&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Appending to ${outputFile.getAbsolutePath}&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
      &lt;span class=&quot;nc&quot;&gt;Files&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;output&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;\n&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;outputFile&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Charset&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;defaultCharset&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;())&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;ssc&lt;/span&gt;
  &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;main&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;args&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Array&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;])&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;args&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;length&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;!=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
      &lt;span class=&quot;nc&quot;&gt;System&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;err&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;println&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Your arguments were ${args.mkString(&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;&quot;&lt;/span&gt;, &lt;span class=&quot;err&quot;&gt;&quot;&lt;/span&gt;, &lt;span class=&quot;err&quot;&gt;&quot;&lt;/span&gt;, &lt;span class=&quot;err&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;)}&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
      &lt;span class=&quot;nc&quot;&gt;System&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;err&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;println&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;
        &lt;span class=&quot;s&quot;&gt;&quot;&quot;&quot;
          |Usage: RecoverableNetworkWordCount &amp;lt;hostname&amp;gt; &amp;lt;port&amp;gt; &amp;lt;checkpoint-directory&amp;gt;
          |     &amp;lt;output-file&amp;gt;. &amp;lt;hostname&amp;gt; and &amp;lt;port&amp;gt; describe the TCP server that Spark
          |     Streaming would connect to receive data. &amp;lt;checkpoint-directory&amp;gt; directory to
          |     HDFS-compatible file system which checkpoint data &amp;lt;output-file&amp;gt; file to which the
          |     word counts will be appended
          |In local mode, &amp;lt;master&amp;gt; should be 'local[n]' with n &amp;gt; 1
          |Both &amp;lt;checkpoint-directory&amp;gt; and &amp;lt;output-file&amp;gt; must be absolute paths
        &quot;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;stripMargin&lt;/span&gt;
      &lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
      &lt;span class=&quot;nc&quot;&gt;System&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;exit&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Array&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ip&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;IntParam&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;port&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;checkpointDirectory&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;outputPath&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;args&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;// 使用StreamingContext.getOrCreate来创建StreamingContext对象，传入的第一个参数是checkpoint的存放目录，第二参数是生成StreamingContext对象的用户自定义方法。
&lt;/span&gt;    &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ssc&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;StreamingContext&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;getOrCreate&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;checkpointDirectory&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt;
      &lt;span class=&quot;o&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;createContext&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ip&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;port&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;outputPath&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;checkpointDirectory&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;))&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;ssc&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;start&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;ssc&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;awaitTermination&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt;
  &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;h1 id=&quot;解决-sparkstreamingkafkapool程序修改兼容checkpoint和广播变量kafkapool&quot;&gt;解决-SparkStreaming+kafkaPool程序修改(兼容checkpoint和广播变量kafkaPool)&lt;/h1&gt;
&lt;p&gt;上述内容即如何将checkpoint与广播变量或累加器兼容的例子，下面则结合上述例子，对上文(&lt;a href=&quot;https://leafming.github.io/bigdata/2018/04/02/SparkStreaming写数据到Kafka-Kafka连接池的使用/&quot;&gt;SparkStreaming写数据到Kafka&lt;/a&gt;)的程序做修改来解决“java.lang.ClassCastException:B cannot be cast to KafkaPool”的问题。&lt;/p&gt;
&lt;h2 id=&quot;第一步包装kafkaproducer-创建kafka连接池不变&quot;&gt;第一步：包装KafkaProducer-创建Kafka连接池（不变）&lt;/h2&gt;
&lt;p&gt;对于上文(&lt;a href=&quot;https://leafming.github.io/bigdata/2018/04/02/SparkStreaming写数据到Kafka-Kafka连接池的使用/&quot;&gt;SparkStreaming写数据到Kafka&lt;/a&gt;)中的程序，第一步保持不变，创建class KafkaPool 以及object KafkaPool，将KafkaProducer以lazy val的方式进行包装。&lt;/p&gt;
&lt;div class=&quot;language-scala highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;java.util.concurrent.Future&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;org.apache.kafka.clients.producer.&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;KafkaProducer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;ProducerRecord&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;RecordMetadata&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;//scala中，类名之后的括号中是构造函数的参数列表，() =&amp;gt;是传值传参，KafkaProducer
&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;KafkaPool&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;K&lt;/span&gt;, &lt;span class=&quot;kt&quot;&gt;V&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;](&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;createProducer&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;KafkaProducer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;K&lt;/span&gt;,&lt;span class=&quot;kt&quot;&gt;V&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;])&lt;/span&gt;  &lt;span class=&quot;k&quot;&gt;extends&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Serializable&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;c1&quot;&gt;//使用lazy关键字修饰变量后，只有在使用该变量时，才会调用其实例化方法
&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;//后续在spark主程序中使用时，将kafkapool广播出去到每个executor里面了，然后到每个executor中，当用到的时候，会实例化一个producer，这样就不会有NotSerializableExceptions的问题了。
&lt;/span&gt;  &lt;span class=&quot;k&quot;&gt;lazy&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;producer&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;createProducer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;send&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;topic&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;key&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;K&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;value&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;V&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Future&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;RecordMetadata&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;producer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;send&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;ProducerRecord&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;K&lt;/span&gt;, &lt;span class=&quot;kt&quot;&gt;V&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;](&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;topic&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;key&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;value&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;))&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;send&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;topic&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;value&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;V&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Future&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;RecordMetadata&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;producer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;send&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;ProducerRecord&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;K&lt;/span&gt;, &lt;span class=&quot;kt&quot;&gt;V&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;](&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;topic&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;value&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;object&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;KafkaPool&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;scala.collection.JavaConversions._&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;apply&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;K&lt;/span&gt;, &lt;span class=&quot;kt&quot;&gt;V&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;](&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;config&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Map&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;String&lt;/span&gt;, &lt;span class=&quot;kt&quot;&gt;Object&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;])&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;KafkaPool&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;K&lt;/span&gt;, &lt;span class=&quot;kt&quot;&gt;V&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
      &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;createProducerFunc&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;nc&quot;&gt;System&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;setProperty&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;java.security.auth.login.config&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;kafka_client_jaas.conf&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;producer&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;KafkaProducer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;K&lt;/span&gt;, &lt;span class=&quot;kt&quot;&gt;V&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;](&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;config&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;sys&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;addShutdownHook&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
          &lt;span class=&quot;c1&quot;&gt;//当发送ececutor中的jvm shutdown时，kafka能够将缓冲区的消息发送出去。
&lt;/span&gt;          &lt;span class=&quot;n&quot;&gt;producer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;close&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;producer&lt;/span&gt;
      &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
      &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;KafkaPool&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;createProducerFunc&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
  &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;apply&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;K&lt;/span&gt;, &lt;span class=&quot;kt&quot;&gt;V&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;](&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;config&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;java.util.Properties&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;KafkaPool&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;K&lt;/span&gt;, &lt;span class=&quot;kt&quot;&gt;V&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;apply&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;config&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;toMap&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;h2 id=&quot;第二步对广播变量懒实例化操作使用单例模式来获取广播变量kafkapool&quot;&gt;第二步：对广播变量懒实例化操作，使用单例模式来获取广播变量KafkaPool&lt;/h2&gt;
&lt;p&gt;这里较上文(&lt;a href=&quot;https://leafming.github.io/bigdata/2018/04/02/SparkStreaming写数据到Kafka-Kafka连接池的使用/&quot;&gt;SparkStreaming写数据到Kafka&lt;/a&gt;)第一种方式中的直接下发广播变量有所区别，而是创建来一个GetKafkaPoolBroadcast的getKafkaPool方法，用于在主程序中driver端调用此方法时再获取或生成广播变量。&lt;/p&gt;
&lt;div class=&quot;language-scala highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;java.util.Properties&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;org.apache.spark.SparkContext&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;org.apache.spark.internal.Logging&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;org.apache.spark.broadcast.Broadcast&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;object&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;GetKafkaPoolBroadcast&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;extends&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Logging&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;nd&quot;&gt;@volatile&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;private&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;var&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;kafkapool&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Broadcast&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;KafkaPool&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;String&lt;/span&gt;, &lt;span class=&quot;kt&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;]]&lt;/span&gt;  &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kc&quot;&gt;null&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;getKafkaPool&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sc&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;SparkContext&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;proKafkaBrokerAddr&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Broadcast&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;KafkaPool&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;String&lt;/span&gt;, &lt;span class=&quot;kt&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;]]&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;kafkapool&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;kc&quot;&gt;null&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;synchronized&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;kafkapool&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;kc&quot;&gt;null&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
          &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;kafkaProducerConfig&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;props&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Properties&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;props&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;put&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;metadata.broker.list&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;proKafkaBrokerAddr&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;props&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;put&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;security.protocol&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;SASL_PLAINTEXT&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;props&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;put&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;sasl.mechanism&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;PLAIN&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;props&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;put&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;key.serializer&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;org.apache.kafka.common.serialization.StringSerializer&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;props&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;put&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;value.serializer&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;org.apache.kafka.common.serialization.StringSerializer&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;props&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;put&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;bootstrap.servers&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;proKafkaBrokerAddr&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;props&lt;/span&gt;
          &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
          &lt;span class=&quot;n&quot;&gt;log&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;warn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;kafka producer init done!&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
          &lt;span class=&quot;n&quot;&gt;kafkapool&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sc&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;broadcast&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;KafkaPool&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;String&lt;/span&gt;, &lt;span class=&quot;kt&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;](&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;kafkaProducerConfig&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;))&lt;/span&gt;
        &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
      &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;kafkapool&lt;/span&gt;
  &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;h2 id=&quot;第三步在主程序中使用getkafkapoolbroadcast的getkafkapool获取或生成广播变量&quot;&gt;第三步：在主程序中使用GetKafkaPoolBroadcast的getKafkaPool获取或生成广播变量&lt;/h2&gt;
&lt;p&gt;在主程序中，driver端的位置调用此方法，这样可以使广播变量在driver失败重启时能够重新示例化。&lt;/p&gt;
&lt;div class=&quot;language-scala highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    &lt;span class=&quot;c1&quot;&gt;//保存处理后的数据到kafka
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;writeDStrem&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;foreachRDD&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;rdd&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
      &lt;span class=&quot;c1&quot;&gt;// driver端运行，涉及操作：广播变量的初始化和更新
&lt;/span&gt;      &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;rdd&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;isEmpty&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;logInfo&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot; No Data in this batchInterval --------&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
      &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;start_time&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;System&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;currentTimeMillis&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;c1&quot;&gt;// Get or register the kafkaPool Broadcast 获取或生成广播变量kafkaPool
&lt;/span&gt;        &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;kafkaProducer&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Broadcast&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;KafkaPool&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;String&lt;/span&gt;, &lt;span class=&quot;kt&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;]]&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;GetKafkaPoolBroadcast&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;getKafkaPool&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;rdd&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sparkContext&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;proKafkaBrokerAddr&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;rdd&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;foreach&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;record&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&amp;gt;{&lt;/span&gt;
          &lt;span class=&quot;n&quot;&gt;kafkaProducer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;value&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;send&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;proKafkaTopicName&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;record&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;o&quot;&gt;})&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;competeTime&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;start_time&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;Processed data write to KAFKA&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
      &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;})&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;p&gt;这样，就不会再尝试从checkpoint中恢复广播变量，而可以避免“java.lang.ClassCastException:B cannot be cast to KafkaPool”这个问题啦。&lt;br /&gt;
至此，本篇内容完成。&lt;br /&gt;
如有问题，请发送邮件至leafming@foxmail.com联系我，谢谢～&lt;br /&gt;
©商业转载请联系作者获得授权，非商业转载请注明出处。&lt;/p&gt;</content><author><name>Liv Yeh</name></author><category term="Spark" /><category term="Kafka" /><summary type="html">上文中说明了如何使用kafka连接池来优化程序，但是在上文中预留了一个问题，就是当使用上文的方式下发KafkaPool广播变量时，如果Spark Streaming程序中也使用了checkpoint，则如果程序中断而重启程序，广播变量无法从checkpoint中恢复，会出现“java.lang.ClassCastException:B cannot be cast to KafkaPool”问题，所以在此篇文章中，对此问题进行解决。 注意: 本文中使用的版本是spark2.2.1和kafka0.10.1.1 背景 在spark信令处理程序中使用checkpoint主要是因为从源头读取kafka数据的时候记录offset，防止数据丢失；并且目前是做的是容器化的集群，如果集群down了，会自动重启容器并且也能把程序恢复。 不过对于Spark Streaming中防止数据丢失可以有两种方式: 使用Spark Streaming的checkpoint机制 自己维护kafka offset 但是，有人说checkpoint有弊端，并且我也遇到了序列化的这个问题。在查资料的过程中，看到有评论说checkpoint与广播变量就是不能同时使用（这是不对的），所以也思考过要不要改成自己手动维护offset，而且发现有好多人也这么做了。不过我们代码更新迭代并不频繁，不会被checkpoint影响太大，所以还是决定再试试使用checkpoint，终于好不容易也让我找到了解决方法，真是巨开心,下面就说下怎么解决的。 解决-示例说明 参考例子 在Spark Streaming中，目前为止累加器和广播变量确实是无法从checkpoint恢复的。但是如果在程序中既使用到checkpoint又使用了累加器和广播变量的话，最好对累加器和广播变量做懒实例化操作，这样可以使累加器和广播变量在driver失败重启时能够重新实例化。 解决方法其实就在spark官方的项目的examples中，访问请戳: RecoverableNetworkWordCount ，它是广播变量和累加器与checkpoint兼容的一个例子。下面我就把代码摘出来记录一下。 第一步：用单例模式来获取或生成广播变量和累加器 /** * Use this singleton to get or register a Broadcast variable. * 单例模式获取广播变量wordBlacklist */ object WordBlacklist { @volatile private var instance: Broadcast[Seq[String]] = null def getInstance(sc: SparkContext): Broadcast[Seq[String]] = { if (instance == null) { synchronized { if (instance == null) { val wordBlacklist = Seq(&quot;a&quot;, &quot;b&quot;, &quot;c&quot;) instance = sc.broadcast(wordBlacklist) } } } instance } } /** * Use this singleton to get or register an Accumulator. * 累加器 */ object DroppedWordsCounter { @volatile private var instance: LongAccumulator = null def getInstance(sc: SparkContext): LongAccumulator = { if (instance == null) { synchronized { if (instance == null) { instance = sc.longAccumulator(&quot;WordsInBlacklistCounter&quot;) } } } instance } } 第二步：在Spark主程序中使用 在主程序的driver端位置使用，懒实例化操作，这样可以使累加器和广播变量在driver失败重启时能够重新实例化。 object RecoverableNetworkWordCount { // 这个是用来生成StreamingContext对象的用户自定义的方法 def createContext(ip: String, port: Int, outputPath: String, checkpointDirectory: String) : StreamingContext = { // If you do not see this printed, that means the StreamingContext has been loaded from the new checkpoint // 如果没有打印出这句话，说明是使用检查点元数据恢复一个StreamingContext println(&quot;Creating new context&quot;) val outputFile = new File(outputPath) if (outputFile.exists()) outputFile.delete() val sparkConf = new SparkConf().setAppName(&quot;RecoverableNetworkWordCount&quot;) // 创建sparkContext，1秒一个批次 val ssc = new StreamingContext(sparkConf, Seconds(1)) // 设置checkpoint ssc.checkpoint(checkpointDirectory) // Create a socket stream on target ip:port and count the words in input stream of \n delimited text (eg. generated by 'nc') // 这里是测试的socket stream val lines = ssc.socketTextStream(ip, port) val words = lines.flatMap(_.split(&quot; &quot;)) val wordCounts = words.map((_, 1)).reduceByKey(_ + _) wordCounts.foreachRDD { (rdd: RDD[(String, Int)], time: Time) =&amp;gt; // Get or register the blacklist Broadcast 广播变量 val blacklist = WordBlacklist.getInstance(rdd.sparkContext) // Get or register the droppedWordsCounter Accumulator 累加器 val droppedWordsCounter = DroppedWordsCounter.getInstance(rdd.sparkContext) // Use blacklist to drop words and use droppedWordsCounter to count them 使用广播变量和累加器 val counts = rdd.filter { case (word, count) =&amp;gt; if (blacklist.value.contains(word)) { droppedWordsCounter.add(count) false } else { true } }.collect().mkString(&quot;[&quot;, &quot;, &quot;, &quot;]&quot;) val output = s&quot;Counts at time $time $counts&quot; println(output) println(s&quot;Dropped ${droppedWordsCounter.value} word(s) totally&quot;) println(s&quot;Appending to ${outputFile.getAbsolutePath}&quot;) Files.append(output + &quot;\n&quot;, outputFile, Charset.defaultCharset()) } ssc } def main(args: Array[String]) { if (args.length != 4) { System.err.println(s&quot;Your arguments were ${args.mkString(&quot;[&quot;, &quot;, &quot;, &quot;]&quot;)}&quot;) System.err.println( &quot;&quot;&quot; |Usage: RecoverableNetworkWordCount &amp;lt;hostname&amp;gt; &amp;lt;port&amp;gt; &amp;lt;checkpoint-directory&amp;gt; | &amp;lt;output-file&amp;gt;. &amp;lt;hostname&amp;gt; and &amp;lt;port&amp;gt; describe the TCP server that Spark | Streaming would connect to receive data. &amp;lt;checkpoint-directory&amp;gt; directory to | HDFS-compatible file system which checkpoint data &amp;lt;output-file&amp;gt; file to which the | word counts will be appended |In local mode, &amp;lt;master&amp;gt; should be 'local[n]' with n &amp;gt; 1 |Both &amp;lt;checkpoint-directory&amp;gt; and &amp;lt;output-file&amp;gt; must be absolute paths &quot;&quot;&quot;.stripMargin ) System.exit(1) } val Array(ip, IntParam(port), checkpointDirectory, outputPath) = args // 使用StreamingContext.getOrCreate来创建StreamingContext对象，传入的第一个参数是checkpoint的存放目录，第二参数是生成StreamingContext对象的用户自定义方法。 val ssc = StreamingContext.getOrCreate(checkpointDirectory, () =&amp;gt; createContext(ip, port, outputPath, checkpointDirectory)) ssc.start() ssc.awaitTermination() } } 解决-SparkStreaming+kafkaPool程序修改(兼容checkpoint和广播变量kafkaPool) 上述内容即如何将checkpoint与广播变量或累加器兼容的例子，下面则结合上述例子，对上文(SparkStreaming写数据到Kafka)的程序做修改来解决“java.lang.ClassCastException:B cannot be cast to KafkaPool”的问题。 第一步：包装KafkaProducer-创建Kafka连接池（不变） 对于上文(SparkStreaming写数据到Kafka)中的程序，第一步保持不变，创建class KafkaPool 以及object KafkaPool，将KafkaProducer以lazy val的方式进行包装。 import java.util.concurrent.Future import org.apache.kafka.clients.producer.{KafkaProducer, ProducerRecord, RecordMetadata} //scala中，类名之后的括号中是构造函数的参数列表，() =&amp;gt;是传值传参，KafkaProducer class KafkaPool[K, V]( createProducer: () =&amp;gt; KafkaProducer[K,V]) extends Serializable{ //使用lazy关键字修饰变量后，只有在使用该变量时，才会调用其实例化方法 //后续在spark主程序中使用时，将kafkapool广播出去到每个executor里面了，然后到每个executor中，当用到的时候，会实例化一个producer，这样就不会有NotSerializableExceptions的问题了。 lazy val producer = createProducer() def send(topic: String, key: K, value: V): Future[RecordMetadata] = producer.send(new ProducerRecord[K, V](topic, key, value)) def send(topic: String, value: V): Future[RecordMetadata] = producer.send(new ProducerRecord[K, V](topic, value)) } object KafkaPool{ import scala.collection.JavaConversions._ def apply[K, V](config: Map[String, Object]): KafkaPool[K, V] = { val createProducerFunc = () =&amp;gt; { System.setProperty(&quot;java.security.auth.login.config&quot;,&quot;kafka_client_jaas.conf&quot;) val producer = new KafkaProducer[K, V](config) sys.addShutdownHook { //当发送ececutor中的jvm shutdown时，kafka能够将缓冲区的消息发送出去。 producer.close() } producer } new KafkaPool(createProducerFunc) } def apply[K, V](config: java.util.Properties): KafkaPool[K, V] = apply(config.toMap) } 第二步：对广播变量懒实例化操作，使用单例模式来获取广播变量KafkaPool 这里较上文(SparkStreaming写数据到Kafka)第一种方式中的直接下发广播变量有所区别，而是创建来一个GetKafkaPoolBroadcast的getKafkaPool方法，用于在主程序中driver端调用此方法时再获取或生成广播变量。 ```scala import java.util.Properties import org.apache.spark.SparkContext import org.apache.spark.internal.Logging import org.apache.spark.broadcast.Broadcast</summary></entry><entry><title type="html">SparkStreaming输出数据到Kafka–Kafka连接池的使用</title><link href="http://localhost:4000/bigdata/2018/04/02/SparkStreaming%E5%86%99%E6%95%B0%E6%8D%AE%E5%88%B0Kafka-Kafka%E8%BF%9E%E6%8E%A5%E6%B1%A0%E7%9A%84%E4%BD%BF%E7%94%A8/" rel="alternate" type="text/html" title="SparkStreaming输出数据到Kafka--Kafka连接池的使用" /><published>2018-04-02T00:00:00+08:00</published><updated>2018-04-02T00:00:00+08:00</updated><id>http://localhost:4000/bigdata/2018/04/02/SparkStreaming%E5%86%99%E6%95%B0%E6%8D%AE%E5%88%B0Kafka-Kafka%E8%BF%9E%E6%8E%A5%E6%B1%A0%E7%9A%84%E4%BD%BF%E7%94%A8</id><content type="html" xml:base="http://localhost:4000/bigdata/2018/04/02/SparkStreaming%E5%86%99%E6%95%B0%E6%8D%AE%E5%88%B0Kafka-Kafka%E8%BF%9E%E6%8E%A5%E6%B1%A0%E7%9A%84%E4%BD%BF%E7%94%A8/">&lt;blockquote&gt;
  &lt;p&gt;最近把spark实时流处理的信令处理程序，由原来的向kafka0.8.2.1中写入数据，改成了向带ACL权限认证的kafka0.10.1.1中写入数据，因此在之前的基础上创建连接前会多一个认证过程，因此导致写入效率有些低下，所以使用Kafka连接池来优化之前程序。&lt;br /&gt;
&lt;strong&gt;注意: 本文中使用的版本是spark2.2.1和kafka0.10.1.1&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h1 id=&quot;原写入方式描述&quot;&gt;原写入方式描述&lt;/h1&gt;
&lt;p&gt;使用Spark Streaming从Kafka中接收数据时，可以使用Spark提供的统一的接口来接收数据，但是写入数据的时候，并没有spark官方提供的写入接口，需要自己写使用底层的kafka方法，使用producer写入。&lt;br /&gt;
下面是原写入方式的程序示例:&lt;/p&gt;
&lt;h2 id=&quot;第一部分spark-streaming主程序部分&quot;&gt;第一部分：Spark Streaming主程序部分&lt;/h2&gt;
&lt;div class=&quot;language-scala highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    &lt;span class=&quot;n&quot;&gt;writeDStrem&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;foreachRDD&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;rdd&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
      &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;rdd&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;isEmpty&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;logInfo&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot; No Data in this batchInterval --------&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
      &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;start_time&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;System&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;currentTimeMillis&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;c1&quot;&gt;// 不能在这里创建KafkaProducer
&lt;/span&gt;	&lt;span class=&quot;n&quot;&gt;rdd&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;foreachPartition&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;iter&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&amp;gt;{&lt;/span&gt;
          &lt;span class=&quot;n&quot;&gt;process&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;writeAsPartitionToKafka&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;proKafkaTopicName&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;iter&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cacheNum&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;props&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;o&quot;&gt;})&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;competeTime&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;start_time&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;Processed data write to KAFKA&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
      &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;})&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;p&gt;在每个partation中调用ProcessData类中的writeAsPartitionToKafka方法来向kafka写入数据。&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;特别说明：这里是通过调用ProcessData类中的方法，在ProcessData类中的方法中创建KafkaProducer来向kafka里写入的，如果直接写创建KafkaProducer，不能把将KafkaProducer的创建放在foreachPartition外边，因为KafkaProducer是不可序列化的（not serializable）。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;第二部分主程序在rddforeachpartition中调用以下类中的方法把数据写入kafka中&quot;&gt;第二部分：主程序在rdd.foreachPartition中调用以下类中的方法把数据写入kafka中&lt;/h2&gt;
&lt;div class=&quot;language-scala highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    &lt;span class=&quot;k&quot;&gt;final&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;ProcessData&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;extends&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Logging&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
      &lt;span class=&quot;cm&quot;&gt;/**
        * 数据发送
        * @param topic
        * @param messages
        * @param props
        */&lt;/span&gt;
      &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sendMessages&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;topic&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;messages&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;props&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Properties&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;nc&quot;&gt;System&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;setProperty&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;java.security.auth.login.config&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;kafka_client_jaas.conf&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;producer&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Producer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;String&lt;/span&gt;, &lt;span class=&quot;kt&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;KafkaProducer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;String&lt;/span&gt;, &lt;span class=&quot;kt&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;](&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;props&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;try&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
          &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;msg&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;ProducerRecord&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;String&lt;/span&gt;, &lt;span class=&quot;kt&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;ProducerRecord&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;String&lt;/span&gt;,&lt;span class=&quot;kt&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;](&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;topic&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;messages&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
          &lt;span class=&quot;n&quot;&gt;producer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;send&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;msg&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;catch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
          &lt;span class=&quot;k&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;e&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;IOException&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&amp;gt;&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;logError&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;partition write data to  kafka exception : &quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;e&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;getMessage&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;\n&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;finally&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
          &lt;span class=&quot;n&quot;&gt;producer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;close&lt;/span&gt;
        &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
      &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
      &lt;span class=&quot;cm&quot;&gt;/**
        * 处理数据，按N条写入一次
        * @param topicName
        * @param iter
        * @param cache 缓存数
        * @param props
        * @return
        */&lt;/span&gt;
      &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;writeAsPartitionToKafka&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;topicName&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;iter&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Iterator&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cache&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Int&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;props&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;Properties&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Try&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;Unit&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Try&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;var&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;record_sum&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&quot;&lt;/span&gt;   &lt;span class=&quot;c1&quot;&gt;//初始化空串
&lt;/span&gt;        &lt;span class=&quot;k&quot;&gt;var&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;count_sum&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;     &lt;span class=&quot;c1&quot;&gt;//计数器
&lt;/span&gt;        &lt;span class=&quot;k&quot;&gt;var&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;record&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&quot;&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;while&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;iter&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;hasNext&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
          &lt;span class=&quot;n&quot;&gt;record&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;iter&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;next&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt;
          &lt;span class=&quot;n&quot;&gt;record_sum&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;record&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;\n&quot;&lt;/span&gt;
          &lt;span class=&quot;n&quot;&gt;count_sum&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;count_sum&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;
          &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;count_sum&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cache&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;sendMessages&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;topicName&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;record_sum&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;props&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;record_sum&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;&quot;&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;count_sum&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;
          &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
        &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(!&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;record_sum&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;isEmpty&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
          &lt;span class=&quot;n&quot;&gt;sendMessages&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;topicName&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;record_sum&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;props&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
      &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;p&gt;此类中主要2个方法，writeAsPartitionToKafka是用于处理数据，sendMessages用来创建KafkaProducer来向kafka生产消息。&lt;br /&gt;
writeAsPartitionToKafka方法为了“提高”写入效率，设置了一个cacheNum值，这个方法会将每个patation中的数据以cacheNum条和并成一条数据来向Kafka中写入，因此是cacheNum条数据以“\n”来分割合并成一条在Kafka里的消息，所以对下游数据处理也造成了麻烦。&lt;br /&gt;
并且使用此方式，相当于对于每个partation的每cacheNum条记录（即每次调用sendMessages方法，发送1条kafka消息）都需要创建KafkaProducer，然后再利用producer进行输出操作
。还是需要较频繁的建立连接，因此使用kafka连接池来更改程序。&lt;/p&gt;

&lt;h1 id=&quot;新写入方式描述使用kafka连接池更改程序&quot;&gt;新写入方式描述:使用Kafka连接池更改程序&lt;/h1&gt;
&lt;h2 id=&quot;第一步包装kafkaproducer-创建kafka连接池&quot;&gt;第一步：包装KafkaProducer-创建Kafka连接池&lt;/h2&gt;
&lt;p&gt;创建class KafkaPool 以及object KafkaPool，将KafkaProducer以lazy val的方式进行包装。&lt;/p&gt;
&lt;div class=&quot;language-scala highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    &lt;span class=&quot;k&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;java.util.concurrent.Future&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;org.apache.kafka.clients.producer.&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;KafkaProducer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;ProducerRecord&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;RecordMetadata&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;//scala中，类名之后的括号中是构造函数的参数列表，() =&amp;gt;是传值传参，KafkaProducer
&lt;/span&gt;    &lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;KafkaPool&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;K&lt;/span&gt;, &lt;span class=&quot;kt&quot;&gt;V&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;](&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;createProducer&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;KafkaProducer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;K&lt;/span&gt;,&lt;span class=&quot;kt&quot;&gt;V&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;])&lt;/span&gt;  &lt;span class=&quot;k&quot;&gt;extends&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Serializable&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
      &lt;span class=&quot;c1&quot;&gt;//使用lazy关键字修饰变量后，只有在使用该变量时，才会调用其实例化方法
&lt;/span&gt;      &lt;span class=&quot;c1&quot;&gt;//后续在spark主程序中使用时，将kafkapool广播出去到每个executor里面了，然后到每个executor中，当用到的时候，会实例化一个producer，这样就不会有NotSerializableExceptions的问题了。
&lt;/span&gt;      &lt;span class=&quot;k&quot;&gt;lazy&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;producer&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;createProducer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt;
      &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;send&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;topic&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;key&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;K&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;value&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;V&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Future&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;RecordMetadata&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; 
        &lt;span class=&quot;n&quot;&gt;producer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;send&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;ProducerRecord&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;K&lt;/span&gt;, &lt;span class=&quot;kt&quot;&gt;V&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;](&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;topic&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;key&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;value&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;))&lt;/span&gt;
      &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;send&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;topic&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;value&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;V&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Future&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;RecordMetadata&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; 
        &lt;span class=&quot;n&quot;&gt;producer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;send&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;ProducerRecord&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;K&lt;/span&gt;, &lt;span class=&quot;kt&quot;&gt;V&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;](&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;topic&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;value&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;))&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;object&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;KafkaPool&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
      &lt;span class=&quot;k&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;scala.collection.JavaConversions._&lt;/span&gt;
      &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;apply&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;K&lt;/span&gt;, &lt;span class=&quot;kt&quot;&gt;V&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;](&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;config&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Map&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;String&lt;/span&gt;, &lt;span class=&quot;kt&quot;&gt;Object&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;])&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;KafkaPool&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;K&lt;/span&gt;, &lt;span class=&quot;kt&quot;&gt;V&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
          &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;createProducerFunc&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
            &lt;span class=&quot;c1&quot;&gt;//kafka权限认证
&lt;/span&gt;            &lt;span class=&quot;nc&quot;&gt;System&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;setProperty&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;java.security.auth.login.config&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;kafka_client_jaas.conf&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;producer&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;KafkaProducer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;K&lt;/span&gt;, &lt;span class=&quot;kt&quot;&gt;V&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;](&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;config&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;sys&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;addShutdownHook&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
	      &lt;span class=&quot;c1&quot;&gt;//当发送ececutor中的jvm shutdown时，kafka能够将缓冲区的消息发送出去。
&lt;/span&gt;              &lt;span class=&quot;n&quot;&gt;producer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;close&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt;
            &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;producer&lt;/span&gt;
          &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
          &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;KafkaPool&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;createProducerFunc&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
      &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
      &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;apply&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;K&lt;/span&gt;, &lt;span class=&quot;kt&quot;&gt;V&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;](&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;config&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;java.util.Properties&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;KafkaPool&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;K&lt;/span&gt;, &lt;span class=&quot;kt&quot;&gt;V&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;apply&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;config&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;toMap&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;blockquote&gt;
  &lt;p&gt;补充说明：&lt;br /&gt;
传值传参和传名的区别（()=&amp;gt;和:=&amp;gt;的区别）&lt;/p&gt;
  &lt;ul&gt;
    &lt;li&gt;传值
      &lt;div class=&quot;language-scala highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;test1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;code&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;()=&amp;gt;&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Unit&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;){&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;println&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;start&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;code&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;//要想调用传入的代码块，必须写成code()，否则不会调用。  
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;println&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;end&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
  &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;test1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;//此代码块，传入后立即执行。  
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;println&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;when evaluated&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;//传入就打印
&lt;/span&gt;    &lt;span class=&quot;o&quot;&gt;()=&amp;gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;println&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;bb&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)}&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;// 执行code()才打印
&lt;/span&gt;  &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
      &lt;/div&gt;
      &lt;p&gt;结果: &lt;br /&gt;
when evaluated &lt;br /&gt;
start&lt;br /&gt;
bb&lt;br /&gt;
end&lt;/p&gt;
    &lt;/li&gt;
    &lt;li&gt;传名
      &lt;div class=&quot;language-scala highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;test2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;code&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Unit&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;){&lt;/span&gt;  
    &lt;span class=&quot;n&quot;&gt;println&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;start&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;  
    &lt;span class=&quot;n&quot;&gt;code&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;// 这行才会调用传入的代码块，写成code()亦可  
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;println&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;end&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;  
  &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;  
  &lt;span class=&quot;n&quot;&gt;test2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;// 此处的代码块不会马上被调用  
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;println&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;when evaluated&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;//执行code的时候才调用
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;println&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;bb&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;//执行code的时候才调用  
&lt;/span&gt;  &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
      &lt;/div&gt;
      &lt;p&gt;结果:&lt;br /&gt;
start&lt;br /&gt;
when evaluated&lt;br /&gt;
bb&lt;br /&gt;
end&lt;/p&gt;
    &lt;/li&gt;
  &lt;/ul&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;第二步利用广播变量下发kafkaproducer&quot;&gt;第二步：利用广播变量下发KafkaProducer&lt;/h2&gt;
&lt;p&gt;利用广播变量，给每一个executor自己的KafkaProducer，将KafkaProducer广播到每一个executor中。  &lt;br /&gt;
&lt;strong&gt;注意：这里暂留一个问题，此种方式只可以Spark Streaming程序不用checkpoint的时候使用，否则，如果程序中断而重启程序，广播变量无法从checkpoint中恢复，会出现 &lt;code class=&quot;highlighter-rouge&quot;&gt;“java.lang.ClassCastException:B cannot be cast to KafkaPool”&lt;/code&gt; 的问题，具体解决方式见下篇文章(&lt;a href=&quot;https://leafming.github.io/bigdata/2018/04/04/SparkStreaming程序中checkpoint与广播变量兼容处理/&quot;&gt;SparkStreaming程序中checkpoint与广播变量兼容处理&lt;/a&gt;)。现在先说明这种不用checkpoint的方式。&lt;/strong&gt;&lt;br /&gt;
在spark主程序中加入如下代码：&lt;/p&gt;
&lt;div class=&quot;language-scala highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    &lt;span class=&quot;c1&quot;&gt;//利用广播变量的形式，将后端写入KafkaProducer广播到每一个executor 注意：这里写广播变量的话，与checkpoint一起用会有问题
&lt;/span&gt;    &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;kafkaProducer&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Broadcast&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;KafkaPool&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;String&lt;/span&gt;, &lt;span class=&quot;kt&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;]]&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
      &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;kafkaProducerConfig&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;props&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Properties&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;props&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;put&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;metadata.broker.list&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;proKafkaBrokerAddr&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;props&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;put&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;security.protocol&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;SASL_PLAINTEXT&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;props&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;put&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;sasl.mechanism&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;PLAIN&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;props&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;put&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;key.serializer&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;org.apache.kafka.common.serialization.StringSerializer&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;props&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;put&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;value.serializer&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;org.apache.kafka.common.serialization.StringSerializer&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;props&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;put&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;bootstrap.servers&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;proKafkaBrokerAddr&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;props&lt;/span&gt;
      &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;log&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;warn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;kafka producer init done!&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;ssc&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sparkContext&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;broadcast&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;KafkaPool&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;String&lt;/span&gt;, &lt;span class=&quot;kt&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;](&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;kafkaProducerConfig&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;))&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;h2 id=&quot;第三步使用广播变量&quot;&gt;第三步：使用广播变量&lt;/h2&gt;
&lt;p&gt;spark 主程序中，在每个executor中使用广播变量。&lt;/p&gt;
&lt;div class=&quot;language-scala highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    &lt;span class=&quot;n&quot;&gt;writeDStrem&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;foreachRDD&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;rdd&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
      &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;rdd&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;isEmpty&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;logInfo&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot; No Data in this batchInterval --------&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
      &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;start_time&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;System&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;currentTimeMillis&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;rdd&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;foreach&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;record&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&amp;gt;{&lt;/span&gt;
           &lt;span class=&quot;n&quot;&gt;kafkaProducer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;value&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;send&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;proKafkaTopicName&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;record&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;o&quot;&gt;})&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;competeTime&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;start_time&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;Processed data write to KAFKA&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
      &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;})&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;p&gt;至此，更改完毕。&lt;/p&gt;
&lt;h1 id=&quot;结果对比&quot;&gt;结果对比&lt;/h1&gt;
&lt;p&gt;使用Kafka连接池更改程序之前以及之后的处理速度对比如下图所示，写入90W条数据由原来的17953ms变为了1966ms，效率大大提高。&lt;br /&gt;
&lt;img src=&quot;https://github.com/leafming/bak/blob/master/images/spark/2018-04-02SparkStreamingKafka.png?raw=true&quot; alt=&quot;compare&quot; /&gt;&lt;/p&gt;

&lt;p&gt;内容即以上，会在下篇文章(&lt;a href=&quot;https://leafming.github.io/bigdata/2018/04/04/SparkStreaming程序中checkpoint与广播变量兼容处理/&quot;&gt;SparkStreaming程序中checkpoint与广播变量兼容处理&lt;/a&gt;)解决spark streaming中checkpoint和广播变量使用冲突的问题，敬请期待。&lt;br /&gt;
如有问题，请发送邮件至leafming@foxmail.com联系我，谢谢～&lt;br /&gt;
©商业转载请联系作者获得授权，非商业转载请注明出处。&lt;/p&gt;</content><author><name>Liv Yeh</name></author><category term="Spark" /><category term="Kafka" /><summary type="html">最近把spark实时流处理的信令处理程序，由原来的向kafka0.8.2.1中写入数据，改成了向带ACL权限认证的kafka0.10.1.1中写入数据，因此在之前的基础上创建连接前会多一个认证过程，因此导致写入效率有些低下，所以使用Kafka连接池来优化之前程序。 注意: 本文中使用的版本是spark2.2.1和kafka0.10.1.1</summary></entry></feed>