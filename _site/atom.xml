<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.7.4">Jekyll</generator><link href="http://localhost:4000/atom.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2018-11-16T14:38:30+08:00</updated><id>http://localhost:4000/atom.xml</id><title type="html">iLeaf</title><subtitle>Yesterday you said tomorrow.</subtitle><author><name>叶子  ( ˘ ³˘)♥</name></author><entry><title type="html">实时流处理系统反压机制（BackPressure）综述[转]</title><link href="http://localhost:4000/bigdata/2018/11/15/%E5%AE%9E%E6%97%B6%E6%B5%81%E5%A4%84%E7%90%86%E7%B3%BB%E7%BB%9F%E5%8F%8D%E5%8E%8B%E6%9C%BA%E5%88%B6-BackPressure-%E7%BB%BC%E8%BF%B0-%E8%BD%AC/" rel="alternate" type="text/html" title="实时流处理系统反压机制（BackPressure）综述[转]" /><published>2018-11-15T00:00:00+08:00</published><updated>2018-11-15T00:00:00+08:00</updated><id>http://localhost:4000/bigdata/2018/11/15/%E5%AE%9E%E6%97%B6%E6%B5%81%E5%A4%84%E7%90%86%E7%B3%BB%E7%BB%9F%E5%8F%8D%E5%8E%8B%E6%9C%BA%E5%88%B6(BackPressure)%E7%BB%BC%E8%BF%B0%5B%E8%BD%AC%5D</id><content type="html" xml:base="http://localhost:4000/bigdata/2018/11/15/%E5%AE%9E%E6%97%B6%E6%B5%81%E5%A4%84%E7%90%86%E7%B3%BB%E7%BB%9F%E5%8F%8D%E5%8E%8B%E6%9C%BA%E5%88%B6-BackPressure-%E7%BB%BC%E8%BF%B0-%E8%BD%AC/">&lt;blockquote&gt;
  &lt;p&gt;本文主要关于实时流处理系统反压机制，最近看到反压问题看到此文章很好，在此分享并mark一下。&lt;br /&gt;
 (￢_￢)ﾉ最近菜叶子没自己写见谅。&lt;br /&gt;
本文转自 &lt;a href=&quot;https://blog.csdn.net/qq_21125183/article/details/80708142&quot;&gt;实时流处理系统反压机制（BackPressure）综述&lt;/a&gt;&lt;br /&gt;
https://blog.csdn.net/qq_21125183/article/details/80708142&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;反压机制（BackPressure）被广泛应用到实时流处理系统中，流处理系统需要能优雅地处理反压（backpressure）问题。反压通常产生于这样的场景：短时负载高峰导致系统接收数据的速率远高于它处理数据的速率。许多日常问题都会导致反压，例如，垃圾回收停顿可能会导致流入的数据快速堆积，或者遇到大促或秒杀活动导致流量陡增。反压如果不能得到正确的处理，可能会导致资源耗尽甚至系统崩溃。反压机制就是指系统能够自己检测到被阻塞的Operator，然后系统自适应地降低源头或者上游的发送速率。目前主流的流处理系统 Apache Storm、JStorm、Spark Streaming、S4、Apache Flink、Twitter Heron都采用反压机制解决这个问题，不过他们的实现各自不同。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://github.com/leafming/bak/blob/master/images/bigdata-total/2018-11-15-实时流处理系统反压机制01.png?raw=true&quot; alt=&quot;实时流处理系统反压机制01&quot; /&gt;&lt;/p&gt;

&lt;p&gt;不同的组件可以不同的速度执行（并且每个组件中的处理速度随时间改变）。 例如，考虑一个工作流程，或由于数据倾斜或任务调度而导致数据被处理十分缓慢。 在这种情况下，如果上游阶段不减速，将导致缓冲区建立长队列，或导致系统丢弃元组。 如果元组在中途丢弃，那么效率可能会有损失，因为已经为这些元组产生的计算被浪费了。并且在一些流处理系统中比如Strom，会将这些丢失的元组重新发送，这样会导致数据的一致性问题，并且还会导致某些Operator状态叠加。进而整个程序输出结果不准确。第二由于系统接收数据的速率是随着时间改变的，短时负载高峰导致系统接收数据的速率远高于它处理数据的速率的情况，也会导致Tuple在中途丢失。所以实时流处理系统必须能够解决发送速率远大于系统能处理速率这个问题，大多数实时流处理系统采用反压（BackPressure）机制解决这个问题。下面我们就来介绍一下不同的实时流处理系统采用的反压机制：&lt;/p&gt;

&lt;h1 id=&quot;strom-反压机制&quot;&gt;Strom 反压机制&lt;/h1&gt;

&lt;h2 id=&quot;storm-10-以前的反压机制&quot;&gt;Storm 1.0 以前的反压机制&lt;/h2&gt;

&lt;p&gt;对于开启了acker机制的storm程序，可以通过设置conf.setMaxSpoutPending参数来实现反压效果，&lt;strong&gt;如果下游组件(bolt)处理速度跟不上导致spout发送的tuple没有及时确认的数超过了参数设定的值，spout会停止发送数据&lt;/strong&gt;，这种方式的缺点是很难调优conf.setMaxSpoutPending参数的设置以达到最好的反压效果，设小了会导致吞吐上不去，设大了会导致worker OOM；有震荡，数据流会处于一个颠簸状态，效果不如逐级反压；另外对于关闭acker机制的程序无效；&lt;/p&gt;

&lt;h2 id=&quot;storm-automatic-backpressure&quot;&gt;Storm Automatic Backpressure&lt;/h2&gt;

&lt;p&gt;新的storm自动反压机制(Automatic Back Pressure)通过监控bolt中的接收队列的情况，当超过高水位值时专门的线程会将反压信息写到 Zookeeper ，Zookeeper上的watch会通知该拓扑的所有Worker都进入反压状态，最后Spout降低tuple发送的速度。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://github.com/leafming/bak/blob/master/images/bigdata-total/2018-11-15-实时流处理系统反压机制02.png?raw=true&quot; alt=&quot;实时流处理系统反压机制02&quot; /&gt;&lt;/p&gt;

&lt;p&gt;每个Executor都有一个接受队列和发送队列用来接收Tuple和发送Spout或者Bolt生成的Tuple元组。每个Worker进程都有一个单的的接收线程监听接收端口。它从每个网络上进来的消息发送到Executor的接收队列中。Executor接收队列存放Worker或者Worker内部其他Executor发过来的消息。Executor工作线程从接收队列中拿出数据，然后调用execute方法，发送Tuple到Executor的发送队列。Executor的发送线程从发送队列中获取消息，按照消息目的地址选择发送到Worker的传输队列中或者其他Executor的接收队列中。最后Worker的发送线程从传输队列中读取消息，然后将Tuple元组发送到网络中。&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;当Worker进程中的Executor线程发现自己的接收队列满了时，也就是接收队列达到high watermark的阈值后，因此它会发送通知消息到背压线程。&lt;/li&gt;
  &lt;li&gt;背压线程将当前worker进程的信息注册到Zookeeper的Znode节点中。具体路径就是 /Backpressure/topo1/wk1下&lt;/li&gt;
  &lt;li&gt;Zookeepre的Znode Watcher监视/Backpreesure/topo1下的节点目录变化情况，如果发现目录增加了znode节点说明或者其他变化。这就说明该Topo1需要反压控制，然后它会通知Topo1所有的Worker进入反压状态。&lt;/li&gt;
  &lt;li&gt;最终Spout降低tuple发送的速度。&lt;/li&gt;
&lt;/ol&gt;

&lt;h1 id=&quot;jstorm-反压机制&quot;&gt;JStorm 反压机制&lt;/h1&gt;

&lt;p&gt;Jstorm做了两级的反压，第一级和Jstorm类似，通过执行队列来监测，但是不会通过ZK来协调，而是通过Topology Master来协调。在队列中会标记high water mark和low water mark，当执行队列超过high water mark时，就认为bolt来不及处理，则向TM发一条控制消息，上游开始减慢发送速率，直到下游低于low water mark时解除反压。&lt;/p&gt;

&lt;p&gt;此外，在Netty层也做了一级反压，由于每个Worker Task都有自己的发送和接收的缓冲区，可以对缓冲区设定限额、控制大小，如果spout数据量特别大，缓冲区填满会导致下游bolt的接收缓冲区填满，造成了反压。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://github.com/leafming/bak/blob/master/images/bigdata-total/2018-11-15-实时流处理系统反压机制03.png?raw=true&quot; alt=&quot;实时流处理系统反压机制03&quot; /&gt;&lt;/p&gt;

&lt;p&gt;限流机制：jstorm的限流机制， 当下游bolt发生阻塞时， 并且阻塞task的比例超过某个比例时（现在默认设置为0.1），触发反压&lt;/p&gt;

&lt;p&gt;限流方式：计算阻塞Task的地方执行线程执行时间，Spout每发送一个tuple等待相应时间，然后讲这个时间发送给Spout，  于是， spout每发送一个tuple，就会等待这个执行时间。&lt;/p&gt;

&lt;p&gt;Task阻塞判断方式：在jstorm 连续4次采样周期中采样，队列情况，当队列超过80%（可以设置）时，即可认为该task处在阻塞状态。&lt;/p&gt;

&lt;h1 id=&quot;sparkstreaming-反压机制&quot;&gt;SparkStreaming 反压机制&lt;/h1&gt;

&lt;h2 id=&quot;为什么引入反压机制backpressure&quot;&gt;为什么引入反压机制Backpressure&lt;/h2&gt;

&lt;p&gt;默认情况下，Spark Streaming通过Receiver以生产者生产数据的速率接收数据，计算过程中会出现batch processing time &amp;gt; batch interval的情况，其中batch processing time 为实际计算一个批次花费时间， batch interval为Streaming应用设置的批处理间隔。这意味着Spark Streaming的数据接收速率高于Spark从队列中移除数据的速率，也就是数据处理能力低，在设置间隔内不能完全处理当前接收速率接收的数据。如果这种情况持续过长的时间，会造成数据在内存中堆积，导致Receiver所在Executor内存溢出等问题（如果设置StorageLevel包含disk, 则内存存放不下的数据会溢写至disk, 加大延迟）。Spark 1.5以前版本，用户如果要限制Receiver的数据接收速率，可以通过设置静态配制参数“spark.streaming.receiver.maxRate”的值来实现，此举虽然可以通过限制接收速率，来适配当前的处理能力，防止内存溢出，但也会引入其它问题。比如：producer数据生产高于maxRate，当前集群处理能力也高于maxRate，这就会造成资源利用率下降等问题。为了更好的协调数据接收速率与资源处理能力，Spark Streaming 从v1.5开始引入反压机制（back-pressure）,通过动态控制数据接收速率来适配集群数据处理能力。&lt;/p&gt;

&lt;h2 id=&quot;反压机制backpressure&quot;&gt;反压机制Backpressure&lt;/h2&gt;

&lt;p&gt;Spark Streaming Backpressure:  根据JobScheduler反馈作业的执行信息来动态调整Receiver数据接收率。通过属性“spark.streaming.backpressure.enabled”来控制是否启用backpressure机制，默认值false，即不启用。&lt;/p&gt;

&lt;p&gt;SparkStreaming 架构图如下所示:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://github.com/leafming/bak/blob/master/images/bigdata-total/2018-11-15-实时流处理系统反压机制04.png?raw=true&quot; alt=&quot;实时流处理系统反压机制04&quot; /&gt;&lt;/p&gt;

&lt;p&gt;SparkStreaming 反压过程执行如下图所示：&lt;/p&gt;

&lt;p&gt;在原架构的基础上加上一个新的组件RateController,这个组件负责监听“OnBatchCompleted”事件，然后从中抽取processingDelay 及schedulingDelay信息.  Estimator依据这些信息估算出最大处理速度（rate），最后由基于Receiver的Input Stream将rate通过ReceiverTracker与ReceiverSupervisorImpl转发给BlockGenerator（继承自RateLimiter）.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://github.com/leafming/bak/blob/master/images/bigdata-total/2018-11-15-实时流处理系统反压机制05.png?raw=true&quot; alt=&quot;实时流处理系统反压机制05&quot; /&gt;&lt;/p&gt;

&lt;h1 id=&quot;heron-反压机制&quot;&gt;Heron 反压机制&lt;/h1&gt;

&lt;p&gt;&lt;img src=&quot;https://github.com/leafming/bak/blob/master/images/bigdata-total/2018-11-15-实时流处理系统反压机制06.png?raw=true&quot; alt=&quot;实时流处理系统反压机制06&quot; /&gt;&lt;/p&gt;

&lt;p&gt;当下游处理速度跟不上上游发送速度时，一旦StreamManager 发现一个或多个Heron Instance 速度变慢，立刻对本地spout进行降级，降低本地Spout发送速度, 停止从这些spout读取数据。并且受影响的StreamManager  会发送一个特殊的start backpressure message 给其他的StreamManager ，要求他们对spout进行本地降级。 当其他StreamManager  接收到这个特殊消息时，他们通过不读取当地Spout中的Tuple来进行降级。一旦出问题的Heron Instance 恢复速度后，本地的SM 会发送stop backpressure message 解除降级。&lt;/p&gt;

&lt;p&gt;很多Socket Channel与应用程序级别的Buffer相关联，该缓冲区由high watermark 和low watermark组成。 当缓冲区大小达到high watermark时触发反压，并保持有效，直到缓冲区大小低于low watermark。 此设计的基本原理是防止拓扑在进入和退出背压缓解模式之间快速振荡。&lt;/p&gt;

&lt;h1 id=&quot;flink-反压机制&quot;&gt;Flink 反压机制&lt;/h1&gt;

&lt;p&gt;Flink 没有使用任何复杂的机制来解决反压问题，因为根本不需要那样的方案！它利用自身作为纯数据流引擎的优势来优雅地响应反压问题。下面我们会深入分析 Flink 是如何在 Task 之间传输数据的，以及数据流如何实现自然降速的。
 Flink 在运行时主要由 operators 和 streams 两大组件构成。每个 operator 会消费中间态的流，并在流上进行转换，然后生成新的流。对于 Flink 的网络机制一种形象的类比是，Flink 使用了高效有界的分布式阻塞队列，就像 Java 通用的阻塞队列（BlockingQueue）一样。还记得经典的线程间通信案例：生产者消费者模型吗？使用 BlockingQueue 的话，一个较慢的接受者会降低发送者的发送速率，因为一旦队列满了（有界队列）发送者会被阻塞。Flink 解决反压的方案就是这种感觉。
 在 Flink 中，这些分布式阻塞队列就是这些逻辑流，而队列容量是通过缓冲池来（LocalBufferPool）实现的。每个被生产和被消费的流都会被分配一个缓冲池。缓冲池管理着一组缓冲(Buffer)，缓冲在被消费后可以被回收循环利用。这很好理解：你从池子中拿走一个缓冲，填上数据，在数据消费完之后，又把缓冲还给池子，之后你可以再次使用它。&lt;/p&gt;

&lt;h2 id=&quot;flink-网络传输中的内存管理&quot;&gt;Flink 网络传输中的内存管理&lt;/h2&gt;

&lt;p&gt;如下图所示展示了 Flink 在网络传输场景下的内存管理。网络上传输的数据会写到 Task 的 InputGate（IG） 中，经过 Task 的处理后，再由 Task 写到 ResultPartition（RS） 中。每个 Task 都包括了输入和输入，输入和输出的数据存在 Buffer 中（都是字节数据）。Buffer 是 MemorySegment 的包装类。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://github.com/leafming/bak/blob/master/images/bigdata-total/2018-11-15-实时流处理系统反压机制07.png?raw=true&quot; alt=&quot;实时流处理系统反压机制07&quot; /&gt;&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;TaskManager（TM）在启动时，会先初始化NetworkEnvironment对象，TM 中所有与网络相关的东西都由该类来管理（如 Netty 连接），其中就包括NetworkBufferPool。根据配置，Flink 会在 NetworkBufferPool 中生成一定数量（默认2048个）的内存块 MemorySegment（关于 Flink 的内存管理，后续文章会详细谈到），内存块的总数量就代表了网络传输中所有可用的内存。NetworkEnvironment 和 NetworkBufferPool 是 Task 之间共享的，每个 TM 只会实例化一个。&lt;/li&gt;
  &lt;li&gt;Task 线程启动时，会向 NetworkEnvironment 注册，NetworkEnvironment 会为 Task 的 InputGate（IG）和 ResultPartition（RP） 分别创建一个 LocalBufferPool（缓冲池）并设置可申请的 MemorySegment（内存块）数量。IG 对应的缓冲池初始的内存块数量与 IG 中 InputChannel 数量一致，RP 对应的缓冲池初始的内存块数量与 RP 中的 ResultSubpartition 数量一致。不过，每当创建或销毁缓冲池时，NetworkBufferPool 会计算剩余空闲的内存块数量，并平均分配给已创建的缓冲池。注意，这个过程只是指定了缓冲池所能使用的内存块数量，并没有真正分配内存块，只有当需要时才分配。为什么要动态地为缓冲池扩容呢？因为内存越多，意味着系统可以更轻松地应对瞬时压力（如GC），不会频繁地进入反压状态，所以我们要利用起那部分闲置的内存块。&lt;/li&gt;
  &lt;li&gt;在 Task 线程执行过程中，当 Netty 接收端收到数据时，为了将 Netty 中的数据拷贝到 Task 中，InputChannel（实际是 RemoteInputChannel）会向其对应的缓冲池申请内存块（上图中的①）。如果缓冲池中也没有可用的内存块且已申请的数量还没到池子上限，则会向 NetworkBufferPool 申请内存块（上图中的②）并交给 InputChannel 填上数据（上图中的③和④）。如果缓冲池已申请的数量达到上限了呢？或者 NetworkBufferPool 也没有可用内存块了呢？这时候，Task 的 Netty Channel 会暂停读取，上游的发送端会立即响应停止发送，拓扑会进入反压状态。当 Task 线程写数据到 ResultPartition 时，也会向缓冲池请求内存块，如果没有可用内存块时，会阻塞在请求内存块的地方，达到暂停写入的目的。&lt;/li&gt;
  &lt;li&gt;当一个内存块被消费完成之后（在输入端是指内存块中的字节被反序列化成对象了，在输出端是指内存块中的字节写入到 Netty Channel 了），会调用 Buffer.recycle() 方法，会将内存块还给 LocalBufferPool （上图中的⑤）。如果LocalBufferPool中当前申请的数量超过了池子容量（由于上文提到的动态容量，由于新注册的 Task 导致该池子容量变小），则LocalBufferPool会将该内存块回收给 NetworkBufferPool（上图中的⑥）。如果没超过池子容量，则会继续留在池子中，减少反复申请的开销。&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;flink-反压机制-1&quot;&gt;Flink 反压机制&lt;/h2&gt;

&lt;p&gt;下面这张图简单展示了两个 Task 之间的数据传输以及 Flink 如何感知到反压的：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://github.com/leafming/bak/blob/master/images/bigdata-total/2018-11-15-实时流处理系统反压机制08.png?raw=true&quot; alt=&quot;实时流处理系统反压机制08&quot; /&gt;&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;记录“A”进入了 Flink 并且被 Task 1 处理。（这里省略了 Netty 接收、反序列化等过程）&lt;/li&gt;
  &lt;li&gt;记录被序列化到 buffer 中。&lt;/li&gt;
  &lt;li&gt;该 buffer 被发送到 Task 2，然后 Task 2 从这个 buffer 中读出记录。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;strong&gt;不要忘了：记录能被 Flink 处理的前提是，必须有空闲可用的 Buffer。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;结合上面两张图看：Task 1 在输出端有一个相关联的 LocalBufferPool（称缓冲池1），Task 2 在输入端也有一个相关联的 LocalBufferPool（称缓冲池2）。如果缓冲池1中有空闲可用的 buffer 来序列化记录 “A”，我们就序列化并发送该 buffer。&lt;/p&gt;

&lt;p&gt;这里我们需要注意两个场景：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;本地传输：如果 Task 1 和 Task 2 运行在同一个 worker 节点（TaskManager），该 buffer 可以直接交给下一个 Task。一旦 Task 2 消费了该 buffer，则该 buffer 会被缓冲池1回收。如果 Task 2 的速度比 1 慢，那么 buffer 回收的速度就会赶不上 Task 1 取 buffer 的速度，导致缓冲池1无可用的 buffer，Task 1 等待在可用的 buffer 上。最终形成 Task 1 的降速。&lt;/li&gt;
  &lt;li&gt;远程传输：如果 Task 1 和 Task 2 运行在不同的 worker 节点上，那么 buffer 会在发送到网络（TCP Channel）后被回收。在接收端，会从 LocalBufferPool 中申请 buffer，然后拷贝网络中的数据到 buffer 中。如果没有可用的 buffer，会停止从 TCP 连接中读取数据。在输出端，通过 Netty 的水位值机制来保证不往网络中写入太多数据（后面会说）。如果网络中的数据（Netty输出缓冲中的字节数）超过了高水位值，我们会等到其降到低水位值以下才继续写入数据。这保证了网络中不会有太多的数据。如果接收端停止消费网络中的数据（由于接收端缓冲池没有可用 buffer），网络中的缓冲数据就会堆积，那么发送端也会暂停发送。另外，这会使得发送端的缓冲池得不到回收，writer 阻塞在向 LocalBufferPool 请求 buffer，阻塞了 writer 往 ResultSubPartition 写数据。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;这种固定大小缓冲池就像阻塞队列一样，保证了 Flink 有一套健壮的反压机制，使得 Task 生产数据的速度不会快于消费的速度。我们上面描述的这个方案可以从两个 Task 之间的数据传输自然地扩展到更复杂的 pipeline 中，保证反压机制可以扩散到整个 pipeline。&lt;/p&gt;

&lt;h2 id=&quot;反压实验&quot;&gt;反压实验&lt;/h2&gt;

&lt;p&gt;另外，官方博客中为了展示反压的效果，给出了一个简单的实验。下面这张图显示了：随着时间的改变，生产者（黄色线）和消费者（绿色线）每5秒的平均吞吐与最大吞吐（在单一JVM中每秒达到8百万条记录）的百分比。我们通过衡量task每5秒钟处理的记录数来衡量平均吞吐。该实验运行在单 JVM 中，不过使用了完整的 Flink 功能栈。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://github.com/leafming/bak/blob/master/images/bigdata-total/2018-11-15-实时流处理系统反压机制09.png?raw=true&quot; alt=&quot;实时流处理系统反压机制09&quot; /&gt;&lt;/p&gt;

&lt;p&gt;首先，我们运行生产task到它最大生产速度的60%（我们通过Thread.sleep()来模拟降速）。消费者以同样的速度处理数据。然后，我们将消费task的速度降至其最高速度的30%。你就会看到背压问题产生了，正如我们所见，生产者的速度也自然降至其最高速度的30%。接着，停止消费task的人为降速，之后生产者和消费者task都达到了其最大的吞吐。接下来，我们再次将消费者的速度降至30%，pipeline给出了立即响应：生产者的速度也被自动降至30%。最后，我们再次停止限速，两个task也再次恢复100%的速度。总而言之，我们可以看到：生产者和消费者在 pipeline 中的处理都在跟随彼此的吞吐而进行适当的调整，这就是我们希望看到的反压的效果。&lt;/p&gt;

&lt;h2 id=&quot;flink-反压监控&quot;&gt;Flink 反压监控&lt;/h2&gt;

&lt;p&gt;在 Storm/JStorm 中，只要监控到队列满了，就可以记录下拓扑进入反压了。但是 Flink 的反压太过于天然了，导致我们无法简单地通过监控队列来监控反压状态。Flink 在这里使用了一个 trick 来实现对反压的监控。如果一个 Task 因为反压而降速了，那么它会卡在向 LocalBufferPool 申请内存块上。那么这时候，该 Task 的 stack trace 就会长下面这样：&lt;/p&gt;

&lt;div class=&quot;language-java highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;java&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;lang&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;Object&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;wait&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Native&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Method&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;o&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.[...].&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;LocalBufferPool&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;requestBuffer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;LocalBufferPool&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;java&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;163&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;o&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.[...].&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;LocalBufferPool&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;requestBufferBlocking&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;LocalBufferPool&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;java&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;133&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;---&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;BLOCKING&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;request&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;[...]&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;那么事情就简单了。通过不断地采样每个 task 的 stack trace 就可以实现反压监控。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://github.com/leafming/bak/blob/master/images/bigdata-total/2018-11-15-实时流处理系统反压机制10.png?raw=true&quot; alt=&quot;实时流处理系统反压机制10&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Flink 的实现中，只有当 Web 页面切换到某个 Job 的 Backpressure 页面，才会对这个 Job 触发反压检测，因为反压检测还是挺昂贵的。JobManager 会通过 Akka 给每个 TaskManager 发送TriggerStackTraceSample消息。默认情况下，TaskManager 会触发100次 stack trace 采样，每次间隔 50ms（也就是说一次反压检测至少要等待5秒钟）。并将这 100 次采样的结果返回给 JobManager，由 JobManager 来计算反压比率（反压出现的次数/采样的次数），最终展现在 UI 上。UI 刷新的默认周期是一分钟，目的是不对 TaskManager 造成太大的负担。&lt;/p&gt;

&lt;h1 id=&quot;总结&quot;&gt;总结&lt;/h1&gt;

&lt;p&gt;Flink不需要一种特殊的机制来处理反压，因为Flink 中的数据传输相当于已经提供了应对反压的机制。因此，Flink 所能获得的最大吞吐量由其 pipeline 中最慢的组件决定。相对于 Storm/JStorm 的实现，Flink 的实现更为简洁优雅，源码中也看不见与反压相关的代码，无需 Zookeeper/TopologyMaster 的参与也降低了系统的负载，也利于对反压更迅速的响应。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;本文转自 &lt;a href=&quot;https://blog.csdn.net/qq_21125183/article/details/80708142&quot;&gt;实时流处理系统反压机制（BackPressure）综述&lt;/a&gt;&lt;br /&gt;
https://blog.csdn.net/qq_21125183/article/details/80708142&lt;/p&gt;
&lt;/blockquote&gt;

&lt;hr /&gt;
&lt;p&gt;至此，本篇内容完成。&lt;/p&gt;</content><author><name>叶子  ( ˘ ³˘)♥</name></author><category term="Spark" /><category term="Flink" /><category term="Storm" /><summary type="html">本文主要关于实时流处理系统反压机制，最近看到反压问题看到此文章很好，在此分享并mark一下。 (￢_￢)ﾉ最近菜叶子没自己写见谅。 本文转自 实时流处理系统反压机制（BackPressure）综述 https://blog.csdn.net/qq_21125183/article/details/80708142</summary></entry><entry><title type="html">Flink配置参数(官网翻译转载)</title><link href="http://localhost:4000/bigdata/2018/10/17/Flink%E9%85%8D%E7%BD%AE%E5%8F%82%E6%95%B0/" rel="alternate" type="text/html" title="Flink配置参数(官网翻译转载)" /><published>2018-10-17T00:00:00+08:00</published><updated>2018-10-17T00:00:00+08:00</updated><id>http://localhost:4000/bigdata/2018/10/17/Flink%E9%85%8D%E7%BD%AE%E5%8F%82%E6%95%B0</id><content type="html" xml:base="http://localhost:4000/bigdata/2018/10/17/Flink%E9%85%8D%E7%BD%AE%E5%8F%82%E6%95%B0/">&lt;blockquote&gt;
  &lt;p&gt;本文所用flink版本为V1.7-SNAPSHOT，官网翻译转载，转载地址：&lt;a href=&quot;https://flink.lantingmeeting.com/ops/config.html#legacy&quot;&gt;配置-https://flink.lantingmeeting.com/ops/config.html#legacy&lt;/a&gt;，官方文档原文&lt;a href=&quot;https://ci.apache.org/projects/flink/flink-docs-master/ops/config.html#configuration&quot;&gt;Configuration&lt;/a&gt;。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;strong&gt;对于单节点设置，Flink已准备好开箱即用，您无需更改默认配置即可开始使用。&lt;/strong&gt;&lt;br /&gt;
开箱即用的配置将使用您的默认Java安装.您可以手动设置环境变量&lt;code class=&quot;highlighter-rouge&quot;&gt;JAVA_HOME&lt;/code&gt;或配置项&lt;code class=&quot;highlighter-rouge&quot;&gt;env.java.home&lt;/code&gt;中&lt;code class=&quot;highlighter-rouge&quot;&gt;conf/flink-conf.yaml&lt;/code&gt;，如果你想手动覆盖Java运行时使用。&lt;br /&gt;
此页面列出了设置性能良好（分布式）安装通常所需的最常用选项。此外，此处还列出了所有可用配置参数的完整列表。&lt;br /&gt;
所有配置都已完成&lt;code class=&quot;highlighter-rouge&quot;&gt;conf/flink-conf.yaml&lt;/code&gt;，预计将是具有格式的&lt;a href=&quot;http://www.yaml.org/spec/1.2/spec.html&quot;&gt;YAML键值对&lt;/a&gt;的扁平集合&lt;code class=&quot;highlighter-rouge&quot;&gt;key: value&lt;/code&gt;。&lt;br /&gt;
系统和运行脚本在启动时解析配置。对配置文件的更改需要重新启动Flink JobManager和TaskManagers。&lt;br /&gt;
TaskManagers的配置文件可能不同，Flink不承担集群中的统一机器。&lt;/p&gt;

&lt;h1 id=&quot;常见选项&quot;&gt;常见选项&lt;/h1&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;键&lt;/th&gt;
      &lt;th&gt;默认&lt;/th&gt;
      &lt;th&gt;描述&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;jobmanager.heap.size&lt;/td&gt;
      &lt;td&gt;“1024m”&lt;/td&gt;
      &lt;td&gt;JobManager的JVM堆大小.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;taskmanager.heap.size&lt;/td&gt;
      &lt;td&gt;“1024m”&lt;/td&gt;
      &lt;td&gt;TaskManagers的JVM堆大小，它是系统的并行工作者.在YARN设置中，此值自动配置为TaskManager的YARN容器的大小，减去一定的容差值.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;parallelism.default&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;taskmanager.numberOfTaskSlots&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;单个TaskManager可以运行的并行算子或用户函数实例的数量.如果此值大于1，则单个TaskManager将获取函数或 算子的多个实例.这样，TaskManager可以使用多个CPU内核，但同时，可用内存在不同的算子或函数实例之间划分.此值通常与TaskManager的计算机具有的物理CPU核心数成比例（例如，等于核心数，或核心数的一半）.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;state.backend&lt;/td&gt;
      &lt;td&gt;(none)&lt;/td&gt;
      &lt;td&gt;状态后台用于存储和检查点状态.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;state.checkpoints.dir&lt;/td&gt;
      &lt;td&gt;(none)&lt;/td&gt;
      &lt;td&gt;用于在Flink支持的文件系统中存储检查点的数据文件和元数据的默认目录.必须可以从所有参与的进程/节点（即所有TaskManagers和JobManagers）访问存储路径.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;state.savepoints.dir&lt;/td&gt;
      &lt;td&gt;(none)&lt;/td&gt;
      &lt;td&gt;保存点的默认目录.由将后台写入文件系统的状态后台（MemoryStateBackend，FsStateBackend，RocksDBStateBackend）使用.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;high-availability&lt;/td&gt;
      &lt;td&gt;“no / not”&lt;/td&gt;
      &lt;td&gt;定义用于群集执行的高可用性模式.要启用高可用性，请将此模式设置为“ZOOKEEPER”.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;high-availability.storageDir&lt;/td&gt;
      &lt;td&gt;(none)&lt;/td&gt;
      &lt;td&gt;文件系统路径（URI）Flink在高可用性设置中持久保存元数据.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;security.ssl.internal.enabled&lt;/td&gt;
      &lt;td&gt;false&lt;/td&gt;
      &lt;td&gt;打开SSL以进行内部网络通信.可选地，特定组件可以通过它们自己的设置（rpc，数据传输，REST等）覆盖它.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;security.ssl.rest.enabled&lt;/td&gt;
      &lt;td&gt;false&lt;/td&gt;
      &lt;td&gt;通过REST端点打开SSL以进行外部通信.&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h1 id=&quot;完整参考&quot;&gt;完整参考&lt;/h1&gt;
&lt;h2 id=&quot;hdfs&quot;&gt;HDFS&lt;/h2&gt;
&lt;p&gt;注意:&lt;strong&gt;不推荐使用这些Keys，建议使用环境变量配置Hadoop路径&lt;code class=&quot;highlighter-rouge&quot;&gt;HADOOP_CONF_DIR&lt;/code&gt;&lt;/strong&gt;。&lt;br /&gt;
这些参数配置Flink使用的默认HDFS。未指定HDFS配置的设置必须指定HDFS文件的完整路径（&lt;code class=&quot;highlighter-rouge&quot;&gt;hdfs://address:port/path/to/files&lt;/code&gt;）文件也将使用默认HDFS参数（块大小，复制因子）编写。&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;fs.hdfs.hadoopconf&lt;/code&gt;：Hadoop文件系统（HDFS）配置&lt;strong&gt;目录&lt;/strong&gt;的绝对路径（可选值）。指定此值允许程序使用短URI引用HDFS文件（&lt;code class=&quot;highlighter-rouge&quot;&gt;hdfs:///path/to/files&lt;/code&gt;不包括文件URI中NameNode的地址和端口）。如果没有此选项，则可以访问HDFS文件，但需要完全限定的URI &lt;code class=&quot;highlighter-rouge&quot;&gt;hdfs://address:port/path/to/files&lt;/code&gt;。此选项还会导致文件编写者获取HDFS的块大小和复制因子的默认值。Flink将在指定目录中查找“core-site.xml”和“hdfs-site.xml”文件。&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;fs.hdfs.hdfsdefault&lt;/code&gt;：Hadoop自己的配置文件“hdfs-default.xml”的绝对路径（DEFAULT：null）。&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;fs.hdfs.hdfssite&lt;/code&gt;：Hadoop自己的配置文件“hdfs-site.xml”的绝对路径（DEFAULT：null）。&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;核心&quot;&gt;核心&lt;/h2&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;键&lt;/th&gt;
      &lt;th&gt;默认&lt;/th&gt;
      &lt;th&gt;描述&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;classloader.parent-first-patterns.additional&lt;/td&gt;
      &lt;td&gt;(none)&lt;/td&gt;
      &lt;td&gt;一个（以分号分隔的）模式列表，指定应始终首先通过父ClassLoader解析哪些类.模式是一个简单的前缀，它根据完全限定的类名进行检查.这些模式附加到“classloader.parent-first-patterns.default”.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;classloader.parent-first-patterns.default&lt;/td&gt;
      &lt;td&gt;“java .; scala .; org.apache.flink .; com.esotericsoftware.kryo; org.apache.hadoop .; javax.annotation .; org.slf4j; org.apache.log4j; org.apache.logging; org. apache.commons.logging; ch.qos.logback“&lt;/td&gt;
      &lt;td&gt;一个（以分号分隔的）模式列表，指定应始终首先通过父ClassLoader解析哪些类.模式是一个简单的前缀，它根据完全限定的类名进行检查.通常不应修改此设置.要添加其他模式，我们建议使用“classloader.parent-first-patterns.additional”.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;classloader.resolve-order&lt;/td&gt;
      &lt;td&gt;“child-first”&lt;/td&gt;
      &lt;td&gt;从用户代码加载类时定义类解析策略，这意味着是首先检查用户代码jar（“child-first”）还是应用程序类路径（“parent-first”）.默认设置指示首先从用户代码jar加载类，这意味着用户代码jar可以包含和加载不同于Flink使用的（依赖）依赖项.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;io.tmp.dirs&lt;/td&gt;
      &lt;td&gt;YARN上的’LOCAL_DIRS’.Mesos上的’_FLINK_TMP_DIR’.独立的System.getProperty（“java.io.tmpdir”）.&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;mode&lt;/td&gt;
      &lt;td&gt;“new”&lt;/td&gt;
      &lt;td&gt;切换到选择执行模式.可能的值为“new”和“legacy”.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;parallelism.default&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h2 id=&quot;jobmanager&quot;&gt;JobManager&lt;/h2&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;键&lt;/th&gt;
      &lt;th&gt;默认&lt;/th&gt;
      &lt;th&gt;描述&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;jobmanager.archive.fs.dir&lt;/td&gt;
      &lt;td&gt;(none)&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;jobmanager.execution.attempts-history-size&lt;/td&gt;
      &lt;td&gt;16&lt;/td&gt;
      &lt;td&gt;历史记录中保存的最大执行尝试次数.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;jobmanager.execution.failover-strategy&lt;/td&gt;
      &lt;td&gt;“full”&lt;/td&gt;
      &lt;td&gt;此选项指定作业计算如何从任务失败中恢复.可接受的值是：’full’：重新启动所有任务.’individual’：仅重新启动失败的任务.仅当所有任务都是独立组件时才应使用.’region’：重新启动可能受任务失败影响的所有任务.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;jobmanager.heap.size&lt;/td&gt;
      &lt;td&gt;“1024m”&lt;/td&gt;
      &lt;td&gt;JobManager的JVM堆大小.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;jobmanager.resourcemanager.&lt;br /&gt;reconnect-interval&lt;/td&gt;
      &lt;td&gt;2000&lt;/td&gt;
      &lt;td&gt;此选项指定在与资源管理器的连接丢失时触发资源管理器重新连接的时间间隔.此选项仅供内部使用.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;jobmanager.rpc.address&lt;/td&gt;
      &lt;td&gt;(none)&lt;/td&gt;
      &lt;td&gt;config参数定义要连接的网络地址以与JobManager进行通信.此值仅在具有静态名称或地址的单个JobManager存在的设置中解释（简单的独立设置或具有动态服务名称解析的容器设置）.当使用Leader选举服务（如ZooKeeper）从潜在的多个Slave JobManagers中选择和发现JobManagerLeader时，它不会在许多高可用性设置中使用.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;jobmanager.rpc.port&lt;/td&gt;
      &lt;td&gt;6123&lt;/td&gt;
      &lt;td&gt;config参数定义要连接的网络端口以与JobManager进行通信.与jobmanager.rpc.address一样，此值仅在设置中解释，其中存在具有静态名称/地址和端口的单个JobManager（简单的独立设置或具有动态服务名称解析的容器设置）.当使用Leader选举服务（如ZooKeeper）从潜在的多个Slave JobManagers中选择和发现JobManagerLeader时，此配置选项不会用于许多高可用性设置.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;jobstore.cache-size&lt;/td&gt;
      &lt;td&gt;52428800&lt;/td&gt;
      &lt;td&gt;作业存储缓存大小（以字节为单位），用于将已完成的作业保存在内存中.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;jobstore.expiration-time&lt;/td&gt;
      &lt;td&gt;3600&lt;/td&gt;
      &lt;td&gt;完成作业到期并从作业库中清除的时间（以秒为单位）.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;slot.idle.timeout&lt;/td&gt;
      &lt;td&gt;50000&lt;/td&gt;
      &lt;td&gt;Slot Pool中空闲槽的超时时间（以ms为单位）.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;slot.request.timeout&lt;/td&gt;
      &lt;td&gt;300000&lt;/td&gt;
      &lt;td&gt;从Slot Pool请求插槽的超时（以ms为单位）.&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h2 id=&quot;taskmanager&quot;&gt;TaskManager&lt;/h2&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;键&lt;/th&gt;
      &lt;th&gt;默认&lt;/th&gt;
      &lt;th&gt;描述&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;task.cancellation.interval&lt;/td&gt;
      &lt;td&gt;30000&lt;/td&gt;
      &lt;td&gt;两次连续任务取消尝试之间的时间间隔（以ms为单位）.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;task.cancellation.timeout&lt;/td&gt;
      &lt;td&gt;180000&lt;/td&gt;
      &lt;td&gt;超时（以ms为单位），在此之后任务取消超时并导致致命的TaskManager错误.值为0将禁用看门狗.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;task.cancellation.timers.timeout&lt;/td&gt;
      &lt;td&gt;7500&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;task.checkpoint.alignment.max-size&lt;/td&gt;
      &lt;td&gt;-1&lt;/td&gt;
      &lt;td&gt;检查点对齐可以缓冲的最大字节数.如果检查点对齐缓冲超过配置的数据量，则中止检查点（跳过）.值-1表示没有限制.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;taskmanager.data.port&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;TaskManager的端口用于数据交换 算子操作.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;taskmanager.data.ssl.enabled&lt;/td&gt;
      &lt;td&gt;true&lt;/td&gt;
      &lt;td&gt;为taskmanager数据传输启用SSL支持.仅当内部SSL的全局标志（security.ssl.internal.enabled）设置为true时，此选项才适用&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;taskmanager.debug.memory.log&lt;/td&gt;
      &lt;td&gt;false&lt;/td&gt;
      &lt;td&gt;指示是否启动线程的标志，该线程重复记录JVM的内存使用情况.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;taskmanager.debug.memory.log-interval&lt;/td&gt;
      &lt;td&gt;5000&lt;/td&gt;
      &lt;td&gt;日志线程记录当前内存使用情况的时间间隔（以ms为单位）.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;taskmanager.exit-on-fatal-akka-error&lt;/td&gt;
      &lt;td&gt;false&lt;/td&gt;
      &lt;td&gt;是否应启动TaskManager的隔离监视器.如果隔离监视器检测到它已隔离另一个actor系统或者它已被另一个actor系统隔离，则会关闭该actor系统.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;taskmanager.heap.size&lt;/td&gt;
      &lt;td&gt;“1024m”&lt;/td&gt;
      &lt;td&gt;TaskManagers的JVM堆大小，它是系统的并行工作者.在YARN设置中，此值自动配置为TaskManager的YARN容器的大小，减去一定的容差值.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;taskmanager.host&lt;/td&gt;
      &lt;td&gt;(none)&lt;/td&gt;
      &lt;td&gt;TaskManager绑定到的网络接口的主机名.默认情况下，TaskManager搜索可以连接到JobManager和其他TaskManagers的网络接口.如果该策略由于某种原因失败，则此选项可用于定义主机名.由于不同的TaskManagers需要此选项的不同值，因此通常在其他非共享的特定于TaskManager的配置文件中指定.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;taskmanager.jvm-exit-on-oom&lt;/td&gt;
      &lt;td&gt;false&lt;/td&gt;
      &lt;td&gt;是否在任务线程抛出OutOfMemoryError时终止TaskManager.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;taskmanager.memory.fraction&lt;/td&gt;
      &lt;td&gt;0.7&lt;/td&gt;
      &lt;td&gt;TaskManager为排序，哈希表和中间结果的缓存预留的相对内存量（在减去网络缓冲区使用的内存量之后）.例如，值“0.8”表示TaskManager为内部数据缓冲区保存80％的内存，为TaskManager的堆留下20％的可用内存，用于由用户定义的函数创建的对象.仅当未设置taskmanager.memory.size时，才会评估此参数.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;taskmanager.memory.off-heap&lt;/td&gt;
      &lt;td&gt;false&lt;/td&gt;
      &lt;td&gt;内存分配方法（JVM堆或堆外），用于TaskManager的托管内存以及网络缓冲区.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;taskmanager.memory.preallocate&lt;/td&gt;
      &lt;td&gt;false&lt;/td&gt;
      &lt;td&gt;在TaskManager启动时是否应预先分配TaskManager托管内存.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;taskmanager.memory.segment-size&lt;/td&gt;
      &lt;td&gt;“32KB”&lt;/td&gt;
      &lt;td&gt;网络堆栈和内存管理器使用的内存缓冲区的大小.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;taskmanager.memory.size&lt;/td&gt;
      &lt;td&gt;“0”&lt;/td&gt;
      &lt;td&gt;TaskManager的内存管理器分配的内存量.如果未设置，将分配相对分数.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;taskmanager.network.detailed-metrics&lt;/td&gt;
      &lt;td&gt;false&lt;/td&gt;
      &lt;td&gt;布尔标志，用于启用/禁用有关入站/出站网络队列长度的更详细指标.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;taskmanager.network.memory.&lt;br /&gt;buffers-per-channel&lt;/td&gt;
      &lt;td&gt;2&lt;/td&gt;
      &lt;td&gt;每个传出/传入通道（子分区/输入通道）使用的最大网络缓冲区数.在基于信用的流量控制模式下，这表示每个输入通道中有多少信用.它应配置至少2以获得良好的性能.1个缓冲区用于接收子分区中的飞行中数据，1个缓冲区用于并行序列化.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;taskmanager.network.memory.&lt;br /&gt;floating-buffers-per-gate&lt;/td&gt;
      &lt;td&gt;8&lt;/td&gt;
      &lt;td&gt;每个输出/输入门（结果分区/输入门）使用的额外网络缓冲区数.在基于信用的流量控制模式中，这表示在所有输入通道之间共享多少浮动信用.浮动缓冲区基于积压（子分区中的实时输出缓冲区）反馈来分布，并且可以帮助减轻由子分区之间的不平衡数据分布引起的背压.如果节点之间的往返时间较长和/或群集中的机器数量较多，则应增加此值.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;taskmanager.network.memory.&lt;br /&gt;fraction&lt;/td&gt;
      &lt;td&gt;0.1&lt;/td&gt;
      &lt;td&gt;用于网络缓冲区的JVM内存的分数.这决定了TaskManager可以同时拥有多少流数据交换通道以及通道缓冲的程度.如果作业被拒绝或者您收到系统没有足够缓冲区的警告，请增加此值或下面的最小/最大值.另请注意，“taskmanager.network.memory.min”和“taskmanager.network.memory.max”可能会覆盖此分数.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;taskmanager.network.memory.max&lt;/td&gt;
      &lt;td&gt;“1GB”&lt;/td&gt;
      &lt;td&gt;网络缓冲区的最大内存大小.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;taskmanager.network.memory.min&lt;/td&gt;
      &lt;td&gt;“64MB”&lt;/td&gt;
      &lt;td&gt;网络缓冲区的最小内存大小.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;taskmanager.network.request-backoff.initial&lt;/td&gt;
      &lt;td&gt;100&lt;/td&gt;
      &lt;td&gt;输入通道的分区请求的最小退避.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;taskmanager.network.request-backoff.max&lt;/td&gt;
      &lt;td&gt;10000&lt;/td&gt;
      &lt;td&gt;输入通道的分区请求的最大退避.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;taskmanager.numberOfTaskSlots&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;单个TaskManager可以运行的并行算子或用户函数实例的数量.如果此值大于1，则单个TaskManager将获取函数或 算子的多个实例.这样，TaskManager可以使用多个CPU内核，但同时，可用内存在不同的算子或函数实例之间划分.此值通常与TaskManager的计算机具有的物理CPU核心数成比例（例如，等于核心数，或核心数的一半）.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;taskmanager.registration.initial-backoff&lt;/td&gt;
      &lt;td&gt;“500ms”&lt;/td&gt;
      &lt;td&gt;两次连续注册尝试之间的初始注册退避.每次新注册尝试的退避加倍，直到达到最大注册退避.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;taskmanager.registration.max-backoff&lt;/td&gt;
      &lt;td&gt;“30s”&lt;/td&gt;
      &lt;td&gt;两次连续注册尝试之间的最大注册退避.最大注册退避需要时间单位指定符（ms / s / min / h / d）.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;taskmanager.registration.refused-backoff&lt;/td&gt;
      &lt;td&gt;“10s”&lt;/td&gt;
      &lt;td&gt;注册后的退避已被作业管理员拒绝，然后重试连接.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;taskmanager.registration.timeout&lt;/td&gt;
      &lt;td&gt;“5m”&lt;/td&gt;
      &lt;td&gt;定义TaskManager注册的超时.如果在未成功注册的情况下超过持续时间，则TaskManager将终止.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;taskmanager.rpc.port&lt;/td&gt;
      &lt;td&gt;“0”&lt;/td&gt;
      &lt;td&gt;TaskManager的IPC端口.接受端口列表（“50100,50101”），范围（“50100-50200”）或两者的组合.建议在同一台计算机上运行多个TaskManagers时设置一系列端口以避免冲突.&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h2 id=&quot;分布式协调通过akka&quot;&gt;分布式协调（通过Akka）&lt;/h2&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;键&lt;/th&gt;
      &lt;th&gt;默认&lt;/th&gt;
      &lt;th&gt;描述&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;akka.ask.timeout&lt;/td&gt;
      &lt;td&gt;“10s”&lt;/td&gt;
      &lt;td&gt;超时用于所有期货并阻止Akka通话.如果Flink由于超时而失败，那么您应该尝试增加此值.超时可能是由于机器速度慢或网络拥挤造成的.超时值需要时间单位指定符（ms / s / min / h / d）.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;akka.client-socket-worker-pool.pool-size-factor&lt;/td&gt;
      &lt;td&gt;1.0&lt;/td&gt;
      &lt;td&gt;池大小因子用于使用以下公式确定线程池大小：ceil（可用处理器*因子）.然后，结果大小由pool-size-min和pool-size-max值限制.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;akka.client-socket-worker-pool.pool-size-max&lt;/td&gt;
      &lt;td&gt;2&lt;/td&gt;
      &lt;td&gt;将基于因子的数量限制为的最大线程数.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;akka.client-socket-worker-pool.pool-size-min&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;将基于因子的数量限制为的最小线程数.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;akka.client.timeout&lt;/td&gt;
      &lt;td&gt;“60s”&lt;/td&gt;
      &lt;td&gt;客户端的所有阻塞调用超时.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;akka.fork-join-executor.parallelism-factor&lt;/td&gt;
      &lt;td&gt;2.0&lt;/td&gt;
      &lt;td&gt;并行因子用于使用以下公式确定线程池大小：ceil（可用处理器*因子）.然后，得到的大小受parallelism-min和parallelism-max值的限制.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;akka.fork-join-executor.parallelism-max&lt;/td&gt;
      &lt;td&gt;64&lt;/td&gt;
      &lt;td&gt;将基于因子的并行数量限制为的最大线程数.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;akka.fork-join-executor.parallelism-min&lt;/td&gt;
      &lt;td&gt;8&lt;/td&gt;
      &lt;td&gt;将基于因子的并行数量限制为的最小线程数.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;akka.framesize&lt;/td&gt;
      &lt;td&gt;“10485760b”&lt;/td&gt;
      &lt;td&gt;在JobManager和TaskManager之间发送的消息的最大大小.如果Flink由于消息超出此限制而失败，那么您应该增加它.邮件大小需要大小单位说明符.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;akka.jvm-exit-on-fatal-error&lt;/td&gt;
      &lt;td&gt;true&lt;/td&gt;
      &lt;td&gt;退出JVM致命的Akka错误.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;akka.log.lifecycle.events&lt;/td&gt;
      &lt;td&gt;false&lt;/td&gt;
      &lt;td&gt;打开Akka远程记录事件.在调试时将此值设置为“true”.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;akka.lookup.timeout&lt;/td&gt;
      &lt;td&gt;“10s”&lt;/td&gt;
      &lt;td&gt;用于查找JobManager的超时.超时值必须包含时间单位说明符（ms / s / min / h / d）.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;akka.retry-gate-closed-for&lt;/td&gt;
      &lt;td&gt;50&lt;/td&gt;
      &lt;td&gt;断开远程连接后，应关闭门的ms数.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;akka.server-socket-worker-pool.pool-size-factor&lt;/td&gt;
      &lt;td&gt;1.0&lt;/td&gt;
      &lt;td&gt;池大小因子用于使用以下公式确定线程池大小：ceil（可用处理器*因子）.然后，结果大小由pool-size-min和pool-size-max值限制.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;akka.server-socket-worker-pool.pool-size-max&lt;/td&gt;
      &lt;td&gt;2&lt;/td&gt;
      &lt;td&gt;将基于因子的数量限制为的最大线程数.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;akka.server-socket-worker-pool.pool-size-min&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;将基于因子的数量限制为的最小线程数.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;akka.ssl.enabled&lt;/td&gt;
      &lt;td&gt;true&lt;/td&gt;
      &lt;td&gt;为Akka的远程通信打开SSL.仅当全局ssl标志security.ssl.enabled设置为true时，这才适用.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;akka.startup-timeout&lt;/td&gt;
      &lt;td&gt;(none)&lt;/td&gt;
      &lt;td&gt;超时之后，远程组件的启动被视为失败.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;akka.tcp.timeout&lt;/td&gt;
      &lt;td&gt;“20s”&lt;/td&gt;
      &lt;td&gt;所有出站连接超时.如果由于网络速度较慢而导致连接到TaskManager时遇到问题，则应增加此值.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;akka.throughput&lt;/td&gt;
      &lt;td&gt;15&lt;/td&gt;
      &lt;td&gt;在将线程返回到池之前批处理的消息数.较低的值表示公平的调度，而较高的值可以以不公平为代价来提高性能.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;akka.transport.heartbeat.interval&lt;/td&gt;
      &lt;td&gt;“1000s”&lt;/td&gt;
      &lt;td&gt;Akka传输故障检测器的心跳间隔.由于Flink使用TCP，因此不需要检测器.因此，通过将间隔设置为非常高的值来禁用检测器.如果您需要传输故障检测器，请将间隔设置为某个合理的值.间隔值需要时间单位指定符（ms / s / min / h / d）.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;akka.transport.heartbeat.pause&lt;/td&gt;
      &lt;td&gt;“6000s”&lt;/td&gt;
      &lt;td&gt;Akka的传输故障检测器可接受的心跳暂停.由于Flink使用TCP，因此不需要检测器.因此，通过将暂停设置为非常高的值来禁用检测器.如果您需要传输故障检测器，请将暂停设置为某个合理的值.暂停值需要时间单位指定符（ms / s / min / h / d）.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;akka.transport.threshold&lt;/td&gt;
      &lt;td&gt;300.0&lt;/td&gt;
      &lt;td&gt;传输故障检测器的阈值.由于Flink使用TCP，因此检测器不是必需的，因此阈值被设置为高值.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;akka.watch.heartbeat.interval&lt;/td&gt;
      &lt;td&gt;“10s”&lt;/td&gt;
      &lt;td&gt;Akka的DeathWatch机制检测死亡TaskManagers的心跳间隔.如果由于心跳消息丢失或延迟而导致TaskManagers被错误地标记为死亡，那么您应该减小此值或增加akka.watch.heartbeat.pause.可在&lt;a href=&quot;http://doc.akka.io/docs/akka/snapshot/scala/remoting.html#failure-detector&quot;&gt;此处&lt;/a&gt;找到Akka的DeathWatch的详尽描述&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;akka.watch.heartbeat.pause&lt;/td&gt;
      &lt;td&gt;“60s”&lt;/td&gt;
      &lt;td&gt;Akka的DeathWatch机制可接受的心跳暂停.较低的值不允许心律不齐.如果由于心跳消息丢失或延迟而导致TaskManagers被错误地标记为死亡，那么您应该增加此值或Reduceakka.watch.heartbeat.interval.较高的值会增加检测死的TaskManager的时间.可在&lt;a href=&quot;http://doc.akka.io/docs/akka/snapshot/scala/remoting.html#failure-detector&quot;&gt;此处&lt;/a&gt;找到Akka的DeathWatch的详尽描述&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;akka.watch.threshold&lt;/td&gt;
      &lt;td&gt;12&lt;/td&gt;
      &lt;td&gt;DeathWatch故障检测器的阈值.较低的值容易出现误报，而较高的值会增加检测死的TaskManager的时间.可在&lt;a href=&quot;http://doc.akka.io/docs/akka/snapshot/scala/remoting.html#failure-detector&quot;&gt;此处&lt;/a&gt;找到Akka的DeathWatch的详尽描述&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h2 id=&quot;rest&quot;&gt;REST&lt;/h2&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;键&lt;/th&gt;
      &lt;th&gt;默认&lt;/th&gt;
      &lt;th&gt;描述&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;rest.address&lt;/td&gt;
      &lt;td&gt;(none)&lt;/td&gt;
      &lt;td&gt;客户端应该用于连接到服务器的地址.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;rest.await-leader-timeout&lt;/td&gt;
      &lt;td&gt;30000&lt;/td&gt;
      &lt;td&gt;客户端等待Leader地址的时间（以ms为单位），例如Dispatcher或WebMonitorEndpoint&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;rest.bind-address&lt;/td&gt;
      &lt;td&gt;(none)&lt;/td&gt;
      &lt;td&gt;服务器绑定自身的地址.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;rest.client.max-content-length&lt;/td&gt;
      &lt;td&gt;104857600&lt;/td&gt;
      &lt;td&gt;客户端将处理的最大内容长度（以字节为单位）.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;rest.connection-timeout&lt;/td&gt;
      &lt;td&gt;15000&lt;/td&gt;
      &lt;td&gt;客户端建立TCP连接的最长时间（以ms为单位）.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;rest.port&lt;/td&gt;
      &lt;td&gt;8081&lt;/td&gt;
      &lt;td&gt;服务器侦听的端口/客户端连接到的端口.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;rest.retry.delay&lt;/td&gt;
      &lt;td&gt;3000&lt;/td&gt;
      &lt;td&gt;客户端在重试之间等待的时间（以ms为单位）（另请参阅“rest.retry.max-attempts”）.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;rest.retry.max-attempts&lt;/td&gt;
      &lt;td&gt;20&lt;/td&gt;
      &lt;td&gt;如果可重试 算子操作失败，客户端将尝试重试的次数.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;rest.server.max-content-length&lt;/td&gt;
      &lt;td&gt;104857600&lt;/td&gt;
      &lt;td&gt;服务器将处理的最大内容长度（以字节为单位）.&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h2 id=&quot;blob服务器&quot;&gt;Blob服务器&lt;/h2&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;键&lt;/th&gt;
      &lt;th&gt;默认&lt;/th&gt;
      &lt;th&gt;描述&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;blob.fetch.backlog&lt;/td&gt;
      &lt;td&gt;1000&lt;/td&gt;
      &lt;td&gt;config参数定义JobManager上BLOB提取的积压.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;blob.fetch.num-concurrent&lt;/td&gt;
      &lt;td&gt;50&lt;/td&gt;
      &lt;td&gt;config参数定义JobManager服务的最大并发BLOB提取数.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;blob.fetch.retries&lt;/td&gt;
      &lt;td&gt;5&lt;/td&gt;
      &lt;td&gt;config参数定义失败的BLOB提取的退出次数.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;blob.offload.minsize&lt;/td&gt;
      &lt;td&gt;1048576&lt;/td&gt;
      &lt;td&gt;要卸载到BlobServer的消息的最小大小.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;blob.server.port&lt;/td&gt;
      &lt;td&gt;“0”&lt;/td&gt;
      &lt;td&gt;config参数定义blob服务的服务器端口.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;blob.service.cleanup.interval&lt;/td&gt;
      &lt;td&gt;3600&lt;/td&gt;
      &lt;td&gt;TaskManager中blob缓存的清理间隔（以秒为单位）.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;blob.service.ssl.enabled&lt;/td&gt;
      &lt;td&gt;true&lt;/td&gt;
      &lt;td&gt;用于覆盖blob服务传输的ssl支持的标志.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;blob.storage.directory&lt;/td&gt;
      &lt;td&gt;(none)&lt;/td&gt;
      &lt;td&gt;config参数，用于定义blob服务器使用的存储目录.&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h2 id=&quot;心跳管理器&quot;&gt;心跳管理器&lt;/h2&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;键&lt;/th&gt;
      &lt;th&gt;默认&lt;/th&gt;
      &lt;th&gt;描述&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;heartbeat.interval&lt;/td&gt;
      &lt;td&gt;10000&lt;/td&gt;
      &lt;td&gt;从发送方请求心跳的时间间隔.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;heartbeat.timeout&lt;/td&gt;
      &lt;td&gt;50000&lt;/td&gt;
      &lt;td&gt;为发送方和接收方双方请求和接收心跳的超时.&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h2 id=&quot;ssl设置&quot;&gt;SSL设置&lt;/h2&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;键&lt;/th&gt;
      &lt;th&gt;默认&lt;/th&gt;
      &lt;th&gt;描述&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;security.ssl.algorithms&lt;/td&gt;
      &lt;td&gt;“TLS_RSA_WITH_AES_128_CBC_SHA”&lt;/td&gt;
      &lt;td&gt;要支持的标准SSL算法的逗号分隔列表.&lt;a href=&quot;http://docs.oracle.com/javase/8/docs/technotes/guides/security/StandardNames.html#ciphersuites&quot;&gt;在这里&lt;/a&gt;阅读更多&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;security.ssl.internal.enabled&lt;/td&gt;
      &lt;td&gt;false&lt;/td&gt;
      &lt;td&gt;打开SSL以进行内部网络通信.可选地，特定组件可以通过它们自己的设置（rpc，数据传输，REST等）覆盖它.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;security.ssl.internal.key-password&lt;/td&gt;
      &lt;td&gt;(none)&lt;/td&gt;
      &lt;td&gt;解密Keys库中Flink内部端点（rpc，数据传输，blob服务器）Keys的密钥.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;security.ssl.internal.keystore&lt;/td&gt;
      &lt;td&gt;(none)&lt;/td&gt;
      &lt;td&gt;带有SSLKeys和证书的JavaKeys库文件，用于Flink的内部端点（rpc，数据传输，blob服务器）.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;security.ssl.internal.keystore-password&lt;/td&gt;
      &lt;td&gt;(none)&lt;/td&gt;
      &lt;td&gt;为Flink的内部端点（rpc，数据传输，blob服务器）解密Flink的Keys库文件的密钥.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;security.ssl.internal.truststore&lt;/td&gt;
      &lt;td&gt;(none)&lt;/td&gt;
      &lt;td&gt;包含公共CA证书的信任库文件，用于验证Flink内部端点（rpc，数据传输，blob服务器）的对等方.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;security.ssl.internal.truststore-password&lt;/td&gt;
      &lt;td&gt;(none)&lt;/td&gt;
      &lt;td&gt;用于解密Flink内部端点（rpc，数据传输，blob服务器）的信任库的密码.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;security.ssl.key-password&lt;/td&gt;
      &lt;td&gt;(none)&lt;/td&gt;
      &lt;td&gt;解密Keys库中的服务器Keys的密钥.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;security.ssl.keystore&lt;/td&gt;
      &lt;td&gt;(none)&lt;/td&gt;
      &lt;td&gt;flink端点用于其SSLKeys和证书的JavaKeys库文件.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;security.ssl.keystore-password&lt;/td&gt;
      &lt;td&gt;(none)&lt;/td&gt;
      &lt;td&gt;解密Keys库文件的密钥.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;security.ssl.protocol&lt;/td&gt;
      &lt;td&gt;“TLSv1.2”&lt;/td&gt;
      &lt;td&gt;ssl传输支持的SSL协议版本.请注意，它不支持以逗号分隔的列表.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;security.ssl.rest.enabled&lt;/td&gt;
      &lt;td&gt;false&lt;/td&gt;
      &lt;td&gt;通过REST端点打开SSL以进行外部通信.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;security.ssl.rest.key-password&lt;/td&gt;
      &lt;td&gt;(none)&lt;/td&gt;
      &lt;td&gt;解密Flink外部REST端点的Keys库中的Keys的密钥.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;security.ssl.rest.keystore&lt;/td&gt;
      &lt;td&gt;(none)&lt;/td&gt;
      &lt;td&gt;带有SSLKeys和证书的JavaKeys库文件，用于Flink的外部REST端点.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;security.ssl.rest.keystore-password&lt;/td&gt;
      &lt;td&gt;(none)&lt;/td&gt;
      &lt;td&gt;为Flink的外部REST端点解密Flink的Keys库文件的密钥.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;security.ssl.rest.truststore&lt;/td&gt;
      &lt;td&gt;(none)&lt;/td&gt;
      &lt;td&gt;包含公共CA证书的信任库文件，用于验证Flink的外部REST端点的对等方.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;security.ssl.rest.truststore-password&lt;/td&gt;
      &lt;td&gt;(none)&lt;/td&gt;
      &lt;td&gt;用于解密Flink外部REST端点的信任库的密码.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;security.ssl.truststore&lt;/td&gt;
      &lt;td&gt;(none)&lt;/td&gt;
      &lt;td&gt;信任库文件，包含flink端点用于验证对等方证书的公共CA证书.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;security.ssl.truststore-password&lt;/td&gt;
      &lt;td&gt;(none)&lt;/td&gt;
      &lt;td&gt;解密信任库的秘诀.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;security.ssl.verify-hostname&lt;/td&gt;
      &lt;td&gt;true&lt;/td&gt;
      &lt;td&gt;标记以在ssl握手期间启用对等方的主机名验证.&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h2 id=&quot;网络通讯通过netty&quot;&gt;网络通讯（通过Netty）&lt;/h2&gt;

&lt;p&gt;这些参数允许高级调整.在大型群集上运行并发高吞吐量作业时，默认值就足够了.&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;键&lt;/th&gt;
      &lt;th&gt;默认&lt;/th&gt;
      &lt;th&gt;描述&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;taskmanager.network.netty.client.&lt;br /&gt;connectTimeoutSec&lt;/td&gt;
      &lt;td&gt;120&lt;/td&gt;
      &lt;td&gt;Netty客户端连接超时.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;taskmanager.network.netty.client.&lt;br /&gt;numThreads&lt;/td&gt;
      &lt;td&gt;-1&lt;/td&gt;
      &lt;td&gt;Netty客户端线程的数量.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;taskmanager.network.netty.num-arenas&lt;/td&gt;
      &lt;td&gt;-1&lt;/td&gt;
      &lt;td&gt;Netty竞技场的数量.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;taskmanager.network.netty.&lt;br /&gt;sendReceiveBufferSize&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;Netty发送和接收缓冲区大小.这默认为系统缓冲区大小（cat / proc / sys / net / ipv4 / tcp_ [rw] mem），在现代Linux中为4 MiB.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;taskmanager.network.netty.server.&lt;br /&gt;backlog&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;netty服务器连接积压.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;taskmanager.network.netty.server.&lt;br /&gt;numThreads&lt;/td&gt;
      &lt;td&gt;-1&lt;/td&gt;
      &lt;td&gt;Netty服务器线程数.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;taskmanager.network.netty.&lt;br /&gt;transport&lt;/td&gt;
      &lt;td&gt;“nio”&lt;/td&gt;
      &lt;td&gt;Netty传输类型，“nio”或“epoll”&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h2 id=&quot;web前端&quot;&gt;Web前端&lt;/h2&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;键&lt;/th&gt;
      &lt;th&gt;默认&lt;/th&gt;
      &lt;th&gt;描述&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;web.access-control-allow-origin&lt;/td&gt;
      &lt;td&gt;“*”&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;web.address&lt;/td&gt;
      &lt;td&gt;(none)&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;web.backpressure.cleanup-interval&lt;/td&gt;
      &lt;td&gt;600000&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;web.backpressure.delay-between-samples&lt;/td&gt;
      &lt;td&gt;50&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;web.backpressure.num-samples&lt;/td&gt;
      &lt;td&gt;100&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;web.backpressure.refresh-interval&lt;/td&gt;
      &lt;td&gt;60000&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;web.checkpoints.history&lt;/td&gt;
      &lt;td&gt;10&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;web.history&lt;/td&gt;
      &lt;td&gt;5&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;web.log.path&lt;/td&gt;
      &lt;td&gt;(none)&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;web.refresh-interval&lt;/td&gt;
      &lt;td&gt;3000&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;web.ssl.enabled&lt;/td&gt;
      &lt;td&gt;true&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;web.submit.enable&lt;/td&gt;
      &lt;td&gt;true&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;web.timeout&lt;/td&gt;
      &lt;td&gt;10000&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;web.tmpdir&lt;/td&gt;
      &lt;td&gt;System.getProperty（ “java.io.tmpdir”）&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;web.upload.dir&lt;/td&gt;
      &lt;td&gt;(none)&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h2 id=&quot;文件系统&quot;&gt;文件系统&lt;/h2&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;键&lt;/th&gt;
      &lt;th&gt;默认&lt;/th&gt;
      &lt;th&gt;描述&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;fs.default-scheme&lt;/td&gt;
      &lt;td&gt;(none)&lt;/td&gt;
      &lt;td&gt;默认文件系统方案，用于未明确声明方案的路径.可能包含权限，例如，在HDFS NameNode的情况下为host：port.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;fs.output.always-create-directory&lt;/td&gt;
      &lt;td&gt;false&lt;/td&gt;
      &lt;td&gt;以大于1的并行度运行的文件编写器为输出文件路径创建目录，并将不同的结果文件（每个并行编写器任务一个）放入该目录中.如果此选项设置为“true”，则并行度为1的编写器也将创建一个目录并将单个结果文件放入其中.如果该选项设置为“false”，则编写器将直接在输出路径上直接创建文件，而不创建包含目录.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;fs.overwrite-files&lt;/td&gt;
      &lt;td&gt;false&lt;/td&gt;
      &lt;td&gt;指定默认情况下文件输出编写器是否应覆盖现有文件.设置为“true”以默认覆盖，否则设置为“false”.&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h2 id=&quot;编译优化&quot;&gt;编译/优化&lt;/h2&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;键&lt;/th&gt;
      &lt;th&gt;默认&lt;/th&gt;
      &lt;th&gt;描述&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;compiler.delimited-informat.max-line-samples&lt;/td&gt;
      &lt;td&gt;10&lt;/td&gt;
      &lt;td&gt;编译器为分隔输入采用的最大行样本数.样本用于估计记录数.可以使用输入格式的参数覆盖特定输入的此值.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;compiler.delimited-informat.max-sample-len&lt;/td&gt;
      &lt;td&gt;2097152&lt;/td&gt;
      &lt;td&gt;编译器用于分隔输入的行样本的最大长度.如果单个样本的长度超过此值（可能是因为解析器配置错误），则取样将中止.可以使用输入格式的参数覆盖特定输入的此值.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;compiler.delimited-informat.min-line-samples&lt;/td&gt;
      &lt;td&gt;2&lt;/td&gt;
      &lt;td&gt;编译器为分隔输入采用的最小行样本数.样本用于估计记录数.可以使用输入格式的参数覆盖特定输入的此值&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h2 id=&quot;运行时算法&quot;&gt;运行时算法&lt;/h2&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;键&lt;/th&gt;
      &lt;th&gt;默认&lt;/th&gt;
      &lt;th&gt;描述&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;taskmanager.runtime.hashjoin-bloom-filters&lt;/td&gt;
      &lt;td&gt;false&lt;/td&gt;
      &lt;td&gt;用于在混合散列连接实现中激活/停用bloom过滤器的标志.如果散列连接需要溢出到磁盘（数据集大于保存的内存部分），这些布隆过滤器可以大大Reduce溢出记录的数量，但需要花费一些CPU周期.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;taskmanager.runtime.max-fan&lt;/td&gt;
      &lt;td&gt;128&lt;/td&gt;
      &lt;td&gt;外部合并的最大扇入连接和扇出用于溢出哈希表.限制每个 算子的文件句柄数，但如果设置得太小，可能会导致中间合并/分区.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;taskmanager.runtime.sort-spilling-threshold&lt;/td&gt;
      &lt;td&gt;0.8&lt;/td&gt;
      &lt;td&gt;当这部分内存预算已满时，排序 算子操作开始溢出.&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h2 id=&quot;resource-manager&quot;&gt;Resource Manager&lt;/h2&gt;

&lt;p&gt;本节中的配置键独立于使用的资源管理框架（YARN，Mesos，Standalone，…）&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;键&lt;/th&gt;
      &lt;th&gt;默认&lt;/th&gt;
      &lt;th&gt;描述&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;containerized.heap-cutoff-min&lt;/td&gt;
      &lt;td&gt;600&lt;/td&gt;
      &lt;td&gt;作为安全边际，要在容器中删除的最小堆内存量.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;containerized.heap-cutoff-ratio&lt;/td&gt;
      &lt;td&gt;0.25&lt;/td&gt;
      &lt;td&gt;要从容器中删除的堆空间百分比（YARN / Mesos），以补偿其他JVM内存使用情况.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;local.number-resourcemanager&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;resourcemanager.job.timeout&lt;/td&gt;
      &lt;td&gt;“5m”&lt;/td&gt;
      &lt;td&gt;没有TaskManager作为Leader的工作超时.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;resourcemanager.rpc.port&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;定义要连接的网络端口以与资源管理器进行通信.默认情况下，JobManager的端口，因为使用了相同的ActorSystem.无法使用此配置键定义端口范围.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;resourcemanager.taskmanager-timeout&lt;/td&gt;
      &lt;td&gt;30000&lt;/td&gt;
      &lt;td&gt;释放空闲TaskManager的超时.&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h2 id=&quot;yarn&quot;&gt;YARN&lt;/h2&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;键&lt;/th&gt;
      &lt;th&gt;默认&lt;/th&gt;
      &lt;th&gt;描述&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;yarn.application-attempts&lt;/td&gt;
      &lt;td&gt;(none)&lt;/td&gt;
      &lt;td&gt;ApplicationMaster重启次数.请注意，整个Flink群集将重新启动，YARN客户端将断开连接.此外，JobManager地址将更改，您需要手动设置JM主机：port.建议将此选项保存为1.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;yarn.application-master.port&lt;/td&gt;
      &lt;td&gt;“0”&lt;/td&gt;
      &lt;td&gt;使用此配置选项，用户可以为Application Master（和JobManager）RPC端口指定端口，一系列端口或端口列表.默认情况下，我们建议使用默认值（0）让 算子操作系统选择适当的端口.特别是当多个AM在同一物理主机上运行时，固定端口分配会阻止AM启动.例如，在具有限制性防火墙的环境中在YARN上运行Flink时，此选项允许指定一系列允许的端口.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;yarn.appmaster.rpc.address&lt;/td&gt;
      &lt;td&gt;(none)&lt;/td&gt;
      &lt;td&gt;应用程序主RPC系统正在侦听的主机名或地址.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;yarn.appmaster.rpc.port&lt;/td&gt;
      &lt;td&gt;-1&lt;/td&gt;
      &lt;td&gt;应用程序主RPC系统正在侦听的端口.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;yarn.containers.vcores&lt;/td&gt;
      &lt;td&gt;-1&lt;/td&gt;
      &lt;td&gt;每个YARN容器的虚拟核心数（vcores）.默认情况下，vcores的数量设置为每个TaskManager的插槽数（如果已设置），或者设置为1，否则设置为1.为了使用此参数，您的群集必须启用CPU调度.您可以通过设置来完成此 算子操作&lt;code class=&quot;highlighter-rouge&quot;&gt;org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler&lt;/code&gt;.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;yarn.heartbeat-delay&lt;/td&gt;
      &lt;td&gt;5&lt;/td&gt;
      &lt;td&gt;使用ResourceManager的心跳之间的时间，以秒为单位.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;yarn.maximum-failed-containers&lt;/td&gt;
      &lt;td&gt;(none)&lt;/td&gt;
      &lt;td&gt;系统在发生故障时将重新分配的最大容器数.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;yarn.per-job-cluster.include-user-jar&lt;/td&gt;
      &lt;td&gt;“ORDER”&lt;/td&gt;
      &lt;td&gt;定义用户jar是否包含在每个作业集群的系统类路径中以及它们在路径中的位置.它们可以位于开头（“FIRST”），末尾（“LAST”），或者根据其名称（“ORDER”）定位.将此参数设置为“DISABLED”会导致jar包含在用户类路径中.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;yarn.properties-file.location&lt;/td&gt;
      &lt;td&gt;(none)&lt;/td&gt;
      &lt;td&gt;将Flink作业提交给YARN时，JobManager的主机和可用处理槽的数量将写入属性文件，以便Flink客户端能够选择这些详细信息.此配置参数允许更改该文件的默认位置（例如，对于在用户之间共享Flink安装的环境）.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;yarn.tags&lt;/td&gt;
      &lt;td&gt;(none)&lt;/td&gt;
      &lt;td&gt;要应用于Flink YARN应用程序的以逗号分隔的标记列表.&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h2 id=&quot;mesos&quot;&gt;Mesos&lt;/h2&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;键&lt;/th&gt;
      &lt;th&gt;默认&lt;/th&gt;
      &lt;th&gt;描述&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;mesos.failover-timeout&lt;/td&gt;
      &lt;td&gt;604800&lt;/td&gt;
      &lt;td&gt;Mesos调度程序的故障转移超时（以秒为单位），之后将自动关闭正在运行的任务.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;mesos.initial-tasks&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;最初的工人在主人开始时提出来.除非Flink处于&lt;a href=&quot;https://flink.lantingmeeting.com/ops/config.html#legacy&quot;&gt;传统模式，&lt;/a&gt;否则将忽略此选项.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;mesos.master&lt;/td&gt;
      &lt;td&gt;(none)&lt;/td&gt;
      &lt;td&gt;Mesos主URL.该值应采用以下形式之一：主持人：portZK：//主机1：端口1，主机2：端口2，… /路径ZK：//用户名：密码@主机1：端口1，主机2：端口2，… /路径文件：///路径/到/文件&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;mesos.maximum-failed-tasks&lt;/td&gt;
      &lt;td&gt;-1&lt;/td&gt;
      &lt;td&gt;群集失败前失败的最大工作数.可以设置为-1以禁用此函数.除非Flink处于&lt;a href=&quot;https://flink.lantingmeeting.com/ops/config.html#legacy&quot;&gt;传统模式，&lt;/a&gt;否则将忽略此选项.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;mesos.resourcemanager.&lt;br /&gt;artifactserver.port&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;config参数定义要使用的Mesos工件服务器端口.将端口设置为0将允许 算子操作系统选择可用端口.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;mesos.resourcemanager.&lt;br /&gt;artifactserver.ssl.enabled&lt;/td&gt;
      &lt;td&gt;true&lt;/td&gt;
      &lt;td&gt;为Flink工件服务器启用SSL.请注意，security.ssl.enabled也需要设置为true加密才能启用加密.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;mesos.resourcemanager.&lt;br /&gt;framework.name&lt;/td&gt;
      &lt;td&gt;“Flink”&lt;/td&gt;
      &lt;td&gt;Mesos框架名称&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;mesos.resourcemanager.&lt;br /&gt;framework.principal&lt;/td&gt;
      &lt;td&gt;(none)&lt;/td&gt;
      &lt;td&gt;Mesos框架主体&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;mesos.resourcemanager.&lt;br /&gt;framework.role&lt;/td&gt;
      &lt;td&gt;“*”&lt;/td&gt;
      &lt;td&gt;Mesos框架角色定义&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;mesos.resourcemanager.&lt;br /&gt;framework.secret&lt;/td&gt;
      &lt;td&gt;(none)&lt;/td&gt;
      &lt;td&gt;Mesos框架密钥&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;mesos.resourcemanager.&lt;br /&gt;framework.user&lt;/td&gt;
      &lt;td&gt;(none)&lt;/td&gt;
      &lt;td&gt;Mesos框架用户&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;mesos.resourcemanager.tasks.port-assignments&lt;/td&gt;
      &lt;td&gt;(none)&lt;/td&gt;
      &lt;td&gt;以逗号分隔的配置键列表，表示可配置端口.所有端口Keys将动态获取通过Mesos分配的端口.&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h3 id=&quot;mesos-taskmanager&quot;&gt;Mesos TaskManager&lt;/h3&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;键&lt;/th&gt;
      &lt;th&gt;默认&lt;/th&gt;
      &lt;th&gt;描述&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;mesos.constraints.hard.hostattribute&lt;/td&gt;
      &lt;td&gt;(none)&lt;/td&gt;
      &lt;td&gt;基于代理属性在Mesos上放置任务的约束.采用逗号分隔的键：值对列表，对应于目标介质代理公开的属性.示例：az：eu-west-1a，系列：t2&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;mesos.resourcemanager.tasks.&lt;br /&gt;bootstrap-cmd&lt;/td&gt;
      &lt;td&gt;(none)&lt;/td&gt;
      &lt;td&gt;在TaskManager启动之前执行的命令.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;mesos.resourcemanager.tasks.&lt;br /&gt;container.docker.force-pull-image&lt;/td&gt;
      &lt;td&gt;false&lt;/td&gt;
      &lt;td&gt;指示docker containerizer强制拉动镜像，而不是重用缓存版本.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;mesos.resourcemanager.tasks.&lt;br /&gt;container.docker.parameters&lt;/td&gt;
      &lt;td&gt;(none)&lt;/td&gt;
      &lt;td&gt;使用docker容器时，要传递给docker run命令的自定义参数.逗号分隔的“key = value”对列表.“值”可能包含“=”.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;mesos.resourcemanager.tasks.&lt;br /&gt;container.image.name&lt;/td&gt;
      &lt;td&gt;(none)&lt;/td&gt;
      &lt;td&gt;用于容器的映像名称.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;mesos.resourcemanager.tasks.&lt;br /&gt;container.type&lt;/td&gt;
      &lt;td&gt;“mesos”&lt;/td&gt;
      &lt;td&gt;使用的集装箱类型：“mesos”或“docker”.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;mesos.resourcemanager.tasks.&lt;br /&gt;container.volumes&lt;/td&gt;
      &lt;td&gt;(none)&lt;/td&gt;
      &lt;td&gt;逗号分隔的[host_path：] container_path [：RO | RW]列表.这允许将额外的卷安装到容器中.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;mesos.resourcemanager.tasks.cpus&lt;/td&gt;
      &lt;td&gt;0.0&lt;/td&gt;
      &lt;td&gt;要分配给Mesos工作者的CPU.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;mesos.resourcemanager.tasks.gpus&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;要分配给Mesos工作者的GPU.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;mesos.resourcemanager.tasks.hostname&lt;/td&gt;
      &lt;td&gt;(none)&lt;/td&gt;
      &lt;td&gt;用于定义TaskManager主机名的可选值.模式_TASK_由Mesos任务的实际ID替换.这可用于配置TaskManager以使用Mesos DNS（例如_TASK_.flink-service.mesos）进行名称查找.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;mesos.resourcemanager.tasks.mem&lt;/td&gt;
      &lt;td&gt;1024&lt;/td&gt;
      &lt;td&gt;要以MB为单位分配给Mesos worker的内存.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;mesos.resourcemanager.tasks.&lt;br /&gt;taskmanager-cmd&lt;/td&gt;
      &lt;td&gt;“$FLINK_HOME/bin/mesos-taskmanager.sh”&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;mesos.resourcemanager.tasks.uris&lt;/td&gt;
      &lt;td&gt;(none)&lt;/td&gt;
      &lt;td&gt;以逗号分隔的自定义工件URI列表，这些URI将下载到Mesos工作者的沙箱中.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;taskmanager.numberOfTaskSlots&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;单个TaskManager可以运行的并行算子或用户函数实例的数量.如果此值大于1，则单个TaskManager将获取函数或 算子的多个实例.这样，TaskManager可以使用多个CPU内核，但同时，可用内存在不同的算子或函数实例之间划分.此值通常与TaskManager的计算机具有的物理CPU核心数成比例（例如，等于核心数，或核心数的一半）.&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h2 id=&quot;高可用性ha&quot;&gt;高可用性（HA）&lt;/h2&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;键&lt;/th&gt;
      &lt;th&gt;默认&lt;/th&gt;
      &lt;th&gt;描述&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;high-availability&lt;/td&gt;
      &lt;td&gt;“NONE”&lt;/td&gt;
      &lt;td&gt;定义用于群集执行的高可用性模式.要启用高可用性，请将此模式设置为“ZOOKEEPER”.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;high-availability.cluster-id&lt;/td&gt;
      &lt;td&gt;“/default”&lt;/td&gt;
      &lt;td&gt;Flink集群的ID，用于将多个Flink集群彼此分开.需要为独立群集设置，但在YARN和Mesos中自动推断.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;high-availability.job.delay&lt;/td&gt;
      &lt;td&gt;(none)&lt;/td&gt;
      &lt;td&gt;故障转移后JobManager之前的时间恢复当前作业.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;high-availability.jobmanager.port&lt;/td&gt;
      &lt;td&gt;“0”&lt;/td&gt;
      &lt;td&gt;JobManager在高可用性模式下使用的可选端口（范围）.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;high-availability.storageDir&lt;/td&gt;
      &lt;td&gt;(none)&lt;/td&gt;
      &lt;td&gt;文件系统路径（URI）Flink在高可用性设置中持久保存元数据.&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h3 id=&quot;基于zookeeper的ha模式&quot;&gt;基于ZooKeeper的HA模式&lt;/h3&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;键&lt;/th&gt;
      &lt;th&gt;默认&lt;/th&gt;
      &lt;th&gt;描述&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;high-availability.zookeeper.client.acl&lt;/td&gt;
      &lt;td&gt;“open”&lt;/td&gt;
      &lt;td&gt;定义要在ZK节点上配置的ACL（open | creator）.如果ZooKeeper服务器配置将“authProvider”属性映射为使用SASLAuthenticationProvider并且群集配置为以安全模式（Kerberos）运行，则可以将配置值设置为“creator”.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;high-availability.zookeeper.client.&lt;br /&gt;connection-timeout&lt;/td&gt;
      &lt;td&gt;15000&lt;/td&gt;
      &lt;td&gt;定义ZooKeeper的连接超时（以ms为单位）.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;high-availability.zookeeper.client.max-retry-attempts&lt;/td&gt;
      &lt;td&gt;3&lt;/td&gt;
      &lt;td&gt;定义客户端放弃之前的连接重试次数.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;high-availability.zookeeper.client.retry-wait&lt;/td&gt;
      &lt;td&gt;5000&lt;/td&gt;
      &lt;td&gt;定义以ms为单位的连续重试之间的暂停.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;high-availability.zookeeper.client.session-timeout&lt;/td&gt;
      &lt;td&gt;60000&lt;/td&gt;
      &lt;td&gt;以ms为单位定义ZooKeeper会话的会话超时.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;high-availability.zookeeper.path.&lt;br /&gt;checkpoint-counter&lt;/td&gt;
      &lt;td&gt;“/checkpoint-counter”&lt;/td&gt;
      &lt;td&gt;ZooKeeper根路径（ZNode）用于检查点计数器.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;high-availability.zookeeper.path.&lt;br /&gt;checkpoints&lt;/td&gt;
      &lt;td&gt;“/checkpoints”&lt;/td&gt;
      &lt;td&gt;已完成检查点的ZooKeeper根路径（ZNode）.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;high-availability.zookeeper.path.jobgraphs&lt;/td&gt;
      &lt;td&gt;“/jobgraphs”&lt;/td&gt;
      &lt;td&gt;作业图的ZooKeeper根路径（ZNode）&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;high-availability.zookeeper.path.latch&lt;/td&gt;
      &lt;td&gt;“/leaderlatch”&lt;/td&gt;
      &lt;td&gt;定义用于选择Leader的Leader锁存器的znode.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;high-availability.zookeeper.path.leader&lt;/td&gt;
      &lt;td&gt;“/leader”&lt;/td&gt;
      &lt;td&gt;定义Leader的znode，其中包含Leader的URL和当前Leader会话ID.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;high-availability.zookeeper.path.&lt;br /&gt;mesos-workers&lt;/td&gt;
      &lt;td&gt;“/mesos-workers”&lt;/td&gt;
      &lt;td&gt;ZooKeeper根路径，用于保存Mesos工作者信息.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;high-availability.zookeeper.path.root&lt;/td&gt;
      &lt;td&gt;“/flink”&lt;/td&gt;
      &lt;td&gt;Flink在ZooKeeper中存储其条目的根路径.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;high-availability.zookeeper.path.&lt;br /&gt;running-registry&lt;/td&gt;
      &lt;td&gt;“/running_job_registry/”&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;high-availability.zookeeper.quorum&lt;/td&gt;
      &lt;td&gt;（none）&lt;/td&gt;
      &lt;td&gt;使用ZooKeeper在高可用性模式下运行Flink时要使用的ZooKeeper quorum.&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h2 id=&quot;zookeeper安全&quot;&gt;ZooKeeper安全&lt;/h2&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;键&lt;/th&gt;
      &lt;th&gt;默认&lt;/th&gt;
      &lt;th&gt;描述&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;zookeeper.sasl.disable&lt;/td&gt;
      &lt;td&gt;false&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;zookeeper.sasl.login-context-name&lt;/td&gt;
      &lt;td&gt;“Client”&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;zookeeper.sasl.service-name&lt;/td&gt;
      &lt;td&gt;“zookeeper”&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h2 id=&quot;基于kerberos的安全性&quot;&gt;基于Kerberos的安全性&lt;/h2&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;键&lt;/th&gt;
      &lt;th&gt;默认&lt;/th&gt;
      &lt;th&gt;描述&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;security.kerberos.login.contexts&lt;/td&gt;
      &lt;td&gt;(none)&lt;/td&gt;
      &lt;td&gt;以逗号分隔的登录上下文列表，用于提供Kerberos凭据（例如，&lt;code class=&quot;highlighter-rouge&quot;&gt;Client，KafkaClient&lt;/code&gt;使用凭证进行ZooKeeper身份验证和Kafka身份验证）&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;security.kerberos.login.keytab&lt;/td&gt;
      &lt;td&gt;(none)&lt;/td&gt;
      &lt;td&gt;包含用户凭据的KerberosKeys表文件的绝对路径.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;security.kerberos.login.principal&lt;/td&gt;
      &lt;td&gt;(none)&lt;/td&gt;
      &lt;td&gt;与keytab关联的Kerberos主体名称.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;security.kerberos.login.use-ticket-cache&lt;/td&gt;
      &lt;td&gt;true&lt;/td&gt;
      &lt;td&gt;指示是否从Kerberos票证缓存中读取.&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h2 id=&quot;环境&quot;&gt;环境&lt;/h2&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;键&lt;/th&gt;
      &lt;th&gt;默认&lt;/th&gt;
      &lt;th&gt;描述&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;env.hadoop.conf.dir&lt;/td&gt;
      &lt;td&gt;(none)&lt;/td&gt;
      &lt;td&gt;hadoop配置目录的路径.需要读取HDFS和/或YARN配置.您也可以通过环境变量进行设置.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;env.java.opts&lt;/td&gt;
      &lt;td&gt;(none)&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;env.java.opts.jobmanager&lt;/td&gt;
      &lt;td&gt;(none)&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;env.java.opts.taskmanager&lt;/td&gt;
      &lt;td&gt;(none)&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;env.log.dir&lt;/td&gt;
      &lt;td&gt;(none)&lt;/td&gt;
      &lt;td&gt;定义保存Flink日志的目录.它必须是一条绝对的道路.（默认为Flink主页下的日志目录）&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;env.log.max&lt;/td&gt;
      &lt;td&gt;5&lt;/td&gt;
      &lt;td&gt;要保存的最大旧日志文件数.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;env.ssh.opts&lt;/td&gt;
      &lt;td&gt;(none)&lt;/td&gt;
      &lt;td&gt;启动或停止JobManager，TaskManager和Zookeeper服务时，其他命令行选项传递给SSH客户端（start-cluster.sh，stop-cluster.sh，start-zookeeper-quorum.sh，stop-zookeeper-quorum.sh）.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;env.yarn.conf.dir&lt;/td&gt;
      &lt;td&gt;(none)&lt;/td&gt;
      &lt;td&gt;YARN配置目录的路径.它需要在YARN上运行flink.您也可以通过环境变量进行设置.&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h2 id=&quot;检查点&quot;&gt;检查点&lt;/h2&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;键&lt;/th&gt;
      &lt;th&gt;默认&lt;/th&gt;
      &lt;th&gt;描述&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;state.backend&lt;/td&gt;
      &lt;td&gt;(none)&lt;/td&gt;
      &lt;td&gt;状态后台用于存储和检查点状态.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;state.backend.async&lt;/td&gt;
      &lt;td&gt;true&lt;/td&gt;
      &lt;td&gt;选择状态后台是否应在可能和可配置的情况下使用异步SNAPSHOT方法.某些状态后台可能不支持异步SNAPSHOT，或者仅支持异步SNAPSHOT，并忽略此选项.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;state.backend.fs.memory-threshold&lt;/td&gt;
      &lt;td&gt;1024&lt;/td&gt;
      &lt;td&gt;状态数据文件的最小大小.小于该值的所有状态块都内联存储在根检查点元数据文件中.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;state.backend.incremental&lt;/td&gt;
      &lt;td&gt;false&lt;/td&gt;
      &lt;td&gt;如果可能，选择状态后台是否应创建增量检查点.对于增量检查点，仅存储来自先前检查点的差异，而不是完整的检查点状态.某些状态后台可能不支持增量检查点并忽略此选项.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;state.backend.local-recovery&lt;/td&gt;
      &lt;td&gt;false&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;state.checkpoints.dir&lt;/td&gt;
      &lt;td&gt;(none)&lt;/td&gt;
      &lt;td&gt;用于在Flink支持的文件系统中存储检查点的数据文件和元数据的默认目录.必须可以从所有参与的进程/节点（即所有TaskManagers和JobManagers）访问存储路径.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;state.checkpoints.num-retained&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;要保存的已完成检查点的最大数量.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;state.savepoints.dir&lt;/td&gt;
      &lt;td&gt;(none)&lt;/td&gt;
      &lt;td&gt;保存点的默认目录.由将后台写入文件系统的状态后台（MemoryStateBackend，FsStateBackend，RocksDBStateBackend）使用.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;taskmanager.state.local.root-dirs&lt;/td&gt;
      &lt;td&gt;(none)&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h2 id=&quot;可查询状态&quot;&gt;可查询状态&lt;/h2&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;键&lt;/th&gt;
      &lt;th&gt;默认&lt;/th&gt;
      &lt;th&gt;描述&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;query.client.network-threads&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;网络数（Netty的事件循环）可查询状态客户端的线程.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;query.proxy.network-threads&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;网络数（Netty的事件循环）可查询状态代理的线程.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;query.proxy.ports&lt;/td&gt;
      &lt;td&gt;“9069”&lt;/td&gt;
      &lt;td&gt;可查询状态代理的端口范围.指定范围可以是单个端口：“9123”，一系列端口：“50100-50200”，或范围和端口列表：“50100-50200,50300-50400,51234”.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;query.proxy.query-threads&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;可查询状态代理的查询线程数.如果设置为0，则使用插槽数.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;query.server.network-threads&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;网络数（Netty的事件循环）可查询状态服务器的线程.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;query.server.ports&lt;/td&gt;
      &lt;td&gt;“9067”&lt;/td&gt;
      &lt;td&gt;可查询状态服务器的端口范围.指定范围可以是单个端口：“9123”，一系列端口：“50100-50200”，或范围和端口列表：“50100-50200,50300-50400,51234”.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;query.server.query-threads&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;可查询状态服务器的查询线程数.如果设置为0，则使用插槽数.&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h2 id=&quot;度量&quot;&gt;度量&lt;/h2&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;键&lt;/th&gt;
      &lt;th&gt;默认&lt;/th&gt;
      &lt;th&gt;描述&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;metrics.latency.granularity&lt;/td&gt;
      &lt;td&gt;“operator”&lt;/td&gt;
      &lt;td&gt;定义延迟指标的粒度.可接受的值是：单一 - 跟踪延迟，无需区分源和子任务.operator - 跟踪延迟，同时区分源，但不区分子任务.子任务 - 在区分源和子任务时跟踪延迟.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;metrics.latency.history-size&lt;/td&gt;
      &lt;td&gt;128&lt;/td&gt;
      &lt;td&gt;定义每个算子维护的测量延迟数.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;metrics.latency.interval&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;定义从源发出延迟跟踪标记的间隔.如果设置为0或负值，则禁用延迟跟踪.启用此函数会显着影响群集的性能.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;metrics.reporter.&lt;name&gt; .&lt;parameter&gt;&lt;/parameter&gt;&lt;/name&gt;&lt;/td&gt;
      &lt;td&gt;(none)&lt;/td&gt;
      &lt;td&gt;为名为&lt;name&gt;的报告器配置参数&lt;parameter&gt;.&lt;/parameter&gt;&lt;/name&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;metrics.reporter.&lt;name&gt;.class&lt;/name&gt;&lt;/td&gt;
      &lt;td&gt;(none)&lt;/td&gt;
      &lt;td&gt;报告类用于为报告命名&lt;name&gt;.&lt;/name&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;metrics.reporter.&lt;name&gt;.interval&lt;/name&gt;&lt;/td&gt;
      &lt;td&gt;(none)&lt;/td&gt;
      &lt;td&gt;报告间隔用于报告名为&lt;name&gt;.&lt;/name&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;metrics.reporters&lt;/td&gt;
      &lt;td&gt;(none)&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;metrics.scope.delimiter&lt;/td&gt;
      &lt;td&gt;“”&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;metrics.scope.jm&lt;/td&gt;
      &lt;td&gt;“&lt;host&gt; .jobmanager”&lt;/host&gt;&lt;/td&gt;
      &lt;td&gt;定义应用于作用于JobManager的所有度量标准的范围格式字符串.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;metrics.scope.jm.job&lt;/td&gt;
      &lt;td&gt;“&lt;host&gt; .jobmanager.&lt;job_name&gt;”&lt;/job_name&gt;&lt;/host&gt;&lt;/td&gt;
      &lt;td&gt;定义范围格式字符串，该字符串应用于作用于JobManager上作业的所有度量标准.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;metrics.scope.operator&lt;/td&gt;
      &lt;td&gt;“&lt;host&gt; .taskmanager.&lt;tm_id&gt; &lt;job_name&gt; &lt;operator_name&gt; &lt;subtask_index&gt;”&lt;/subtask_index&gt;&lt;/operator_name&gt;&lt;/job_name&gt;&lt;/tm_id&gt;&lt;/host&gt;&lt;/td&gt;
      &lt;td&gt;定义应用于作用于 算子的所有度量标准的范围格式字符串.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;metrics.scope.task&lt;/td&gt;
      &lt;td&gt;“&lt;host&gt; .taskmanager.&lt;tm_id&gt; &lt;job_name&gt; &lt;task_name&gt; &lt;subtask_index&gt;”&lt;/subtask_index&gt;&lt;/task_name&gt;&lt;/job_name&gt;&lt;/tm_id&gt;&lt;/host&gt;&lt;/td&gt;
      &lt;td&gt;定义应用于作用于任务的所有度量标准的范围格式字符串.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;metrics.scope.tm&lt;/td&gt;
      &lt;td&gt;“&lt;host&gt; .taskmanager.&lt;tm_id&gt;”&lt;/tm_id&gt;&lt;/host&gt;&lt;/td&gt;
      &lt;td&gt;定义应用于作用于TaskManager的所有度量标准的范围格式字符串.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;metrics.scope.tm.job&lt;/td&gt;
      &lt;td&gt;“&lt;host&gt; .taskmanager.&lt;tm_id&gt; &lt;job_name&gt;”&lt;/job_name&gt;&lt;/tm_id&gt;&lt;/host&gt;&lt;/td&gt;
      &lt;td&gt;定义范围格式字符串，该字符串应用于作用于TaskManager上作业的所有度量标准.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;metrics.system-resource&lt;/td&gt;
      &lt;td&gt;false&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;metrics.system-resource-probing-interval&lt;/td&gt;
      &lt;td&gt;5000&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h2 id=&quot;历史服务器&quot;&gt;历史服务器&lt;/h2&gt;

&lt;p&gt;如果要通过HistoryServer的Web前端显示它们，则必须进行配置&lt;code class=&quot;highlighter-rouge&quot;&gt;jobmanager.archive.fs.dir&lt;/code&gt;以存档已终止的作业并将其添加到受监视目录列表中&lt;code class=&quot;highlighter-rouge&quot;&gt;historyserver.archive.fs.dir&lt;/code&gt;.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;jobmanager.archive.fs.dir&lt;/code&gt;：将有关已终止作业的信息上载到的目录.您必须将此目录添加到历史服务器的受监视目录列表中&lt;code class=&quot;highlighter-rouge&quot;&gt;historyserver.archive.fs.dir&lt;/code&gt;.&lt;/li&gt;
&lt;/ul&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;键&lt;/th&gt;
      &lt;th&gt;默认&lt;/th&gt;
      &lt;th&gt;描述&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;historyserver.archive.fs.dir&lt;/td&gt;
      &lt;td&gt;(none)&lt;/td&gt;
      &lt;td&gt;以逗号分隔的目录列表，用于从中获取已归档的作业.历史服务器将监视这些目录以获取已存档的作业.您可以将JobManager配置为通过&lt;code class=&quot;highlighter-rouge&quot;&gt;jobmanager.archive.fs.dir&lt;/code&gt;将作业存档到目录.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;historyserver.archive.fs.refresh-interval&lt;/td&gt;
      &lt;td&gt;10000&lt;/td&gt;
      &lt;td&gt;刷新已归档作业目录的时间间隔（以ms为单位）.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;historyserver.web.address&lt;/td&gt;
      &lt;td&gt;(none)&lt;/td&gt;
      &lt;td&gt;HistoryServer的Web界面的地址.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;historyserver.web.port&lt;/td&gt;
      &lt;td&gt;8082&lt;/td&gt;
      &lt;td&gt;HistoryServers的Web界面的端口.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;historyserver.web.refresh-interval&lt;/td&gt;
      &lt;td&gt;10000&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;historyserver.web.ssl.enabled&lt;/td&gt;
      &lt;td&gt;false&lt;/td&gt;
      &lt;td&gt;启用对HistoryServer Web前端的HTTP访问.仅当全局SSL标志security.ssl.enabled设置为true时，此选项才适用.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;historyserver.web.tmpdir&lt;/td&gt;
      &lt;td&gt;(none)&lt;/td&gt;
      &lt;td&gt;此配置参数允许定义历史服务器Web界面使用的Flink Web目录.Web界面将其静态文件复制到目录中.&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h1 id=&quot;留存&quot;&gt;留存&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;mode&lt;/code&gt;：Flink的执行模式.可能的值是&lt;code class=&quot;highlighter-rouge&quot;&gt;legacy&lt;/code&gt;和&lt;code class=&quot;highlighter-rouge&quot;&gt;new&lt;/code&gt;.要启动旧组件，您必须指定&lt;code class=&quot;highlighter-rouge&quot;&gt;legacy&lt;/code&gt;（DEFAULT：）&lt;code class=&quot;highlighter-rouge&quot;&gt;new&lt;/code&gt;。&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;背景&quot;&gt;背景&lt;/h1&gt;
&lt;h2 id=&quot;配置网络缓冲区&quot;&gt;配置网络缓冲区&lt;/h2&gt;
&lt;p&gt;如果您看到异常&lt;code class=&quot;highlighter-rouge&quot;&gt;java.io.IOException: Insufficient number of network buffers&lt;/code&gt;，则需要调整用于网络缓冲区的内存量，以便程序在您的TaskManager上运行。&lt;br /&gt;
网络缓冲区是通信层的关键资源.它们用于在通过网络传输之前缓冲记录，并在将传入数据解析为记录并将其传递给应用程序之前缓冲传入数据.足够数量的网络缓冲区对于实现良好的吞吐量至关重要。&lt;br /&gt;
从Flink 1.3开始，你可以遵循“越多越好”的成语而不会对延迟造成任何惩罚（我们通过限制每个通道使用的实际缓冲区数量来防止每个传出和传入通道中的过度缓冲，即&lt;em&gt;缓冲膨胀&lt;/em&gt;） 。&lt;br /&gt;
通常，将TaskManager配置为具有足够的缓冲区，以使您希望同时打开的每个逻辑网络连接都具有专用缓冲区。对于网络上的每个点对点数据交换存在逻辑网络连接，这通常发生在重新分区或广播步骤（混洗阶段）。在那些中，TaskManager中的每个并行任务必须能够与所有其他并行任务进行通信。&lt;br /&gt;
&lt;strong&gt;注意：&lt;/strong&gt;从Flink 1.5开始，网络缓冲区将始终在堆外分配，即在JVM堆之外，而不管其值是多少&lt;code class=&quot;highlighter-rouge&quot;&gt;taskmanager.memory.off-heap&lt;/code&gt;。这样，我们可以将这些缓冲区直接传递给底层网络堆栈层。&lt;/p&gt;

&lt;h3 id=&quot;设置内存分数&quot;&gt;设置内存分数&lt;/h3&gt;
&lt;p&gt;以前，手动设置网络缓冲区的数量，这成为一个非常容易出错的任务（见下文）。从Flink 1.3开始，可以使用以下配置参数定义用于网络缓冲区的一小部分内存：&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;taskmanager.network.memory.fraction&lt;/code&gt;：用于网络缓冲区的JVM内存的分数（DEFAULT：0.1），&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;taskmanager.network.memory.min&lt;/code&gt;：网络缓冲区的最小内存大小（默认值：64MB），&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;taskmanager.network.memory.max&lt;/code&gt;：网络缓冲区的最大内存大小（默认值：1GB），&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;taskmanager.memory.segment-size&lt;/code&gt;：内存管理器和网络堆栈使用的内存缓冲区大小（以字节为单位）（默认值：32KB）。&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;直接设置网络缓冲区的数量&quot;&gt;直接设置网络缓冲区的数量&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;注意：不建议使用&lt;/strong&gt;这种配置网络缓冲区使用的内存量的方法。请考虑使用上述方法定义要使用的内存部分。&lt;br /&gt;
缓冲器的上一个TaskManager所要求数量为 &lt;em&gt;总度的平行度&lt;/em&gt;（数的目标）* &lt;em&gt;节点内并行性&lt;/em&gt;（源在一个TaskManager数）× &lt;em&gt;N&lt;/em&gt; 与 &lt;em&gt;N&lt;/em&gt; 是限定多少repartitioning-恒定/您希望同时处于活动状态的广播步骤。由于&lt;em&gt;节点内并行&lt;/em&gt;性通常是核心数量，并且超过4个重新分区或广播频道很少并行活动，因此它经常归结为&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;#slots-per-TM^2 * #TMs * 4
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;哪里&lt;code class=&quot;highlighter-rouge&quot;&gt;#slots per TM&lt;/code&gt;是&lt;a href=&quot;https://flink.lantingmeeting.com/ops/config.html#configuring-taskmanager-processing-slots&quot;&gt;每个TaskManager插槽数量&lt;/a&gt;和&lt;code class=&quot;highlighter-rouge&quot;&gt;#TMs&lt;/code&gt;是TaskManager的总数。&lt;br /&gt;
例如，为了支持20个8插槽机器的集群，您应该使用大约5000个网络缓冲区来获得最佳吞吐量。&lt;br /&gt;
默认情况下，每个网络缓冲区的大小为32 KiBytes.在上面的示例中，系统因此将为网络缓冲区分配大约300 MiBytes。&lt;br /&gt;
可以使用以下参数配置网络缓冲区的数量和大小：&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;taskmanager.network.numberOfBuffers&lt;/code&gt;，&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;taskmanager.memory.segment-size&lt;/code&gt;。&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;配置临时i--o目录&quot;&gt;配置临时I / O目录&lt;/h2&gt;
&lt;p&gt;虽然Flink的目标是尽可能多地处理主内存中的数据，但是需要处理的内存比内存更多的数据并不少见。Flink的运行时用于将临时数据写入磁盘以处理这些情况。&lt;br /&gt;
该&lt;code class=&quot;highlighter-rouge&quot;&gt;taskmanager.tmp.dirs&lt;/code&gt;参数指定Flink写入临时文件的目录列表.目录的路径需要用’：’（冒号字符）分隔.Flink将同时向（从）每个配置的目录写入（或读取）一个临时文件.这样，临时I / O可以均匀地分布在多个独立的I / O设备（如硬盘）上，以提高性能.要利用快速I / O设备（例如，SSD，RAID，NAS），可以多次指定目录。&lt;br /&gt;
如果&lt;code class=&quot;highlighter-rouge&quot;&gt;taskmanager.tmp.dirs&lt;/code&gt;未显式指定参数，Flink会将临时数据写入 算子操作系统的临时目录，例如Linux系统中的&lt;em&gt;/ tmp&lt;/em&gt;。&lt;/p&gt;

&lt;h2 id=&quot;配置taskmanager处理槽&quot;&gt;配置TaskManager处理槽&lt;/h2&gt;
&lt;p&gt;Flink通过将程序拆分为子任务并将这些子任务调度到处理槽来并行执行程序。&lt;br /&gt;
每个Flink TaskManager都在集群中提供处理插槽.插槽数通常与&lt;strong&gt;每个&lt;/strong&gt; TaskManager 的可用CPU核心数成比例.作为一般建议，可用的CPU核心数量是一个很好的默认值&lt;code class=&quot;highlighter-rouge&quot;&gt;taskmanager.numberOfTaskSlots&lt;/code&gt;。&lt;br /&gt;
启动Flink应用程序时，用户可以提供用于该作业的默认插槽数.因此调用命令行值&lt;code class=&quot;highlighter-rouge&quot;&gt;-p&lt;/code&gt;（用于并行）.此外，可以为整个应用程序和各个算子&lt;a href=&quot;https://flink.lantingmeeting.com/dev/parallel.html&quot;&gt;设置编程API中的插槽数&lt;/a&gt;。&lt;br /&gt;
&lt;img src=&quot;https://github.com/leafming/bak/blob/master/images/flink/2018-10-17-flink配置-slots_parallelism.png?raw=true&quot; alt=&quot;2018-10-17-flink配置-slots_parallelism&quot; /&gt;&lt;/p&gt;</content><author><name>叶子  ( ˘ ³˘)♥</name></author><category term="Flink" /><summary type="html">本文所用flink版本为V1.7-SNAPSHOT，官网翻译转载，转载地址：配置-https://flink.lantingmeeting.com/ops/config.html#legacy，官方文档原文Configuration。 对于单节点设置，Flink已准备好开箱即用，您无需更改默认配置即可开始使用。 开箱即用的配置将使用您的默认Java安装.您可以手动设置环境变量JAVA_HOME或配置项env.java.home中conf/flink-conf.yaml，如果你想手动覆盖Java运行时使用。 此页面列出了设置性能良好（分布式）安装通常所需的最常用选项。此外，此处还列出了所有可用配置参数的完整列表。 所有配置都已完成conf/flink-conf.yaml，预计将是具有格式的YAML键值对的扁平集合key: value。 系统和运行脚本在启动时解析配置。对配置文件的更改需要重新启动Flink JobManager和TaskManagers。 TaskManagers的配置文件可能不同，Flink不承担集群中的统一机器。 常见选项 键 默认 描述 jobmanager.heap.size “1024m” JobManager的JVM堆大小. taskmanager.heap.size “1024m” TaskManagers的JVM堆大小，它是系统的并行工作者.在YARN设置中，此值自动配置为TaskManager的YARN容器的大小，减去一定的容差值. parallelism.default 1   taskmanager.numberOfTaskSlots 1 单个TaskManager可以运行的并行算子或用户函数实例的数量.如果此值大于1，则单个TaskManager将获取函数或 算子的多个实例.这样，TaskManager可以使用多个CPU内核，但同时，可用内存在不同的算子或函数实例之间划分.此值通常与TaskManager的计算机具有的物理CPU核心数成比例（例如，等于核心数，或核心数的一半）. state.backend (none) 状态后台用于存储和检查点状态. state.checkpoints.dir (none) 用于在Flink支持的文件系统中存储检查点的数据文件和元数据的默认目录.必须可以从所有参与的进程/节点（即所有TaskManagers和JobManagers）访问存储路径. state.savepoints.dir (none) 保存点的默认目录.由将后台写入文件系统的状态后台（MemoryStateBackend，FsStateBackend，RocksDBStateBackend）使用. high-availability “no / not” 定义用于群集执行的高可用性模式.要启用高可用性，请将此模式设置为“ZOOKEEPER”. high-availability.storageDir (none) 文件系统路径（URI）Flink在高可用性设置中持久保存元数据. security.ssl.internal.enabled false 打开SSL以进行内部网络通信.可选地，特定组件可以通过它们自己的设置（rpc，数据传输，REST等）覆盖它. security.ssl.rest.enabled false 通过REST端点打开SSL以进行外部通信. 完整参考 HDFS 注意:不推荐使用这些Keys，建议使用环境变量配置Hadoop路径HADOOP_CONF_DIR。 这些参数配置Flink使用的默认HDFS。未指定HDFS配置的设置必须指定HDFS文件的完整路径（hdfs://address:port/path/to/files）文件也将使用默认HDFS参数（块大小，复制因子）编写。 fs.hdfs.hadoopconf：Hadoop文件系统（HDFS）配置目录的绝对路径（可选值）。指定此值允许程序使用短URI引用HDFS文件（hdfs:///path/to/files不包括文件URI中NameNode的地址和端口）。如果没有此选项，则可以访问HDFS文件，但需要完全限定的URI hdfs://address:port/path/to/files。此选项还会导致文件编写者获取HDFS的块大小和复制因子的默认值。Flink将在指定目录中查找“core-site.xml”和“hdfs-site.xml”文件。 fs.hdfs.hdfsdefault：Hadoop自己的配置文件“hdfs-default.xml”的绝对路径（DEFAULT：null）。 fs.hdfs.hdfssite：Hadoop自己的配置文件“hdfs-site.xml”的绝对路径（DEFAULT：null）。 核心 键 默认 描述 classloader.parent-first-patterns.additional (none) 一个（以分号分隔的）模式列表，指定应始终首先通过父ClassLoader解析哪些类.模式是一个简单的前缀，它根据完全限定的类名进行检查.这些模式附加到“classloader.parent-first-patterns.default”. classloader.parent-first-patterns.default “java .; scala .; org.apache.flink .; com.esotericsoftware.kryo; org.apache.hadoop .; javax.annotation .; org.slf4j; org.apache.log4j; org.apache.logging; org. apache.commons.logging; ch.qos.logback“ 一个（以分号分隔的）模式列表，指定应始终首先通过父ClassLoader解析哪些类.模式是一个简单的前缀，它根据完全限定的类名进行检查.通常不应修改此设置.要添加其他模式，我们建议使用“classloader.parent-first-patterns.additional”. classloader.resolve-order “child-first” 从用户代码加载类时定义类解析策略，这意味着是首先检查用户代码jar（“child-first”）还是应用程序类路径（“parent-first”）.默认设置指示首先从用户代码jar加载类，这意味着用户代码jar可以包含和加载不同于Flink使用的（依赖）依赖项. io.tmp.dirs YARN上的’LOCAL_DIRS’.Mesos上的’_FLINK_TMP_DIR’.独立的System.getProperty（“java.io.tmpdir”）.   mode “new” 切换到选择执行模式.可能的值为“new”和“legacy”. parallelism.default 1   JobManager 键 默认 描述 jobmanager.archive.fs.dir (none)   jobmanager.execution.attempts-history-size 16 历史记录中保存的最大执行尝试次数. jobmanager.execution.failover-strategy “full” 此选项指定作业计算如何从任务失败中恢复.可接受的值是：’full’：重新启动所有任务.’individual’：仅重新启动失败的任务.仅当所有任务都是独立组件时才应使用.’region’：重新启动可能受任务失败影响的所有任务. jobmanager.heap.size “1024m” JobManager的JVM堆大小. jobmanager.resourcemanager.reconnect-interval 2000 此选项指定在与资源管理器的连接丢失时触发资源管理器重新连接的时间间隔.此选项仅供内部使用. jobmanager.rpc.address (none) config参数定义要连接的网络地址以与JobManager进行通信.此值仅在具有静态名称或地址的单个JobManager存在的设置中解释（简单的独立设置或具有动态服务名称解析的容器设置）.当使用Leader选举服务（如ZooKeeper）从潜在的多个Slave JobManagers中选择和发现JobManagerLeader时，它不会在许多高可用性设置中使用. jobmanager.rpc.port 6123 config参数定义要连接的网络端口以与JobManager进行通信.与jobmanager.rpc.address一样，此值仅在设置中解释，其中存在具有静态名称/地址和端口的单个JobManager（简单的独立设置或具有动态服务名称解析的容器设置）.当使用Leader选举服务（如ZooKeeper）从潜在的多个Slave JobManagers中选择和发现JobManagerLeader时，此配置选项不会用于许多高可用性设置. jobstore.cache-size 52428800 作业存储缓存大小（以字节为单位），用于将已完成的作业保存在内存中. jobstore.expiration-time 3600 完成作业到期并从作业库中清除的时间（以秒为单位）. slot.idle.timeout 50000 Slot Pool中空闲槽的超时时间（以ms为单位）. slot.request.timeout 300000 从Slot Pool请求插槽的超时（以ms为单位）. TaskManager 键 默认 描述 task.cancellation.interval 30000 两次连续任务取消尝试之间的时间间隔（以ms为单位）. task.cancellation.timeout 180000 超时（以ms为单位），在此之后任务取消超时并导致致命的TaskManager错误.值为0将禁用看门狗. task.cancellation.timers.timeout 7500   task.checkpoint.alignment.max-size -1 检查点对齐可以缓冲的最大字节数.如果检查点对齐缓冲超过配置的数据量，则中止检查点（跳过）.值-1表示没有限制. taskmanager.data.port 0 TaskManager的端口用于数据交换 算子操作. taskmanager.data.ssl.enabled true 为taskmanager数据传输启用SSL支持.仅当内部SSL的全局标志（security.ssl.internal.enabled）设置为true时，此选项才适用 taskmanager.debug.memory.log false 指示是否启动线程的标志，该线程重复记录JVM的内存使用情况. taskmanager.debug.memory.log-interval 5000 日志线程记录当前内存使用情况的时间间隔（以ms为单位）. taskmanager.exit-on-fatal-akka-error false 是否应启动TaskManager的隔离监视器.如果隔离监视器检测到它已隔离另一个actor系统或者它已被另一个actor系统隔离，则会关闭该actor系统. taskmanager.heap.size “1024m” TaskManagers的JVM堆大小，它是系统的并行工作者.在YARN设置中，此值自动配置为TaskManager的YARN容器的大小，减去一定的容差值. taskmanager.host (none) TaskManager绑定到的网络接口的主机名.默认情况下，TaskManager搜索可以连接到JobManager和其他TaskManagers的网络接口.如果该策略由于某种原因失败，则此选项可用于定义主机名.由于不同的TaskManagers需要此选项的不同值，因此通常在其他非共享的特定于TaskManager的配置文件中指定. taskmanager.jvm-exit-on-oom false 是否在任务线程抛出OutOfMemoryError时终止TaskManager. taskmanager.memory.fraction 0.7 TaskManager为排序，哈希表和中间结果的缓存预留的相对内存量（在减去网络缓冲区使用的内存量之后）.例如，值“0.8”表示TaskManager为内部数据缓冲区保存80％的内存，为TaskManager的堆留下20％的可用内存，用于由用户定义的函数创建的对象.仅当未设置taskmanager.memory.size时，才会评估此参数. taskmanager.memory.off-heap false 内存分配方法（JVM堆或堆外），用于TaskManager的托管内存以及网络缓冲区. taskmanager.memory.preallocate false 在TaskManager启动时是否应预先分配TaskManager托管内存. taskmanager.memory.segment-size “32KB” 网络堆栈和内存管理器使用的内存缓冲区的大小. taskmanager.memory.size “0” TaskManager的内存管理器分配的内存量.如果未设置，将分配相对分数. taskmanager.network.detailed-metrics false 布尔标志，用于启用/禁用有关入站/出站网络队列长度的更详细指标. taskmanager.network.memory.buffers-per-channel 2 每个传出/传入通道（子分区/输入通道）使用的最大网络缓冲区数.在基于信用的流量控制模式下，这表示每个输入通道中有多少信用.它应配置至少2以获得良好的性能.1个缓冲区用于接收子分区中的飞行中数据，1个缓冲区用于并行序列化. taskmanager.network.memory.floating-buffers-per-gate 8 每个输出/输入门（结果分区/输入门）使用的额外网络缓冲区数.在基于信用的流量控制模式中，这表示在所有输入通道之间共享多少浮动信用.浮动缓冲区基于积压（子分区中的实时输出缓冲区）反馈来分布，并且可以帮助减轻由子分区之间的不平衡数据分布引起的背压.如果节点之间的往返时间较长和/或群集中的机器数量较多，则应增加此值. taskmanager.network.memory.fraction 0.1 用于网络缓冲区的JVM内存的分数.这决定了TaskManager可以同时拥有多少流数据交换通道以及通道缓冲的程度.如果作业被拒绝或者您收到系统没有足够缓冲区的警告，请增加此值或下面的最小/最大值.另请注意，“taskmanager.network.memory.min”和“taskmanager.network.memory.max”可能会覆盖此分数. taskmanager.network.memory.max “1GB” 网络缓冲区的最大内存大小. taskmanager.network.memory.min “64MB” 网络缓冲区的最小内存大小. taskmanager.network.request-backoff.initial 100 输入通道的分区请求的最小退避. taskmanager.network.request-backoff.max 10000 输入通道的分区请求的最大退避. taskmanager.numberOfTaskSlots 1 单个TaskManager可以运行的并行算子或用户函数实例的数量.如果此值大于1，则单个TaskManager将获取函数或 算子的多个实例.这样，TaskManager可以使用多个CPU内核，但同时，可用内存在不同的算子或函数实例之间划分.此值通常与TaskManager的计算机具有的物理CPU核心数成比例（例如，等于核心数，或核心数的一半）. taskmanager.registration.initial-backoff “500ms” 两次连续注册尝试之间的初始注册退避.每次新注册尝试的退避加倍，直到达到最大注册退避. taskmanager.registration.max-backoff “30s” 两次连续注册尝试之间的最大注册退避.最大注册退避需要时间单位指定符（ms / s / min / h / d）. taskmanager.registration.refused-backoff “10s” 注册后的退避已被作业管理员拒绝，然后重试连接. taskmanager.registration.timeout “5m” 定义TaskManager注册的超时.如果在未成功注册的情况下超过持续时间，则TaskManager将终止. taskmanager.rpc.port “0” TaskManager的IPC端口.接受端口列表（“50100,50101”），范围（“50100-50200”）或两者的组合.建议在同一台计算机上运行多个TaskManagers时设置一系列端口以避免冲突. 分布式协调（通过Akka） 键 默认 描述 akka.ask.timeout “10s” 超时用于所有期货并阻止Akka通话.如果Flink由于超时而失败，那么您应该尝试增加此值.超时可能是由于机器速度慢或网络拥挤造成的.超时值需要时间单位指定符（ms / s / min / h / d）. akka.client-socket-worker-pool.pool-size-factor 1.0 池大小因子用于使用以下公式确定线程池大小：ceil（可用处理器*因子）.然后，结果大小由pool-size-min和pool-size-max值限制. akka.client-socket-worker-pool.pool-size-max 2 将基于因子的数量限制为的最大线程数. akka.client-socket-worker-pool.pool-size-min 1 将基于因子的数量限制为的最小线程数. akka.client.timeout “60s” 客户端的所有阻塞调用超时. akka.fork-join-executor.parallelism-factor 2.0 并行因子用于使用以下公式确定线程池大小：ceil（可用处理器*因子）.然后，得到的大小受parallelism-min和parallelism-max值的限制. akka.fork-join-executor.parallelism-max 64 将基于因子的并行数量限制为的最大线程数. akka.fork-join-executor.parallelism-min 8 将基于因子的并行数量限制为的最小线程数. akka.framesize “10485760b” 在JobManager和TaskManager之间发送的消息的最大大小.如果Flink由于消息超出此限制而失败，那么您应该增加它.邮件大小需要大小单位说明符. akka.jvm-exit-on-fatal-error true 退出JVM致命的Akka错误. akka.log.lifecycle.events false 打开Akka远程记录事件.在调试时将此值设置为“true”. akka.lookup.timeout “10s” 用于查找JobManager的超时.超时值必须包含时间单位说明符（ms / s / min / h / d）. akka.retry-gate-closed-for 50 断开远程连接后，应关闭门的ms数. akka.server-socket-worker-pool.pool-size-factor 1.0 池大小因子用于使用以下公式确定线程池大小：ceil（可用处理器*因子）.然后，结果大小由pool-size-min和pool-size-max值限制. akka.server-socket-worker-pool.pool-size-max 2 将基于因子的数量限制为的最大线程数. akka.server-socket-worker-pool.pool-size-min 1 将基于因子的数量限制为的最小线程数. akka.ssl.enabled true 为Akka的远程通信打开SSL.仅当全局ssl标志security.ssl.enabled设置为true时，这才适用. akka.startup-timeout (none) 超时之后，远程组件的启动被视为失败. akka.tcp.timeout “20s” 所有出站连接超时.如果由于网络速度较慢而导致连接到TaskManager时遇到问题，则应增加此值. akka.throughput 15 在将线程返回到池之前批处理的消息数.较低的值表示公平的调度，而较高的值可以以不公平为代价来提高性能. akka.transport.heartbeat.interval “1000s” Akka传输故障检测器的心跳间隔.由于Flink使用TCP，因此不需要检测器.因此，通过将间隔设置为非常高的值来禁用检测器.如果您需要传输故障检测器，请将间隔设置为某个合理的值.间隔值需要时间单位指定符（ms / s / min / h / d）. akka.transport.heartbeat.pause “6000s” Akka的传输故障检测器可接受的心跳暂停.由于Flink使用TCP，因此不需要检测器.因此，通过将暂停设置为非常高的值来禁用检测器.如果您需要传输故障检测器，请将暂停设置为某个合理的值.暂停值需要时间单位指定符（ms / s / min / h / d）. akka.transport.threshold 300.0 传输故障检测器的阈值.由于Flink使用TCP，因此检测器不是必需的，因此阈值被设置为高值. akka.watch.heartbeat.interval “10s” Akka的DeathWatch机制检测死亡TaskManagers的心跳间隔.如果由于心跳消息丢失或延迟而导致TaskManagers被错误地标记为死亡，那么您应该减小此值或增加akka.watch.heartbeat.pause.可在此处找到Akka的DeathWatch的详尽描述 akka.watch.heartbeat.pause “60s” Akka的DeathWatch机制可接受的心跳暂停.较低的值不允许心律不齐.如果由于心跳消息丢失或延迟而导致TaskManagers被错误地标记为死亡，那么您应该增加此值或Reduceakka.watch.heartbeat.interval.较高的值会增加检测死的TaskManager的时间.可在此处找到Akka的DeathWatch的详尽描述 akka.watch.threshold 12 DeathWatch故障检测器的阈值.较低的值容易出现误报，而较高的值会增加检测死的TaskManager的时间.可在此处找到Akka的DeathWatch的详尽描述 REST 键 默认 描述 rest.address (none) 客户端应该用于连接到服务器的地址. rest.await-leader-timeout 30000 客户端等待Leader地址的时间（以ms为单位），例如Dispatcher或WebMonitorEndpoint rest.bind-address (none) 服务器绑定自身的地址. rest.client.max-content-length 104857600 客户端将处理的最大内容长度（以字节为单位）. rest.connection-timeout 15000 客户端建立TCP连接的最长时间（以ms为单位）. rest.port 8081 服务器侦听的端口/客户端连接到的端口. rest.retry.delay 3000 客户端在重试之间等待的时间（以ms为单位）（另请参阅“rest.retry.max-attempts”）. rest.retry.max-attempts 20 如果可重试 算子操作失败，客户端将尝试重试的次数. rest.server.max-content-length 104857600 服务器将处理的最大内容长度（以字节为单位）. Blob服务器 键 默认 描述 blob.fetch.backlog 1000 config参数定义JobManager上BLOB提取的积压. blob.fetch.num-concurrent 50 config参数定义JobManager服务的最大并发BLOB提取数. blob.fetch.retries 5 config参数定义失败的BLOB提取的退出次数. blob.offload.minsize 1048576 要卸载到BlobServer的消息的最小大小. blob.server.port “0” config参数定义blob服务的服务器端口. blob.service.cleanup.interval 3600 TaskManager中blob缓存的清理间隔（以秒为单位）. blob.service.ssl.enabled true 用于覆盖blob服务传输的ssl支持的标志. blob.storage.directory (none) config参数，用于定义blob服务器使用的存储目录. 心跳管理器 键 默认 描述 heartbeat.interval 10000 从发送方请求心跳的时间间隔. heartbeat.timeout 50000 为发送方和接收方双方请求和接收心跳的超时. SSL设置 键 默认 描述 security.ssl.algorithms “TLS_RSA_WITH_AES_128_CBC_SHA” 要支持的标准SSL算法的逗号分隔列表.在这里阅读更多 security.ssl.internal.enabled false 打开SSL以进行内部网络通信.可选地，特定组件可以通过它们自己的设置（rpc，数据传输，REST等）覆盖它. security.ssl.internal.key-password (none) 解密Keys库中Flink内部端点（rpc，数据传输，blob服务器）Keys的密钥. security.ssl.internal.keystore (none) 带有SSLKeys和证书的JavaKeys库文件，用于Flink的内部端点（rpc，数据传输，blob服务器）. security.ssl.internal.keystore-password (none) 为Flink的内部端点（rpc，数据传输，blob服务器）解密Flink的Keys库文件的密钥. security.ssl.internal.truststore (none) 包含公共CA证书的信任库文件，用于验证Flink内部端点（rpc，数据传输，blob服务器）的对等方. security.ssl.internal.truststore-password (none) 用于解密Flink内部端点（rpc，数据传输，blob服务器）的信任库的密码. security.ssl.key-password (none) 解密Keys库中的服务器Keys的密钥. security.ssl.keystore (none) flink端点用于其SSLKeys和证书的JavaKeys库文件. security.ssl.keystore-password (none) 解密Keys库文件的密钥. security.ssl.protocol “TLSv1.2” ssl传输支持的SSL协议版本.请注意，它不支持以逗号分隔的列表. security.ssl.rest.enabled false 通过REST端点打开SSL以进行外部通信. security.ssl.rest.key-password (none) 解密Flink外部REST端点的Keys库中的Keys的密钥. security.ssl.rest.keystore (none) 带有SSLKeys和证书的JavaKeys库文件，用于Flink的外部REST端点. security.ssl.rest.keystore-password (none) 为Flink的外部REST端点解密Flink的Keys库文件的密钥. security.ssl.rest.truststore (none) 包含公共CA证书的信任库文件，用于验证Flink的外部REST端点的对等方. security.ssl.rest.truststore-password (none) 用于解密Flink外部REST端点的信任库的密码. security.ssl.truststore (none) 信任库文件，包含flink端点用于验证对等方证书的公共CA证书. security.ssl.truststore-password (none) 解密信任库的秘诀. security.ssl.verify-hostname true 标记以在ssl握手期间启用对等方的主机名验证. 网络通讯（通过Netty） 这些参数允许高级调整.在大型群集上运行并发高吞吐量作业时，默认值就足够了. 键 默认 描述 taskmanager.network.netty.client.connectTimeoutSec 120 Netty客户端连接超时. taskmanager.network.netty.client.numThreads -1 Netty客户端线程的数量. taskmanager.network.netty.num-arenas -1 Netty竞技场的数量. taskmanager.network.netty.sendReceiveBufferSize 0 Netty发送和接收缓冲区大小.这默认为系统缓冲区大小（cat / proc / sys / net / ipv4 / tcp_ [rw] mem），在现代Linux中为4 MiB. taskmanager.network.netty.server.backlog 0 netty服务器连接积压. taskmanager.network.netty.server.numThreads -1 Netty服务器线程数. taskmanager.network.netty.transport “nio” Netty传输类型，“nio”或“epoll” Web前端 键 默认 描述 web.access-control-allow-origin “*”   web.address (none)   web.backpressure.cleanup-interval 600000   web.backpressure.delay-between-samples 50   web.backpressure.num-samples 100   web.backpressure.refresh-interval 60000   web.checkpoints.history 10   web.history 5   web.log.path (none)   web.refresh-interval 3000   web.ssl.enabled true   web.submit.enable true   web.timeout 10000   web.tmpdir System.getProperty（ “java.io.tmpdir”）   web.upload.dir (none)   文件系统 键 默认 描述 fs.default-scheme (none) 默认文件系统方案，用于未明确声明方案的路径.可能包含权限，例如，在HDFS NameNode的情况下为host：port. fs.output.always-create-directory false 以大于1的并行度运行的文件编写器为输出文件路径创建目录，并将不同的结果文件（每个并行编写器任务一个）放入该目录中.如果此选项设置为“true”，则并行度为1的编写器也将创建一个目录并将单个结果文件放入其中.如果该选项设置为“false”，则编写器将直接在输出路径上直接创建文件，而不创建包含目录. fs.overwrite-files false 指定默认情况下文件输出编写器是否应覆盖现有文件.设置为“true”以默认覆盖，否则设置为“false”. 编译/优化 键 默认 描述 compiler.delimited-informat.max-line-samples 10 编译器为分隔输入采用的最大行样本数.样本用于估计记录数.可以使用输入格式的参数覆盖特定输入的此值. compiler.delimited-informat.max-sample-len 2097152 编译器用于分隔输入的行样本的最大长度.如果单个样本的长度超过此值（可能是因为解析器配置错误），则取样将中止.可以使用输入格式的参数覆盖特定输入的此值. compiler.delimited-informat.min-line-samples 2 编译器为分隔输入采用的最小行样本数.样本用于估计记录数.可以使用输入格式的参数覆盖特定输入的此值 运行时算法 键 默认 描述 taskmanager.runtime.hashjoin-bloom-filters false 用于在混合散列连接实现中激活/停用bloom过滤器的标志.如果散列连接需要溢出到磁盘（数据集大于保存的内存部分），这些布隆过滤器可以大大Reduce溢出记录的数量，但需要花费一些CPU周期. taskmanager.runtime.max-fan 128 外部合并的最大扇入连接和扇出用于溢出哈希表.限制每个 算子的文件句柄数，但如果设置得太小，可能会导致中间合并/分区. taskmanager.runtime.sort-spilling-threshold 0.8 当这部分内存预算已满时，排序 算子操作开始溢出. Resource Manager 本节中的配置键独立于使用的资源管理框架（YARN，Mesos，Standalone，…） 键 默认 描述 containerized.heap-cutoff-min 600 作为安全边际，要在容器中删除的最小堆内存量. containerized.heap-cutoff-ratio 0.25 要从容器中删除的堆空间百分比（YARN / Mesos），以补偿其他JVM内存使用情况. local.number-resourcemanager 1   resourcemanager.job.timeout “5m” 没有TaskManager作为Leader的工作超时. resourcemanager.rpc.port 0 定义要连接的网络端口以与资源管理器进行通信.默认情况下，JobManager的端口，因为使用了相同的ActorSystem.无法使用此配置键定义端口范围. resourcemanager.taskmanager-timeout 30000 释放空闲TaskManager的超时. YARN 键 默认 描述 yarn.application-attempts (none) ApplicationMaster重启次数.请注意，整个Flink群集将重新启动，YARN客户端将断开连接.此外，JobManager地址将更改，您需要手动设置JM主机：port.建议将此选项保存为1. yarn.application-master.port “0” 使用此配置选项，用户可以为Application Master（和JobManager）RPC端口指定端口，一系列端口或端口列表.默认情况下，我们建议使用默认值（0）让 算子操作系统选择适当的端口.特别是当多个AM在同一物理主机上运行时，固定端口分配会阻止AM启动.例如，在具有限制性防火墙的环境中在YARN上运行Flink时，此选项允许指定一系列允许的端口. yarn.appmaster.rpc.address (none) 应用程序主RPC系统正在侦听的主机名或地址. yarn.appmaster.rpc.port -1 应用程序主RPC系统正在侦听的端口. yarn.containers.vcores -1 每个YARN容器的虚拟核心数（vcores）.默认情况下，vcores的数量设置为每个TaskManager的插槽数（如果已设置），或者设置为1，否则设置为1.为了使用此参数，您的群集必须启用CPU调度.您可以通过设置来完成此 算子操作org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler. yarn.heartbeat-delay 5 使用ResourceManager的心跳之间的时间，以秒为单位. yarn.maximum-failed-containers (none) 系统在发生故障时将重新分配的最大容器数. yarn.per-job-cluster.include-user-jar “ORDER” 定义用户jar是否包含在每个作业集群的系统类路径中以及它们在路径中的位置.它们可以位于开头（“FIRST”），末尾（“LAST”），或者根据其名称（“ORDER”）定位.将此参数设置为“DISABLED”会导致jar包含在用户类路径中. yarn.properties-file.location (none) 将Flink作业提交给YARN时，JobManager的主机和可用处理槽的数量将写入属性文件，以便Flink客户端能够选择这些详细信息.此配置参数允许更改该文件的默认位置（例如，对于在用户之间共享Flink安装的环境）. yarn.tags (none) 要应用于Flink YARN应用程序的以逗号分隔的标记列表. Mesos 键 默认 描述 mesos.failover-timeout 604800 Mesos调度程序的故障转移超时（以秒为单位），之后将自动关闭正在运行的任务. mesos.initial-tasks 0 最初的工人在主人开始时提出来.除非Flink处于传统模式，否则将忽略此选项. mesos.master (none) Mesos主URL.该值应采用以下形式之一：主持人：portZK：//主机1：端口1，主机2：端口2，… /路径ZK：//用户名：密码@主机1：端口1，主机2：端口2，… /路径文件：///路径/到/文件 mesos.maximum-failed-tasks -1 群集失败前失败的最大工作数.可以设置为-1以禁用此函数.除非Flink处于传统模式，否则将忽略此选项. mesos.resourcemanager.artifactserver.port 0 config参数定义要使用的Mesos工件服务器端口.将端口设置为0将允许 算子操作系统选择可用端口. mesos.resourcemanager.artifactserver.ssl.enabled true 为Flink工件服务器启用SSL.请注意，security.ssl.enabled也需要设置为true加密才能启用加密. mesos.resourcemanager.framework.name “Flink” Mesos框架名称 mesos.resourcemanager.framework.principal (none) Mesos框架主体 mesos.resourcemanager.framework.role “*” Mesos框架角色定义 mesos.resourcemanager.framework.secret (none) Mesos框架密钥 mesos.resourcemanager.framework.user (none) Mesos框架用户 mesos.resourcemanager.tasks.port-assignments (none) 以逗号分隔的配置键列表，表示可配置端口.所有端口Keys将动态获取通过Mesos分配的端口. Mesos TaskManager 键 默认 描述 mesos.constraints.hard.hostattribute (none) 基于代理属性在Mesos上放置任务的约束.采用逗号分隔的键：值对列表，对应于目标介质代理公开的属性.示例：az：eu-west-1a，系列：t2 mesos.resourcemanager.tasks.bootstrap-cmd (none) 在TaskManager启动之前执行的命令. mesos.resourcemanager.tasks.container.docker.force-pull-image false 指示docker containerizer强制拉动镜像，而不是重用缓存版本. mesos.resourcemanager.tasks.container.docker.parameters (none) 使用docker容器时，要传递给docker run命令的自定义参数.逗号分隔的“key = value”对列表.“值”可能包含“=”. mesos.resourcemanager.tasks.container.image.name (none) 用于容器的映像名称. mesos.resourcemanager.tasks.container.type “mesos” 使用的集装箱类型：“mesos”或“docker”. mesos.resourcemanager.tasks.container.volumes (none) 逗号分隔的[host_path：] container_path [：RO | RW]列表.这允许将额外的卷安装到容器中. mesos.resourcemanager.tasks.cpus 0.0 要分配给Mesos工作者的CPU. mesos.resourcemanager.tasks.gpus 0 要分配给Mesos工作者的GPU. mesos.resourcemanager.tasks.hostname (none) 用于定义TaskManager主机名的可选值.模式_TASK_由Mesos任务的实际ID替换.这可用于配置TaskManager以使用Mesos DNS（例如_TASK_.flink-service.mesos）进行名称查找. mesos.resourcemanager.tasks.mem 1024 要以MB为单位分配给Mesos worker的内存. mesos.resourcemanager.tasks.taskmanager-cmd “$FLINK_HOME/bin/mesos-taskmanager.sh”   mesos.resourcemanager.tasks.uris (none) 以逗号分隔的自定义工件URI列表，这些URI将下载到Mesos工作者的沙箱中. taskmanager.numberOfTaskSlots 1 单个TaskManager可以运行的并行算子或用户函数实例的数量.如果此值大于1，则单个TaskManager将获取函数或 算子的多个实例.这样，TaskManager可以使用多个CPU内核，但同时，可用内存在不同的算子或函数实例之间划分.此值通常与TaskManager的计算机具有的物理CPU核心数成比例（例如，等于核心数，或核心数的一半）. 高可用性（HA） 键 默认 描述 high-availability “NONE” 定义用于群集执行的高可用性模式.要启用高可用性，请将此模式设置为“ZOOKEEPER”. high-availability.cluster-id “/default” Flink集群的ID，用于将多个Flink集群彼此分开.需要为独立群集设置，但在YARN和Mesos中自动推断. high-availability.job.delay (none) 故障转移后JobManager之前的时间恢复当前作业. high-availability.jobmanager.port “0” JobManager在高可用性模式下使用的可选端口（范围）. high-availability.storageDir (none) 文件系统路径（URI）Flink在高可用性设置中持久保存元数据. 基于ZooKeeper的HA模式 键 默认 描述 high-availability.zookeeper.client.acl “open” 定义要在ZK节点上配置的ACL（open | creator）.如果ZooKeeper服务器配置将“authProvider”属性映射为使用SASLAuthenticationProvider并且群集配置为以安全模式（Kerberos）运行，则可以将配置值设置为“creator”. high-availability.zookeeper.client.connection-timeout 15000 定义ZooKeeper的连接超时（以ms为单位）. high-availability.zookeeper.client.max-retry-attempts 3 定义客户端放弃之前的连接重试次数. high-availability.zookeeper.client.retry-wait 5000 定义以ms为单位的连续重试之间的暂停. high-availability.zookeeper.client.session-timeout 60000 以ms为单位定义ZooKeeper会话的会话超时. high-availability.zookeeper.path.checkpoint-counter “/checkpoint-counter” ZooKeeper根路径（ZNode）用于检查点计数器. high-availability.zookeeper.path.checkpoints “/checkpoints” 已完成检查点的ZooKeeper根路径（ZNode）. high-availability.zookeeper.path.jobgraphs “/jobgraphs” 作业图的ZooKeeper根路径（ZNode） high-availability.zookeeper.path.latch “/leaderlatch” 定义用于选择Leader的Leader锁存器的znode. high-availability.zookeeper.path.leader “/leader” 定义Leader的znode，其中包含Leader的URL和当前Leader会话ID. high-availability.zookeeper.path.mesos-workers “/mesos-workers” ZooKeeper根路径，用于保存Mesos工作者信息. high-availability.zookeeper.path.root “/flink” Flink在ZooKeeper中存储其条目的根路径. high-availability.zookeeper.path.running-registry “/running_job_registry/”   high-availability.zookeeper.quorum （none） 使用ZooKeeper在高可用性模式下运行Flink时要使用的ZooKeeper quorum. ZooKeeper安全 键 默认 描述 zookeeper.sasl.disable false   zookeeper.sasl.login-context-name “Client”   zookeeper.sasl.service-name “zookeeper”   基于Kerberos的安全性 键 默认 描述 security.kerberos.login.contexts (none) 以逗号分隔的登录上下文列表，用于提供Kerberos凭据（例如，Client，KafkaClient使用凭证进行ZooKeeper身份验证和Kafka身份验证） security.kerberos.login.keytab (none) 包含用户凭据的KerberosKeys表文件的绝对路径. security.kerberos.login.principal (none) 与keytab关联的Kerberos主体名称. security.kerberos.login.use-ticket-cache true 指示是否从Kerberos票证缓存中读取. 环境 键 默认 描述 env.hadoop.conf.dir (none) hadoop配置目录的路径.需要读取HDFS和/或YARN配置.您也可以通过环境变量进行设置. env.java.opts (none)   env.java.opts.jobmanager (none)   env.java.opts.taskmanager (none)   env.log.dir (none) 定义保存Flink日志的目录.它必须是一条绝对的道路.（默认为Flink主页下的日志目录） env.log.max 5 要保存的最大旧日志文件数. env.ssh.opts (none) 启动或停止JobManager，TaskManager和Zookeeper服务时，其他命令行选项传递给SSH客户端（start-cluster.sh，stop-cluster.sh，start-zookeeper-quorum.sh，stop-zookeeper-quorum.sh）. env.yarn.conf.dir (none) YARN配置目录的路径.它需要在YARN上运行flink.您也可以通过环境变量进行设置. 检查点 键 默认 描述 state.backend (none) 状态后台用于存储和检查点状态. state.backend.async true 选择状态后台是否应在可能和可配置的情况下使用异步SNAPSHOT方法.某些状态后台可能不支持异步SNAPSHOT，或者仅支持异步SNAPSHOT，并忽略此选项. state.backend.fs.memory-threshold 1024 状态数据文件的最小大小.小于该值的所有状态块都内联存储在根检查点元数据文件中. state.backend.incremental false 如果可能，选择状态后台是否应创建增量检查点.对于增量检查点，仅存储来自先前检查点的差异，而不是完整的检查点状态.某些状态后台可能不支持增量检查点并忽略此选项. state.backend.local-recovery false   state.checkpoints.dir (none) 用于在Flink支持的文件系统中存储检查点的数据文件和元数据的默认目录.必须可以从所有参与的进程/节点（即所有TaskManagers和JobManagers）访问存储路径. state.checkpoints.num-retained 1 要保存的已完成检查点的最大数量. state.savepoints.dir (none) 保存点的默认目录.由将后台写入文件系统的状态后台（MemoryStateBackend，FsStateBackend，RocksDBStateBackend）使用. taskmanager.state.local.root-dirs (none)   可查询状态 键 默认 描述 query.client.network-threads 0 网络数（Netty的事件循环）可查询状态客户端的线程. query.proxy.network-threads 0 网络数（Netty的事件循环）可查询状态代理的线程. query.proxy.ports “9069” 可查询状态代理的端口范围.指定范围可以是单个端口：“9123”，一系列端口：“50100-50200”，或范围和端口列表：“50100-50200,50300-50400,51234”. query.proxy.query-threads 0 可查询状态代理的查询线程数.如果设置为0，则使用插槽数. query.server.network-threads 0 网络数（Netty的事件循环）可查询状态服务器的线程. query.server.ports “9067” 可查询状态服务器的端口范围.指定范围可以是单个端口：“9123”，一系列端口：“50100-50200”，或范围和端口列表：“50100-50200,50300-50400,51234”. query.server.query-threads 0 可查询状态服务器的查询线程数.如果设置为0，则使用插槽数. 度量 键 默认 描述 metrics.latency.granularity “operator” 定义延迟指标的粒度.可接受的值是：单一 - 跟踪延迟，无需区分源和子任务.operator - 跟踪延迟，同时区分源，但不区分子任务.子任务 - 在区分源和子任务时跟踪延迟. metrics.latency.history-size 128 定义每个算子维护的测量延迟数. metrics.latency.interval 0 定义从源发出延迟跟踪标记的间隔.如果设置为0或负值，则禁用延迟跟踪.启用此函数会显着影响群集的性能. metrics.reporter. . (none) 为名为的报告器配置参数. metrics.reporter..class (none) 报告类用于为报告命名. metrics.reporter..interval (none) 报告间隔用于报告名为. metrics.reporters (none)   metrics.scope.delimiter “”   metrics.scope.jm “ .jobmanager” 定义应用于作用于JobManager的所有度量标准的范围格式字符串. metrics.scope.jm.job “ .jobmanager.” 定义范围格式字符串，该字符串应用于作用于JobManager上作业的所有度量标准. metrics.scope.operator “ .taskmanager. ” 定义应用于作用于 算子的所有度量标准的范围格式字符串. metrics.scope.task “ .taskmanager. ” 定义应用于作用于任务的所有度量标准的范围格式字符串. metrics.scope.tm “ .taskmanager.” 定义应用于作用于TaskManager的所有度量标准的范围格式字符串. metrics.scope.tm.job “ .taskmanager. ” 定义范围格式字符串，该字符串应用于作用于TaskManager上作业的所有度量标准. metrics.system-resource false   metrics.system-resource-probing-interval 5000   历史服务器 如果要通过HistoryServer的Web前端显示它们，则必须进行配置jobmanager.archive.fs.dir以存档已终止的作业并将其添加到受监视目录列表中historyserver.archive.fs.dir. jobmanager.archive.fs.dir：将有关已终止作业的信息上载到的目录.您必须将此目录添加到历史服务器的受监视目录列表中historyserver.archive.fs.dir. 键 默认 描述 historyserver.archive.fs.dir (none) 以逗号分隔的目录列表，用于从中获取已归档的作业.历史服务器将监视这些目录以获取已存档的作业.您可以将JobManager配置为通过jobmanager.archive.fs.dir将作业存档到目录. historyserver.archive.fs.refresh-interval 10000 刷新已归档作业目录的时间间隔（以ms为单位）. historyserver.web.address (none) HistoryServer的Web界面的地址. historyserver.web.port 8082 HistoryServers的Web界面的端口. historyserver.web.refresh-interval 10000   historyserver.web.ssl.enabled false 启用对HistoryServer Web前端的HTTP访问.仅当全局SSL标志security.ssl.enabled设置为true时，此选项才适用. historyserver.web.tmpdir (none) 此配置参数允许定义历史服务器Web界面使用的Flink Web目录.Web界面将其静态文件复制到目录中. 留存 mode：Flink的执行模式.可能的值是legacy和new.要启动旧组件，您必须指定legacy（DEFAULT：）new。 背景 配置网络缓冲区 如果您看到异常java.io.IOException: Insufficient number of network buffers，则需要调整用于网络缓冲区的内存量，以便程序在您的TaskManager上运行。 网络缓冲区是通信层的关键资源.它们用于在通过网络传输之前缓冲记录，并在将传入数据解析为记录并将其传递给应用程序之前缓冲传入数据.足够数量的网络缓冲区对于实现良好的吞吐量至关重要。 从Flink 1.3开始，你可以遵循“越多越好”的成语而不会对延迟造成任何惩罚（我们通过限制每个通道使用的实际缓冲区数量来防止每个传出和传入通道中的过度缓冲，即缓冲膨胀） 。 通常，将TaskManager配置为具有足够的缓冲区，以使您希望同时打开的每个逻辑网络连接都具有专用缓冲区。对于网络上的每个点对点数据交换存在逻辑网络连接，这通常发生在重新分区或广播步骤（混洗阶段）。在那些中，TaskManager中的每个并行任务必须能够与所有其他并行任务进行通信。 注意：从Flink 1.5开始，网络缓冲区将始终在堆外分配，即在JVM堆之外，而不管其值是多少taskmanager.memory.off-heap。这样，我们可以将这些缓冲区直接传递给底层网络堆栈层。</summary></entry><entry><title type="html">Flink基础运行时环境</title><link href="http://localhost:4000/bigdata/2018/10/09/Flink%E5%9F%BA%E7%A1%80%E8%BF%90%E8%A1%8C%E6%97%B6%E7%8E%AF%E5%A2%83/" rel="alternate" type="text/html" title="Flink基础运行时环境" /><published>2018-10-09T00:00:00+08:00</published><updated>2018-10-09T00:00:00+08:00</updated><id>http://localhost:4000/bigdata/2018/10/09/Flink%E5%9F%BA%E7%A1%80%E8%BF%90%E8%A1%8C%E6%97%B6%E7%8E%AF%E5%A2%83</id><content type="html" xml:base="http://localhost:4000/bigdata/2018/10/09/Flink%E5%9F%BA%E7%A1%80%E8%BF%90%E8%A1%8C%E6%97%B6%E7%8E%AF%E5%A2%83/">&lt;blockquote&gt;
  &lt;p&gt;本文所用flink版本为1.6，官方文档链接&lt;a href=&quot;https://ci.apache.org/projects/flink/flink-docs-release-1.6/concepts/runtime.html&quot;&gt;Apache Flink 1.6&lt;/a&gt;，本文所参考的文档均在正文中每个部分直接详细指出了，就不再汇总了。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h1 id=&quot;flink运行时环境&quot;&gt;Flink运行时环境&lt;/h1&gt;
&lt;h2 id=&quot;tasks和operator-chains&quot;&gt;Tasks和Operator Chains&lt;/h2&gt;
&lt;ol&gt;
  &lt;li&gt;基础说明&lt;br /&gt;
在实际的分布式计算环境中，Flink会将多个运算子任务（ operator subtasks）链接一起（chains）形成分布式计算任务（tasks）。每个任务（task）在一个线程中执行。&lt;br /&gt;
优点：将运算符（operators）链接成计算任务（tasks）中，形成Operator Chains对于系统性能的提升有很大的帮助：
    &lt;ul&gt;
      &lt;li&gt;降低了线程间的切换&lt;/li&gt;
      &lt;li&gt;减少了数据在与缓冲区的开销&lt;/li&gt;
      &lt;li&gt;减少消息的序列化/反序列化&lt;/li&gt;
      &lt;li&gt;在降低延时的同时减少了系统的总体吞吐量&lt;/li&gt;
    &lt;/ul&gt;

    &lt;p&gt;我们可以对这种chain操作进行配置，具体内容请参考&lt;a href=&quot;https://ci.apache.org/projects/flink/flink-docs-release-1.6/dev/stream/operators/#task-chaining-and-resource-groups&quot;&gt;chaining docs&lt;/a&gt;。&lt;br /&gt;
如下图是官网所示的数据流图包含五个子任务，也就是说其中有五个并行线程：&lt;br /&gt;
&lt;img src=&quot;https://ci.apache.org/projects/flink/flink-docs-release-1.6/fig/tasks_chains.svg&quot; alt=&quot;Tasks and Operator Chains&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;形成Operator Chains的条件：&lt;br /&gt;
上述描述了Tasks和Operator Chains的概念，下面以经典的WordCount为例，看下Operator Chains的形成。此部分结合&lt;a href=&quot;http://wuchong.me/blog/2016/05/09/flink-internals-understanding-execution-resources/&quot;&gt;Flink 原理与实现：理解 Flink 中的计算资源&lt;/a&gt;整理。&lt;br /&gt;
下面这幅图，展示了Source并行度为1，FlatMap、KeyAggregation、Sink并行度均为2，最终以5个并行的线程来执行的优化过程。&lt;br /&gt;
&lt;img src=&quot;https://github.com/leafming/bak/blob/master/images/flink/2018-10-09-FlinkOperatorChains形成.png?raw=true&quot; alt=&quot;flinkOperatorChains形成&quot; /&gt;&lt;br /&gt;
上图中将KeyAggregation和Sink两个operator进行了合并，因为这两个合并后并不会改变整体的拓扑结构。但是，并不是任意两个 operator 就能 chain 一起的。还是需要一定的条件：
    &lt;ul&gt;
      &lt;li&gt;没有禁用Chain&lt;/li&gt;
      &lt;li&gt;上下游算子并行度一致&lt;/li&gt;
      &lt;li&gt;下游算子的入度为1（也就是说下游节点没有来自其他节点的输入）&lt;/li&gt;
      &lt;li&gt;上下游算子都在同一个slot group中（文章后续会解释slot group）&lt;/li&gt;
      &lt;li&gt;上下游算子之间没有shuffle（两个算子间数据分区方式是forward）&lt;/li&gt;
      &lt;li&gt;下游的chain策略为ALWAYS（可以与上下游链接，map、flatmap、filter等默认是ALWAYS）&lt;/li&gt;
      &lt;li&gt;上游的chain策略为ALWAYS或HEAD（只能与下游链接，不能与上游链接，Source默认是HEAD）&lt;/li&gt;
    &lt;/ul&gt;

    &lt;p&gt;Operator chain的行为可以通过编程API中进行指定。可以通过在DataStream的operator后面（如someStream.map(..))调用startNewChain()来指示从该operator开始一个新的chain（与前面截断，不会被chain到前面）。或者调用disableChaining()来指示该operator不参与chaining（不会与前后的operator chain一起）。在底层，这两个方法都是通过调整operator的 chain 策略（HEAD、NEVER）来实现的。另外，也可以通过调用StreamExecutionEnvironment.disableOperatorChaining()来全局禁用chaining。参考官网API&lt;a href=&quot;https://ci.apache.org/projects/flink/flink-docs-release-1.6/dev/stream/operators/#task-chaining-and-resource-groups&quot;&gt;Task chaining and resource groups&lt;/a&gt;。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;原理与实现（转）&lt;br /&gt;
转载自&lt;a href=&quot;https://yq.aliyun.com/articles/64819#&quot;&gt;Flink 原理与实现：理解 Flink 中的计算资源&lt;/a&gt;，此文应该是基于flink1.3，可以参考。&lt;br /&gt;
那么 Flink 是如何将多个 operators chain在一起的呢？chain在一起的operators是如何作为一个整体被执行的呢？它们之间的数据流又是如何避免了序列化/反序列化以及网络传输的呢？下图展示了operators chain的内部实现：&lt;br /&gt;
&lt;img src=&quot;https://github.com/leafming/bak/blob/master/images/flink/2018-10-09-FlinkChains原理.png?raw=true&quot; alt=&quot;2018-10-09-FlinkChains原理&quot; /&gt;&lt;br /&gt;
如上图所示，Flink内部是通过OperatorChain这个类来将多个operator链在一起形成一个新的operator。OperatorChain形成的框框就像一个黑盒，Flink 无需知道黑盒中有多少个ChainOperator、数据在chain内部是怎么流动的，只需要将input数据交给 HeadOperator 就可以了，这就使得OperatorChain在行为上与普通的operator无差别，上面的OperaotrChain就可以看做是一个入度为1，出度为2的operator。所以在实现中，对外可见的只有HeadOperator，以及与外部连通的实线输出，这些输出对应了JobGraph中的JobEdge，在底层通过RecordWriterOutput来实现。另外，框中的虚线是operator chain内部的数据流，这个流内的数据不会经过序列化/反序列化、网络传输，而是直接将消息对象传递给下游的 ChainOperator 处理，这是性能提升的关键点，在底层是通过 ChainingOutput 实现的，源码如下方所示：&lt;br /&gt;
注：HeadOperator和ChainOperator并不是具体的数据结构，前者指代chain中的第一个operator，后者指代chain中其余的operator，它们实际上都是StreamOperator。
    &lt;div class=&quot;language-scala highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;private&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;static&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;ChainingOutput&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;implements&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Output&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;StreamRecord&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
 &lt;span class=&quot;c1&quot;&gt;// 注册的下游operator
&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;protected&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;final&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;OneInputStreamOperator&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;?&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;operator&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;
 &lt;span class=&quot;n&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;ChainingOutput&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;OneInputStreamOperator&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;?&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;operator&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
     &lt;span class=&quot;k&quot;&gt;this&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;operator&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;operator&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;
 &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
 &lt;span class=&quot;nd&quot;&gt;@Override&lt;/span&gt;
 &lt;span class=&quot;c1&quot;&gt;// 发送消息方法的实现，直接将消息对象传递给operator处理，不经过序列化/反序列化、网络传输
&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;collect&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;StreamRecord&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;record&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
     &lt;span class=&quot;k&quot;&gt;try&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
         &lt;span class=&quot;n&quot;&gt;operator&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;setKeyContextElement1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;record&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
         &lt;span class=&quot;c1&quot;&gt;// 下游operator直接处理消息对象
&lt;/span&gt;         &lt;span class=&quot;n&quot;&gt;operator&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;processElement&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;record&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
     &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
     &lt;span class=&quot;k&quot;&gt;catch&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Exception&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;e&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
         &lt;span class=&quot;k&quot;&gt;throw&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;ExceptionInChainedOperatorException&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;e&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
     &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
 &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
 &lt;span class=&quot;o&quot;&gt;...&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;作业管理器任务管理器与客户端-job-managers-task-managers-clients&quot;&gt;作业管理器，任务管理器与客户端-Job Managers, Task Managers, Clients&lt;/h2&gt;
&lt;ol&gt;
  &lt;li&gt;Flink运行时环境由两种类型进程组成：
    &lt;ul&gt;
      &lt;li&gt;JobManagers-作业管理器（也称为master）&lt;br /&gt;
用于协调程序的分布式执行。它的主要功能是调度任务（tasks），协调checkpoint，故障恢复等。&lt;br /&gt;
每个Flink环境中只有一个JobManagers。高可用设计中会包含多个JobManagers，其中一个是leader，其他standby。&lt;/li&gt;
      &lt;li&gt;TaskManagers-任务管理器（也称为worker）&lt;br /&gt;
用于执行数据流图（dataflow）的任务（tasks）（更准确地说，是计算子任务（subtasks）），并对数据流进行缓冲、交换。&lt;br /&gt;
每个Flink环境中至少包含一个TaskManagers。&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;JobManagers和TaskManagers可以以多种方式启动：
    &lt;ul&gt;
      &lt;li&gt;直接在机器上作为独立群集(&lt;a href=&quot;https://ci.apache.org/projects/flink/flink-docs-release-1.6/ops/deployment/cluster_setup.html&quot;&gt;standalone cluster&lt;/a&gt;)&lt;/li&gt;
      &lt;li&gt;容器中启动&lt;/li&gt;
      &lt;li&gt;YARN或Mesos等资源框架来管理&lt;/li&gt;
    &lt;/ul&gt;

    &lt;p&gt;启动之后，TaskManagers会连接到JobManagers来宣布自己可用报告自身的状态，便于JobManagers来分配工作。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;关于客户端（Client）&lt;br /&gt;
 Client其实并不是运行时及程序执行时的一个组成部分，而是被用来准备和发送的数据流(dataflow)给JobManager的。在发送完数据流图之后，客户端可以选择断开与JobManager的连接，或继续保持连接以接收程序运行的进度报告。Client程序可以以 Java/Scala 程序的形式执行，也可以以命令行的形式（./bin/flink run …）执行。&lt;/p&gt;

    &lt;p&gt;官网运行时架构图如下：&lt;br /&gt;
 &lt;img src=&quot;https://ci.apache.org/projects/flink/flink-docs-release-1.6/fig/processes.svg&quot; alt=&quot;runtime架构图&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;小结(转)&lt;br /&gt;
本部分内容转载自&lt;a href=&quot;http://wuchong.me/blog/2016/05/03/flink-internals-overview/#Job-例子&quot;&gt;Flink 原理与实现：架构和拓扑概览&lt;/a&gt;，此文章应该是基于flink1.3，可以参考。&lt;br /&gt;
当Flink集群启动后，首先会启动一个JobManger和一个或多个的TaskManager。由Client提交任务给JobManager，JobManager再调度任务到各个TaskManager去执行，然后TaskManager将心跳和统计信息汇报给JobManager。TaskManager 之间以流的形式进行数据的传输。上述三者均为独立的JVM 进程。
    &lt;ul&gt;
      &lt;li&gt;Client为提交Job的客户端，可以是运行在任何机器上（与JobManager环境连通即可）。提交Job后，Client可以结束进程（Streaming的任务），也可以不结束并等待结果返回。&lt;/li&gt;
      &lt;li&gt;JobManager主要负责调度Job并协调Task做checkpoint，职责上很像Storm的Nimbus。从Client处接收到Job和JAR包等资源后，会生成优化后的执行计划，并以Task的单元调度到各个TaskManager去执行。&lt;/li&gt;
      &lt;li&gt;TaskManager在启动的时候就设置好了槽位数（Slot），每个slot能启动一个Task，Task为线程。从JobManager处接收需要部署的Task，部署启动后，与自己的上游建立 Netty 连接，接收数据并处理。&lt;/li&gt;
    &lt;/ul&gt;

    &lt;p&gt;可以看到Flink的任务调度是多线程模型，并且不同Job/Task混合在一个TaskManager进程中。虽然这种方式可以有效提高CPU利用率，但是个人不太喜欢这种设计，因为不仅缺乏资源隔离机制，同时也不方便调试。类似Storm的进程模型，一个JVM中只跑该Job的Tasks实际应用中更为合理。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;其它&lt;br /&gt;
Flink运行时角色间的通信使用akka，数据的传输使用netty。对比spark，从Spark1.3.1版本开始，为了解决大数据块（如shuffle）的传输问题，Spark引入了Netty通信框架，到了1.6.0版本，Netty完全取代了Akka，承担Spark内部所有的RPC通信以及数据流传输。&lt;br /&gt;
参考&lt;a href=&quot;https://blog.csdn.net/yanghua_kobe/article/details/51156218?utm_source=itdadao&amp;amp;utm_medium=referral&quot;&gt;Akka在Flink中的使用剖析&lt;/a&gt;。&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;任务槽与资源-task-slots-and-resources&quot;&gt;任务槽与资源-Task Slots and Resources&lt;/h2&gt;
&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;TaskManager和Slot的关系&lt;br /&gt;
每个worker（即TaskManager）都是一个独立的JVM进程，可以运行一个或多个子任务（subtask）在其不同的线程中。为了控制worker（TaskManager）接收任务（tasks）的数量，在worker 中引入了任务槽（task slots）的概念（每个worker中至少包含一个任务槽）。&lt;br /&gt;
每个任务槽（task slots）代表任务管理器（TaskManager）中一个特定的资源池子集，槽把TaskManager的资源进行平分。例如，如果任务管理器有3个槽，它会为每个槽分配1/3的内存。将资源池槽化可以让子任务（subtask）获取指定容量的内存资源，而避免同其他作业（job）中的子任务（subtask）竞争。注意，这里没有对CPU进行隔离；目前任务槽仅仅用于隔离任务（tasks）的内存。&lt;br /&gt;
通过调整任务槽（task slots）的数量，用户可以设定子任务（subtasks）如何相互隔离。如果任务管理器（TaskManager）中只有一个槽，那么每个任务组（task group）都运行在一个独立的JVM中（which can be started in a separate container, for example）。若任务管理器（TaskManager ）有多个槽就意味着会有更多的子任务共享同一个JVM。在同一个JVM中的任务会共享 TCP连接（通过多路复用（multiplexing）的方式）和心跳信息，可以减少数据的网络传输，同时他们也会共享数据集和数据结构，一定程度上可以降低每个task的开销。&lt;br /&gt;
如上文所述的 WordCount 例子，5个Task可能会在TaskManager的slots中如下图分布，2个TaskManager，每个有3个slot：&lt;br /&gt;
&lt;img src=&quot;https://github.com/leafming/bak/blob/master/images/flink/2018-10-09-FlinkSlot分布例子.png?raw=true&quot; alt=&quot;2018-10-09-FlinkSlot分布例子&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;槽和并行度的关系-任务调度&lt;br /&gt;
官网&lt;a href=&quot;https://ci.apache.org/projects/flink/flink-docs-release-1.6/internals/job_scheduling.html#scheduling&quot;&gt;Scheduling&lt;/a&gt;。&lt;br /&gt;
Flink通过任务槽（Task Slot）定义执行资源，每个TaskManager都有一或多个任务槽，每个任务槽都可以运行一个并行任务流(one pipeline of parallel tasks)，一个流(pipeline)包括多个连续的任务，例如一个MapFunction的第n个并行实例与一个ReduceFunction的第n个并行实例的连续任务可以组成一个pipeline。注意，Flink通常会并行的执行连续的任务，对于Streaming程序来说，任何情况都如此执行；而对于batch 程序，多数情况也如此执行。&lt;br /&gt;
下图举例说明。由一个data source、一个MapFunction和一个ReduceFunction组成的程序，data source和MapFunction的并发度都为4，而ReduceFunction的并发度为3。一个数据流由Source-Map-Reduce的顺序组成，在具有2个TaskManager，每个TaskManager都有3个Task Slot的集群上运行，则程序执行情况如图所述。&lt;br /&gt;
&lt;img src=&quot;https://ci.apache.org/projects/flink/flink-docs-release-1.6/fig/slots.svg&quot; alt=&quot;Scheduling&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;slot共享机制-SlotSharingGroup与CoLocationGroup&lt;br /&gt;
参考官网和&lt;a href=&quot;http://wuchong.me/blog/2016/05/09/flink-internals-understanding-execution-resources/&quot;&gt;Flink 原理与实现：理解 Flink 中的计算资源&lt;/a&gt;。&lt;br /&gt;
默认情况下，Flink允许subtasks共享slot，即Flink会允许同一个作业（job）中来自不同的task的多个子任务（subtasks）共享一个槽，即前提是他们来自同一个job，哪怕不同task也可以。这种情况下，有可能会出现某个槽中包含一个完整的作业流水的场景(原文：The result is that one slot may hold an entire pipeline of the job.)。开启这样的slot共享机制主要有两点好处：&lt;/p&gt;
    &lt;ul&gt;
      &lt;li&gt;Flink集群需要确保job中任务槽的数量和程序最高并发量完全一致，因此不需要去计算一个程序中一共会起多少个task。&lt;/li&gt;
      &lt;li&gt;可以提高资源利用率。如果没有任务槽共享机制，非密集型（non-intensive）的source/map()子任务就会和（intensive）密集型的window子任务一样阻塞大量资源。如果有任务槽共享机制，会提高程序的基础并发量，比如说从2提高到6，就可以让密集型子任务（heavy subtasks）公平的完全分散到任务管理器（TaskManager）中，从而可以显著提高槽的资源利用率充分利用资源。&lt;br /&gt;
如下图，我们将WordCount的并行度从之前的2个增加到6个（Source并行度仍为1），并开启slot共享（所有operator都在default共享组），就可以得到下图所示的slot分布图。首先，我们不用去计算这个job会其多少个task，总之该任务最终会占用6个slots（最高并行度为6）。其次，我们可以看到密集型操作keyAggregation/sink被平均地分配到各个TaskManager。&lt;br /&gt;
&lt;img src=&quot;https://github.com/leafming/bak/blob/master/images/flink/2018-10-09-slot共享示例.png?raw=true&quot; alt=&quot;2018-10-09-slot共享示例&quot; /&gt;&lt;/li&gt;
    &lt;/ul&gt;

    &lt;p&gt;a. 关于是如何实现共享slot呢？槽分配的策略？&lt;/p&gt;
    &lt;ul&gt;
      &lt;li&gt;SlotSharingGroup是Flink中用来实现slot共享的类，它尽可能地让subtasks共享一个slot。&lt;/li&gt;
      &lt;li&gt;CoLocationGroup类用来强制将subtasks放到同一个slot中。CoLocationGroup主要用于迭代流中，用来保证迭代头与迭代尾的第i个subtask能被调度到同一个TaskManager上。这里我们不会详细讨论CoLocationGroup的实现细节。&lt;/li&gt;
    &lt;/ul&gt;

    &lt;p&gt;b. 怎么判断operator（算子）属于哪个slot共享组呢？（怎么确定一个算子的SlotSharingGroup？）&lt;br /&gt;
默认情况下，所有的operator（算子）都属于默认的共享组default，也就是说默认情况下所有的operator都是可以共享一个slot的。而当所有input operators具有相同的slot共享组时，该operator会继承这个共享组。最后，为了防止不合理的共享，用户也能通过API来强制指定operator的共享组，比如：someStream.filter(…).slotSharingGroup(“group1”);就强制指定了filter的slot共享组为group1。（总结：根据input的group和自身是否设置group共同确定）适当的设置可以减少每个slot运行的线程数，从而整体上减少机器的负载。&lt;/p&gt;

    &lt;p&gt;c.原理与实现（转）&lt;br /&gt;
那么多个tasks（或者说operators）是如何共享slot的呢？本部分转自&lt;a href=&quot;http://wuchong.me/blog/2016/05/09/flink-internals-understanding-execution-resources/&quot;&gt;Flink 原理与实现：理解 Flink 中的计算资源&lt;/a&gt;。&lt;br /&gt;
来看一下用来定义计算资源的slot的类。抽象类Slot定义了该槽位属于哪个TaskManager（instance）的第几个槽位（slotNumber），属于哪个Job（jobID）等信息。最简单的情况下，一个slot只持有一个task，也就是SimpleSlot的实现。复杂点的情况，一个slot能共享给多个task使用，也就是SharedSlot的实现。SharedSlot能包含其他的SharedSlot，也能包含SimpleSlot。所以一个SharedSlot能定义出一棵slots树。&lt;br /&gt;
接下来我们来看看 Flink 为subtask分配slot的过程。关于Flink调度，有两个非常重要的原则我们必须知道：A.同一个operator的各个subtask是不能呆在同一个SharedSlot中的，例如FlatMap[1]和FlatMap[2]是不能在同一个SharedSlot中的。B.Flink是按照拓扑顺序从Source一个个调度到Sink的。例如WordCount（Source并行度为1，其他并行度为2），那么调度的顺序依次是：Source -&amp;gt; FlatMap[1] -&amp;gt; FlatMap[2] -&amp;gt; KeyAgg-&amp;gt;Sink[1] -&amp;gt; KeyAgg-&amp;gt;Sink[2]。假设现在有2个TaskManager，每个只有1个slot（为简化问题），那么分配slot的过程如图所示：&lt;br /&gt;
&lt;img src=&quot;https://github.com/leafming/bak/blob/master/images/flink/2018-10-10-slot共享机制实现例子图.png?raw=true&quot; alt=&quot;2018-10-10-slot共享机制实现例子图&quot; /&gt;&lt;br /&gt;
注：图中 SharedSlot 与 SimpleSlot 后带的括号中的数字代表槽位号（slotNumber）。&lt;/p&gt;
    &lt;ul&gt;
      &lt;li&gt;为Source分配slot。首先，我们从TaskManager1中分配出一个SharedSlot。并从SharedSlot中为Source分配出一个SimpleSlot。如上图中的①和②。&lt;/li&gt;
      &lt;li&gt;为FlatMap[1]分配slot。目前已经有一个SharedSlot，则从该SharedSlot中分配出一个SimpleSlot用来部署FlatMap[1]。如上图中的③。&lt;/li&gt;
      &lt;li&gt;为FlatMap[2]分配slot。由于TaskManager1的SharedSlot中已经有同operator的FlatMap[1]了，我们只能分配到其他SharedSlot中去。从TaskManager2中分配出一个SharedSlot，并从该SharedSlot中为FlatMap[2]分配出一个SimpleSlot。如上图的④和⑤。&lt;/li&gt;
      &lt;li&gt;为Key-&amp;gt;Sink[1]分配slot。目前两个SharedSlot都符合条件，从TaskManager1的SharedSlot中分配出一个SimpleSlot用来部署Key-&amp;gt;Sink[1]。如上图中的⑥。&lt;/li&gt;
      &lt;li&gt;为Key-&amp;gt;Sink[2]分配slot。TaskManager1的SharedSlot中已经有同operator的Key-&amp;gt;Sink[1]了，则只能选择另一个SharedSlot中分配出一个SimpleSlot用来部署Key-&amp;gt;Sink[2]。如上图中的⑦。&lt;/li&gt;
    &lt;/ul&gt;

    &lt;p&gt;最后Source、FlatMap[1]、Key-&amp;gt;Sink[1]这些subtask都会部署到TaskManager1的唯一一个slot中，并启动对应的线程。FlatMap[2]、Key-&amp;gt;Sink[2]这些subtask都会被部署到TaskManager2的唯一一个slot中，并启动对应的线程。从而实现了slot共享。&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Flink API中包含一个资源组机制，可以避免不合理的任务槽共享。&lt;br /&gt;
依照以往的经验来说，默认的任务槽数量应设置为CPU core的数量。如果使用超线程技术，每个槽中甚至可以调度处理超过2个硬件线程。&lt;br /&gt;
总结：一个应用需要多少个slot？&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;不设置SlotSharingGroup的情况下：应用的最大并行度。&lt;/li&gt;
  &lt;li&gt;设置了SlotSharingGroup：所有SlotSharingGroup中最大并行度之和。如下图：source时为default，然后在map算子处设置gourp为test，那么这个需要的槽数是10+20=30。&lt;br /&gt;
&lt;img src=&quot;https://github.com/leafming/bak/blob/master/images/flink/2018-10-10-slot和并行度关系.png?raw=true&quot; alt=&quot;2018-10-10-slot和并行度关系&quot; /&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;state-backends&quot;&gt;State Backends&lt;/h2&gt;
&lt;p&gt;通过键值对索引的数据结构保存在指定的后端存储(State Backends)中。有的后端存储将数据保存在内存中的哈希表中，而有的存储会使用RocksDB来保存键值对。除了定义保存状态的数据结构之外，后端存储还实现了获取键值对的特定时间点快照的功能，该功能可以将快照保存为检查点的一部分。&lt;br /&gt;
&lt;img src=&quot;https://ci.apache.org/projects/flink/flink-docs-release-1.6/fig/checkpoints.svg&quot; alt=&quot;State Backends官网图片&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;保存点-savepoints&quot;&gt;保存点-Savepoints&lt;/h2&gt;
&lt;p&gt;使用Data Stream API的程序可以从指定的保存点恢复。保存点可以更新程序和Flink集群，并且不丢失任何状态的功能。也就是相对于checkpoint来比较，checkpoint是针对于内部的，savepoint是针对于外部的。SparkStreaming中，如果使用了checkpoint，流处理程序有更新的话，进行程序替换需要清理调checkpoint才能生效，而在flink中，可以在流处理程序更新后，手动添加savepoint，那么新程序能从savepoint的地方开始读取数据，能与老程序并行存在或者直接替换。&lt;br /&gt;
保存点可以看作是一种手动触发的检查点，该检查点可以获取程序的快照并将其写入后端存储（State Backend）中。所以说保存点的功能依赖于一般的检查点机制。程序执行时会定期在worker节点生成快照和检查点（checkpoint）。由于Flink的恢复机制只需要使用最新一个有效的检查点（checkpoint），在新的检查点（checkpoint）生成后就可以安全移除其余旧的检查点（checkpoint）了。&lt;br /&gt;
保存点（savepoint）和定期检查点（checkpoint）在大部分情况下都很相似，区别只在于保存点是由用户触发的，并且在新的检查点生成后不会自动过期失效。保存点可以通过命令行生成，也可以在调用&lt;a href=&quot;https://ci.apache.org/projects/flink/flink-docs-release-1.6/monitoring/rest_api.html#cancel-job-with-savepoint&quot;&gt;REST API&lt;/a&gt;取消作业时产生。&lt;br /&gt;
关于Savepoints的详细说明，可见官网&lt;a href=&quot;https://ci.apache.org/projects/flink/flink-docs-release-1.6/ops/state/savepoints.html#savepoints&quot;&gt;Savepoints&lt;/a&gt;。&lt;/p&gt;

&lt;h2 id=&quot;总结&quot;&gt;总结&lt;/h2&gt;
&lt;p&gt;Flink中计算资源的相关，最核心的是 Task Slot，每个slot能运行一个或多个task。为了更高效地运行，Flink提出了Chaining，尽可能地将operators chain在一起作为一个task来处理。为了资源更充分的利用，Flink又提出了SlotSharingGroup，尽可能地让多个task共享一个slot。&lt;/p&gt;

&lt;hr /&gt;
&lt;p&gt;至此，本篇内容完成。&lt;/p&gt;</content><author><name>叶子  ( ˘ ³˘)♥</name></author><category term="Flink" /><summary type="html">本文所用flink版本为1.6，官方文档链接Apache Flink 1.6，本文所参考的文档均在正文中每个部分直接详细指出了，就不再汇总了。</summary></entry><entry><title type="html">Flink基础概念</title><link href="http://localhost:4000/bigdata/2018/09/05/Flink%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5/" rel="alternate" type="text/html" title="Flink基础概念" /><published>2018-09-05T00:00:00+08:00</published><updated>2018-09-05T00:00:00+08:00</updated><id>http://localhost:4000/bigdata/2018/09/05/Flink%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5</id><content type="html" xml:base="http://localhost:4000/bigdata/2018/09/05/Flink%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5/">&lt;blockquote&gt;
  &lt;p&gt;项目说要做创新活动，所以需要把原来的流处理从Spark替换成Flink。嗯，学习Flink！本文所用flink版本为1.6。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h1 id=&quot;flink基础概念&quot;&gt;Flink基础概念&lt;/h1&gt;
&lt;h2 id=&quot;程序和数据流-programs-and-dataflows&quot;&gt;程序和数据流-Programs and Dataflows&lt;/h2&gt;
&lt;p&gt;官网地址：&lt;a href=&quot;https://ci.apache.org/projects/flink/flink-docs-release-1.6/concepts/programming-model.html#programs-and-dataflows&quot;&gt;Programs and Dataflows&lt;/a&gt;。&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Flink基本构建块：
    &lt;ul&gt;
      &lt;li&gt;Streams-中间结果&lt;/li&gt;
      &lt;li&gt;Transformations-以一个或多个stream作为输入的某种operation,输出一个或多个result stream。&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;运行的程序-映射成-Streaming Dataflows&lt;br /&gt;
Dataflow：由一组stream和transformation Operators组成。由一个或多个Source开始，一个或多个Sink结束。Dataflow类似与DAG。&lt;br /&gt;
当编写好的一个Flink程序运行的时候，会被映射成Streaming Dataflow。程序中写的transformation和dataflow中的operator关系一般1:1，也可能1:n。&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;并行数据流-parallel-dataflows&quot;&gt;并行数据流-Parallel Dataflows&lt;/h2&gt;
&lt;p&gt;官网地址：&lt;a href=&quot;https://ci.apache.org/projects/flink/flink-docs-release-1.6/concepts/programming-model.html#parallel-dataflows&quot;&gt;Parallel Dataflows&lt;/a&gt;。&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;程序在Flink内部的执行具有并行、分布式的特性：
    &lt;ul&gt;
      &lt;li&gt;stream-被分割成stream partition：一个Stream可以被分成多个Stream分区（Stream Partitions）。&lt;/li&gt;
      &lt;li&gt;operator-被分割成operator subtask：一个Operator可以被分成多个Operator Subtask，每一个Operator Subtask是在不同的线程中独立执行的。&lt;/li&gt;
    &lt;/ul&gt;

    &lt;p&gt;一个Operator的并行度=Operator Subtask的个数&lt;br /&gt;
 一个Stream的并行度=生成它的Operator的并行度（The parallelism of a stream is always that of its producing operator.）&lt;br /&gt;
 一个程序中，不同的operator可能具有不同的并行度。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;数据传输形式&lt;br /&gt;
Stream在operator之间传输数据的形式可以是one-to-one(forwarding)的模式也可以是redistributing的模式。&lt;br /&gt;
官网示例图：&lt;br /&gt;
&lt;img src=&quot;https://ci.apache.org/projects/flink/flink-docs-release-1.6/fig/parallel_dataflow.svg&quot; alt=&quot;数据流&quot; /&gt;
    &lt;ul&gt;
      &lt;li&gt;One-to-one模式：One-to-one streams保持着分区以及元素的顺序。比如从Source[1]到map()[1]，它保持了Source的分区特性（Partitioning）和分区内元素处理的有序性，也就是说map()[1]的Subtask看到数据流中记录的顺序，与Source[1]中看到的记录顺序是一致的。&lt;/li&gt;
      &lt;li&gt;Redistribution模式：Redistributing streams 的分区会发生改变，改变了输入数据流的分区。比如从map()[1]、map()[2]到keyBy()/window()/apply()[1]、keyBy()/window()/apply()[2]，每个上游的operator subtask向下游的多个不同的subtasks发送数据，这与选择的transformation有关（比如说keyBy() （基于hash码重分区），broadcast()或者rebalance()（随机redistribution））。在一个redistribution的交换中，只有每一对的发送、接收subtask间的elements顺序才会被维持（比如说，subtask[1] of map() and subtask[2] of keyBy/window）。So in this example, the ordering within each key is preserved, but the parallelism does introduce non-determinism regarding the order in which the aggregated results for different keys arrive at the sink。&lt;/li&gt;
    &lt;/ul&gt;

    &lt;p&gt;并且在本例中，Source Operator对应2个Subtask，所以并行度为2，而Sink Operator的Subtask只有1个，故而并行度为1。&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;窗口-windows&quot;&gt;窗口-Windows&lt;/h2&gt;
&lt;p&gt;官网地址：&lt;a href=&quot;https://ci.apache.org/projects/flink/flink-docs-release-1.6/concepts/programming-model.html#windows&quot;&gt;Windows&lt;/a&gt;。&lt;br /&gt;
窗口可以是时间驱动的（比如，每30秒）也可以是数据驱动的（比如，每100个元素）。通常我们将窗口划分为：tumbing windows(不重叠)，sliding windows（有重叠）和session windows(有空隙的活动)。&lt;/p&gt;
&lt;h2 id=&quot;时间-time&quot;&gt;时间-Time&lt;/h2&gt;
&lt;p&gt;官网地址：&lt;a href=&quot;https://ci.apache.org/projects/flink/flink-docs-release-1.6/concepts/programming-model.html#time&quot;&gt;Time&lt;/a&gt;。&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Event Time：事件的创建时间，通常通过事件中的一个时间戳来描述。&lt;/li&gt;
  &lt;li&gt;Ingestion time：事件进入Flink 数据流的source的时间。&lt;/li&gt;
  &lt;li&gt;Processing Time：Processing Time表示某个Operator对事件进行处理时的本地系统时间（是在TaskManager节点上）。&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;有状态的数据操作-stateful-operations&quot;&gt;有状态的数据操作-Stateful Operations&lt;/h2&gt;
&lt;p&gt;官网地址：&lt;a href=&quot;https://ci.apache.org/projects/flink/flink-docs-release-1.6/concepts/programming-model.html#stateful-operations&quot;&gt;Stateful Operations&lt;/a&gt;。&lt;br /&gt;
在流处理中，有些操作仅仅在某一时间针对单一事件（如事件转换map），有些操作需要记住多个事件的信息并进行处理（window operators），则后面这些操作称为有状态的操作。&lt;br /&gt;
有状态的操作，其状态被维护的地方，可以将其看作是一个内嵌的key/value存储器。这些状态信息会跟数据流一起分区并且分布存储，并且可以通过有状态的数据操作来访问。因此这些key/value的状态信息仅在keyed streams（通过keyBy() 函数处理过）中才能访问到，并且只能根据当前事件的key来访问其值。数据流按照key排列能保证所有的状态更新都是本地操作，保证一致性且无事务问题。同时这种排列方式使Flink能够透明的再分发状态信息和调整数据流分区。&lt;br /&gt;
关于Flink有状态的流的工作，可以详细参考文章：&lt;a href=&quot;https://www.jianshu.com/p/e9a330399b30&quot;&gt;Flink 有状态的流的工作-Working with state&lt;/a&gt;。&lt;/p&gt;

&lt;h2 id=&quot;容错的checkpoint-checkpoints-for-fault-tolerance&quot;&gt;容错的Checkpoint-Checkpoints for Fault Tolerance&lt;/h2&gt;
&lt;p&gt;官网地址：&lt;a href=&quot;https://ci.apache.org/projects/flink/flink-docs-release-1.6/concepts/programming-model.html#checkpoints-for-fault-tolerance&quot;&gt;Checkpoints for Fault Tolerance&lt;/a&gt;。&lt;br /&gt;
Flink 通过流回放（stream replay）和设置检查点（checkpointing）的方式实现容错。&lt;br /&gt;
一个checkpoint关联了输入流中的某个记录和相应状态operators。数据流（a streaming dataflow）可以从checkpoint中进行恢复，通过恢复Operators的状态以及从该checkpoint重放事件，其保证一致性（exactly-once 的处理语义）。 &lt;br /&gt;
Checkpoint的间隔关系到执行时的容错性和恢复时间，也决定了需要被重放的事件数。&lt;/p&gt;

&lt;h2 id=&quot;流上的批处理-batch-on-streaming&quot;&gt;流上的批处理-Batch on Streaming&lt;/h2&gt;
&lt;p&gt;官网地址：&lt;a href=&quot;https://ci.apache.org/projects/flink/flink-docs-release-1.6/concepts/programming-model.html#batch-on-streaming&quot;&gt;Batch on Streaming&lt;/a&gt;。&lt;br /&gt;
Flink把批处理作为特殊的流处理程序来执行，将其看作有界的流（有限数量的元素）。&lt;br /&gt;
DataSet在内部被当作一个流数据，因此上面的适用于流处理的这些概念在批处理中同样适用，除了一些小的不同：&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;容错机制不同：批处理的容错机制不使用checkpoints，恢复机制是通过完整的流重放来实现。这是因为inputs是有界的，它将开销更多地引入到恢复操作上，但另一方面也使得运行时的常规流程代价更低，因为它规避了检查点机制。&lt;/li&gt;
  &lt;li&gt;有状态的Operations数据结构不同：DataSet API的有状态操作API使用简单的内存和堆外内存（in-memory/out-of-core）的数据结构，而不是key/value的索引。&lt;/li&gt;
  &lt;li&gt;DataSet API中引入一种独特的同步的迭代操作（superstep-based），这个仅应用于有界数据流。详见&lt;a href=&quot;https://ci.apache.org/projects/flink/flink-docs-release-1.6/dev/batch/iterations.html#iterations&quot;&gt;Iterations&lt;/a&gt;。&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;
&lt;p&gt;至此，本篇内容完成。&lt;/p&gt;</content><author><name>叶子  ( ˘ ³˘)♥</name></author><category term="Flink" /><summary type="html">项目说要做创新活动，所以需要把原来的流处理从Spark替换成Flink。嗯，学习Flink！本文所用flink版本为1.6。</summary></entry><entry><title type="html">Spark(Streaming)写入数据到文件-关键为根据数据内容输出到不同自定义名称文件(saveAsHadoopFile以及自定义MultipleOutputFormat)</title><link href="http://localhost:4000/bigdata/2018/07/02/Spark-Streaming-%E5%86%99%E5%85%A5%E6%95%B0%E6%8D%AE%E5%88%B0%E6%96%87%E4%BB%B6-%E5%85%B3%E9%94%AE%E4%B8%BASpark%E6%A0%B9%E6%8D%AE%E6%95%B0%E6%8D%AE%E5%86%85%E5%AE%B9%E8%BE%93%E5%87%BA%E5%88%B0%E4%B8%8D%E5%90%8C%E8%87%AA%E5%AE%9A%E4%B9%89%E5%90%8D%E7%A7%B0%E6%96%87%E4%BB%B6-saveAsHadoopFile%E4%BB%A5%E5%8F%8A%E8%87%AA%E5%AE%9A%E4%B9%89MultipleOutputFormat/" rel="alternate" type="text/html" title="Spark(Streaming)写入数据到文件-关键为根据数据内容输出到不同自定义名称文件(saveAsHadoopFile以及自定义MultipleOutputFormat)" /><published>2018-07-02T00:00:00+08:00</published><updated>2018-07-02T00:00:00+08:00</updated><id>http://localhost:4000/bigdata/2018/07/02/Spark(Streaming)%E5%86%99%E5%85%A5%E6%95%B0%E6%8D%AE%E5%88%B0%E6%96%87%E4%BB%B6-%E5%85%B3%E9%94%AE%E4%B8%BASpark%E6%A0%B9%E6%8D%AE%E6%95%B0%E6%8D%AE%E5%86%85%E5%AE%B9%E8%BE%93%E5%87%BA%E5%88%B0%E4%B8%8D%E5%90%8C%E8%87%AA%E5%AE%9A%E4%B9%89%E5%90%8D%E7%A7%B0%E6%96%87%E4%BB%B6(saveAsHadoopFile%E4%BB%A5%E5%8F%8A%E8%87%AA%E5%AE%9A%E4%B9%89MultipleOutputFormat)</id><content type="html" xml:base="http://localhost:4000/bigdata/2018/07/02/Spark-Streaming-%E5%86%99%E5%85%A5%E6%95%B0%E6%8D%AE%E5%88%B0%E6%96%87%E4%BB%B6-%E5%85%B3%E9%94%AE%E4%B8%BASpark%E6%A0%B9%E6%8D%AE%E6%95%B0%E6%8D%AE%E5%86%85%E5%AE%B9%E8%BE%93%E5%87%BA%E5%88%B0%E4%B8%8D%E5%90%8C%E8%87%AA%E5%AE%9A%E4%B9%89%E5%90%8D%E7%A7%B0%E6%96%87%E4%BB%B6-saveAsHadoopFile%E4%BB%A5%E5%8F%8A%E8%87%AA%E5%AE%9A%E4%B9%89MultipleOutputFormat/">&lt;blockquote&gt;
  &lt;p&gt;之前的Spark实时流处理的数据处理程序，要求把数据从kafka接收之后，分2路分别写入kafka和hdfs，写入kafka的部分之前已经有过总结，现在回过头来把之前的写入HDFS的地方重新总结一下，整个过程从头到尾有一个写入方式的优化，不过时间有点长啦，尽量描述完整( ˘ ³˘)♥。&lt;br /&gt;
&lt;strong&gt;注意: 本文中使用的版本是spark2.2.1和2.6.0-cdh5.11.0&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h1 id=&quot;背景&quot;&gt;背景&lt;/h1&gt;
&lt;p&gt;在工作中，需要将从kafka收到的数据做一些处理，然后分2路存储到kafka和HDFS中，再供下游进行使用。&lt;br /&gt;
所以，在通过Spark Streaming写入HDFS的时候根据业务需要，最后变革了好多次，才形成了最后的版本。&lt;/p&gt;

&lt;h1 id=&quot;最基础直接方式-直接使用saveastextfile&quot;&gt;最基础直接方式-直接使用saveAsTextFile&lt;/h1&gt;
&lt;p&gt;对于将数据直接存入HDFS或本地文件等，spark提供了现成的算子：&lt;strong&gt;saveAsTextFile&lt;/strong&gt;。&lt;/p&gt;
&lt;div class=&quot;language-scala highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;saveAsTextFile&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;path&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Unit&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;saveAsTextFile&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;path&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;codec&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Class&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;_&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;&amp;lt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;CompressionCodec&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;])&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Unit&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;saveAsTextFile用于将RDD以文本文件的格式存储到文件系统中&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;。&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;不过，直接使用saveAsTextFile有很多需要注意的问题。首先，&lt;strong&gt;saveAsTextFile要求保存的目录之前是没有的，否则会报错。&lt;/strong&gt;所以，最好程序中保存前先判断一下目录是否存在。&lt;strong&gt;下面的代码的例子先没有判断目录是否存在，需要自己调整&lt;/strong&gt;。&lt;br /&gt;
下面我们说一下直接使用saveAsTextFile可能遇到的问题：&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;文件内容会被覆盖掉&lt;br /&gt;
对于初学spark的时候，第一次使用saveAsTextFile，可能会遇到文件内容会被覆盖掉的问题。&lt;br /&gt;
在第一次使用的时候，可能会想要这么写的：
    &lt;div class=&quot;language-scala highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;     &lt;span class=&quot;n&quot;&gt;saveDstream&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;foreachRDD&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;rdd&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
       &lt;span class=&quot;c1&quot;&gt;//EmptyRDD是没有分区的，所以调用partitions.isEmpty是true，所以这样可以避免写空文件
&lt;/span&gt;       &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;rdd&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;partitions&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;isEmpty&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
         &lt;span class=&quot;n&quot;&gt;logInfo&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot; No Data in this batchInterval --------&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
       &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
         &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;start_time&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;System&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;currentTimeMillis&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt;
         &lt;span class=&quot;n&quot;&gt;rdd&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;saveAsTextFile&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;hdfs://cdh5hdfs/savepath&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
         &lt;span class=&quot;n&quot;&gt;competeTime&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;start_time&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;Processed data write to hdfs&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
       &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
     &lt;span class=&quot;o&quot;&gt;})&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
    &lt;p&gt;而一旦实际测试之后，你会发现savepath目录里的文件每次都会被覆盖掉，只保存着最后一次saveAsTextFIle的内容。&lt;br /&gt;
这是因为foreachRDD中使用saveAsTextFile默认保存的文件名就是part-0000_ … part-0000n，每一个rdd都是这样，所以在Spark Streaming程序中，后面的批次数据过来在同一路径下后面的文件可能会覆盖前面的，因此会出现文件内容会被覆盖掉。所以来说，为了避免这个问题，可以在保存的时候在文件夹后面加上时间戳来解决。&lt;/p&gt;
    &lt;div class=&quot;language-scala highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;     &lt;span class=&quot;n&quot;&gt;saveDstream&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;foreachRDD&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;rdd&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
       &lt;span class=&quot;c1&quot;&gt;//EmptyRDD是没有分区的，所以调用partitions.isEmpty是true，所以这样可以避免写空文件
&lt;/span&gt;       &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;rdd&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;partitions&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;isEmpty&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
         &lt;span class=&quot;n&quot;&gt;logInfo&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot; No Data in this batchInterval --------&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
       &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
         &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;start_time&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;System&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;currentTimeMillis&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt;
         &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;curDay&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;=new&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Date&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;start_time&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
         &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;date&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;String&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dateFormat&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;format&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;curDay&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
         &lt;span class=&quot;n&quot;&gt;rdd&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;saveAsTextFile&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;hdfs://cdh5hdfs/savepath/&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;date&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;/&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;start_time&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
         &lt;span class=&quot;n&quot;&gt;competeTime&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;start_time&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;Processed data write to hdfs&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
       &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
     &lt;span class=&quot;o&quot;&gt;})&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
    &lt;p&gt;即：rdd.saveAsTextFile(“hdfs://cdh5hdfs/savepath/”+date+”/”+start_time)，这样写之后，保存的路径会根据当前时间来生成，假设运行到此段程序的时间是“2018-06-30 18:30:20”，那么文件存储的目录就会是“hdfs://cdh5hdfs/savepath/2018-06-30/1530354620”，如下显示：&lt;/p&gt;
    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;dcos@d8pccdsj3[~]$hadoop fs -ls /savepath/2018-06-30/1530354620
Found 8 items
-rw-r--r--   3 test cgroup          0 2018-06-30 18:30 /savepath/2018-06-30/1530354620/_SUCCESS
-rw-r--r--   3 test cgroup 2201736217 2018-06-30 18:30 /savepath/2018-06-30/1530354620/part-00000
-rw-r--r--   3 test cgroup 2201037065 2018-06-30 18:30 /savepath/2018-06-30/1530354620/part-00001
-rw-r--r--   3 test cgroup 2202157942 2018-06-30 18:30 /savepath/2018-06-30/1530354620/part-00002
-rw-r--r--   3 test cgroup 2202523100 2018-06-30 18:30 /savepath/2018-06-30/1530354620/part-00003
-rw-r--r--   3 test cgroup 2202310836 2018-06-30 18:30 /savepath/2018-06-30/1530354620/part-00004
-rw-r--r--   3 test cgroup 2202639458 2018-06-30 18:30 /savepath/2018-06-30/1530354620/part-00005
-rw-r--r--   3 test cgroup 2201906597 2018-06-30 18:30 /savepath/2018-06-30/1530354620/part-00006
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
    &lt;p&gt;这样暂且解决了文件内容会被覆盖掉的问题。不过，这种情况下，我们会发现以日期命名的文件夹2018-06-30下，会根据每个批次生成一个时间戳命名的目录，并且目录下文件名称名称为part-0000n，所以说只是解决了这个还不够，此种方式还有其他需要注意的问题。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;保存文件过多&lt;br /&gt;
使用saveAsTextFile经过以上操作之后，不会再出现文件覆盖的问题。但是，当实际运行后会发现，在sparkStreming程序中使用这种方式，会根据每个批次生成一个时间戳命名的目录，目录太多；并且在目录下会有很多很多文件，名称为part-00000 … part-0000n,这样如果文件太小并且过多，就会浪费hdfs的block空间，需要尽可能把文件大小调整到和block大小差不多为好。&lt;br /&gt;
之所以产生了这么多文件，这是因为在spark运行的时候，spark一般会按照执行task的多少生成多少个文件，spark把数据分成了很多个partation，每个partation对应一个task，一个partation的数据由task来执行保存动作，这样的话，在调用saveAsTextFile的时候，会把每个partation的数据保存为一个part-0000n文件。&lt;br /&gt;
所以，为了把文件保存为一个或较少文件，可以使用coalesce或repartition算子。如果生成一个文件，可以在RDD上调用coalesce(1,true).saveAsTextFile()，意味着做完计算之后将数据汇集到一个分区，然后再执行保存的动作，显然，一个分区，Spark自然只起一个task来执行保存的动作，也就只有一个文件产生了。又或者，可以调用repartition(1)，它其实是coalesce的一个包装，默认第二个参数为true。即：
    &lt;div class=&quot;language-scala highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;rdd&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;coalesce&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;true&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;saveAsTextFile&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;hdfs://cdh5hdfs/savepath/&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;date&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;/&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;start_time&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;//或
//rdd.repartition(1).saveAsTextFile(&quot;hdfs://cdh5hdfs/savepath/&quot;+date+&quot;/&quot;+start_time)
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
    &lt;p&gt;不过这样写，在数据过多的时候有很大的隐患：一般情况下，Spark面对的是大量的数据，并且是并行执行的，在数据过多的时候，如果强行要求最后只有一个分区，必然导致大量的磁盘IO和网络IO产生，并且最终操作的节点的内存也会承受很大考验，可能会出现单节点内存不足的问题或者效率及其低下。因此，有人提出，可以采用HDFS磁盘合并操作，即HDFS的getmerge操作。&lt;/p&gt;
    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;//hadoop fs -getmerge 源路径 目的路径 
hadoop fs -getmerge /hdfs/output   /hdfs2/output.txt
//或者cat &amp;gt;操作
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;不能自定义名称，目录层级太多&lt;br /&gt;
经过以上操作之后，就能把数据写到hdfs中，并且文件数量不会过多了。但是经过以上测试，我们会发现有个问题，为了防止文件内容被覆盖我们使用了时间戳，这样的话相当于生成的是一个不同的目录，在sparkStreming程序中使用这种方式，会根据每个批次生成一个时间戳命名的目录，目录太多；并且在那个目录里面，仍然是part-0000n命名的文件，不能自定义名称。因此，我们就思考能不能从文件名称入手，自定义文件名称而不是目录名称呢？&lt;/li&gt;
&lt;/ol&gt;

&lt;h1 id=&quot;直接使用hdfs-api-append方法测试非生产&quot;&gt;直接使用HDFS API-append方法（测试，非生产）&lt;/h1&gt;
&lt;p&gt;为了实现自定义文件名称、减少目录层级、追加写文件的需要，有文章提示说可以直接调用HDFS的api-append。但是实际上，有资料表明，hadoop的版本1.0.4以后，API中已经有了追加写入的功能，但不建议在生产环境中使用，不过我们也可以测试下。&lt;br /&gt;
如果需要使用此方法，需要修改配置文件，开启此功能，把dfs.support.appen的参数设置为true，不然客户端写入的时候会报错：&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Exception in thread &quot;main&quot; org.apache.hadoop.ipc.RemoteException: java.io.IOException: Append to hdfs not supported. Please refer to dfs.support.append configuration parameter.
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;修改namenode节点上的hdfs-site.xml：&lt;/p&gt;
&lt;div class=&quot;language-xml highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  &lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;  
       &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;dfs.support.append&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;  
       &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;true&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;  
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;或者，可以直接在程序里面代码设置：&lt;/p&gt;
&lt;div class=&quot;language-scala highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;private&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;conf&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Configuration&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;conf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;setBoolean&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;dfs.support.append&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;kc&quot;&gt;true&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;//后续直接使用其创建fs如：
//var fs=FileSystem.get(uri, conf)
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;并且需要注意的是，如果使用append追加写入文件，如果文件不存在，需求先创建。那么如果出现了这样的问题，你可能会直接像如下代码那么写（注意是错误的）：&lt;/p&gt;
&lt;div class=&quot;language-scala highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;path&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;=new&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Path&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;strpath&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;uri&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;URI&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;strpath&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;var&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fs&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;FileSystem&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;get&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;uri&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;conf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(!&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fs&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;exists&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;path&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;fs&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;create&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;path&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;out&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fs&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;path&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;out&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;write&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;record_sum1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;getBytes&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;())&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;这样的话，会报如下错误：&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Exception in thread &quot;main&quot; org.apache.hadoop.ipc.RemoteException: org.apache.hadoop.hdfs.protocol.AlreadyBeingCreatedException: failed to create file /hdfs/testfile/file for DFSClient_-14565853217 on client 132.90.130.101 because current leaseholder is trying to recreate file.
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;通过搜索发现可能和fs句柄有关，因此解决的时候，可以创建完文件之后，关闭流fs，再次获得一次新的fs：&lt;/p&gt;
&lt;div class=&quot;language-scala highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;path&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;=new&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Path&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;strpath&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;uri&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;URI&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;strpath&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;var&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fs&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;FileSystem&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;get&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;uri&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;conf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(!&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fs&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;exists&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;path&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;fs&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;create&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;path&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;fs&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;close&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;fs&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;FileSystem&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;get&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;uri&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;conf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;out&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fs&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;path&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;out&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;write&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;record_sum1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;getBytes&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;())&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;blockquote&gt;
  &lt;p&gt;参考&lt;a href=&quot;https://www.cnblogs.com/byrhuangqiang/p/3926663.html&quot;&gt;Hadoop HDFS文件常用操作及注意事项（更新）遇到的问题2&lt;/a&gt;，&lt;a href=&quot;https://blog.csdn.net/liu0bing/article/details/78951415&quot;&gt;HDFS写入异常:追加文件第
一次抛异常&lt;/a&gt;。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;因此整体的写入HDFS的方法，我们这么写（假设这里测试数据的Iterator[(String,String)]元组，需要写入第二个字段），在spark调用的时候，每cache条写入一次：&lt;/p&gt;
&lt;div class=&quot;language-scala highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;writeToHDFS&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;strpath&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;iter&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Iterator&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;String&lt;/span&gt;,&lt;span class=&quot;kt&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cache&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Int&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Try&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;Unit&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Try&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;var&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;record_sum1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&quot;&lt;/span&gt;   &lt;span class=&quot;c1&quot;&gt;//初始化空串
&lt;/span&gt;    &lt;span class=&quot;k&quot;&gt;var&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;count_sum1&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;     &lt;span class=&quot;c1&quot;&gt;//计数器
&lt;/span&gt;    &lt;span class=&quot;k&quot;&gt;var&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;record&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&quot;&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;path&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;=new&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Path&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;strpath&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;uri&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;URI&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;strpath&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;var&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fs&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;FileSystem&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;get&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;uri&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;conf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(!&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fs&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;exists&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;path&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;fs&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;create&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;path&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;fs&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;close&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;fs&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;FileSystem&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;get&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;uri&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;conf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;out&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fs&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;path&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;while&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;iter&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;hasNext&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;record&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;iter&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;next&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;().&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_2&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;record_sum1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;record&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;\n&quot;&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;count_sum1&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;count_sum1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;
      &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;count_sum1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cache&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;out&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;write&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;record_sum1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;getBytes&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;())&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;record_sum1&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;&quot;&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;count_sum1&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;
      &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(!&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;record_sum1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;isEmpty&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;out&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;write&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;record_sum1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;getBytes&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;())&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;out&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;flush&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;out&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;close&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;fs&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;close&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt;
  &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;在spark程序里面可以直接rdd处这样使用：&lt;/p&gt;
&lt;div class=&quot;language-scala highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;      &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(!&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;rdd&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;isEmpty&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()){&lt;/span&gt;
      &lt;span class=&quot;c1&quot;&gt;//注意这里， 因为不需要返回值，所以用foreachPartition直接落地存储了最好。foreachPartition是collect算子，mapPartitions是transofmation。
&lt;/span&gt;        &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;start_time&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;System&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;currentTimeMillis&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;curDay&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;=new&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Date&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;start_time&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;date&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;String&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dateFormat&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;format&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;curDay&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;rdd&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;foreachPartition&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;iter&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&amp;gt;{&lt;/span&gt;
           &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;strpath&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;hdfs://cdh5hdfs/savepath/&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;date&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;/&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;start_time&lt;/span&gt;
           &lt;span class=&quot;n&quot;&gt;writeToHDFS&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;strpath&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;iter&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;300&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;          
       &lt;span class=&quot;o&quot;&gt;})&lt;/span&gt;       
       &lt;span class=&quot;c1&quot;&gt;//rdd.repartition(1).mapPartitions(iter=&amp;gt;{
&lt;/span&gt;       &lt;span class=&quot;c1&quot;&gt;//   val str=List[String]()
&lt;/span&gt;       &lt;span class=&quot;c1&quot;&gt;//   val strpath=&quot;hdfs://cdh5hdfs/savepath/&quot;+date+&quot;/&quot;+start_time
&lt;/span&gt;       &lt;span class=&quot;c1&quot;&gt;//   writeToHDFS(strpath,iter,300)
&lt;/span&gt;       &lt;span class=&quot;c1&quot;&gt;//   str.iterator
&lt;/span&gt;       &lt;span class=&quot;c1&quot;&gt;// }).collect()
&lt;/span&gt;      &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;这样的话，目录层次就变成了“hdfs://cdh5hdfs/savepath/当前日期/时间戳文件”内容即直接追加写入了以时间戳命名的文件中，减少了目录层级，并且能够自定义文件名称了。
但是使用此种方法，相当于一个partation建立一次HDFS连接，执行起来会特别慢，是否可以考虑向Kafka似的弄个连接池的方式提高效率，但是我没有这样实验，毕竟append被说是测试版本，不建议用于生产。&lt;/p&gt;
&lt;h1 id=&quot;需求更改&quot;&gt;需求更改&lt;/h1&gt;
&lt;p&gt;上面的操作均是是对数据没有任何区分，直接将数据写入文件中。但是，后来我们的需要因为业务需要而有所更改。&lt;br /&gt;
我们处理的数据也是从上游接收过来的，每条数据中都有记录此条数据生成的时间，但是我们实际收到的时间可能较生成有所延迟，所以不仅仅要求需要自定义存储的文件名，而且要根据数据内容（数据内容的生成时间字段），来决定将数据写入到哪个文件夹的哪个文件内。&lt;br /&gt;
比如如数据格式如下所示：&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;0|18610000000|460010000000000|2018|07|28|16-21-35|41003|22002|35004007800300|0000|||||0|||2018-07-28 16:21:35
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;因此，我们根据需求，生成的目录格式需要是：&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;dcos@d8pccdsj3[~]$hadoop fs -ls /savepath/2018-07-28
Found 11 items
drwxr-xr-x   - user1 cgroup          0 2018-07-28 10:42 /savepath/2018-07-28/00
drwxr-xr-x   - user1 cgroup          0 2018-07-28 09:48 /savepath/2018-07-28/01
drwxr-xr-x   - user1 cgroup          0 2018-07-28 09:40 /savepath/2018-07-28/02
drwxr-xr-x   - user1 cgroup          0 2018-07-28 08:54 /savepath/2018-07-28/03
drwxr-xr-x   - user1 cgroup          0 2018-07-28 10:26 /savepath/2018-07-28/04
drwxr-xr-x   - user1 cgroup          0 2018-07-28 10:30 /savepath/2018-07-28/05
drwxr-xr-x   - user1 cgroup          0 2018-07-28 10:38 /savepath/2018-07-28/06
drwxr-xr-x   - user1 cgroup          0 2018-07-28 10:26 /savepath/2018-07-28/07
drwxr-xr-x   - user1 cgroup          0 2018-07-28 10:42 /savepath/2018-07-28/08
drwxr-xr-x   - user1 cgroup          0 2018-07-28 10:42 /savepath/2018-07-28/09
drwxr-xr-x   - user1 cgroup          0 2018-07-28 11:42 /savepath/2018-07-28/10
...
drwxr-xr-x   - user1 cgroup          0 2018-07-28 16:40 /savepath/2018-07-28/16
...
drwxr-xr-x   - user1 cgroup          0 2018-07-29 00:30 /savepath/2018-07-28/23
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;即目录要求为/savepath/日期/小时/文件名，文件名需要辨识当前此文件的写入时间（即系统时间），而目录名称的日期和小时需要根据数据里面的业务时间决定，即上述示例数据的第18个字段，那么上面那条数据就需要放在/savepath/2018-07-28/16目录下的某个文件内（如16-16-06-00）。&lt;br /&gt;
所以来说，根据这个需求，我们是不能直接使用saveAsTextFile的，因为文件名称需要自定义；而也尝试直接用append的时候有很大的麻烦，需要根据每条数据内容来决定放入某个目录和文件，并且数据可能延迟比如说现在10点，能零零散散收到几条3点的数据，所以来说在使用append的时候把每条数据的提取日期等信息处理成了三元组的形式来在writeToHDFS方法里面提取时间决定目录和文件名称，但是使用起来还是很复杂并且处理和写入时间太长，影响实时性，并且append还是测试方法不适合投入生产。因此，最终再寻找了下面的最终方法。&lt;/p&gt;
&lt;h1 id=&quot;最终方法-saveashadoopfile自定义的rddmultipletextoutputformat&quot;&gt;最终方法-saveAsHadoopFile+自定义的RDDMultipleTextOutputFormat&lt;/h1&gt;
&lt;h2 id=&quot;分析&quot;&gt;分析&lt;/h2&gt;
&lt;p&gt;为了解决上述需求，我需要另寻找解决办法。我们还是从spark本身的算子入手，可以先看一下saveAsTextFile的源码：&lt;/p&gt;
&lt;div class=&quot;language-scala highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;cm&quot;&gt;/**
   * Save this RDD as a text file, using string representations of elements.
   */&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;saveAsTextFile&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;path&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Unit&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;withScope&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;// https://issues.apache.org/jira/browse/SPARK-2075
&lt;/span&gt;    &lt;span class=&quot;c1&quot;&gt;// NullWritable is a `Comparable` in Hadoop 1.+, so the compiler cannot find an implicit Ordering for it and will use the default `null`. However, it's a `Comparable[NullWritable]`in Hadoop 2.+, so the compiler will call the implicit `Ordering.ordered` method to create an Ordering for `NullWritable`. That's why the compiler will generate different anonymous classes for `saveAsTextFile` in Hadoop 1.+ and Hadoop 2.+.Therefore, here we provide an explicit Ordering `null` to make sure the compiler generate same bytecodes for `saveAsTextFile`.
&lt;/span&gt;    &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nullWritableClassTag&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;implicitly&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;ClassTag&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;NullWritable&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;]]&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;textClassTag&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;implicitly&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;ClassTag&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;Text&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;]]&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;r&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;this&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mapPartitions&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;iter&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&amp;gt;&lt;/span&gt;
      &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;text&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Text&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;iter&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;map&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&amp;gt;&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;text&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;set&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;toString&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;NullWritable&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;get&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;text&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
      &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;nc&quot;&gt;RDD&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;rddToPairRDDFunctions&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;r&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nullWritableClassTag&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;textClassTag&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;kc&quot;&gt;null&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
      &lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;saveAsHadoopFile&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;TextOutputFormat&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;NullWritable&lt;/span&gt;, &lt;span class=&quot;kt&quot;&gt;Text&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;]](&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;path&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
  &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
  &lt;span class=&quot;cm&quot;&gt;/**
   * Save this RDD as a compressed text file, using string representations of elements.
   */&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;saveAsTextFile&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;path&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;codec&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Class&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;_&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;&amp;lt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;CompressionCodec&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;])&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Unit&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;withScope&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;// https://issues.apache.org/jira/browse/SPARK-2075
&lt;/span&gt;    &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nullWritableClassTag&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;implicitly&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;ClassTag&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;NullWritable&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;]]&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;textClassTag&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;implicitly&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;ClassTag&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;Text&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;]]&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;r&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;this&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mapPartitions&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;iter&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&amp;gt;&lt;/span&gt;
      &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;text&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Text&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;iter&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;map&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&amp;gt;&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;text&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;set&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;toString&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;NullWritable&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;get&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;text&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
      &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;nc&quot;&gt;RDD&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;rddToPairRDDFunctions&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;r&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nullWritableClassTag&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;textClassTag&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;kc&quot;&gt;null&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
      &lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;saveAsHadoopFile&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;TextOutputFormat&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;NullWritable&lt;/span&gt;, &lt;span class=&quot;kt&quot;&gt;Text&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;]](&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;path&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;codec&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
  &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;可以发现，saveAsTextFile函数是依赖于saveAsHadoopFile函数，由于saveAsHadoopFile函数接受PairRDD，所以在saveAsTextFile函数中利用rddToPairRDDFunctions函数转化为(NullWritable,Text)类型的RDD，然后通过saveAsHadoopFile函数实现相应的写操作。&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;参考：&lt;a href=&quot;https://www.jianshu.com/p/4d4a7fdaca5c&quot;&gt;【SparkJavaAPI】Action(6)—saveAsTextFile、saveAsObjectFile&lt;/a&gt;。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;并且我们通过saveAsTextFile的源码看到，可以看出Spark内部写文件方式其实调用的都是Hadoop那一套东西，当saveAsTextFile调用saveAsHadoopFile方法时候，默认OutputFormat使用的是TextOutputFormat[NullWritable, Text]。&lt;br /&gt;
而对于TextOutputFormat，在Hadoop的MapReduce中多文件输出默认就是TextOutputFormat，因此默认输出为part-r-00000和part-r-00001依次递增的文件名，所有Mapreduce作业都输出一组文件，并没有和我们的需求一样，根据文件内容输出多组文件或者把一个数据集分为多个数据集（比如说将一个log里面属于不同业务线的日志分开来输出，并交给相关的业务线，或者像我们这种根据数据时间分文件存储）。而在Hadoop中，Hadoop的多文件输出根据Key或者Value的不同将属于不同的类型记录写到不同的文件中的需求，可以使用MultipleOutputFormat或者MultipleOutputs替换TextOutputFormat来解决。&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;具体可以参考以下文章，虽然文章时间较长了，但是都写的非常好，可以参考学习：&lt;a href=&quot;https://www.iteblog.com/archives/842.html&quot;&gt;“Hadoop多文件输出：MultipleOutputFormat和MultipleOutputs深究(一)”&lt;/a&gt;、&lt;a href=&quot;https://www.iteblog.com/archives/848.html&quot;&gt;“Hadoop多文件输出：MultipleOutputFormat和MultipleOutputs深究(二)”&lt;/a&gt;、&lt;a href=&quot;https://blog.csdn.net/dajuezhao/article/details/5799388&quot;&gt;“Hadoop的MultipleOutputFormat使用”&lt;/a&gt;。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;因此，既然Spark内部写文件方式其实调用的都是Hadoop那一套东西，所以，我们就可以使用saveAsHadoopFile，自定义一个MultipleOutputFormat的OutputFormat类就可以了。&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;题外话：到这里，就可以继续我们下面的工作直接解决问题了，不过看到这里我就有了个疑问，既然saveAsTextFile默认使用TextOutputFormat向hdfs输出文件，但是默认的文件输出文件名称为part-00000和part-00001依次递增的文件名，而hadoop默认输出的是part-r-00000，想知道文件名称是什么时候变化的呢，因此就追踪了一下spark源码学习学习，关于这个问题的源码分析，后续有时间再写文章说明。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;代码编写&quot;&gt;代码编写&lt;/h2&gt;
&lt;p&gt;下面我们开始正式的如何使用spark实现多文件输出，根据文件内容划分文件存储并且自定义文件名称。&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;参考：&lt;a href=&quot;https://blog.csdn.net/qq_19917081/article/details/56841299&quot;&gt;“spark streaming实现根据文件内容自定义文件名并实现文件内容追加”&lt;/a&gt;、&lt;a href=&quot;https://www.iteblog.com/archives/1281.html&quot;&gt;“Spark多文件输出(MultipleOutputFormat)”&lt;/a&gt;。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;saveashadoopfile算子&quot;&gt;saveAsHadoopFile算子&lt;/h3&gt;
&lt;p&gt;首先看看一下&lt;strong&gt;saveAsHadoopFile&lt;/strong&gt;算子的官方说明：&lt;/p&gt;
&lt;div class=&quot;language-scala highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; &lt;span class=&quot;cm&quot;&gt;/**
   * Output the RDD to any Hadoop-supported file system, using a Hadoop `OutputFormat` class supporting the key and value types K and V in this RDD.
   */&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;saveAsHadoopFile&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;F&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;&amp;lt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;OutputFormat&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;K&lt;/span&gt;, &lt;span class=&quot;kt&quot;&gt;V&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;]](&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;path&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;implicit&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fm&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;ClassTag&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;F&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;])&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Unit&lt;/span&gt; 
 &lt;span class=&quot;cm&quot;&gt;/**
   * Output the RDD to any Hadoop-supported file system, using a Hadoop `OutputFormat` class supporting the key and value types K and V in this RDD. Compress the result with the supplied codec.
   */&lt;/span&gt;
 &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;saveAsHadoopFile&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;F&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;&amp;lt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;OutputFormat&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;K&lt;/span&gt;, &lt;span class=&quot;kt&quot;&gt;V&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;]](&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;path&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;codec&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Class&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;_&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;&amp;lt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;CompressionCodec&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;])(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;implicit&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fm&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;ClassTag&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;F&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;])&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Unit&lt;/span&gt; 
&lt;span class=&quot;cm&quot;&gt;/**
   * Output the RDD to any Hadoop-supported file system, using a Hadoop `OutputFormat` class supporting the key and value types K and V in this RDD. Compress with the supplied codec.
   */&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;saveAsHadoopFile&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;path&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;keyClass&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Class&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;_&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;],&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;valueClass&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Class&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;_&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;],&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;outputFormatClass&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Class&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;_&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;&amp;lt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;OutputFormat&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;_&lt;/span&gt;, &lt;span class=&quot;k&quot;&gt;_&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;]],&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;codec&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Class&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;_&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;&amp;lt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;CompressionCodec&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;])&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Unit&lt;/span&gt; 
 &lt;span class=&quot;cm&quot;&gt;/**
   * Output the RDD to any Hadoop-supported file system, using a Hadoop `OutputFormat` class supporting the key and value types K and V in this RDD.
   * @note We should make sure our tasks are idempotent when speculation is enabled, i.e. do not use output committer that writes data directly.
   * There is an example in https://issues.apache.org/jira/browse/SPARK-10063 to show the bad result of using direct output committer with speculation enabled.
   */&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;saveAsHadoopFile&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;path&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;keyClass&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Class&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;_&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;],&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;valueClass&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Class&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;_&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;],&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;outputFormatClass&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Class&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;_&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;&amp;lt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;OutputFormat&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;_&lt;/span&gt;, &lt;span class=&quot;k&quot;&gt;_&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;]],&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;conf&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;JobConf&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;JobConf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;context&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;hadoopConfiguration&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;),&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;codec&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Option&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;Class&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;_&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;&amp;lt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;CompressionCodec&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;]]&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Unit&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;这里我们要使用的算子是:&lt;br /&gt;
&lt;strong&gt;def saveAsHadoopFile(path: String,keyClass: Class[&lt;em&gt;],valueClass: Class[&lt;/em&gt;],outputFormatClass: Class[_ &amp;lt;: OutputFormat[&lt;em&gt;, _]],conf: JobConf = new JobConf(self.context.hadoopConfiguration),codec: Option[Class[&lt;/em&gt; &amp;lt;: CompressionCodec]] = None): Unit&lt;/strong&gt;&lt;br /&gt;
这个算子里需要传入的参数依次是：文件路径、key类型、value类型、outputFormat方式。&lt;br /&gt;
之前用的saveAsTextFile，在&lt;strong&gt;org.apache.spark.rdd.RDD&lt;/strong&gt;类中，而saveAsHadoopFile算子属于&lt;strong&gt;org.apache.spark.rdd.PairRDDFunctions&lt;/strong&gt;类，需要接收的参数是PairRDD，所以我们在使用前需要将原来的rdd做一下map操作，变成(key, value) 形式，这里先不详细说，在最后贴出来的代码之后再说一次。因此，我们暂且定（K，V）类型为classOf[String]、classOf[String]，再之后传入hdfs保存目录、类型，剩下的就是关键的需要传入OutputFormat，按照上面的分析，我们要自定义一个MultipleOutputFormat。&lt;/p&gt;

&lt;h3 id=&quot;multipleoutputformat分析&quot;&gt;MultipleOutputFormat分析&lt;/h3&gt;
&lt;p&gt;下面我们先看一下MultipleOutputFormat的源码：&lt;/p&gt;
&lt;div class=&quot;language-java highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;cm&quot;&gt;/**
 * This abstract class extends the FileOutputFormat, allowing to write the
 * output data to different output files. There are three basic use cases for
 * this class. 
 * Case one: This class is used for a map reduce job with at least one reducer.
 * The reducer wants to write data to different files depending on the actual
 * keys. It is assumed that a key (or value) encodes the actual key (value)
 * and the desired location for the actual key (value).
 * Case two: This class is used for a map only job. The job wants to use an
 * output file name that is either a part of the input file name of the input
 * data, or some derivation of it.
 * Case three: This class is used for a map only job. The job wants to use an
 * output file name that depends on both the keys and the input file name,
 */&lt;/span&gt;
&lt;span class=&quot;nd&quot;&gt;@InterfaceAudience&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;Public&lt;/span&gt;
&lt;span class=&quot;nd&quot;&gt;@InterfaceStability&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;Stable&lt;/span&gt;
&lt;span class=&quot;kd&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;kd&quot;&gt;abstract&lt;/span&gt; &lt;span class=&quot;kd&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;MultipleOutputFormat&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;K&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;V&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;
&lt;span class=&quot;kd&quot;&gt;extends&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;FileOutputFormat&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;K&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;V&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;cm&quot;&gt;/**
   * Create a composite record writer that can write key/value data to different
   * output files
   * @param fs
   *          the file system to use
   * @param job
   *          the job conf for the job
   * @param name
   *          the leaf file name for the output file (such as part-00000&quot;)
   * @param arg3
   *          a progressable for reporting progress.
   * @return a composite record writer
   * @throws IOException
   */&lt;/span&gt;
  &lt;span class=&quot;kd&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;RecordWriter&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;K&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;V&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;getRecordWriter&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;FileSystem&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fs&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;JobConf&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;job&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;String&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Progressable&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;arg3&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;kd&quot;&gt;throws&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;IOException&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;

    &lt;span class=&quot;kd&quot;&gt;final&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;FileSystem&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;myFS&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fs&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;kd&quot;&gt;final&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;String&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;myName&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;generateLeafFileName&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
    &lt;span class=&quot;kd&quot;&gt;final&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;JobConf&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;myJob&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;job&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;kd&quot;&gt;final&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Progressable&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;myProgressable&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;arg3&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;RecordWriter&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;K&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;V&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;

      &lt;span class=&quot;c1&quot;&gt;// a cache storing the record writers for different output files.&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;TreeMap&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;RecordWriter&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;K&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;V&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;recordWriters&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;TreeMap&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;RecordWriter&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;K&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;V&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;();&lt;/span&gt;

      &lt;span class=&quot;kd&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;write&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;K&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;key&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;V&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;value&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;kd&quot;&gt;throws&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;IOException&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;

        &lt;span class=&quot;c1&quot;&gt;// get the file name based on the key&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;String&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;keyBasedPath&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;generateFileNameForKeyValue&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;key&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;value&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;myName&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;

        &lt;span class=&quot;c1&quot;&gt;// get the file name based on the input file name&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;String&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;finalPath&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;getInputFileBasedOutputFileName&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;myJob&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;keyBasedPath&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;

        &lt;span class=&quot;c1&quot;&gt;// get the actual key&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;K&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;actualKey&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;generateActualKey&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;key&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;value&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;V&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;actualValue&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;generateActualValue&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;key&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;value&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;

        &lt;span class=&quot;n&quot;&gt;RecordWriter&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;K&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;V&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rw&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;this&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;recordWriters&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;get&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;finalPath&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;rw&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;kc&quot;&gt;null&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
          &lt;span class=&quot;c1&quot;&gt;// if we don't have the record writer yet for the final path, create&lt;/span&gt;
          &lt;span class=&quot;c1&quot;&gt;// one&lt;/span&gt;
          &lt;span class=&quot;c1&quot;&gt;// and add it to the cache&lt;/span&gt;
          &lt;span class=&quot;n&quot;&gt;rw&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;getBaseRecordWriter&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;myFS&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;myJob&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;finalPath&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;myProgressable&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
          &lt;span class=&quot;k&quot;&gt;this&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;recordWriters&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;put&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;finalPath&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rw&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
        &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;rw&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;write&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;actualKey&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;actualValue&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
      &lt;span class=&quot;o&quot;&gt;};&lt;/span&gt;

      &lt;span class=&quot;kd&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;close&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Reporter&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;reporter&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;kd&quot;&gt;throws&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;IOException&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;Iterator&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;keys&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;this&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;recordWriters&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;keySet&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;().&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;iterator&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;();&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;while&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;keys&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;hasNext&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;())&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
          &lt;span class=&quot;n&quot;&gt;RecordWriter&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;K&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;V&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rw&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;this&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;recordWriters&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;get&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;keys&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;next&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;());&lt;/span&gt;
          &lt;span class=&quot;n&quot;&gt;rw&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;close&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;reporter&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
        &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;this&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;recordWriters&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;clear&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;();&lt;/span&gt;
      &lt;span class=&quot;o&quot;&gt;};&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;};&lt;/span&gt;
  &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
  &lt;span class=&quot;cm&quot;&gt;/**
   * Generate the leaf name for the output file name. The default behavior does not change the leaf file name (such as part-00000) 
   * @param name
   *          the leaf file name for the output file
   * @return the given leaf file name
   */&lt;/span&gt;
  &lt;span class=&quot;kd&quot;&gt;protected&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;String&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;generateLeafFileName&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;String&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;
  &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
  &lt;span class=&quot;cm&quot;&gt;/**
   * Generate the file output file name based on the given key and the leaf file
   * name. The default behavior is that the file name does not depend on the
   * key. 
   * @param key
   *          the key of the output data
   * @param name
   *          the leaf file name
   * @return generated file name
   */&lt;/span&gt;
  &lt;span class=&quot;kd&quot;&gt;protected&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;String&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;generateFileNameForKeyValue&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;K&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;key&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;V&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;value&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;String&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;
  &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
  &lt;span class=&quot;cm&quot;&gt;/**
   * Generate the actual key from the given key/value. The default behavior is that
   * the actual key is equal to the given key 
   * @param key
   *          the key of the output data
   * @param value
   *          the value of the output data
   * @return the actual key derived from the given key/value
   */&lt;/span&gt;
  &lt;span class=&quot;kd&quot;&gt;protected&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;K&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;generateActualKey&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;K&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;key&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;V&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;value&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;key&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;
  &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
  &lt;span class=&quot;cm&quot;&gt;/**
   * Generate the actual value from the given key and value. The default behavior is that
   * the actual value is equal to the given value 
   * @param key
   *          the key of the output data
   * @param value
   *          the value of the output data
   * @return the actual value derived from the given key/value
   */&lt;/span&gt;
  &lt;span class=&quot;kd&quot;&gt;protected&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;V&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;generateActualValue&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;K&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;key&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;V&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;value&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;value&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;
  &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
  &lt;span class=&quot;cm&quot;&gt;/**
   * Generate the outfile name based on a given anme and the input file name. If
   * the {@link JobContext#MAP_INPUT_FILE} does not exists (i.e. this is not for a map only job),
   * the given name is returned unchanged. If the config value for
   * &quot;num.of.trailing.legs.to.use&quot; is not set, or set 0 or negative, the given
   * name is returned unchanged. Otherwise, return a file name consisting of the
   * N trailing legs of the input file name where N is the config value for
   * &quot;num.of.trailing.legs.to.use&quot;. 
   * @param job
   *          the job config
   * @param name
   *          the output file name
   * @return the outfile name based on a given anme and the input file name.
   */&lt;/span&gt;
  &lt;span class=&quot;kd&quot;&gt;protected&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;String&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;getInputFileBasedOutputFileName&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;JobConf&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;job&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;String&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;String&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;infilepath&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;job&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;get&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;MRJobConfig&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;MAP_INPUT_FILE&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;infilepath&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;kc&quot;&gt;null&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
      &lt;span class=&quot;c1&quot;&gt;// if the {@link JobContext#MAP_INPUT_FILE} does not exists,&lt;/span&gt;
      &lt;span class=&quot;c1&quot;&gt;// then return the given name&lt;/span&gt;
      &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;numOfTrailingLegsToUse&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;job&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;getInt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;mapred.outputformat.numOfTrailingLegs&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;numOfTrailingLegsToUse&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
      &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;Path&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;infile&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Path&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;infilepath&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;Path&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;parent&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;infile&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;getParent&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;();&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;String&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;midName&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;infile&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;getName&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;();&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;Path&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;outPath&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Path&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;midName&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;numOfTrailingLegsToUse&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;++)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
      &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;parent&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;kc&quot;&gt;null&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;break&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;midName&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;parent&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;getName&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;();&lt;/span&gt;
      &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;midName&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;length&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;break&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;parent&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;parent&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;getParent&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;();&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;outPath&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Path&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;midName&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;outPath&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;outPath&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;toString&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;();&lt;/span&gt;
  &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
  &lt;span class=&quot;cm&quot;&gt;/**
   * @param fs
   *          the file system to use
   * @param job
   *          a job conf object
   * @param name
   *          the name of the file over which a record writer object will be
   *          constructed
   * @param arg3
   *          a progressable object
   * @return A RecordWriter object over the given file
   * @throws IOException
   */&lt;/span&gt;
  &lt;span class=&quot;kd&quot;&gt;abstract&lt;/span&gt; &lt;span class=&quot;kd&quot;&gt;protected&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;RecordWriter&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;K&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;V&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;getBaseRecordWriter&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;FileSystem&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fs&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;JobConf&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;job&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;String&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Progressable&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;arg3&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;kd&quot;&gt;throws&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;IOException&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;在源码的最开始，我们看到对于MultipleOutputFormat&amp;lt;K, V&amp;gt;的描述，它可以将相似的记录输出到相同的数据集。我们可以看出，在写每条记录之前，MultipleOutputFormat将调用generateFileNameForKeyValue方法来确定需要写入的文件名。&lt;br /&gt;
通过下图源码我们可以看出，在getRecordWriter中，对于文件名称的生成会先调用generateLeafFileName方法，而其只是传入了“name”来生成文件的leaf名称（图中标号1的myName），而此部分传入的name即默认的每个part生成的文件名称（如part-0000，关于这个name的值，也可以继续向父类FileOutputFormat或MultipleOutputs类继续挖掘，找出来为何这个默认值，或者参考后续的关于spark这里的源码说明文档，这里就不说明了）；而之后生成的myName会传入generateFileNameForKeyValue的方法，这个方法接受3个参数，可以根据k、v以及传入的name再次生成一个KeyBasePath即文件名称（图中标号2），之后获取到的KeyBasePath再作为参数传入getInputFileBasedOutputFileName方法生成finalPath。可以看到在默认情况下，我们看到generateLeafFileName方法和generateFileNameForKeyValue的方法均是直接&lt;strong&gt;“return name”&lt;/strong&gt;，因此默认情况下得到name==myName==KeyBasePath，文件的名称即为part-0000。&lt;br /&gt;
&lt;img src=&quot;https://github.com/leafming/bak/blob/master/images/spark/2018-07-26-SparkStreaming写入数据到HDFS-Outputformat方法说明.png?raw=true&quot; alt=&quot;MultipleOutputFormat-文件名称生成&quot; /&gt;&lt;br /&gt;
所以，为了根据内容来确定写入的文件名称，generateLeafFileName只与name有关（后续写个示例中测试一下generateLeafFileName），而generateFileNameForKeyValue与内容key、value、name均有关，所以我们就直接在自己的类中重写generateFileNameForKeyValue方法即可。&lt;br /&gt;
不过，我们需要写入的是文本，所以通常情况下，我们可以直接继承MultipleTextOutputFormat类，来完成实现generateFileNameForKeyValue方法以返回每个输出键/值对的文件名。MultipleTextOutputFormat也是继承的MultipleOutputFormat类，可以在官方文档的说明的&lt;a href=&quot;http://hadoop.apache.org/docs/current/api/org/apache/hadoop/mapred/lib/MultipleTextOutputFormat.html&quot;&gt;MultipleTextOutputFormat&lt;/a&gt;也可以看到类的继承关系。&lt;br /&gt;
MultipleTextOutputFormat的官方描述如下：&lt;/p&gt;
&lt;div class=&quot;language-java highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;cm&quot;&gt;/**
 * This class extends the MultipleOutputFormat, allowing to write the output
 * data to different output files in Text output format.
 */&lt;/span&gt;
&lt;span class=&quot;nd&quot;&gt;@InterfaceAudience&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;Public&lt;/span&gt;
&lt;span class=&quot;nd&quot;&gt;@InterfaceStability&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;Stable&lt;/span&gt;
&lt;span class=&quot;kd&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;kd&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;MultipleTextOutputFormat&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;K&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;V&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;kd&quot;&gt;extends&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;MultipleOutputFormat&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;K&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;V&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;kd&quot;&gt;private&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;TextOutputFormat&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;K&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;V&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;theTextOutputFormat&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kc&quot;&gt;null&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;

  &lt;span class=&quot;nd&quot;&gt;@Override&lt;/span&gt;
  &lt;span class=&quot;kd&quot;&gt;protected&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;RecordWriter&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;K&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;V&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;getBaseRecordWriter&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;FileSystem&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fs&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;JobConf&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;job&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;String&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Progressable&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;arg3&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;kd&quot;&gt;throws&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;IOException&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;theTextOutputFormat&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;kc&quot;&gt;null&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;theTextOutputFormat&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;TextOutputFormat&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;K&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;V&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;();&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;theTextOutputFormat&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;getRecordWriter&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fs&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;job&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;arg3&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
  &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;  
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;它默认能够将以text的格式将数据输出到不同的目录中，我们需要输出的也是文本，只不过是写入目录需要自定义一下，所以我们只需要继承MultipleTextOutputFormat来自定义一个类即可。&lt;/p&gt;
&lt;h3 id=&quot;测试generateleaffilename补充可略过&quot;&gt;测试generateLeafFileName（补充，可略过）&lt;/h3&gt;
&lt;p&gt;上面我们说了MultipleOutputFormat中有两个决定文件名称的方法，generateLeafFileName和generateFileNameForKeyValue，我们在正式代码前，先直接写入文件系统测试下generateLeafFileName，可略过。&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;自定义一个OutputFormat名称为TestMultipleTextOutputFormat。
    &lt;div class=&quot;language-scala highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;package&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;com.ileaf.test&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;java.text.SimpleDateFormat&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;java.util.Date&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;org.apache.hadoop.mapred.lib.MultipleTextOutputFormat&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;TestMultipleTextOutputFormat&lt;/span&gt;  &lt;span class=&quot;k&quot;&gt;extends&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;MultipleTextOutputFormat&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;Any&lt;/span&gt;, &lt;span class=&quot;kt&quot;&gt;Any&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;]{&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;private&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;HOURFORMAT&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;SimpleDateFormat&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;HH-mm-ss&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;private&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;YMDFORMAT&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;SimpleDateFormat&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;yyyy-mm-dd&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;private&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;start_time&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;System&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;currentTimeMillis&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;private&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;curDay&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;=new&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Date&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;start_time&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;private&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fileName&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;HOURFORMAT&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;format&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;curDay&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;private&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dirName&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;YMDFORMAT&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;format&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;curDay&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;override&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;generateLeafFileName&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;={&lt;/span&gt;
 &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;filename&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dirName&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;/&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fileName&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;_&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;
 &lt;span class=&quot;n&quot;&gt;filename&lt;/span&gt;
  &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;spark程序中测试使用
    &lt;div class=&quot;language-scala highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;org.apache.spark.&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;SparkConf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;SparkContext&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;org.apache.spark.rdd.RDD&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;object&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;TestSparkSave&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;main&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;args&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Array&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;])&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Unit&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
 &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sparkConf&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;SparkConf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;().&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;setMaster&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;local&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;setAppName&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;flatMap Demo&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
 &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sc&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;SparkContext&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sparkConf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
 &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rdd&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sc&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;parallelize&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;List&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;0|18610000000|460010000000000|2018|07|21|16-21-35|41003|22002|35004007800300|0000|||||0|||2018-07-21 16:21:35&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt;
   &lt;span class=&quot;s&quot;&gt;&quot;0|18610000001|460010000000001|2018|07|21|15-21-35|41000|22000|35004007800301|0000|||||0|||2018-07-21 15:21:35&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt;
   &lt;span class=&quot;s&quot;&gt;&quot;0|18610000002|460010000000002|2018|07|21|15-20-35|41000|22001|35004007800302|0000|||||0|||2018-07-21 15:20:35&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt;
   &lt;span class=&quot;s&quot;&gt;&quot;0|18610000003|460010000000003|2018|07|21|17-21-35|41001|22002|35004007800303|0000|||||0|||2018-07-21 17:21:35&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;))&lt;/span&gt;
 &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rdd1&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;RDD&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;String&lt;/span&gt;, &lt;span class=&quot;kt&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)]&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;rdd&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;map&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&amp;gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;))&lt;/span&gt;
 &lt;span class=&quot;n&quot;&gt;rdd1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;rapartation&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;saveAsHadoopFile&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;/Users/yeziming/test/saveDir&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;classOf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;classOf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;],&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;classOf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;RDDMultipleTextOutputFormat&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;])&lt;/span&gt;
  &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;然后我们运行一下程序，可以看到生成的文件(日期有点问题。。不管了)：&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;yezm:saveDir yeziming$ ls
2018-24-28    _SUCCESS
yezm:saveDir yeziming$ cd 2018-24-28/
yezm:2018-24-28 yeziming$ ls -l
total 16
-rw-r--r--  1 yeziming  staff  222  7 28 11:24 11-24-44_part-00000
-rw-r--r--  1 yeziming  staff  222  7 28 11:24 11-24-44_part-00001
yezm:2018-24-28 yeziming$ cat 11-24-44_part-00000
0|18610000000|460010000000000|2018|07|21|16-21-35|41003|22002|35004007800300|0000|||||0|||2018-07-21 16:21:35
0|18610000002|460010000000002|2018|07|21|15-20-35|41000|22001|35004007800302|0000|||||0|||2018-07-21 15:20:35
yezm:2018-24-28 yeziming$ cat 11-24-44_part-00001
0|18610000001|460010000000001|2018|07|21|15-21-35|41000|22000|35004007800301|0000|||||0|||2018-07-21 15:21:35
0|18610000003|460010000000003|2018|07|21|17-21-35|41001|22002|35004007800303|0000|||||0|||2018-07-21 17:21:35
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;可以看到，我们文件名称的拼接使用的是“val filename=dirName+”/”+fileName+”_“+name”，因此是时间+name的方式传入的，所以可以看出，name的值果然是part-0000n，后面的数字为partation的标号，所以我们在使用的过程中，也可以留下来默认的name的值的标号来区分不同的partation。&lt;/p&gt;
&lt;h3 id=&quot;正式代码编写&quot;&gt;正式代码编写&lt;/h3&gt;
&lt;p&gt;下面，我们开始根据业务的正式的代码编写，经过了以上分析，写起来也很简单。(业务需求见上述4需求更改部分)&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;SparkStreaming程序中使用saveAsHadoopFile&lt;br /&gt;
我们在SparkStreaming程序中，使用saveAsHadoopFile算子。由于之前的数据是rdd，而saveAsHadoopFile需要的是pairRDD，因此，我们使用map将数据转换一下，数据内容作为key，空串“”作为value，这里需要与后续我们自定义的RDDMultipleTextOutputFormat生成文件名称的时候相对应。&lt;br /&gt;
后续我们自定义的RDDMultipleTextOutputFormat，与文件基础路径、key格式、value格式一同传入saveAsHadoopFile算子中。
    &lt;div class=&quot;language-scala highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;//...部分内容
&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;saveDstream&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;DStream&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;writeDStrem&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;repartition&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;numHdfsFile_Repartition&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
 &lt;span class=&quot;c1&quot;&gt;//保存处理后的数据到hdfs
&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;saveDstream&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;foreachRDD&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;rdd&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
   &lt;span class=&quot;c1&quot;&gt;// driver端运行，涉及操作：广播变量的初始化和更新
&lt;/span&gt;   &lt;span class=&quot;c1&quot;&gt;// 这里的数据就是一个批次生成一次，然后下发到不同的patition的时候数据是一样的
&lt;/span&gt;   &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;start_time&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;System&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;currentTimeMillis&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt;
   &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;rdd&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;isEmpty&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
     &lt;span class=&quot;n&quot;&gt;logInfo&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot; No Data in this batchInterval --------&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
   &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
     &lt;span class=&quot;c1&quot;&gt;//这里，因为saveAsHadoopFile需要接受pairRDD，所以用map转换一下
&lt;/span&gt;     &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;RDD&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;String&lt;/span&gt;, &lt;span class=&quot;kt&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)]&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;rdd&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;map&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&amp;gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;))&lt;/span&gt;
     &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;saveAsHadoopFile&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;hdfsPath&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;/&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;classOf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;classOf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;],&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;classOf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;RDDMultipleTextOutputFormat&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;])&lt;/span&gt;
     &lt;span class=&quot;n&quot;&gt;competeTime&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;start_time&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;Processed data write to hdfs&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
   &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
 &lt;span class=&quot;o&quot;&gt;})&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;//foreachRDD
//...
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;自定义RDDMultipleTextOutputFormat继承MultipleTextOutputFormat[Any, Any]&lt;br /&gt;
因为我们这里继承的是MultipleTextOutputFormat，已经帮我把getRecordWriter重写好了，所以我们就很方便简单的重写一个generateFileNameForKeyValue，来根据数据内容划分文件目录就好了。
    &lt;div class=&quot;language-scala highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;java.text.SimpleDateFormat&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;java.util.Date&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;org.apache.hadoop.mapred.lib.MultipleTextOutputFormat&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;RDDMultipleTextOutputFormat&lt;/span&gt;  &lt;span class=&quot;k&quot;&gt;extends&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;MultipleTextOutputFormat&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;Any&lt;/span&gt;, &lt;span class=&quot;kt&quot;&gt;Any&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;]{&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;private&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pre_flag&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;\\|&quot;&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;private&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;HOURFORMAT&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;SimpleDateFormat&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;HH-mm-ss&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;private&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;start_time&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;System&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;currentTimeMillis&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;private&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;curDay&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;=new&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Date&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;start_time&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;private&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fileName&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;HOURFORMAT&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;format&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;curDay&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;override&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;generateFileNameForKeyValue&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;key&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Any&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;value&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Any&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;String&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;={&lt;/span&gt;
 &lt;span class=&quot;c1&quot;&gt;//0|18610000000|460010000000000|2018|07|21|16-21-35|41003|22002|35004007800300|0000|||||0|||2018-07-21 16:21:35
&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;line&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;key&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;toString&lt;/span&gt;
 &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;split&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;line&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;split&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pre_flag&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
 &lt;span class=&quot;c1&quot;&gt;//2018-01-24 12:58:16:@TODO 这里有个问题：如果time是空可能会报错，有时间再处理，目前此字段经过之前处理都非空
&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;time&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;split&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;18&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
 &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ymd&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;time&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;substring&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;time&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;indexOf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot; &quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;))&lt;/span&gt;
 &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;hour&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;time&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;substring&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;time&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;indexOf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot; &quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;time&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;indexOf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;:&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;))&lt;/span&gt;
 &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;service_date&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ymd&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;/&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;hour&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;/&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fileName&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;-&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;substring&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;length&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;//.split(&quot;-&quot;)(0)
&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;service_date&lt;/span&gt;
  &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
    &lt;p&gt;在generateFileNameForKeyValue方法中，我们根据上面用map转换的“rdd.map(x=&amp;gt;(x,””))”，则key为数据内容。所以对key进行切分，取第18个字段的日期来作为目录生成的依据。并且我们截取默认name的后两位，来作为partation编号，所以我们最后生成的文件路径名为“文件基础路径（即上述saveAsHadoopFile中传入的hdfsPath）/业务年月日/业务小时/文件写入时间_part编号”。&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;所以，最终显示样式可如下：&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;//这次就是数据有延迟，12:12才写入12点目录中
dcos@d8pccdsj3[~]$hadoop fs -ls /encrypt_data/4g_info_c60/2018-07-28/12
Found 40 items
-rw-r--r--   3 user1 cgroup    6541003 2018-07-28 12:12 /encrypt_data/4g_info_c60/2018-07-28/12/12-12-05-00
-rw-r--r--   3 user1 cgroup    6555677 2018-07-28 12:12 /encrypt_data/4g_info_c60/2018-07-28/12/12-12-05-01
-rw-r--r--   3 user1 cgroup    6538441 2018-07-28 12:12 /encrypt_data/4g_info_c60/2018-07-28/12/12-12-05-02
-rw-r--r--   3 user1 cgroup    6567709 2018-07-28 12:12 /encrypt_data/4g_info_c60/2018-07-28/12/12-12-05-03
-rw-r--r--   3 user1 cgroup    6570481 2018-07-28 12:12 /encrypt_data/4g_info_c60/2018-07-28/12/12-12-05-04
-rw-r--r--   3 user1 cgroup   29486262 2018-07-28 12:12 /encrypt_data/4g_info_c60/2018-07-28/12/12-12-22-00
-rw-r--r--   3 user1 cgroup   29477123 2018-07-28 12:12 /encrypt_data/4g_info_c60/2018-07-28/12/12-12-22-01
-rw-r--r--   3 user1 cgroup   29476448 2018-07-28 12:12 /encrypt_data/4g_info_c60/2018-07-28/12/12-12-22-02
-rw-r--r--   3 user1 cgroup   29425074 2018-07-28 12:12 /encrypt_data/4g_info_c60/2018-07-28/12/12-12-22-03
-rw-r--r--   3 user1 cgroup   29435407 2018-07-28 12:12 /encrypt_data/4g_info_c60/2018-07-28/12/12-12-22-04
-rw-r--r--   3 user1 cgroup   66757368 2018-07-28 12:12 /encrypt_data/4g_info_c60/2018-07-28/12/12-12-43-00
-rw-r--r--   3 user1 cgroup   66862913 2018-07-28 12:12 /encrypt_data/4g_info_c60/2018-07-28/12/12-12-43-01
-rw-r--r--   3 user1 cgroup   66854597 2018-07-28 12:12 /encrypt_data/4g_info_c60/2018-07-28/12/12-12-43-02
-rw-r--r--   3 user1 cgroup   66809042 2018-07-28 12:12 /encrypt_data/4g_info_c60/2018-07-28/12/12-12-43-03
-rw-r--r--   3 user1 cgroup   66777279 2018-07-28 12:12 /encrypt_data/4g_info_c60/2018-07-28/12/12-12-43-04
-rw-r--r--   3 user1 cgroup   73288280 2018-07-28 12:13 /encrypt_data/4g_info_c60/2018-07-28/12/12-13-03-00
-rw-r--r--   3 user1 cgroup   73285173 2018-07-28 12:13 /encrypt_data/4g_info_c60/2018-07-28/12/12-13-03-01
-rw-r--r--   3 user1 cgroup   73355198 2018-07-28 12:13 /encrypt_data/4g_info_c60/2018-07-28/12/12-13-03-02
-rw-r--r--   3 user1 cgroup   73337561 2018-07-28 12:13 /encrypt_data/4g_info_c60/2018-07-28/12/12-13-03-03
-rw-r--r--   3 user1 cgroup   73320851 2018-07-28 12:13 /encrypt_data/4g_info_c60/2018-07-28/12/12-13-03-04
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;大功告成！&lt;/p&gt;

&lt;h1 id=&quot;补充-需求2实现-validateoutputspecs参数-2018-09-03&quot;&gt;补充-需求2实现-validateOutputSpecs参数-2018-09-03&lt;/h1&gt;
&lt;h2 id=&quot;需求描述&quot;&gt;需求描述&lt;/h2&gt;
&lt;p&gt;数据从很多接口接入，每条数据的第一个字段标明接口来源，需使用spark streaming程序，实时根据将数据根据不同的接口标注，写入到HDFS对应的目录的对应文件之中。&lt;br /&gt;
数据样式：&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;60,2018-08-14 10:16:50.062211990,2018-08-14 10:17:28.652398109,0,6......
61,2018-08-14 10:16:47.095155954,2018-08-14 10:17:21.435997962,0,52......
62,2018-08-14 10:17:05.457761049,2018-08-14 10:17:28.077723979,0,6......
...
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;h2 id=&quot;解决&quot;&gt;解决&lt;/h2&gt;
&lt;p&gt;此需求跟上述问题解决方案一摸一样，也是重写自己的RDDMultipleTextOutputFormat即可。代码示例如下:&lt;/p&gt;
&lt;h3 id=&quot;重写的rddmultipletextoutputformat&quot;&gt;重写的RDDMultipleTextOutputFormat&lt;/h3&gt;
&lt;div class=&quot;language-scala highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;java.text.SimpleDateFormat&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;java.util.Date&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;org.apache.hadoop.mapred.lib.MultipleTextOutputFormat&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;RDDMultipleTextOutputFormat&lt;/span&gt;  &lt;span class=&quot;k&quot;&gt;extends&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;MultipleTextOutputFormat&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;Any&lt;/span&gt;, &lt;span class=&quot;kt&quot;&gt;Any&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;]{&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;private&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;final&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;PREFLAG&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;,&quot;&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;private&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;final&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;YMDFORMAT&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;SimpleDateFormat&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;yyyyMMdd&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;private&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;final&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;YMDHMFORMAT&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;=new&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;SimpleDateFormat&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;yyyyMMddHHmm&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;private&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cur_time&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;System&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;currentTimeMillis&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;private&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;curDay&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;=new&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Date&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cur_time&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;private&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dirName&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;YMDFORMAT&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;format&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;curDay&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;private&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fileName&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;YMDHMFORMAT&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;format&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;curDay&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;private&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;filePrefix&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;xx-xxxxx-events-&quot;&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;private&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fileSuffix&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;.txt&quot;&lt;/span&gt;

  &lt;span class=&quot;k&quot;&gt;override&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;generateFileNameForKeyValue&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;key&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Any&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;value&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Any&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;String&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;={&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;line&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;key&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;toString&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;split&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;line&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;split&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;PREFLAG&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;filePath&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dirName&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;/&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;filePrefix&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;split&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)+&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;-&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fileName&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;substring&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;length&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)+&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fileSuffix&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;filePath&lt;/span&gt;
  &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;h3 id=&quot;本机测试调用&quot;&gt;本机测试调用&lt;/h3&gt;
&lt;div class=&quot;language-scala highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;org.apache.spark.&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;SparkConf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;SparkContext&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;org.apache.spark.rdd.RDD&lt;/span&gt;
&lt;span class=&quot;cm&quot;&gt;/**
  * Create by Liv on 2018/8/31.
  */&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;object&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;TestXXOriFile&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;main&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;args&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Array&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;])&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Unit&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sparkConf&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;SparkConf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;().&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;setMaster&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;local&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;setAppName&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;flatMap Demo&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;cm&quot;&gt;/*
    不设置此参数，会报错：
    Exception in thread &quot;main&quot; org.apache.hadoop.mapred.FileAlreadyExistsException: Output directory file:/Users/yeziming/test/xxdata already exists
    此参数含义：
    若设置为true，saveAsHadoopFile会验证输出目录是否存在。
    虽然设为false可以忽略文件存在的异常，但建议使用 Hadoop文件系统的API手动删除输出目录。
    当通过Spark Streaming的StreamingContext时本参数会被忽略，因为当进行checkpoint恢复时会重写已经存在的文件。
    */&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;sparkConf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;set&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;spark.hadoop.validateOutputSpecs&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;false&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sc&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;SparkContext&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sparkConf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fileName&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;/Users/yeziming/IdeaProjects/SparkAclKafka/resource/table_data.properties&quot;&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rdd&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;RDD&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sc&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;textFile&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fileName&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pairRdd&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;RDD&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;String&lt;/span&gt;, &lt;span class=&quot;kt&quot;&gt;Null&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)]&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rdd&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;map&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&amp;gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;null&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;))&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;pairRdd&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;repartition&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;saveAsHadoopFile&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;/Users/yeziming/test/xxdata&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;/&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;classOf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;],&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;classOf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;],&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;classOf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;RDDMultipleTextOutputFormat&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;])&lt;/span&gt;
  &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;为了测试RDDMultipleTextOutputFormat的文件目录格式写的是否正确，所以在本机使用sparkcore写spark程序测试了一下，但是在测试的过程中，在最初的时候，没有设置spark.hadoop.validateOutputSpecs，因此每次执行一次之后，如果不删除原来的目录，则会报错如下：&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Exception in thread &quot;main&quot; org.apache.hadoop.mapred.FileAlreadyExistsException: Output directory file:/Users/yeziming/test/xxdata already exists
	at org.apache.hadoop.mapred.FileOutputFormat.checkOutputSpecs(FileOutputFormat.java:132)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;是因为在spark中也是用的hadoop那一套，所以原来mr中保存文件的时候，其中的org.apache.hadoop.mapred.FileOutputFormat.checkOutputSpecs方法会检查输出目录是否合法，如果没有指定，则抛出InvalidJobConfException，文件已经存在则抛出FileAlreadyExistsException。&lt;br /&gt;
因此，因为再次执行，目录是存在的，所以会报出FileAlreadyExistsException的错误。&lt;br /&gt;
可是之前直接通过spark streaming程序的时候，并没有出现这个错误。查询这个错误怎么解决的时候，大部分都说自己删除目录即可。后来通过查询spark的参数设置，发现了“spark.hadoop.validateOutputSpecs”这个参数。其说明如下：&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;spark.hadoop.validateOutputSpecs
默认是true。若设置为true，saveAsHadoopFile会验证输出目录是否存在。虽然设为false可以忽略文件存在的异常，但建议使用 Hadoop文件系统的API手动删除输出目录。当通过Spark Streaming的StreamingContext时本参数会被忽略，因为当进行checkpoint恢复时会重写已经存在的文件。  
If set to true, validates the output specification (e.g. checking if the output directory already exists) used in saveAsHadoopFile and other variants. This can be disabled to silence exceptions due to pre-existing output directories. We recommend that users do not disable this except if trying to achieve compatibility with previous versions of Spark. Simply use Hadoop's FileSystem API to delete output directories by hand. This setting is ignored for jobs generated through Spark Streaming's StreamingContext, since data may need to be rewritten to pre-existing output directories during checkpoint recovery.
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;所以，我们再用spark streaming程序的时候，不会出现这个问题。&lt;br /&gt;
因此，如果后续使用spark core程序的时候，如果出现了此问题，想要覆盖目录，则可设置此参数。&lt;br /&gt;
注意：文件名称不同，文件是不会覆盖的。&lt;br /&gt;
通过设置了这个参数之后，再次运行我上面写的程序，目录下的文件如下：&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;yezm:20180903 yeziming$ ls
xx-xxxxx-events-60-20180903132300.txt
xx-xxxxx-events-60-20180903132301.txt
xx-xxxxx-events-60-20180903132400.txt
xx-xxxxx-events-60-20180903132401.txt
xx-xxxxx-events-60-20180903134300.txt
xx-xxxxx-events-60-20180903134301.txt
xx-xxxxx-events-61-20180903132300.txt
xx-xxxxx-events-61-20180903132301.txt
xx-xxxxx-events-61-20180903132400.txt
xx-xxxxx-events-61-20180903132401.txt
xx-xxxxx-events-61-20180903134300.txt
xx-xxxxx-events-61-20180903134301.txt
...
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;即，我的输出文件是以分钟命名的，所以在不同的分钟运行多次，会在那个目录里面生成多个文件，并不会将文件覆盖。&lt;br /&gt;
但是，一般情况下，是建议不设置这个参数的，因为需要将hdfs中的旧文件删除的话。&lt;br /&gt;
具体spark中删除HDFS目录，有个文章中写了但是没有测试，可以参考&lt;a href=&quot;https://blog.csdn.net/zhouyan8603/article/details/51658950&quot;&gt;spark删除hdfs文件&lt;/a&gt;。&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;至此，本篇内容完成。&lt;br /&gt;
本文由2018-07-02开始建立文档，于2018-07-28整理完成，几乎历时一个月，期间断断续续抽时间整理成文，很有收获。&lt;br /&gt;
2018-09-03更新6补充需求2。&lt;/p&gt;</content><author><name>叶子  ( ˘ ³˘)♥</name></author><category term="Spark" /><category term="HDFS" /><summary type="html">之前的Spark实时流处理的数据处理程序，要求把数据从kafka接收之后，分2路分别写入kafka和hdfs，写入kafka的部分之前已经有过总结，现在回过头来把之前的写入HDFS的地方重新总结一下，整个过程从头到尾有一个写入方式的优化，不过时间有点长啦，尽量描述完整( ˘ ³˘)♥。 注意: 本文中使用的版本是spark2.2.1和2.6.0-cdh5.11.0</summary></entry><entry><title type="html">Kerberos具体实践3-Kerberos与ZK的整合操作</title><link href="http://localhost:4000/bigdata/2018/06/29/Kerberos%E5%85%B7%E4%BD%93%E5%AE%9E%E8%B7%B53-Kerberos%E4%B8%8EZK%E7%9A%84%E6%95%B4%E5%90%88%E6%93%8D%E4%BD%9C/" rel="alternate" type="text/html" title="Kerberos具体实践3-Kerberos与ZK的整合操作" /><published>2018-06-29T00:00:00+08:00</published><updated>2018-06-29T00:00:00+08:00</updated><id>http://localhost:4000/bigdata/2018/06/29/Kerberos%E5%85%B7%E4%BD%93%E5%AE%9E%E8%B7%B53-Kerberos%E4%B8%8EZK%E7%9A%84%E6%95%B4%E5%90%88%E6%93%8D%E4%BD%9C</id><content type="html" xml:base="http://localhost:4000/bigdata/2018/06/29/Kerberos%E5%85%B7%E4%BD%93%E5%AE%9E%E8%B7%B53-Kerberos%E4%B8%8EZK%E7%9A%84%E6%95%B4%E5%90%88%E6%93%8D%E4%BD%9C/">&lt;blockquote&gt;
  &lt;p&gt;本文主要关于Kerberos的简单应用。因为工作测试需要，自己装了一套集群进行了Kerberos的部署，并且与HDFS、ZK进行整合，然后将操作过程进行了整理，以便后续再查看。本文主要涉及到其与ZK的整合操做，此文为2018-06-28文章Kerberos具体实践2的后续。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h1 id=&quot;zookeeper整合kerberos&quot;&gt;Zookeeper整合Kerberos&lt;/h1&gt;
&lt;p&gt;关于zookeeper上配置Kerberos，参考&lt;a href=&quot;https://yq.aliyun.com/articles/25626&quot;&gt;zookeeper配置Kerberos认证&lt;/a&gt;。&lt;/p&gt;
&lt;h2 id=&quot;zookeeper-server配置&quot;&gt;Zookeeper Server配置&lt;/h2&gt;
&lt;p&gt;若hdfs配置过程中需要配置zookeeper与Kerberos结合，则目前先需要配置server即可。&lt;/p&gt;
&lt;h3 id=&quot;创建认证规则并生成keytabzookeeper-server&quot;&gt;创建认证规则并生成keytab（zookeeper-server）&lt;/h3&gt;
&lt;p&gt;zk整合Kerberos需要先创建启动zk用户的认证规则以及keytab，由于本次操作中，zk和hadoop均使用hadoop用户启动，则在本次操作中，不必再需要去创建新的认证规则和keytab，直接使用原来的hdfs.keytab即可。&lt;/p&gt;

&lt;p&gt;补充：&lt;br /&gt;
若有创建需要（如需要使用zookeeper用户启动zk服务），可再继续再次参考下述操作（其实同hdfs的操作）。&lt;br /&gt;
在node1节点，即KDC server节点上执行下面命令，在KCD server上（这里是 node1）创建zookeeper principal：&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;kadmin.local -q &quot;addprinc -randkey zookeeper/node1@HADOOP.COM&quot;   
kadmin.local -q &quot;addprinc -randkey zookeeper/node2@HADOOP.COM&quot;  
kadmin.local -q &quot;addprinc -randkey zookeeper/node3@HADOOP.COM&quot;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;执行如下命令，在当前目录中创建keytab，名为zookeeper.keytab：&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;kadmin.local -q &quot;xst  -k zookeeper.keytab  zookeeper/node1@HADOOP.COM &quot;
kadmin.local -q &quot;xst  -k zookeeper.keytab  zookeeper/node2@HADOOP.COM &quot;
kadmin.local -q &quot;xst  -k zookeeper.keytab  zookeeper/node3@HADOOP.COM &quot;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;h3 id=&quot;部署keytabzookeeper-server&quot;&gt;部署Keytab（zookeeper-server）&lt;/h3&gt;
&lt;p&gt;拷贝node1上生成的keytab(新创建的就是zookeeper.keytab)文件到其他节点的某一目录上（如/opt/zookeeper/conf，为了在zk配置文件种找到keytab），并为其设置属主和权限400（如chown zookeeper:hadoop zookeeper.keytab ;chmod 400 *.keytab），同HDFS配置过程中的操作。&lt;br /&gt;
此次测试中，启动zk和启动hdfs的用户都是hadoop，并且在进行hdfs配置kerberos的过程中，已经将hdfs.keytab复制到其他节点的/opt/hadoop_krb5/conf/hdfs.keytab目录下了，并且也设置了权限所以此次我不再进行操作。&lt;/p&gt;
&lt;h3 id=&quot;修改zookeeper配置文件zookeeper-server&quot;&gt;修改zookeeper配置文件（zookeeper-server）&lt;/h3&gt;
&lt;p&gt;在node1节点上修改/opt/zookeeper-3.4.8/conf/（zookeeper安装目录下的conf）zoo.cfg文件，添加下面内容：&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;authProvider.1=org.apache.zookeeper.server.auth.SASLAuthenticationProvider
jaasLoginRenew=3600000
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;将修改的上面文件同步到其他节点：node2、node3：&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ scp /opt/zookeeper-3.4.8/conf/zoo.cfg node2:/opt/zookeeper-3.4.8/conf/zoo.cfg
$ scp /opt/zookeeper-3.4.8/conf/zoo.cfg node3:/opt/zookeeper-3.4.8/conf/zoo.cfg
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;h3 id=&quot;创建jaas文件zookeeper-server&quot;&gt;创建jaas文件（zookeeper-server）&lt;/h3&gt;
&lt;p&gt;在node1的配置文件目录/opt/zookeeper-3.4.8/conf/（zookeeper安装目录下的conf）创建 jaas.conf文件，内容如下：&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Server {
  com.sun.security.auth.module.Krb5LoginModule required
  useKeyTab=true
  keyTab=&quot;/opt/hadoop_krb5/conf/hdfs.keytab&quot;【上述操作创建出的keytab，因为本次操作中zk用hadoop用户启动的，和hdfs一样，则没用重新生产keytab，和hdfs的用一个】
  storeKey=true
  useTicketCache=false【这里有踩过的一个小坑：如果krb5.conf 去掉了default_ccache_name = KEYRING:persistent:%{uid}，则一定用false，要不然zk起不来】
  principal=&quot;hadoop/node1@HADOOP.COM&quot;;
};
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;其中，keytab填写真实的keytab的绝对路径，principal填写对应的认证的用户和机器名称。需要在 node2和node3节点也创建该文件，注意每个节点的principal有所不同。&lt;/p&gt;
&lt;h3 id=&quot;创建javaenv文件zookeeper-server&quot;&gt;创建java.env文件（zookeeper-server）&lt;/h3&gt;
&lt;p&gt;在node1的配置文件目录/opt/zookeeper-3.4.8/conf/（zookeeper安装目录下的conf）创建 java.env文件，内容如下：&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;export JVMFLAGS=&quot;-Djava.security.auth.login.config=/opt/zookeeper-3.4.8/conf/jaas.conf&quot;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;并将该文件同步到其他节点：&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ scp /opt/zookeeper-3.4.8/conf/java.env node2:/opt/zookeeper-3.4.8/conf/java.env
$ scp /opt/zookeeper-3.4.8/conf/java.env node3:/opt/zookeeper-3.4.8/conf/java.env
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;以上Zookeeper-server配置完毕。&lt;/p&gt;
&lt;h3 id=&quot;重新启动zookeeper&quot;&gt;重新启动zookeeper&lt;/h3&gt;
&lt;p&gt;启动方式和平常无异，如成功使用安全方式启动，日志中看到如下日志：&lt;br /&gt;
2017-09-18 10:23:30,067 … - successfully logged in.&lt;/p&gt;

&lt;h2 id=&quot;zookeeper-client配置未测试&quot;&gt;Zookeeper Client配置（未测试）&lt;/h2&gt;
&lt;h3 id=&quot;创建认证规则生成keytab&quot;&gt;创建认证规则生成keytab&lt;/h3&gt;
&lt;p&gt;在node1节点，即KDC server节点上执行下面命令：&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ cd /var/kerberos/krb5kdc/
kadmin.local -q &quot;addprinc -randkey zkcli/node1@HADOOP.COM &quot;
kadmin.local -q &quot;addprinc -randkey zkcli/node2@HADOOP.COM&quot;
kadmin.local -q &quot;addprinc -randkey zkcli/node3@HADOOP.COM&quot;

kadmin.local -q &quot;xst  -k zkcli.keytab  zkcli/node1@HADOOP.COM&quot;
kadmin.local -q &quot;xst  -k zkcli.keytab  zkcli/node2@HADOOP.COM &quot;
kadmin.local -q &quot;xst  -k zkcli.keytab  zkcli/node3@HADOOP.COM &quot;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;拷贝 zkcli.keytab文件到其他节点的zk配置目录：&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ scp zkcli.keytab node1:/etc/zookeeper/conf
$ scp zkcli.keytab node2:/etc/zookeeper/conf
$ scp zkcli.keytab node3:/etc/zookeeper/conf
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;并设置属主和权限，分别在node1、node2、node3 上执行：&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ ssh node1 &quot;cd /etc/zookeeper/conf/;chown zookeeper:hadoop zkcli.keytab ;chmod 400 *.keytab&quot;
$ ssh node2 &quot;cd /etc/zookeeper/conf/;chown zookeeper:hadoop zkcli.keytab ;chmod 400 *.keytab&quot;
$ ssh node3 &quot;cd /etc/zookeeper/conf/;chown zookeeper:hadoop zkcli.keytab ;chmod 400 *.keytab&quot;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;h3 id=&quot;创建jaas配置文件&quot;&gt;创建jaas配置文件&lt;/h3&gt;
&lt;p&gt;在node1的zk配置文件目录创建 client-jaas.conf 文件，内容如下：&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Client {
  com.sun.security.auth.module.Krb5LoginModule required
  useKeyTab=true
  keyTab=&quot;/etc/zookeeper/conf/zkcli.keytab&quot;
  storeKey=true
  useTicketCache=false
  principal=&quot;zkcli@HADOOP.COM&quot;;
};
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;同步到其他client节点：&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ scp client-jaas.conf node2:/etc/zookeeper/conf
$ scp client-jaas.conf node3:/etc/zookeeper/conf
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;h3 id=&quot;创建javaenv文件&quot;&gt;创建java.env文件&lt;/h3&gt;
&lt;p&gt;然后，在zk安装目录conf目录创建或者修改java.env，内容如下：&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;export CLIENT_JVMFLAGS=&quot;-Djava.security.auth.login.config=/etc/zookeeper/conf/client-jaas.conf&quot;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;blockquote&gt;
  &lt;p&gt;如果，zookeeper-client 和 zookeeper-server 安装在同一个节点上，则 java.env 中的 java.security.auth.login.config 参数会被覆盖，这一点从 zookeeper-client 命令启动日志可以看出来。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;并将该文件同步到其他节点：&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ scp /etc/zookeeper/conf/java.env node2:/etc/zookeeper/conf/java.env
$ scp /etc/zookeeper/conf/java.env node3:/etc/zookeeper/conf/java.env
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;h3 id=&quot;启动并验证&quot;&gt;启动并验证&lt;/h3&gt;
&lt;p&gt;启动客户端：&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ zookeeper-client -server node1:2181
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;创建一个znode 节点：&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;k: node1:2181(CONNECTED) 0] create /znode1 sasl:zkcli@HADOOP.COM:cdwra
    Created /znode1
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;验证该节点是否创建以及其 ACL：&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;[zk: node1:2181(CONNECTED) 1] getAcl /znode1
    'world,'anyone
    : cdrwa
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;以上为ZK整合Kerberos操作部分。&lt;/p&gt;

&lt;hr /&gt;
&lt;p&gt;至此，本篇内容完成。&lt;br /&gt;
以上，此文章是关于ZK结合Kerberos的部署等内容，下篇将补充说明主从KDC的搭建。&lt;/p&gt;</content><author><name>叶子  ( ˘ ³˘)♥</name></author><category term="Kerberos" /><summary type="html">本文主要关于Kerberos的简单应用。因为工作测试需要，自己装了一套集群进行了Kerberos的部署，并且与HDFS、ZK进行整合，然后将操作过程进行了整理，以便后续再查看。本文主要涉及到其与ZK的整合操做，此文为2018-06-28文章Kerberos具体实践2的后续。 Zookeeper整合Kerberos 关于zookeeper上配置Kerberos，参考zookeeper配置Kerberos认证。 Zookeeper Server配置 若hdfs配置过程中需要配置zookeeper与Kerberos结合，则目前先需要配置server即可。 创建认证规则并生成keytab（zookeeper-server） zk整合Kerberos需要先创建启动zk用户的认证规则以及keytab，由于本次操作中，zk和hadoop均使用hadoop用户启动，则在本次操作中，不必再需要去创建新的认证规则和keytab，直接使用原来的hdfs.keytab即可。 补充： 若有创建需要（如需要使用zookeeper用户启动zk服务），可再继续再次参考下述操作（其实同hdfs的操作）。 在node1节点，即KDC server节点上执行下面命令，在KCD server上（这里是 node1）创建zookeeper principal： kadmin.local -q &quot;addprinc -randkey zookeeper/node1@HADOOP.COM&quot; kadmin.local -q &quot;addprinc -randkey zookeeper/node2@HADOOP.COM&quot; kadmin.local -q &quot;addprinc -randkey zookeeper/node3@HADOOP.COM&quot; 执行如下命令，在当前目录中创建keytab，名为zookeeper.keytab： kadmin.local -q &quot;xst -k zookeeper.keytab zookeeper/node1@HADOOP.COM &quot; kadmin.local -q &quot;xst -k zookeeper.keytab zookeeper/node2@HADOOP.COM &quot; kadmin.local -q &quot;xst -k zookeeper.keytab zookeeper/node3@HADOOP.COM &quot; 部署Keytab（zookeeper-server） 拷贝node1上生成的keytab(新创建的就是zookeeper.keytab)文件到其他节点的某一目录上（如/opt/zookeeper/conf，为了在zk配置文件种找到keytab），并为其设置属主和权限400（如chown zookeeper:hadoop zookeeper.keytab ;chmod 400 *.keytab），同HDFS配置过程中的操作。 此次测试中，启动zk和启动hdfs的用户都是hadoop，并且在进行hdfs配置kerberos的过程中，已经将hdfs.keytab复制到其他节点的/opt/hadoop_krb5/conf/hdfs.keytab目录下了，并且也设置了权限所以此次我不再进行操作。 修改zookeeper配置文件（zookeeper-server） 在node1节点上修改/opt/zookeeper-3.4.8/conf/（zookeeper安装目录下的conf）zoo.cfg文件，添加下面内容： authProvider.1=org.apache.zookeeper.server.auth.SASLAuthenticationProvider jaasLoginRenew=3600000 将修改的上面文件同步到其他节点：node2、node3： $ scp /opt/zookeeper-3.4.8/conf/zoo.cfg node2:/opt/zookeeper-3.4.8/conf/zoo.cfg $ scp /opt/zookeeper-3.4.8/conf/zoo.cfg node3:/opt/zookeeper-3.4.8/conf/zoo.cfg 创建jaas文件（zookeeper-server） 在node1的配置文件目录/opt/zookeeper-3.4.8/conf/（zookeeper安装目录下的conf）创建 jaas.conf文件，内容如下： Server { com.sun.security.auth.module.Krb5LoginModule required useKeyTab=true keyTab=&quot;/opt/hadoop_krb5/conf/hdfs.keytab&quot;【上述操作创建出的keytab，因为本次操作中zk用hadoop用户启动的，和hdfs一样，则没用重新生产keytab，和hdfs的用一个】 storeKey=true useTicketCache=false【这里有踩过的一个小坑：如果krb5.conf 去掉了default_ccache_name = KEYRING:persistent:%{uid}，则一定用false，要不然zk起不来】 principal=&quot;hadoop/node1@HADOOP.COM&quot;; }; 其中，keytab填写真实的keytab的绝对路径，principal填写对应的认证的用户和机器名称。需要在 node2和node3节点也创建该文件，注意每个节点的principal有所不同。 创建java.env文件（zookeeper-server） 在node1的配置文件目录/opt/zookeeper-3.4.8/conf/（zookeeper安装目录下的conf）创建 java.env文件，内容如下： export JVMFLAGS=&quot;-Djava.security.auth.login.config=/opt/zookeeper-3.4.8/conf/jaas.conf&quot; 并将该文件同步到其他节点： $ scp /opt/zookeeper-3.4.8/conf/java.env node2:/opt/zookeeper-3.4.8/conf/java.env $ scp /opt/zookeeper-3.4.8/conf/java.env node3:/opt/zookeeper-3.4.8/conf/java.env 以上Zookeeper-server配置完毕。 重新启动zookeeper 启动方式和平常无异，如成功使用安全方式启动，日志中看到如下日志： 2017-09-18 10:23:30,067 … - successfully logged in.</summary></entry><entry><title type="html">Kerberos具体实践4-Kerberos主从KDC部署</title><link href="http://localhost:4000/bigdata/2018/06/29/Kerberos%E5%85%B7%E4%BD%93%E5%AE%9E%E8%B7%B54-Kerberos%E4%B8%BB%E4%BB%8EKDC%E9%83%A8%E7%BD%B2/" rel="alternate" type="text/html" title="Kerberos具体实践4-Kerberos主从KDC部署" /><published>2018-06-29T00:00:00+08:00</published><updated>2018-06-29T00:00:00+08:00</updated><id>http://localhost:4000/bigdata/2018/06/29/Kerberos%E5%85%B7%E4%BD%93%E5%AE%9E%E8%B7%B54-Kerberos%E4%B8%BB%E4%BB%8EKDC%E9%83%A8%E7%BD%B2</id><content type="html" xml:base="http://localhost:4000/bigdata/2018/06/29/Kerberos%E5%85%B7%E4%BD%93%E5%AE%9E%E8%B7%B54-Kerberos%E4%B8%BB%E4%BB%8EKDC%E9%83%A8%E7%BD%B2/">&lt;blockquote&gt;
  &lt;p&gt;本文主要关于Kerberos的简单应用。因为工作测试需要，自己装了一套集群进行了Kerberos的部署，并且与HDFS、ZK进行整合，然后将操作过程进行了整理，以便后续再查看。本文主要涉及Kerberos主从KDC部署，此文为2018-06-29文章Kerberos具体实践3的后续；本文为本系列的最后一篇。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h1 id=&quot;kerberos主从kdc部署&quot;&gt;Kerberos主从KDC部署&lt;/h1&gt;
&lt;p&gt;在进行生产环境中进行Kerberos部署时，最好配置1个master KDC以及多个slave KDC来保证Kerberos服务的可靠性。每个KDC都能够包括一个Kerberos数据库的副本。在master KDC中包含一个可写的realm数据库副本，并且他会定期同步到slave KDC中。所有数据库的更改（如更改密码）都是由master KDC负责。当主KDC不可用，slave KDCs提供Kerberos的票据授予服务，不负责数据库管理。&lt;/p&gt;

&lt;p&gt;规划：&lt;br /&gt;
node1   - master KDC  &lt;br /&gt;
node2  - slave KDC&lt;br /&gt;
-HADOOP.COM - realm name&lt;br /&gt;
.k5.ATHENA.MIT.EDU  - stash file&lt;br /&gt;
root/admin         - admin principal&lt;/p&gt;

&lt;p&gt;主从KDC部署可在远单节点KDC的基础上进行配置更改，配置内容基本与单节点情况相似，关键细节参考上述单节点部署。&lt;br /&gt;
本次操作即，当配置好单节点KDC之后，再其基础上进行更改。&lt;/p&gt;

&lt;h2 id=&quot;准备工作-添加主体&quot;&gt;准备工作-添加主体&lt;/h2&gt;
&lt;p&gt;部署单节点KDC完毕，node1为主KDC，在主KDC服务器上启动kadmin。&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;在主KDC服务器上，向数据库中添加主机主体（如果尚未完成）：&lt;br /&gt;
每个kdc都要有host key在kerberos数据库中。这些keys用于双向认证的时候，从主kdc向从属KDC传播数据库转储文件。&lt;br /&gt;
如果需要将从KDC和主KDC交换的话，要使从KDC服务器正常工作，它必须有主机主体。&lt;br /&gt;
注：当主体实例名为主机名时，无论名称服务中的域名是大写还是小写，都必须以小写字母指定FQDN。
    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;kadmin：addprinc -randkey host/node2
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;在主KDC服务器上，创建kiprop主体。&lt;br /&gt;
kiprop主体用于授权来自主KDC服务器的更新。
    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;kadmin：addprinc -randkey kiprop/node1
kadmin：addprinc -randkey kiprop/node2
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;在node2上安装kerberos-server&quot;&gt;在node2上安装Kerberos-server&lt;/h2&gt;
&lt;p&gt;node2:&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ yum install krb5-server -y 
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;修改配置文件&quot;&gt;修改配置文件&lt;/h2&gt;
&lt;p&gt;kdc 服务器涉及到三个配置文件：&lt;br /&gt;
/etc/krb5.conf&lt;br /&gt;
/var/kerberos/krb5kdc/kdc.conf&lt;br /&gt;
/var/kerberos/krb5kdc/kadm5.acl&lt;/p&gt;
&lt;h3 id=&quot;krb5conf配置-node1&quot;&gt;krb5.conf配置-node1&lt;/h3&gt;
&lt;p&gt;在主KDC服务器（node1）上编辑krb5.conf文件，基本和单节点KDC配置类似，仅在[realms]部分加入slave kdc信息，并且设置admin_server为主kdc即可，如下：&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;#node1上操作krb5.conf，之后再拷贝到其他机器
[realms]
HADOOP.COM = {
  kdc = node1
  kdc = node2
  admin_server = node1
  default_domain = HADOOP.COM
 }
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;配置文件整体示例：&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;[logging]
 default = FILE:/var/log/krb5libs.log
 kdc = FILE:/var/log/krb5kdc.log
 admin_server = FILE:/var/log/kadmind.log

[libdefaults]
 dns_lookup_realm = false
 ticket_lifetime = 24h
 renew_lifetime = 7d
 # forwardable = true
 rdns = false
 default_realm = HADOOP.COM
 udp_preference_limit = 1

[realms]
HADOOP.COM = {
  kdc = node1
  kdc = node2
  admin_server = node1
  #default_domain = HADOOP.COM
 }

[kdc]
 profile=/var/kerberos/krb5kdc/kdc.conf

# [domain_realm]
# .hadoop.com = HADOOP.COM
# hadoop.com = HADOOP.COM
# # if the domain name and realm name are equivalent,
# # this entry is not needed
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;kdcconf配置-node1&quot;&gt;kdc.conf配置-node1&lt;/h3&gt;
&lt;p&gt;在主KDC服务器（node1）上编辑kdc.conf文件，realms部分添加用于增量传播和选择主KDC服务器将在日志中保留的更新数的行。&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;[realms]
HADOOP.COM={
    ...
  iprop_enable = true
  iprop_master_ulogsize = 1000
    ...
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;kadm5acl配置-node1&quot;&gt;kadm5.acl配置-node1&lt;/h3&gt;
&lt;p&gt;在主KDC服务器上，向kadm5.acl添加kiprop项。&lt;br /&gt;
通过此项，主KDC服务器可以接受对kdc2服务器的kerberos数据库增量传播请求。&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;[root@node1 ~]# cat /var/kerberos/krb5kdc/kadm5.acl
root/admin@HADOOP.COM    *
kiprop/node2@HADOOP.COM p
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;在kdc服务器上重启kadmin以使用kadm5acl文件中新的内容&quot;&gt;在KDC服务器上，重启kadmin以使用kadm5.acl文件中新的内容&lt;/h3&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;[root@node1 etc]# service kadmin restart
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;h3 id=&quot;将主kdc服务器上以下文件复制到所有从kdc上&quot;&gt;将主KDC服务器上以下文件复制到所有从KDC上&lt;/h3&gt;
&lt;p&gt;主KDC和从KDC间的数据库扩展，传播的是master的数据库内容的拷贝，而不是配置文件、stash文件或kadm5 ACL文件。
需要在所有的从 KDC 服务器上执行该步骤，因为主 KDC 服务器已经更新了每个 KDC 服务器需要的信息。
因此以下文件必须手动从主KDC拷贝到从KDC的对应目录上。&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;krb5.conf&lt;/li&gt;
  &lt;li&gt;kdc.conf&lt;/li&gt;
  &lt;li&gt;kadm5.acl（kadm5.acl is only needed to allow a slave to swap with the master KDC.）&lt;/li&gt;
  &lt;li&gt;master key stash file&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ scp /etc/krb5.conf node2:/etc/krb5.conf
$ scp /var/kerberos/krb5kdc/kdc.conf node2:/var/kerberos/krb5kdc/kdc.conf
$ scp /var/kerberos/krb5kdc/.k5.HADOOP.COM node2:/var/kerberos/krb5kdc/.k5.HADOOP.COM
#此步骤有人说可以在新的从 KDC 服务器上，使用kdb5_util创建一个存储文件。（需测试）
$ scp /var/kerberos/krb5kdc/kadm5.acl node2:/var/kerberos/krb5kdc/kadm5.acl
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;从主服务器其他配置操作&quot;&gt;从、主服务器其他配置操作&lt;/h2&gt;
&lt;h3 id=&quot;在所有的从kdc服务器上将主kdc服务器和每个从kdc服务器的项添加到数据库传播配置文件kpropdacl中&quot;&gt;在所有的从KDC服务器上，将主KDC服务器和每个从KDC服务器的项添加到数据库传播配置文件kpropd.acl中&lt;/h3&gt;
&lt;p&gt;在master KDC和slave KDCs之间传输数据库是通过kpropd daemon来实现，因此需要明确的定义允许在slave机器的新数据库上提供kerberos dump更新的主体。&lt;br /&gt;
在所有从KDC服务器上，在KDC state文件夹中创建kpropd.acl文件，将主KDC服务器和每个从KDC服务器的主机主体项添加到其中。&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;[root@node2 krb5kdc]# cat kpropd.acl
host/node1@HADOOP.COM
host/node2@HADOOP.COM
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;说明：从KDC服务器上的kpropd.acl文件提供主机主体名称的列表(每个名称占一行)，用于指定该KDC可以通过传播从其接收更新数据库的系统。如果希望主KDC和从KDC能够交换，则需要在全部KDC的kpropd.acl列出全部KDC服务器的host主体。否则，如果仅使用主KDC服务器传播到所有从KDC服务器，则每个从KDC服务器上的kpropd.acl文件仅需包含主KDC服务器的主机主体名称。&lt;/p&gt;

&lt;h3 id=&quot;在所有从kdc服务器上确保未填充kerberos访问控制列表文件kadm5acl&quot;&gt;在所有从KDC服务器上，确保未填充kerberos访问控制列表文件kadm5.acl。&lt;/h3&gt;
&lt;p&gt;如果该文件中包含kiprop项，请将其删除。&lt;/p&gt;

&lt;h3 id=&quot;在新的从kdc服务器上更改kdcconf某个项&quot;&gt;在新的从KDC服务器上，更改kdc.conf某个项&lt;/h3&gt;
&lt;p&gt;使用定义“iprop_slave_poll = 2m”替换“iprop_master_ulogsize = 1000”。该项将轮询时间设为2分钟。&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;[realms]
HADOOP.COM={
    ...
  iprop_enable = true
  iprop_slave_poll = 2m
    ...
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;h3 id=&quot;在新的从kdc服务器上启动kadmin命添加主体到密钥表&quot;&gt;在新的从KDC服务器上，启动kadmin命，添加主体到密钥表。&lt;/h3&gt;
&lt;p&gt;必须使用在配置主KDC服务器时创建的一个admin主体名称登录。&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;echo root@1234|kinit root/admin
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;ol&gt;
  &lt;li&gt;使用kadmin将从KDC服务器的主机主体添加到从KDC服务器的密钥表文件中。&lt;br /&gt;
该项可使kprop及其他基于Kerberos的应用程序正常工作。请注意，当主体实例为主机名时，无论名称服务中的域名是大写还是小写，都必须以小写字母指定FQDN。&lt;br /&gt;
注：添加自己的host主体到自己的密钥表文件中。
    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;#在node2上执行  
kadmin: ktadd host/node2  
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
    &lt;p&gt;理想情况下，应该在自己本地导出自己的keytab。如果不可行，则应该创建一个加密的会话来在网络中传输。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;将kiprop主体添加到从KDC服务器的密钥表文件中。&lt;br /&gt;
通过将kiprop主体添加到krb5.keytab文件，允许kpropd命令在启动增量传播时对其自身进行验证。
    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;#在node2执行
kadmin: ktadd kiprop/node2
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;在新的从kdc服务器上启动kerberos传播守护进程不是增量传播是否需要此步骤todo记不清了&quot;&gt;在新的从KDC服务器上，启动Kerberos传播守护进程。（不是增量传播是否需要此步骤@TODO记不清了）&lt;/h3&gt;
&lt;p&gt;如果需要启动增量传播，需要启动kpropd作为一个独立的进程。&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;kpropd
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;至此，slave KDC可以接受数据库传播，需要将数据库从master server中传过来。&lt;br /&gt;
注意：目前不能够启动slave KDC，因为还没有复制master的database。&lt;/p&gt;

&lt;h2 id=&quot;将数据库复制到每一个slave-kdc中&quot;&gt;将数据库复制到每一个slave KDC中&lt;/h2&gt;
&lt;p&gt;在master KDC（node1）上创建dump file：&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;[root@node1 kerberos]# kdb5_util dump /var/kerberos/krb5kdc/slave_datatrans 
[root@node1 kerberos]# ls
krb5  krb5kdc  slave_datatrans  slave_datatrans.dump_ok
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;手动传播脚本传播&quot;&gt;手动传播（脚本传播）&lt;/h3&gt;
&lt;ol&gt;
  &lt;li&gt;手动传播操作&lt;br /&gt;
手动传输数据库文件到每一个slave KDC上：
    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;[root@node1 kerberos]#  kprop -f /var/kerberos/krb5kdc/slave_datatrans  node2
Database propagation to node2: SUCCEEDED
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
    &lt;blockquote&gt;
      &lt;p&gt;补充说明：Kerberos的数据库在master KDC上，因此需要定期的把这个数据库复制到slave KDCs上。如何设置数据库复制的频率，需要跟进传播时间以及用户等待密码生效的最大时间而设置。如果传播时间比这个最大限制时间长，（比如有一个很大的数据库，并且有很多slave，或者频繁的网络延迟），则可能希望能通过并行传播来减少传播延迟。因此，可以将数据库先从主节点传播给一部分从节点，然后从从节点再传播给其他节点。  &lt;br /&gt;
因为此时没有配置开启增量传播，因此，需要手动或脚本定时复制数据库，类似如下。&lt;/p&gt;
    &lt;/blockquote&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;#脚本方式：
#!/bin/sh
kdclist = &quot;kerberos-1.mit.edu kerberos-2.mit.edu&quot;
kdb5_util dump /usr/local/var/krb5kdc/slave_datatrans
for kdc in $kdclist
do
 kprop -f /usr/local/var/krb5kdc/slave_datatrans $kdc
done
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
    &lt;p&gt;需要设置一个定时任务去运行这个脚本，或者在切换之前执行。&lt;br /&gt;
至此，slave KDC中有了Kerberos database的复制, slave上/var/kerberos/krb5kdc/会多出一些文件。&lt;br /&gt;
现在即可启动krb5kdc daemon:&lt;/p&gt;
    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;[root@node2 kerberos]# systemctl start krb5kdc.service
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;启动遇到问题处理
    &lt;ol&gt;
      &lt;li&gt;手动传输数据库文件报错：
        &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; kprop: No route to host while connecting to server
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;        &lt;/div&gt;
        &lt;p&gt;处理：Make sure that the hostname of the slave (as given to kprop) is correct, and that any firewalls between the master and the slave allow a connection on port 754.&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;从节点启动可以直接打“krb5kdc”来启动，但是直接krb5kdc和systemctl start krb5kdc.service只能使用一种。&lt;br /&gt;
报错：
        &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; [root@node2 krb5kdc]# systemctl status krb5kdc.service -l
 ● krb5kdc.service - Kerberos 5 KDC
   Loaded: loaded (/usr/lib/systemd/system/krb5kdc.service; disabled; vendor preset: disabled)
Active: failed (Result: exit-code) since Tue 2017-09-19 16:06:57 CST; 17s ago
   Process: 9097 ExecStart=/usr/sbin/krb5kdc -P /var/run/krb5kdc.pid $KRB5KDC_ARGS (code=exited, status=1/FAILURE)
 Sep 19 16:06:57 node2 systemd[1]: Starting Kerberos 5 KDC...
 Sep 19 16:06:57 node2 systemd[1]: krb5kdc.service: control process exited, code=exited status=1
 Sep 19 16:06:57 node2 systemd[1]: Failed to start Kerberos 5 KDC.
 Sep 19 16:06:57 node2 systemd[1]: Unit krb5kdc.service entered failed state.
 Sep 19 16:06:57 node2 systemd[1]: krb5kdc.service failed.
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;        &lt;/div&gt;
        &lt;p&gt;处理：&lt;/p&gt;
        &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; [root@node2 krb5kdc]# ps -ef | grep krb5
 root      5080     1  0 15:47 ?        00:00:00 krb5kdc
 root      9330  2940  0 16:07 pts/0    00:00:00 grep --color=auto krb5
 [root@node2 krb5kdc]# kill 5080
 [root@node2 krb5kdc]# systemctl start krb5kdc.service
 [root@node2 krb5kdc]# systemctl status krb5kdc.service -l
 ● krb5kdc.service - Kerberos 5 KDC
Loaded: loaded (/usr/lib/systemd/system/krb5kdc.service; disabled; vendor preset: disabled)
Active: active (running) since Tue 2017-09-19 16:08:09 CST; 2s ago
   Process: 9345 ExecStart=/usr/sbin/krb5kdc -P /var/run/krb5kdc.pid $KRB5KDC_ARGS (code=exited, status=0/SUCCESS)
  Main PID: 9348 (krb5kdc)
Memory: 2.7M
CGroup: /system.slice/krb5kdc.service
        └─9348 /usr/sbin/krb5kdc -P /var/run/krb5kdc.pid    
 Sep 19 16:08:09 node2 systemd[1]: Starting Kerberos 5 KDC...
 Sep 19 16:08:09 node2 systemd[1]: PID file /var/run/krb5kdc.pid not readable (yet?) after start.
 Sep 19 16:08:09 node2 systemd[1]: Started Kerberos 5 KDC.
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;        &lt;/div&gt;
      &lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;增量传播目前配置增量传播后有些问题无法主从切换-因此此部分内容仅供参考未证实可用todo手动传播正常可以使用&quot;&gt;增量传播（目前配置增量传播后，有些问题无法主从切换-因此此部分内容仅供参考，未证实可用@TODO，手动传播正常可以使用）&lt;/h3&gt;
&lt;p&gt;当开启增量数据库传播，当master KDC更改了，则会将更改信息写到一个更新日志中，日志处于一个固定的缓存大小。
在每一个slave KDC 上会有一个进程链接master KDC上的一个服务，并且定期请求自上次检查以来所做的更改。默认情况下，每2分钟检查一次。如果数据库刚刚在前几秒进行了修改(currently the threshold is hard-coded at 10 seconds)，则slave不能检查到更新，而是暂停并在不久之后再次尝试。这减少了当一个管理员试图在同一时间进行很多数据库更改而导致增量更新查询造成延迟的可能性。&lt;br /&gt;
每个realm的增量更新在kdc.conf中配置。&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;主、从配置文件如上面步骤已经配置&lt;/li&gt;
  &lt;li&gt;创建kiprop/hostname主体（master 和slave KDC）和keytab  （已经操作则不用再进行）&lt;br /&gt;
master和slave KDC必须在Kerberos database中含有kiprop/hostname主体，并且创建默认keytab。&lt;br /&gt;
在1.13版本后，kiprop/hostname principal会自动在master KDC中创建，但是在slave KDCs需手动创建。 &lt;br /&gt;
If incremental propagation is enabled, the principal kiprop/slavehostname@REALM (where slavehostname is the name of the slave KDC host, and REALM is the name of the Kerberos realm) must be present in the slave’s keytab file.&lt;/li&gt;
  &lt;li&gt;slave KDC运行kpropd&lt;br /&gt;
当增量传播开启之后，slave kdc 的kpropd进程会链接master kdc的kadmind，并且开始请求更新。&lt;br /&gt;
通常情况下，kprop在增量传播支持中是禁用的。然而，如果很长时间内slave不能从master kdc中取到更新（比如因为网络原因），那么在master上的slave没来得急检索的日志可能被覆盖。在这种情况下，slave会通知master KDC转储当前的数据库到一文件中，并且调用一次kprop传播，并且通过特殊选项的设置，也能够更新日志中的关于slave应该获取增量更新的位置传输过去。因此，keytab和acl需要进行上述的kprop配置。&lt;br /&gt;
如果环境中有大量的slave，则希望将他们安排在一个层次性结构中，而不是让master为每一个slave提供更新。这么做的情况下，在每一个中间的slave上使用kadmind -proponly命令，并且使用kpropd -A upstreamhostname 将下游slaves指向对应的的上游slave。&lt;br /&gt;
当前实现中有几个已知的限制：
    &lt;ul&gt;
      &lt;li&gt;The incremental update protocol does not transport changes to policy objects. Any policy changes on the master will result in full resyncs to all slaves.&lt;/li&gt;
      &lt;li&gt;The slave’s KDB module must support locking; it cannot be using the LDAP KDB module.&lt;/li&gt;
      &lt;li&gt;The master and slave must be able to initiate TCP connections in both directions, without an intervening NAT.  &lt;br /&gt;
 直接输入如下，启动kpropd作为一个独立的进程。
        &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; kpropd
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;        &lt;/div&gt;
        &lt;p&gt;关闭：pkill kpropd&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;测试启动kdc&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;master和slave-kdc切换&quot;&gt;master和slave KDC切换&lt;/h2&gt;
&lt;p&gt;通过手动同步数据库的方式，将数据库从主KDC复制到从KDC之后，可进行KDC主从的切换操作。&lt;br /&gt;
仅当主 KDC 服务器由于某种原因出现故障，或者需要重新安装主 KDC 服务器(例如，由于安 装了新硬件)时，才应将主KDC服务器与从KDC 服务器进行交换。&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;切换步骤：
    &lt;ul&gt;
      &lt;li&gt;如果master KDC正在运行，则需要在老的master KDC上执行：&lt;br /&gt;
0、原主kdc上的kpropd.acl文件去掉[root@node1 krb5kdc]# mv kpropd.acl.bak kpropd.acl；注释掉kadm5.acl中的kiprop项。 &lt;br /&gt;
1、kill kadmind进程 systemctl stop kadmin.service&lt;br /&gt;
2、关闭传播数据库的定时任务&lt;br /&gt;
3、手动执行数据库传播脚本，保证从节点们都有最新的数据库复制&lt;/li&gt;
      &lt;li&gt;在新的master KDC上执行：&lt;br /&gt;
0、新主kdc上增加kpropd.acl文件[root@node2 krb5kdc]# mv kpropd.acl kpropd.acl.bak；增加kadm5.acl中的kiprop项，和原主kdc一致。&lt;br /&gt;
1、开启kadmin进程 systemctl start kadmin.service&lt;br /&gt;
2、运行传播数据库的定时任务&lt;br /&gt;
3、切换 master KDC 的cname。如果不能够这么做，则需要去更改每一个client节点的krb5.conf文件里面配置的Kerberos realm。&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;测试主从是否生效(成功)
    &lt;ol&gt;
      &lt;li&gt;从第三台服务器，使用kinit获取ticket，正常情况下会从master上获取&lt;/li&gt;
      &lt;li&gt;关闭master上的kdc服务&lt;/li&gt;
      &lt;li&gt;再次从第三台服务器上，使用kinit 获取ticket，如果成功，说明生效。也可以观察kdc的日志，在/var/log/krb5kdc.log。&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;错误处理
    &lt;ol&gt;
      &lt;li&gt;found kpropd.acl-报错如下：
        &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; [root@node1 krb5kdc]# systemctl status kadmin.service
 ● kadmin.service - Kerberos 5 Password-changing and Administration
Loaded: loaded (/usr/lib/systemd/system/kadmin.service; enabled; vendor preset: disabled)
Active: failed (Result: exit-code) since Tue 2017-09-19 15:29:26 CST; 8s ago
   Process: 32161 ExecStart=/usr/sbin/_kadmind -P /var/run/kadmind.pid $KADMIND_ARGS (code=exited, status=6)
  Main PID: 5242 (code=exited, status=2)
 Sep 19 15:29:26 node1 systemd[1]: Starting Kerberos 5 Password-changing and Administration...
 Sep 19 15:29:26 node1 _kadmind[32161]: Error. This appears to be a slave server, found kpropd.acl
 Sep 19 15:29:26 node1 systemd[1]: kadmin.service: control process exited, code=exited status=6
 Sep 19 15:29:26 node1 systemd[1]: Failed to start Kerberos 5 Password-changing and Administration.
 Sep 19 15:29:26 node1 systemd[1]: Unit kadmin.service entered failed state.
 Sep 19 15:29:26 node1 systemd[1]: kadmin.service failed.
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;        &lt;/div&gt;
        &lt;p&gt;问题解决：&lt;br /&gt;
 成为主节点的KDC，不能有kpropd.acl文件，删除原主kpropd.acl。 &lt;br /&gt;
 解决参照：&lt;a href=&quot;http://compgroups.net/comp.protocols.kerberos/kerberos-master-slave-setup-database/3021964&quot;&gt;报错解决&lt;/a&gt;。&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;密钥版本不匹配-Decrypt integrity check failed
        &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; [root@node1 krb5kdc]#  kprop -f /var/kerberos/krb5kdc/slave_datatrans  node2
 kprop: Server rejected authentication (during sendauth exchange) while authenticating to server
 kprop: Key version is not available signalled from server
 Error text from server: Key version is not available
 或者报错：
 kprop: Decrypt integrity check failed while getting initial credentials
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;        &lt;/div&gt;
        &lt;p&gt;原因：您的票证可能无效。&lt;br /&gt;
 解决方法分析：&lt;br /&gt;
 请检验以下两种情况：&lt;/p&gt;
        &lt;ul&gt;
          &lt;li&gt;确保您的凭证有效。使用 kdestroy 销毁票证，然后使用 kinit 创建新的票证。&lt;/li&gt;
          &lt;li&gt;确保目标主机的密钥表文件的服务密钥版本正确。使用 kadmin 查看 Kerberos 数据库中服务主体（例如 host/FQDN-hostname）的密钥版本号。另外，在目标主机上使用 klist -k，以确保该主机具有相同的密钥版本号。可用“kvno  host/node2@HADOOP.COM”命令查看版本号。  &lt;br /&gt;
 实际解决：&lt;br /&gt;
 我出错的原因是因为主KDC和从KDC中都有host/node2@HADOOP.COM和host/node1@HADOOP.COM的keytab内容，然后导致互相获取kvno的时候版本不匹配。&lt;br /&gt;
 1」.主从同时删除keytab文件和kdestroy
            &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; #node1和node2上执行
 rm -rf krb5.keytab
 kadmin:kdestroy
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;            &lt;/div&gt;
            &lt;p&gt;2」.分别执行：&lt;br /&gt;
 node1上：&lt;/p&gt;
            &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; [root@node1 krb5kdc]# kvno  host/node1@HADOOP.COM
 kvno: No credentials cache found (filename: /tmp/krb5cc_0) while getting client principal name
 kadmin: ktadd host/node1  
 [root@node1 krb5kdc]# kinit -k -t /etc/krb5.keytab host/node1@HADOOP.COM
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;            &lt;/div&gt;
            &lt;p&gt;node2上：&lt;/p&gt;
            &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; kadmin: ktadd host/node2  
 [root@node2 tmp]# kinit -k -t /etc/krb5.keytab   host/node2@HADOOP.COM
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;            &lt;/div&gt;
            &lt;p&gt;3」.查看密钥版本是否互相匹配&lt;br /&gt;
 node1上：&lt;/p&gt;
            &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; [root@node1 krb5kdc]# klist -k
 #此处此命令可查看到自己的kvno
 [root@node1 krb5kdc]# kvno  host/node1@HADOOP.COM
 host/node1@HADOOP.COM: kvno = 4
 [root@node2 tmp]# kvno host/node2@HADOOP.COM
 host/node2@HADOOP.COM: kvno = 6
 #看此是否与node2的对应kvno匹配
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;            &lt;/div&gt;
            &lt;p&gt;node2上：&lt;/p&gt;
            &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; [root@node2 krb5kdc]# klist -k
 #此处此命令可查看到自己的kvno
 [root@node2 tmp]# kvno host/node2@HADOOP.COM
 host/node2@HADOOP.COM: kvno = 6
 [root@node2 krb5kdc]# kvno  host/node1@HADOOP.COM
 host/node1@HADOOP.COM: kvno = 4
 #看此是否与node1的对应kvno匹配
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;            &lt;/div&gt;
            &lt;p&gt;之后即可解决。&lt;br /&gt;
 问题处理参考：&lt;a href=&quot;http://compgroups.net/comp.protocols.kerberos/decrypt-integrity-check-failed-3/1946334&quot;&gt;密钥版本不匹配&lt;/a&gt;。&lt;/p&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;hr /&gt;
&lt;p&gt;至此，本篇内容完成。&lt;br /&gt;
以上，此文章以及0505、0628三篇内容基本上是完全关于Kerberos相关知识，HDFS、ZK结合Kerberos的部署等内容，由于时间有限以及测试不够充分，仍存在很多漏洞以及待处理的问题，以后有机会再深入学习一下。&lt;/p&gt;</content><author><name>叶子  ( ˘ ³˘)♥</name></author><category term="Kerberos" /><summary type="html">本文主要关于Kerberos的简单应用。因为工作测试需要，自己装了一套集群进行了Kerberos的部署，并且与HDFS、ZK进行整合，然后将操作过程进行了整理，以便后续再查看。本文主要涉及Kerberos主从KDC部署，此文为2018-06-29文章Kerberos具体实践3的后续；本文为本系列的最后一篇。 Kerberos主从KDC部署 在进行生产环境中进行Kerberos部署时，最好配置1个master KDC以及多个slave KDC来保证Kerberos服务的可靠性。每个KDC都能够包括一个Kerberos数据库的副本。在master KDC中包含一个可写的realm数据库副本，并且他会定期同步到slave KDC中。所有数据库的更改（如更改密码）都是由master KDC负责。当主KDC不可用，slave KDCs提供Kerberos的票据授予服务，不负责数据库管理。</summary></entry><entry><title type="html">Kerberos具体实践2-Kerberos与HDFS的整合操作</title><link href="http://localhost:4000/bigdata/2018/06/28/Kerberos%E5%85%B7%E4%BD%93%E5%AE%9E%E8%B7%B52-Kerberos%E4%B8%8EHDFS%E7%9A%84%E6%95%B4%E5%90%88%E6%93%8D%E4%BD%9C/" rel="alternate" type="text/html" title="Kerberos具体实践2-Kerberos与HDFS的整合操作" /><published>2018-06-28T00:00:00+08:00</published><updated>2018-06-28T00:00:00+08:00</updated><id>http://localhost:4000/bigdata/2018/06/28/Kerberos%E5%85%B7%E4%BD%93%E5%AE%9E%E8%B7%B52-Kerberos%E4%B8%8EHDFS%E7%9A%84%E6%95%B4%E5%90%88%E6%93%8D%E4%BD%9C</id><content type="html" xml:base="http://localhost:4000/bigdata/2018/06/28/Kerberos%E5%85%B7%E4%BD%93%E5%AE%9E%E8%B7%B52-Kerberos%E4%B8%8EHDFS%E7%9A%84%E6%95%B4%E5%90%88%E6%93%8D%E4%BD%9C/">&lt;blockquote&gt;
  &lt;p&gt;本文主要关于Kerberos的简单应用。因为工作测试需要，自己装了一套集群进行了Kerberos的部署，并且与HDFS、ZK进行整合，然后将操作过程进行了整理，以便后续再查看。本文主要涉及到其与HDFS的整合操作，此文为2018-05-05文章Kerberos具体实践1的后续，上文说明了Kerberos集群的安装以及基本命令的使用；由于篇幅有限，下文在2018-06-29文章Kerberos具体实践3中继续说明Kerberos与ZK整合操作。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h1 id=&quot;hdfs整合kerberos部署&quot;&gt;HDFS整合Kerberos（部署）&lt;/h1&gt;
&lt;h2 id=&quot;创建认证规则&quot;&gt;创建认证规则&lt;/h2&gt;
&lt;p&gt;在 Kerberos 安全机制里，一个principal就是realm里的一个对象，一个principal总是和一个密钥（secret key）成对出现的。&lt;br /&gt;
这个 principal 的对应物可以是service，可以是host，也可以是user，对于Kerberos来说，都没有区别。&lt;br /&gt;
Kdc(Key distribute center) 知道所有principal的secret key，但每个principal对应的对象只知道自己的那个secret key。这也是“共享密钥“的由来。&lt;br /&gt;
对于hadoop，principals的格式为username/fully.qualified.domain.name@YOUR-REALM.COM。&lt;br /&gt;
本次测试中，直接解压安装2.6.0-cdh5.11.0，并使用hadoop用户来进行NameNode和DataNode的启动，因此为集群中每个服务器节点添加principals：hadoop、HTTP、host（后续使用）。&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;补充：若通过yum源安装的cdh集群中，NameNode和DataNode是通过hdfs启动的，故为集群中每个服务器节点添加两个principals：hdfs、HTTP。-官网说法：The properties for each daemon (NameNode, Secondary NameNode, and DataNode) must specify both the HDFS and HTTP principals, as well as the path to the HDFS keytab file.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;在 KCD server 上（这里是 node1）创建 hadoop principal：&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;kadmin.local -q &quot;addprinc -randkey hadoop/node1@HADOOP.COM&quot;   
kadmin.local -q &quot;addprinc -randkey hadoop/node2@HADOOP.COM&quot;  
kadmin.local -q &quot;addprinc -randkey hadoop/node3@HADOOP.COM&quot;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;创建 HTTP principal：&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;kadmin.local -q &quot;addprinc -randkey HTTP/node1@HADOOP.COM&quot; 
kadmin.local -q &quot;addprinc -randkey HTTP/node2@HADOOP.COM&quot;  
kadmin.local -q &quot;addprinc -randkey HTTP/node3@HADOOP.COM&quot;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;blockquote&gt;
  &lt;p&gt;说明：randkey 标志没有为新principal 设置密码，而是指示kadmin生成一个随机密钥。之所以在这里使用这个标志，是因为此principal不需要用户交互。它是计算机的一个服务器帐户。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;创建完成后，查看：&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ kadmin.local -q &quot;listprincs&quot;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;操作结果小例子：&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;[root@node1 /]# kadmin.local -q &quot;addprinc -randkey hadoop/node1@HADOOP.COM&quot;
Authenticating as principal root/admin@HADOOP.COM with password.
WARNING: no policy specified for hadoop/node1@HADOOP.COM; defaulting to no policy
Principal &quot;hadoop/node1@HADOOP.COM&quot; created.
[root@node1 /]# kadmin.local -q &quot;addprinc -randkey hadoop/node2@HADOOP.COM&quot;
Authenticating as principal root/admin@HADOOP.COM with password.
WARNING: no policy specified for hadoop/node2@HADOOP.COM; defaulting to no policy
Principal &quot;hadoop/node2@HADOOP.COM&quot; created.
[root@node1 /]# kadmin.local -q &quot;addprinc -randkey hadoop/node3@HADOOP.COM&quot;
Authenticating as principal root/admin@HADOOP.COM with password.
WARNING: no policy specified for hadoop/node3@HADOOP.COM; defaulting to no policy
Principal &quot;hadoop/node3@HADOOP.COM&quot; created.
[root@node1 /]# kadmin.local -q &quot;addprinc -randkey HTTP/node1@HADOOP.COM&quot;
Authenticating as principal root/admin@HADOOP.COM with password.
WARNING: no policy specified for HTTP/node1@HADOOP.COM; defaulting to no policy
Principal &quot;HTTP/node1@HADOOP.COM&quot; created.
[root@node1 /]# kadmin.local -q &quot;addprinc -randkey HTTP/node2@HADOOP.COM&quot;
Authenticating as principal root/admin@HADOOP.COM with password.
WARNING: no policy specified for HTTP/node2@HADOOP.COM; defaulting to no policy
Principal &quot;HTTP/node2@HADOOP.COM&quot; created.
[root@node1 /]# kadmin.local -q &quot;addprinc -randkey HTTP/node3@HADOOP.COM&quot;
Authenticating as principal root/admin@HADOOP.COM with password.
WARNING: no policy specified for HTTP/node3@HADOOP.COM; defaulting to no policy
Principal &quot;HTTP/node3@HADOOP.COM&quot; created. 
[root@node1 hadoop_logs]# kadmin.local -q &quot;addprinc -randkey host/node1@HADOOP.COM&quot;
Authenticating as principal root/admin@HADOOP.COM with password.
WARNING: no policy specified for host/node1@HADOOP.COM; defaulting to no policy
Principal &quot;host/node1@HADOOP.COM&quot; created.
[root@node1 hadoop_logs]# kadmin.local -q &quot;addprinc -randkey host/node2@HADOOP.COM&quot;
Authenticating as principal root/admin@HADOOP.COM with password.
WARNING: no policy specified for host/node2@HADOOP.COM; defaulting to no policy
Principal &quot;host/node2@HADOOP.COM&quot; created.
[root@node1 hadoop_logs]# kadmin.local -q &quot;addprinc -randkey host/node3@HADOOP.COM&quot;
Authenticating as principal root/admin@HADOOP.COM with password.
WARNING: no policy specified for host/node3@HADOOP.COM; defaulting to no policy
Principal &quot;host/node3@HADOOP.COM&quot; created.
[root@node1 /]# kadmin.local -q &quot;listprincs&quot;
Authenticating as principal root/admin@HADOOP.COM with password.
HTTP/node1@HADOOP.COM
HTTP/node2@HADOOP.COM
HTTP/node3@HADOOP.COM
K/M@HADOOP.COM
hadoop/node1@HADOOP.COM
hadoop/node2@HADOOP.COM
hadoop/node3@HADOOP.COM
host/node1@HADOOP.COM
host/node2@HADOOP.COM
host/node3@HADOOP.COM
kadmin/admin@HADOOP.COM
kadmin/changepw@HADOOP.COM
kadmin/node1@HADOOP.COM
kiprop/node1@HADOOP.COM
krbtgt/HADOOP.COM@HADOOP.COM
root/admin@HADOOP.COM
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;h2 id=&quot;生成keytab&quot;&gt;生成keytab&lt;/h2&gt;
&lt;p&gt;keytab是包含principals和加密principal key的文件。keytab文件对于每个host是唯一的，因为key包含hostname。keytab文件用于不需要人工交互和保存纯文本密码，实现到kerberos上验证一个主机上的principal。因为服务器上可以访问keytab文件即可以以principal的身份通过 kerberos 的认证，所以，keytab文件应该被妥善保存，应该只有少数的用户可以访问。&lt;br /&gt;
创建包含hadoop principal和HTTP principal的keytab。&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;方法一：&lt;br /&gt;
在node1节点，即KDC server节点上执行下面命令，会在当前目录下创建keytab，名字为hdfs.keytab：
    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;1、kadmin.local进入kerberos shell中
2、kadmin.local:  xst -norandkey -k hdfs.keytab hadoop/node1@HADOOP.COM hadoop/node2@HADOOP.COM hadoop/node3@HADOOP.COM HTTP/node1@HADOOP.COM HTTP/node2@HADOOP.COM HTTP/node3@HADOOP.COM
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
    &lt;p&gt;使用klist显示hdfs.keytab文件列表,查看执行结果：&lt;/p&gt;
    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;[root@node1 etc]# klist -ket  hdfs.keytab
Keytab name: FILE:hdfs.keytab
KVNO Timestamp           Principal
---- ------------------- ------------------------------------------------------
1 09/06/2017 17:53:54 hadoop/node1@HADOOP.COM (des3-cbc-sha1)
1 09/06/2017 17:53:54 hadoop/node1@HADOOP.COM (arcfour-hmac)
1 09/06/2017 17:53:54 hadoop/node1@HADOOP.COM (camellia256-cts-cmac)
1 09/06/2017 17:53:54 hadoop/node1@HADOOP.COM (camellia128-cts-cmac)
1 09/06/2017 17:53:54 hadoop/node1@HADOOP.COM (des-hmac-sha1)
1 09/06/2017 17:53:54 hadoop/node1@HADOOP.COM (des-cbc-md5)
1 09/06/2017 17:53:54 hadoop/node2@HADOOP.COM (des3-cbc-sha1)
1 09/06/2017 17:53:54 hadoop/node2@HADOOP.COM (arcfour-hmac)
1 09/06/2017 17:53:54 hadoop/node2@HADOOP.COM (camellia256-cts-cmac)
1 09/06/2017 17:53:54 hadoop/node2@HADOOP.COM (camellia128-cts-cmac)
1 09/06/2017 17:53:54 hadoop/node2@HADOOP.COM (des-hmac-sha1)
1 09/06/2017 17:53:54 hadoop/node2@HADOOP.COM (des-cbc-md5)
1 09/06/2017 17:53:54 hadoop/node3@HADOOP.COM (des3-cbc-sha1)
1 09/06/2017 17:53:54 hadoop/node3@HADOOP.COM (arcfour-hmac)
1 09/06/2017 17:53:54 hadoop/node3@HADOOP.COM (camellia256-cts-cmac)
1 09/06/2017 17:53:54 hadoop/node3@HADOOP.COM (camellia128-cts-cmac)
1 09/06/2017 17:53:54 hadoop/node3@HADOOP.COM (des-hmac-sha1)
1 09/06/2017 17:53:54 hadoop/node3@HADOOP.COM (des-cbc-md5)
1 09/06/2017 17:53:54 HTTP/node1@HADOOP.COM (des3-cbc-sha1)
1 09/06/2017 17:53:54 HTTP/node1@HADOOP.COM (arcfour-hmac)
1 09/06/2017 17:53:54 HTTP/node1@HADOOP.COM (camellia256-cts-cmac)
1 09/06/2017 17:53:54 HTTP/node1@HADOOP.COM (camellia128-cts-cmac)
1 09/06/2017 17:53:54 HTTP/node1@HADOOP.COM (des-hmac-sha1)
1 09/06/2017 17:53:54 HTTP/node1@HADOOP.COM (des-cbc-md5)
1 09/06/2017 17:53:54 HTTP/node2@HADOOP.COM (des3-cbc-sha1)
1 09/06/2017 17:53:54 HTTP/node2@HADOOP.COM (arcfour-hmac)
1 09/06/2017 17:53:54 HTTP/node2@HADOOP.COM (camellia256-cts-cmac)
1 09/06/2017 17:53:54 HTTP/node2@HADOOP.COM (camellia128-cts-cmac)
1 09/06/2017 17:53:54 HTTP/node2@HADOOP.COM (des-hmac-sha1)
1 09/06/2017 17:53:54 HTTP/node2@HADOOP.COM (des-cbc-md5)
1 09/06/2017 17:53:54 HTTP/node3@HADOOP.COM (des3-cbc-sha1)
1 09/06/2017 17:53:54 HTTP/node3@HADOOP.COM (arcfour-hmac)
1 09/06/2017 17:53:54 HTTP/node3@HADOOP.COM (camellia256-cts-cmac)
1 09/06/2017 17:53:54 HTTP/node3@HADOOP.COM (camellia128-cts-cmac)
1 09/06/2017 17:53:54 HTTP/node3@HADOOP.COM (des-hmac-sha1)
1 09/06/2017 17:53:54 HTTP/node3@HADOOP.COM (des-cbc-md5)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;方法二（未使用）：&lt;br /&gt;
在node1节点，即KDC server节点上执行下面命令，分别创建keytab，名字为hdfs.keytab：
    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ cd /var/kerberos/krb5kdc/  
$ kadmin.local -q &quot;xst  -k hdfs-unmerged.keytab hadoop/node1@HADOOP.COM&quot;  
$ kadmin.local -q &quot;xst  -k hdfs-unmerged.keytab hadoop/node2@HADOOP.COM&quot;  
$ kadmin.local -q &quot;xst  -k hdfs-unmerged.keytab hadoop/node3@HADOOP.COM&quot;  
$ kadmin.local -q &quot;xst  -k HTTP.keytab  HTTP/node1@HADOOP.COM&quot;  
$ kadmin.local -q &quot;xst  -k HTTP.keytab  HTTP/node2@HADOOP.COM&quot;  
$ kadmin.local -q &quot;xst  -k HTTP.keytab  HTTP/node3@HADOOP.COM&quot;  
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
    &lt;p&gt;这样，就会在/var/kerberos/krb5kdc/（当前）目录下生成hdfs-unmerged.keytab和HTTP.keytab两个文件，接下来使用ktutil合并者两个文件为hdfs.keytab。&lt;/p&gt;
    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ cd /var/kerberos/krb5kdc/   
$ ktutil  
ktutil: rkt hdfs-unmerged.keytab  
ktutil: rkt HTTP.keytab  
ktutil: wkt hdfs.keytab
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
    &lt;p&gt;使用klist显示hdfs.keytab文件列表：&lt;/p&gt;
    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ klist -ket  hdfs.keytab
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;测试：&lt;br /&gt;
验证是否正确合并了key，使用合并后的keytab，分别使用hadoop和HTTP principals来获取证书。
    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ kinit -k -t hdfs.keytab hadoop/node1@HADOOP.COM
$ kinit -k -t hdfs.keytab HTTP/node1@HADOOP.COM
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
    &lt;p&gt;如果出现错误：kinit: Key table entry not found while getting initial credentials，则上面的（生成）合并有问题，重新执行前面的操作。&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;部署kerberos-keytabhdfs&quot;&gt;部署Kerberos Keytab（hdfs）&lt;/h2&gt;
&lt;p&gt;拷贝生成的hdfs.keytab文件到其他节点的/etc/hadoop/conf目录【可以自己定义目录，后续需要在hdfs配置文件中使用此目录】&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ cd /var/kerberos/krb5kdc/  【刚刚生成keytab文件所在目录】
$ scp hdfs.keytab node1:/etc/hadoop/conf  
$ scp hdfs.keytab node2:/etc/hadoop/conf  
$ scp hdfs.keytab node3:/etc/hadoop/conf
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;并设置权限，分别在node1、node2、node3上执行更改文件属主和权限命令：&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ ssh node1 &quot;chown hadoop:hadoop /etc/hadoop/conf/hdfs.keytab ;chmod 400 /etc/hadoop/conf/hdfs.keytab&quot;
$ ssh node2 &quot;chown hadoop:hadoop /etc/hadoop/conf/hdfs.keytab ;chmod 400 /etc/hadoop/conf/hdfs.keytab&quot;
$ ssh node3 &quot;chown hadoop:hadoop /etc/hadoop/conf/hdfs.keytab ;chmod 400 /etc/hadoop/conf/hdfs.keytab&quot;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;blockquote&gt;
  &lt;p&gt;注意：由于keytab相当于有了永久凭证，不需要提供密码(如果修改kdc中的principal的密码，则该keytab就会失效)，所以其他用户如果对该文件有读权限，就可以冒充 keytab中指定的用户身份访问hadoop，所以keytab文件需要确保只对owner有读权限(0400)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;hdfs配置修改&quot;&gt;HDFS配置修改&lt;/h2&gt;
&lt;p&gt;关于HDFS集群的部署配置就不在此文中说明，以下直接进行说明Kerberos整合HDFS之时所做的修改操作。&lt;/p&gt;
&lt;h3 id=&quot;修改core-sitexml配置文件&quot;&gt;修改core-site.xml配置文件&lt;/h3&gt;
&lt;p&gt;在集群中所有节点的core-site.xml文件中添加下面的配置:&lt;/p&gt;
&lt;div class=&quot;language-xml highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;hadoop.security.authentication&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;kerberos&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;

&lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;hadoop.security.authorization&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;true&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;h3 id=&quot;修改hdfs-sitexml配置文件&quot;&gt;修改hdfs-site.xml配置文件&lt;/h3&gt;
&lt;p&gt;在集群中所有节点的hdfs-site.xml文件中添加下面的配置：&lt;/p&gt;
&lt;div class=&quot;language-xml highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c&quot;&gt;&amp;lt;!-- General HDFS security config --&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;dfs.block.access.token.enable&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;true&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;&amp;lt;!-- NameNode security config --&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;dfs.namenode.keytab.file&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;/opt/hadoop_krb5/conf/hdfs.keytab&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt; &lt;span class=&quot;c&quot;&gt;&amp;lt;!-- HDFS keytab的目录 --&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;dfs.namenode.kerberos.principal&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;hadoop/_HOST@HADOOP.COM&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;dfs.namenode.kerberos.internal.spnego.principal&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;HTTP/_HOST@HADOOP.COM&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;&amp;lt;!-- DataNode security config --&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;dfs.datanode.data.dir.perm&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;700&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;dfs.datanode.address&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;0.0.0.0:61004&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;dfs.datanode.http.address&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;0.0.0.0:61006&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;dfs.datanode.keytab.file&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;/opt/hadoop_krb5/conf/hdfs.keytab&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt; &lt;span class=&quot;c&quot;&gt;&amp;lt;!-- HDFS keytab的目录 --&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;dfs.datanode.kerberos.principal&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;hadoop/_HOST@HADOOP.COM&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;dfs.datanode.kerberos.https.principal&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;HTTP/_HOST@HADOOP.COM&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;&amp;lt;!-- 开启SSL(jsvc时可不配置；可选，详见下属总结以及启动datanode部分) --&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;dfs.http.policy&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;HTTPS_ONLY&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;&amp;lt;!-- SASL 模式--&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;dfs.data.transfer.protection&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;integrity&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;&amp;lt;!-- Web Authentication config --&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;dfs.webhdfs.enabled&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;true&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;dfs.web.authentication.kerberos.keytab&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;/opt/hadoop_krb5/conf/hdfs.keytab&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt; &lt;span class=&quot;c&quot;&gt;&amp;lt;!-- HDFS keytab的目录 --&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;dfs.web.authentication.kerberos.principal&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;HTTP/_HOST@HADOOP.COM&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
 &lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;&amp;lt;!--- HDFS QJM HA：如果HDFS配置了QJM HA，则需要添加；另外，你还要在zookeeper上配置kerberos（详见后续文章说明） --&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;dfs.journalnode.keytab.file&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;/opt/hadoop_krb5/conf/hdfs.keytab&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;dfs.journalnode.kerberos.principal&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;hadoop/_HOST@HADOOP.COM&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;dfs.journalnode.kerberos.internal.spnego.principal&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;HTTP/_HOST@HADOOP.COM&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;h3 id=&quot;修改hadoop-envsh配置文件&quot;&gt;修改hadoop-env.sh配置文件&lt;/h3&gt;
&lt;p&gt;在hadoop-env.sh文件中，需要修改HADOOP_SECURE_DN_USER的值，其依据datanode启动方式不同，有不同的设置。&lt;br /&gt;
注意的关键点如下：&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;jsvc模式启动datanode：HADOOP_SECURE_DN_USER有值&lt;/li&gt;
  &lt;li&gt;SASL模式启动datanode：HADOOP_SECURE_DN_USER没值，要注释掉。&lt;/li&gt;
&lt;/ol&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;#export HADOOP_SECURE_DN_USER=${HADOOP_SECURE_DN_USER}
#export HADOOP_SECURE_DN_USER=hadoop
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;具体配置方式，见下述启动datanode的部分，以不同的启动方式来详细说明。&lt;/p&gt;

&lt;p&gt;配置中有几点要注意的：&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;如果不进行SSL配置，则hadoop需要使用jsvc来启动（如下条解释）。&lt;/li&gt;
  &lt;li&gt;dfs.datanode.address、dfs.datanode.http.address表示data transceiver RPC server所绑定的hostname或IP地址，此部分配置与datanode的启动方式有关（本条内容目前是靠个人理解，由于目前还是菜鸟学习阶段，所以理解可能问题，请大家指出并告诉我，谢谢啦～我的邮箱leafming@foxmail.com），这部分的端口值有两种设置情况；
    &lt;ul&gt;
      &lt;li&gt;一定小于1024-jsvc:如果开启security，并且使用jsvc模式启动datanode（不配置SSL），dfs.datanode.address、dfs.datanode.http.address的端口一定要小于1024（privileged端口），否则的话启动datanode时候会报Cannot start secure cluster without privileged resources错误。CDH官网说明如下（详见&lt;a href=&quot;https://www.cloudera.com/documentation/enterprise/5-11-x/topics/cdh_sg_secure_hdfs_config.html#concept_nsy_21z_xn&quot;&gt;Configure Secure HDFS&lt;/a&gt;）：
        &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; The dfs.datanode.address and dfs.datanode.http.address port numbers for the DataNode must be below 1024,because this provides part of the security mechanism to make it impossible for a user to run a map task which impersonates a DataNode. 
 The port numbers for the NameNode and Secondary NameNode can be anything you want, but the default port numbers are good ones to use.
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;        &lt;/div&gt;
      &lt;/li&gt;
      &lt;li&gt;一定大于1024-SASL:如果使用在2.6之前的版本，安全模式的hadoop只能使用jsvc，即先以root用户来启动datanode，然后再切到普通用户。而在2.6.0之后的版本，SASL可以用来验证数据传输。在使用SASL的配置下，不再需要root用jsvc来启动安全模式的集群，并且也不在需要使用特权端口。如果启用SASL模式，需要在hdfs-site.xml中设置dfs.data.transfer.protection，并且dfs.datanode.address的端口要大于1024（non-privileged端口），并且设置dfs.http.policy为HTTPS_ONLY，而且保证HADOOP_SECURE_DN_USER环境变量值没有设置。一定要注意的是，dfs.datanode.address若设置成了特权端口，则SASL无法使用，这是向后兼容性原因所必需的。官网说明如下&lt;a href=&quot;http://hadoop.apache.org/docs/stable/hadoop-project-dist/hadoop-common/SecureMode.html&quot;&gt;Hadoop in Secure Mode-Secure DataNode&lt;/a&gt; ：
        &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; As of version 2.6.0, SASL can be used to authenticate the data transfer protocol. 
 In this configuration, it is no longer required for secured clusters to start the DataNode as root using jsvc and bind to privileged ports. To enable SASL on data transfer protocol, set dfs.data.transfer.
 protection in hdfs-site.xml, set a non-privileged port for dfs.datanode.address, set dfs.http.policy to HTTPS_ONLY and make sure the HADOOP_SECURE_DN_USER environment variable is not defined. 
 Note that it is not possible to use SASL on data transfer protocol if dfs.datanode.address is set to a privileged port. This is required for backwards-compatibility reasons.
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;        &lt;/div&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;principal中的instance部分可以使用_HOST标记，系统会自动替换它为全称域名。&lt;/li&gt;
  &lt;li&gt;如果开启了security, hadoop会对hdfs block data(由dfs.data.dir指定)做permission check，方式用户的代码不是调用hdfs api而是直接本地读block data，这样就绕过了kerberos和文件权限验证，管理员可以通过设置dfs.datanode.data.dir.perm 来修改datanode 文件权限，这里我们设置为700。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;本次集群配置示例：&lt;/p&gt;

&lt;div class=&quot;language-xml highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;core-site.xml  
-----------------------------------------------------------------
&lt;span class=&quot;nt&quot;&gt;&amp;lt;configuration&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;fs.defaultFS&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;hdfs://ns1&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;ha.zookeeper.quorum&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;node1:2181,node2:2181,node3:2181&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;io.compression.codecs&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;org.apache.hadoop.io.compress.SnappyCodec&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;hadoop.tmp.dir&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;/opt/hadoop-dir&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;hadoop.security.authentication&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;kerberos&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;hadoop.security.authorization&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;true&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;/configuration&amp;gt;&lt;/span&gt;
-----------------------------------------------------------------
hdfs-site.xml
-----------------------------------------------------------------
&lt;span class=&quot;nt&quot;&gt;&amp;lt;configuration&amp;gt;&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;&amp;lt;!-- General HDFS security config --&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;dfs.block.access.token.enable&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;true&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;dfs.nameservices&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;ns1&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;dfs.ha.namenodes.ns1&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;node1,node2&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;dfs.namenode.rpc-address.ns1.node1&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;node1:8020&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;dfs.namenode.rpc-address.ns1.node2&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;node2:8020&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;dfs.namenode.http-address.ns1.node1&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;node1:8570&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;dfs.namenode.http-address.ns1.node2&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;node2:8570&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;&amp;lt;!-- NameNode security config --&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;dfs.namenode.keytab.file&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;/opt/hadoop_krb5/conf/hdfs.keytab&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt; &lt;span class=&quot;c&quot;&gt;&amp;lt;!-- path to the HDFS keytab --&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;dfs.namenode.kerberos.principal&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;hadoop/_HOST@HADOOP.COM&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;dfs.namenode.kerberos.internal.spnego.principal&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;HTTP/_HOST@HADOOP.COM&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;&amp;lt;!-- DataNode security config --&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;dfs.datanode.data.dir.perm&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;700&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;dfs.datanode.address&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;0.0.0.0:61004&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;dfs.datanode.http.address&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;0.0.0.0:61006&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;dfs.datanode.keytab.file&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;/opt/hadoop_krb5/conf/hdfs.keytab&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt; &lt;span class=&quot;c&quot;&gt;&amp;lt;!-- path to the HDFS keytab --&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;dfs.datanode.kerberos.principal&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;hadoop/_HOST@HADOOP.COM&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;dfs.datanode.kerberos.https.principal&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;HTTP/_HOST@HADOOP.COM&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;dfs.http.policy&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;HTTPS_ONLY&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;dfs.data.transfer.protection&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;integrity&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;&amp;lt;!-- Web Authentication config --&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;dfs.webhdfs.enabled&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;true&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;dfs.web.authentication.kerberos.keytab&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;/opt/hadoop_krb5/conf/hdfs.keytab&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt; &lt;span class=&quot;c&quot;&gt;&amp;lt;!-- path to the HTTP keytab --&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;dfs.web.authentication.kerberos.principal&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;HTTP/_HOST@HADOOP.COM&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;&amp;lt;!-- HDFS QJM HA--&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;dfs.journalnode.keytab.file&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;/opt/hadoop_krb5/conf/hdfs.keytab&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;dfs.journalnode.kerberos.principal&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;hadoop/_HOST@HADOOP.COM&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;dfs.journalnode.kerberos.internal.spnego.principal&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;HTTP/_HOST@HADOOP.COM&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;dfs.namenode.shared.edits.dir&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;qjournal://node1:8485;node2:8485;node3:8485/ns1&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;dfs.journalnode.edits.dir&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;/opt/hadoop-dir/journal&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;dfs.ha.fencing.methods&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;sshfence&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;dfs.ha.fencing.ssh.private-key-files&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;/home/hadoop/.ssh/id_rsa&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;dfs.permissions.enabled&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;true&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;dfs.namenode.acls.enabled&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;true&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;dfs.permissions.superusergroup&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;cgroup&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;dfs.replication&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;3&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;final&amp;gt;&lt;/span&gt;true&lt;span class=&quot;nt&quot;&gt;&amp;lt;/final&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;dfs.namenode.name.dir&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;file:///opt/hadoop-dir/hadoop_data/nn&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;dfs.datanode.data.dir&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;file:///opt/hadoop-dir/hadoop_data/dn&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;ha.zookeeper.session-timeout.ms&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;5000&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;dfs.ha.automatic-failover.enabled&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;true&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;dfs.client.failover.proxy.provider.ns1&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;  
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;dfs.socket.timeout&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;90000&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;dfs.balance.bandwidthPerSec&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;10485760&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;/configuration&amp;gt;&lt;/span&gt;
-----------------------------------------------------------------
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;h2 id=&quot;检查集群上的hdfs和本地文件的权限未尝试hdfs配置kerberos认证-文章中写需要此操作&quot;&gt;检查集群上的HDFS和本地文件的权限（未尝试，&lt;a href=&quot;https://yq.aliyun.com/articles/25636?spm=5176.100240.searchblog.8.wbY2wv&quot;&gt;HDFS配置Kerberos认证&lt;/a&gt; 文章中写需要此操作）&lt;/h2&gt;
&lt;p&gt;请参考&lt;a href=&quot;https://www.cloudera.com/documentation/enterprise/latest/topics/cdh_sg_users_groups_verify.html?spm=5176.100239.blogcont25636.6.wkeCKj&quot;&gt;Verify User Accounts and Groups in CDH 5 Due to Security&lt;/a&gt;或者&lt;a href=&quot;http://hadoop.apache.org/docs/r2.5.2/hadoop-project-dist/hadoop-common/SecureMode.html?spm=5176.100239.blogcont25636.7.wkeCKj&quot;&gt;Hadoop in Secure Mode&lt;/a&gt;。&lt;/p&gt;

&lt;h1 id=&quot;hdfs整合kerberos启动&quot;&gt;HDFS整合Kerberos（启动）&lt;/h1&gt;
&lt;p&gt;启动之前，请确认JCE jar已经替换，即若master_key_type和supported_enctypes使用aes256-cts（klist -e 命令查看采用了什么encryption），则需要替换JCE jar，请参考前面的说明。否则可能出现问题，可参考&lt;a href=&quot;https://www.cloudera.com/documentation/enterprise/5-11-x/topics/cm_sg_sec_troubleshooting.html#topic_17_1_5&quot;&gt;The NameNode starts but clients cannot connect to it and error message contains enctype code 18&lt;/a&gt;。
而本次操作中，没有使用aes256-cts，所以不用进行替换。&lt;/p&gt;

&lt;h2 id=&quot;kerberoskdc已经启动&quot;&gt;KerberosKDC已经启动&lt;/h2&gt;
&lt;h2 id=&quot;启动namenode可不单独做这个操作直接配置好之后启动但可优先测试&quot;&gt;启动NameNode（可不单独做这个操作，直接配置好之后启动，但可优先测试）&lt;/h2&gt;
&lt;h3 id=&quot;启动操作&quot;&gt;启动操作&lt;/h3&gt;
&lt;p&gt;上述更改配置文件的时候，已经停掉了全部hdfs服务，现在进行启动操作。&lt;br /&gt;
在每个节点上获取root用户的ticket，这里root为之前创建的root/admin的密码。&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ ssh cdh1 &quot;echo root@1234|kinit root/admin&quot;
$ ssh cdh2 &quot;echo root@1234|kinit root/admin&quot;
$ ssh cdh3 &quot;echo root@1234|kinit root/admin&quot;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;关闭selinux&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;setenforce 0
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;获取node1的启动namenode的ticket：&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;kinit -k -t /opt/hadoop_krb5/conf/hdfs.keytab hadoop/node1@HADOOP.COM
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;如果出现下面异常kinit: Password incorrect while getting initial credentials，则重新导出keytab再试试。&lt;/p&gt;

&lt;p&gt;然后启动服务，观察日志： 
在node1启动namenode&lt;br /&gt;
hadoop-daemon.sh start namenode&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;待全部配置好之后，hdfs ha启动可参看&lt;a href=&quot;http://www.cnblogs.com/raphael5200/p/5154325.html&quot;&gt;配置HDFS HA(高可用)&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;测试启动&quot;&gt;测试启动&lt;/h3&gt;
&lt;p&gt;在本次操作中，未直接进行测试，是在namenode和datanode全部启动之后才进行测试，但是，验证NameNode是否启动可参照下属操作：&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;打开 web 界面查看启动状态&lt;/li&gt;
  &lt;li&gt;运行下面命令查看 hdfs（hadoop fs -ls /）：
    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; $ hadoop fs -ls /
 Found 4 items
 drwxrwxrwx   - yarn hadoop          0 2014-06-26 15:24 /logroot
 drwxrwxrwt   - hdfs hadoop          0 2014-11-04 10:44 /tmp
 drwxr-xr-x   - hdfs hadoop          0 2014-08-10 10:53 /user
 drwxr-xr-x   - hdfs hadoop          0 2013-05-20 22:52 /var
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;问题总结&quot;&gt;问题总结&lt;/h3&gt;
&lt;p&gt;采用此种方式过程中，可能遇到以下问题运行问题：&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;一个用户如果在你的凭据缓存中没有有效的kerberos ticket，执行上面命令将会失败，将会出现下面的错误：
    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;     11/01/04 12:08:12 WARN ipc.Client: Exception encountered while connecting to the server : javax.security.sasl.SaslException:
     GSS initiate failed [Caused by GSSException: No valid credentials provided (Mechanism level: Failed to find any Kerberos tgt)]
     Bad connection to FS. command aborted. exception: Call to nn-host/10.0.0.2:8020 failed on local exception: java.io.IOException:
     javax.security.sasl.SaslException: GSS initiate failed [Caused by GSSException: No valid credentials provided (Mechanism level: Failed to find any Kerberos tgt)]
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
    &lt;p&gt;解决方法：可通过klist来查看缓存状态，或重新kinit更新缓存。&lt;/p&gt;
    &lt;blockquote&gt;
      &lt;p&gt;此问题官网说明参考&lt;a href=&quot;https://www.cloudera.com/documentation/enterprise/5-11-x/topics/cm_sg_sec_troubleshooting.html#topic_17_1_0&quot;&gt;Running any Hadoop command fails after enabling security.&lt;/a&gt;&lt;/p&gt;
    &lt;/blockquote&gt;
  &lt;/li&gt;
  &lt;li&gt;但是，如果使用的是MIT kerberos 1.8.1或更高版本、并且Oracle JDK 6 Update 26或更低版本，即使成功的使用kinit获取了ticket，java仍然无法读取kerberos票据缓存，可能出现如下错误：
    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;     11/01/04 12:08:12 WARN ipc.Client: Exception encountered while connecting to the server : javax.security.sasl.SaslException:
     GSS initiate failed [Caused by GSSException: No valid credentials provided (Mechanism level: Failed to find any Kerberos tgt)]
     Bad connection to FS. command aborted. exception: Call to nn-host/10.0.0.2:8020 failed on local exception: java.io.IOException:
     javax.security.sasl.SaslException: GSS initiate failed [Caused by GSSException: No valid credentials provided (Mechanism level: Failed to find any Kerberos tgt)]
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
    &lt;p&gt;问题原因：这个问题是因为MIT kerberos 1.8.1或更高版本在写凭证缓存的时候做了一个更改（change参考&lt;a href=&quot;http://krbdev.mit.edu/rt/Ticket/Display.html?id=6206&quot;&gt;MIT Kerberos Change&lt;/a&gt;），如果使用是Oracle JDK 6 Update 26或更低版本，会遇到一个bug（bug参考&lt;a href=&quot;http://bugs.sun.com/bugdatabase/view_bug.do?bug_id=6979329&quot;&gt;Report of bug in Oracle JDK 6 Update 26 and lower&lt;/a&gt;），这个bug导致了在MIT kerberos 1.8.1或更高版中，java无法去读取Kerberos的票据缓存。而需要额外说明的是，Kerberos 1.8.1在Ubuntu Lucid或更高版本、 Debian Squeeze或更高版本中是默认Kerberos，会出现这个问题；但是在RHEL或CentOS中,默认的Kerberos是较老的版本，所以目前不会出现此问题。&lt;br /&gt;
解决方法：在使用kinit获取ticket之后使用&lt;strong&gt;&lt;em&gt;kinit -R&lt;/em&gt;&lt;/strong&gt;来renew ticket。这样，将重写票据缓存中的ticket为java可读的格式，如下：&lt;/p&gt;
    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;     $ klist
     klist: No credentials cache found (ticket cache FILE:/tmp/krb5cc_1000)
     $ hadoop fs -ls
     11/01/04 13:15:51 WARN ipc.Client: Exception encountered while connecting to the server : javax.security.sasl.SaslException:
     GSS initiate failed [Caused by GSSException: No valid credentials provided (Mechanism level: Failed to find any Kerberos tgt)]
     Bad connection to FS. command aborted. exception: Call to nn-host/10.0.0.2:8020 failed on local exception: java.io.IOException:
     javax.security.sasl.SaslException: GSS initiate failed [Caused by GSSException: No valid credentials provided (Mechanism level: Failed to find any Kerberos tgt)]
     $ kinit
     Password for atm@YOUR-REALM.COM: 
     $ klist
     Ticket cache: FILE:/tmp/krb5cc_1000
     Default principal: atm@YOUR-REALM.COM
        
     Valid starting     Expires            Service principal
     01/04/11 13:19:31  01/04/11 23:19:31  krbtgt/YOUR-REALM.COM@YOUR-REALM.COM
        
     renew until 01/05/11 13:19:30
     $ hadoop fs -ls
     11/01/04 13:15:59 WARN ipc.Client: Exception encountered while connecting to the server : javax.security.sasl.SaslException:
     GSS initiate failed [Caused by GSSException: No valid credentials provided (Mechanism level: Failed to find any Kerberos tgt)]
     Bad connection to FS. command aborted. exception: Call to nn-host/10.0.0.2:8020 failed on local exception: java.io.IOException:
     javax.security.sasl.SaslException: GSS initiate failed [Caused by GSSException: No valid credentials provided (Mechanism level: Failed to find any Kerberos tgt)]
     $ kinit -R
     $ hadoop fs -ls
     Found 6 items
     drwx------   - atm atm          0 2011-01-02 16:16 /user/atm/.staging
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;在上述问题2中，也有kinit -R 问题：&lt;br /&gt;
     但是，需要注意的是使用2这种方法，要求的是ticket是可renew的。而能否获取renewable tickets依赖于KDC的设置和每一个principal的设置（包括realm中有问题的principal和TGT service端的principal）。&lt;br /&gt;
     如果，一个ticker不可renew，那么它的”valid starting”和”renew until”的值是相同的时间。这时，使用kinit -R就会遇到下面的问题：
    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;     kinit: Ticket expired while renewing credentials
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
    &lt;blockquote&gt;
      &lt;p&gt;此问题官网说明参考&lt;a href=&quot;https://www.cloudera.com/documentation/enterprise/5-11-x/topics/cm_sg_sec_troubleshooting.html#topic_17_1_1&quot;&gt;Java is unable to read the Kerberos credentials cache created by versions of MIT Kerberos 1.8.1 or higher.&lt;/a&gt;&lt;/p&gt;
    &lt;/blockquote&gt;

    &lt;p&gt;所以为了获取可renew的ticket，可尝试使用以下方法-未彻底测试，若有问题，还需要大家自行解决下，并希望大家告诉我一下啦～（以下解决方法部分参考其他文章，&lt;a href=&quot;http://blog.csdn.net/wulantian/article/details/42173095&quot;&gt;CDH的Kerberos认证配置&lt;/a&gt;，时间过去挺久了，有些遗忘，待有时间再重新测试下）：&lt;br /&gt;
a.在kdc.conf中添加默认flag&lt;/p&gt;
    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;     default_principal_flags = +forwardable,+renewable
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
    &lt;p&gt;但是实际没有起作用，因为查看资料，默认的principal_flags就包含了renewable，所以问题不是出在这里。另外需要说明一点，default_principal_flags只对这个flags生效以后创建的principal生效，之前创建的不生效，需要使用modprinc来使之前的principal生效。&lt;br /&gt;
b.在kdc.conf中添加，并加大该参数：&lt;/p&gt;
    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;     max_renewable_life = 10d
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
    &lt;p&gt;修改之后重启kdc，重新kinit，再重新执行kinit -R则可以正常renew了。&lt;br /&gt;
为了进行验证，再次将参数修改为“max_renewable_life = 0s”，再重新kinit后执行kinit -R则再次不能renew，则说明是否可以获取renew的ticket中，默认是可以获取renew的ticket的，但是，可以renw的最长时间是0s，所以造成无法renew，解决的办法是在kdc.conf中增大该参数。&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;blockquote&gt;
  &lt;p&gt;另外补充：&lt;br /&gt;
1」关于krb5.conf中的renew_lifetime = 7d参数，该参数设置该服务器上的使用kinit -R时renew的时间。&lt;br /&gt;
2」可以通过modprinc来修改max_renewable_life的值，使用modprinc修改的值比kdc.conf中的配置有更高的优先级，例如，使用modprinc设置了为7天，kdc.conf中设置了为10天，使用getprinc可以看出，实际生效的是7天。需要注意的是，既要修改krbtgt/for_hadoop@for_hadoop，也要修改类似于hdfs/hadoop.local@for_hadoop这样的prinicials。使用modprinc来修改max_renewable_life，即kadmin.local进入kerberos的shell之后，执行：&lt;/p&gt;
  &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;modprinc -maxrenewlife 7days krbtgt/for_hadoop@for_hadoop  
getprinc krbtgt/for_hadoop@for_hadoop
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;  &lt;/div&gt;
&lt;/blockquote&gt;

&lt;p&gt;到这里，kinit -R的问题解决，可以成功的执行hadoop fs -ls了。&lt;br /&gt;
其他问题参考官网&lt;a href=&quot;https://www.cloudera.com/documentation/enterprise/5-11-x/topics/cm_sg_sec_troubleshooting.html#topic_17_1_0&quot;&gt;Troubleshooting Authentication Issues&lt;/a&gt;。&lt;/p&gt;

&lt;h2 id=&quot;启动datanode&quot;&gt;启动datanode&lt;/h2&gt;
&lt;p&gt;根据hdfs配置的区别，有两种启动datanode的方式，一种是使用jscv，一种是开启SASL。&lt;/p&gt;
&lt;h3 id=&quot;方式一jsvc启动datanode-目前此种方式测试有些问题能成功启动并正常使用但是启动后通过jps查看发现datanode处有进程号但无进程名字datanode原因未知待解决&quot;&gt;方式一：jsvc启动datanode-目前此种方式测试有些问题，能成功启动并正常使用，但是启动后通过jps查看，发现datanode处有进程号，但无进程名字“datanode”，原因未知，待解决。&lt;/h3&gt;
&lt;p&gt;如果没有配置TLS/SSL for HDFS（hdfs-site.xml里的dfs.http.policy），则datanode需要通过JSVC启动（只能root用户）。&lt;/p&gt;

&lt;p&gt;关于Datanode+jsvc：&lt;br /&gt;
在2.6版本前，启用hadoop安全模式，因为DataNode的数据传输协议没有使用HadoopRPC框架，DataNodes必须使用被dfs.datanode.address和dfs.datanode.http.address指定的特权端口来认证他们自己，该认证使基于假设攻击者无法获取在DataNode主机上的root特权。启动datanode的时候，必须用root用户，而当你使用root执行hdfs datanode命令时，服务器进程首先绑定特权端口，随后销毁特权并使用被HADOOP_SECURE_DN_USER指定的用户账号运行。这个启动进程使用被安装在JSVC_HOME的jsvc program。因此必须在启动项中hadoop-env.sh指定HADOOP_SECURE_DN_USER和JSVC_HOME做为环境变量。&lt;/p&gt;

&lt;p&gt;jsvc模式启动datanode关键点先说明：&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;hdfs-site.xml中没有开启TLS/SSL HDFS配置；&lt;/li&gt;
  &lt;li&gt;hdfs-site.xml中dfs.datanode.address、dfs.datanode.http.address的端口一定小于1024（特权端口）；&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;hadoop-env.sh设置HADOOP_SECURE_DN_USER为实际启动用户；&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  export HADOOP_SECURE_DN_USER=hadoop
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;安装jsvc，在hdfs-site.xml下加入安装目录JSVC_HOME，jsvc相关jar包替换；&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  export JSVC_HOME=/opt/hadoop/sbin/Linux/bigtop-jsvc-1.0.10-cdh5.11.0
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;启动服务前，先获取ticket再运行相关命令，要使用root用户启动datanode。&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;ijsvc环境部署hdfs集群的所有节点都要进行此操作&quot;&gt;i.jsvc环境部署（hdfs集群的所有节点都要进行此操作）&lt;/h4&gt;
&lt;p&gt;使用jsvc模式，hdfs-site.xml中去掉ssl配置，并且相关端口号使用特权端口，之后需要部署jsvc环境。
因为系统里未安装jsvc，则首先进行安装操作，安装参考&lt;a href=&quot;http://blog.csdn.net/shuchangwen/article/details/45242549&quot;&gt;jscv安装&lt;/a&gt;。&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;下载安装包
因为我的hdoop版本是2.6.0-cdh5.11.0，因此我在&lt;a href=&quot;http://archive.cloudera.com/cdh5/cdh/5/&quot;&gt;CDH组件下载&lt;/a&gt;处下载了bigtop-jsvc-1.0.10-cdh5.11.0.tar.gz。
    &lt;blockquote&gt;
      &lt;p&gt;补充：有些文章说明，apache hadoop可去&lt;a href=&quot;http://archive.apache.org/dist/commons/daemon/binaries/&quot;&gt;apache网站&lt;/a&gt;下载源代码和bin包。并且，关于JSVC，默认指向hadoop安装目录的libexec下，但libexec下并没有jsvc文件（hadoop是直接下载的tar.gz包，不是rpm安装），如下载commons-daemon-1.0.15-src.tar.gz及commons-daemon-1.0.15-bin.tar.gz，先解压src包后进入src/native/unix目录依次(可能需要先yum install gcc make sdk autoconf，再执行)执行./configure命令，make命令，这样会在当前目录下生成一个叫jsvc的文件，之后把它拷贝到hadoop目录下的libexec下，或更改环境变量如3。&lt;/p&gt;
    &lt;/blockquote&gt;
  &lt;/li&gt;
  &lt;li&gt;安装操作&lt;br /&gt;
把安装包放到了HADOOP_HOME家目录”/sbin/Linux/”目录下，直接解压即可。&lt;br /&gt;
解压成bigtop-jsvc-1.0.10-cdh5.11.0后，进入到$HADOOP_HOME/sbin/Linux/bigtop-jsvc-1.0.10-cdh5.11.0目录下，可以看到jsvc，使用“./jsvc -help”命令测试jsvc能否使用（注意修改整个文件的权限drwxr-xr-x. 5 hadoop root   4096 Sep  8 13:54 bigtop-jsvc-1.0.10-cdh5.11.0）。&lt;/li&gt;
  &lt;li&gt;配置环境变量&lt;br /&gt;
在hadoop-env.sh文件中加入以下内容：
    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;export HADOOP_SECURE_DN_USER=hadoop
export JSVC_HOME=/opt/hadoop/sbin/Linux/bigtop-jsvc-1.0.10-cdh5.11.0
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
    &lt;blockquote&gt;
      &lt;p&gt;说明：设置了HADOOP_SECURE_DN_USER的环境变量后，start-dfs.sh的启动脚本将会自动跳过DATANODE的启动。&lt;/p&gt;
    &lt;/blockquote&gt;
  &lt;/li&gt;
  &lt;li&gt;替换jar包&lt;br /&gt;
之前是没有进行替换jar包的操作，之后启动过程中出现错误，之后查阅资料得知，JSVC运行还需要一个commons-daemon-xxx.jar包，因此发现需要进行jar包替换，通过查阅资料得知，需要替换$HADOOP_HOME/share/hadoop/hdfs/lib下的commons-daemon-xxx.jar。&lt;br /&gt;
因为我下载的是bigtop-jsvc-1.0.10-cdh5.11.0.tar.gz，而在HADOOP_HOME家目录的/share/hadoop/hdfs/lib下的是commons-daemon-1.0.13.jar，因此从&lt;a href=&quot;http://archive.apache.org/dist/commons/daemon/binaries/&quot;&gt;commons／daemon&lt;/a&gt;下下载了commons-daemon-1.0.10.jar，然后把得到的commons-daemon-1.0.10.jar文件拷贝到hadoop安装目录下share/hadoop/hdfs/lib下（有文章说明要同时删除自带版本的commons-daemon-xxx.jar包，但我没有删除也可以使用）并更改了权限和其它内容保持一致(如-rwxr-xr-x. 1 hadoop root    24242 Sep  8 14:13 commons-daemon-1.0.10.jar)。&lt;/li&gt;
&lt;/ol&gt;

&lt;blockquote&gt;
  &lt;p&gt;接1补充：如果下载的是apache commons，即可解压bin包，然后把得到的commons-daemon-**.jar文件拷贝到hadoop安装目录下share/hadoop/hdfs/lib下，同时删除自带版本的commons-daemon-xxx.jar包。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;将上述操作在集群中的所有节点重复一遍（node1、node2、node3）。&lt;br /&gt;
至此，jsvc的安装结束，注意hdfs的所有节点都要进行以上安装操作。&lt;/p&gt;
&lt;h4 id=&quot;ii启动集群datanode&quot;&gt;ii.启动（集群）datanode&lt;/h4&gt;
&lt;h5 id=&quot;启动操作-1&quot;&gt;启动操作&lt;/h5&gt;
&lt;p&gt;设置了Security后，NameNode、QJM、ZKFC可以通过start-dfs.sh启动，DataNode需要使用（jsvc）root权限启动。&lt;br /&gt;
并且因为设置了HADOOP_SECURE_DN_USER的环境变量后，执行start-dfs.sh的启动脚本将会自动跳过DATANODE的启动。&lt;br /&gt;
所以使用jsvc模式，启动集群的时候需要两个步骤：&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;启动NameNode、QJM、ZKFC（详细参考上述启动namenode）（若不是第一次启动，第一次配置好了hadoop的启动需要参考&lt;a href=&quot;http://www.cnblogs.com/raphael5200/p/5154325.html&quot;&gt;配置HDFS HA(高可用)&lt;/a&gt; ）
    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;#每台机器上（kinit启动的用户）
kinit -k -t /opt/hadoop_krb5/conf/hdfs.keytab hadoop/node1@HADOOP.COM
#node1上
start-dfs.sh
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
    &lt;p&gt;使用start-dfs.sh之后查看QJM的日志和ZKFC的日志（QJM的报错不会有明显的提示）检查有无exception；如果启动不成功则仍需进行排查（keytab、zk的kerberos等）。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;启动Datanode &lt;br /&gt;
因为Datanode需要通过jsvc启动进程，当你使用root执行启动脚本（如hdfs datanode）命令时，服务器进程首先绑定特权端口，随后销毁特权并使用被HADOOP_SECURE_DN_USER指定的用户账号运行。&lt;br /&gt;
所以先需要在集群中的每台机器上都获取原启动用户（hadoop）ticket（现在登陆的是root用户,时间有点长了，有些遗忘好像也需要kinitroot的），然后再启动服务。&lt;br /&gt;
kinit并启动服务：
    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; # ssh node1 &quot;kinit -k -t /opt/hadoop_krb5/conf/hdfs.keytab hadoop/node1@HADOOP.COM; ./opt/hadoop/sbin/hadoop-daemon.sh start datanode&quot;
 # ssh node2 &quot;kinit -k -t /opt/hadoop_krb5/conf/hdfs.keytab hadoop/node2@HADOOP.COM; ./opt/hadoop/sbin/hadoop-daemon.sh start datanode&quot;
 # ssh node3 &quot;kinit -k -t /opt/hadoop_krb5/conf/hdfs.keytab hadoop/node3@HADOOP.COM; ./opt/hadoop/sbin/hadoop-daemon.sh start datanode&quot;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
    &lt;p&gt;补充，或在kinit后每台机器上使用命令启动：&lt;/p&gt;
    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; HADOOP_DATANODE_USER=hadoop sudo -E /opt/hadoop/bin/hdfs datanode
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
    &lt;p&gt;或：&lt;/p&gt;
    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; [root@node1 ~]# kinit -k -t /opt/hadoop_krb5/conf/hdfs.keytab hadoop/node1@HADOOP.COM
 [root@node1 ~]# start-secure-dns.sh
 node3: starting datanode, logging to /app/dcos/hadoop_logs//hadoop-hadoop-datanode-node3.out
 node1: starting datanode, logging to /app/dcos/hadoop_logs//hadoop-hadoop-datanode-node1.out
 node2: starting datanode, logging to /app/dcos/hadoop_logs//hadoop-hadoop-datanode-node2.out
    
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;验证datanode启动情况：观看node1上NameNode日志，出现下面日志表示DataNode启动成功：
    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;2017-09-11 10:06:27,667 INFO org.apache.hadoop.security.UserGroupInformation: Login successful for user hadoop/node1@HADOOP.COM using keytab file /opt/hadoop_krb5/conf/hdfs.keytab
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h5 id=&quot;遇到问题&quot;&gt;遇到问题&lt;/h5&gt;
&lt;p&gt;通过此方法启动datanode之后，通过jps查看，发现进程名字无法显示，但是hadoop集群运行正常。&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;[root@node1 sbin]# jps
6912 QuorumPeerMain
8785 NameNode
9251 DFSZKFailoverController
27156 Jps
10456
19929 Main
9033 JournalNode
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;排查问题补充相关：&lt;br /&gt;
jps(Java Virtual Machine Process Status Tool)是提供的一个显示当前所有java进程pid的命令，而jvm运行时会生成一个目录hsperfdata_$USER(其中user是启动java进程的用户)，默认的是生成在 java.io.tmpdir目录下，在linux中默认是/tmp，目录下会有些pid文件,存放jvm进程信息可以利用strings查看里面的文件内容，一般就是jvm的进程信息而已。&lt;br /&gt;
以上问题是只有进程号，没有进程名字，就思考是不是pid文件问题，于是去/tmp/hsperfdata_hadoop/和/tmp/hsperfdata_root/下看看是否有相关进程信息，发现datanode虽然是用jsvc方式用root用户启动的，而“10456”进程在/tmp/hsperfdata_hadoop/下。&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;[root@node1 tmp]# cd hsperfdata_
hsperfdata_apple1/  hsperfdata_apple2/  hsperfdata_hadoop/  hsperfdata_root/    hsperfdata_sitech1/ hsperfdata_sitech2/
[root@node1 tmp]# cd hsperfdata_hadoop/
[root@node1 hsperfdata_hadoop]# ls
10456  6912  8785  9033  9251
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;之后就去尝试使用SASL方式启动datanode了，这个问题就没有继续解决。怀疑是不是上面部署步骤出现问题了，有时间回来再看看是什么问题，再进行修改@TODO，希望大家有消息告诉我下，非常感谢！邮箱：leafming@foxmail.com。&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;此文“&lt;a href=&quot;http://blog.csdn.net/xiao_jun_0820/article/details/39375819&quot;&gt;Hadoop的kerberos的实践部署&lt;/a&gt;”和“&lt;a href=&quot;http://blog.csdn.net/wulantian/article/details/42173095&quot;&gt;CDH的Kerberos认证&lt;/a&gt;”内有关于datanode使用jsvc启动内容，但未完全参照。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;补充其他问题（好像这个问题没啥关系，不是这么解决，就先放这放着吧）：有人说，有时候端口问题服务无法正常启动，如：“WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: node2/10.211.55.11:8020”，使用“netstat -an|grep 8020”命令查看端口状态，如果不正常，映射为127.0.0.1:8020，则可尝试修改/etc/hosts文件中，去掉“127.0.0.1 localhost”，添加自己ip和主机名的映射，重新启动。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h5 id=&quot;小总结&quot;&gt;小总结&lt;/h5&gt;
&lt;p&gt;加强理解，再次重复总结：jsvc模式启动datanode关键点：&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;hdfs-site.xml中没有开启TLS/SSL HDFS配置；&lt;/li&gt;
  &lt;li&gt;hdfs-site.xml中dfs.datanode.address、dfs.datanode.http.address的端口一定小于1024（特权端口）；&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;hadoop-env.sh设置HADOOP_SECURE_DN_USER为实际启动用户；&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  export HADOOP_SECURE_DN_USER=hadoop
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;安装jsvc，在hdfs-site.xml下加入安装目录JSVC_HOME，jsvc相关jar包替换；&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  export JSVC_HOME=/opt/hadoop/sbin/Linux/bigtop-jsvc-1.0.10-cdh5.11.0
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;启动服务前，先获取ticket再运行相关命令，要使用root用户启动datanode，其它正常用hadoop用户即可。&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;方式二hfds中开启sasl整体配置&quot;&gt;方式二：Hfds中开启SASL整体配置&lt;/h3&gt;

&lt;blockquote&gt;
  &lt;p&gt;过渡说明：关于迁移一个使用root验证的hdfs集群为SASL方式，官方网站（&lt;a href=&quot;http://hadoop.apache.org/docs/stable/hadoop-project-dist/hadoop-common/SecureMode.html&quot;&gt;Hadoop in Secure Mode-Secure DataNode&lt;/a&gt; ）上有如下说明：&lt;/p&gt;

  &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;In order to migrate an existing cluster that used root authentication to start using SASL instead, first ensure that version 2.6.0 or later has been deployed to all cluster nodes as well as any external applications that need to connect to the cluster. Only versions 2.6.0 and later of the HDFS client can connect to a DataNode that uses SASL for authentication of data transfer protocol, so it is vital that all callers have the correct version before migrating. After version 2.6.0 or later has been deployed everywhere, update configuration of any external applications to enable SASL. If an HDFS client is enabled for SASL, then it can connect successfully to a DataNode running with either root authentication or SASL authentication. Changing configuration for all clients guarantees that subsequent configuration changes on DataNodes will not disrupt the applications. Finally, each individual DataNode can be migrated by changing its configuration and restarting. It is acceptable to have a mix of some DataNodes running with root authentication and some DataNodes running with SASL authentication temporarily during this migration period, because an HDFS client enabled for SASL can connect to both.
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;  &lt;/div&gt;
&lt;/blockquote&gt;

&lt;p&gt;方式一介绍了使用jsvc启动datanode（稍有问题），下面开始介绍使用SASL的方式。&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;有文章写了sasl in hdfs的配置方式相关操作，参考&lt;a href=&quot;http://blog.csdn.net/dxl342/article/details/55510659&quot;&gt;HDFS使用Kerberos&lt;/a&gt;。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;关于SASL模式的配置关键主要有以下几点，文章上面配置hadoop部分也有部分说明：&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;hdfs-site.xml中开启TLS/SSL HDFS配置；&lt;/li&gt;
  &lt;li&gt;hdfs-site.xml中dfs.datanode.address、dfs.datanode.http.address的端口一定大于1024（非特权端口）；&lt;/li&gt;
  &lt;li&gt;hadoop-env.sh中的HADOOP_SECURE_DN_USER内容一定为空，并且和jsvc模式不同，不需要进行jsvc的环境部署；&lt;/li&gt;
  &lt;li&gt;https配置；&lt;/li&gt;
  &lt;li&gt;正常启动hdfs集群。&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;ihdfs配置1基础配置&quot;&gt;i.hdfs配置（1基础配置）&lt;/h4&gt;
&lt;p&gt;虽然上面配置地方已经提过了，不过这次还是再重复写一遍吧，保持操作完整性嘛，大家配置过的可以去检查一次。&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;hdfs-site.xml中开启TLS/SSL HDFS配置，即在hdfs-site.xml中定义dfs.http.policy，指定要在HDFS的守护进程启动HTTPS服务器。增加如下内容：
    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; &amp;lt;!-- 开启SSL(jsvc时可不配置；可选，详见下属总结以及启动datanode部分) --&amp;gt;
 &amp;lt;property&amp;gt;
  	&amp;lt;name&amp;gt;dfs.http.policy&amp;lt;/name&amp;gt;
  	&amp;lt;value&amp;gt;HTTPS_ONLY&amp;lt;/value&amp;gt;
 &amp;lt;/property&amp;gt;
 &amp;lt;!-- SASL 模式--&amp;gt;
 &amp;lt;property&amp;gt;
  	&amp;lt;name&amp;gt;dfs.data.transfer.protection&amp;lt;/name&amp;gt;
 	 &amp;lt;value&amp;gt;integrity&amp;lt;/value&amp;gt;
 &amp;lt;/property&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
    &lt;p&gt;说明，这里可以使用三个参数：  &lt;br /&gt;
HTTP_ONLY: Only HTTP server is started&lt;br /&gt;
HTTPS_ONLY: Only HTTPS server is started&lt;br /&gt;
HTTP_AND_HTTPS: Both HTTP and HTTPS server are started  &lt;br /&gt;
值得一提的是，如果dfs.http.policy设置了https_only，则普通的WebHDFS不再可用。您将需要使用WebHDFS基于HTTPS，在这种结构中，它能保护你通过WebHDFS的数据。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;检查hdfs-site.xml中dfs.datanode.address、dfs.datanode.http.address的端口一定大于1024（非特权端口）；hadoop-env.sh中的HADOOP_SECURE_DN_USER内容一定为空。&lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&quot;iihttps配置&quot;&gt;ii.https配置&lt;/h4&gt;
&lt;p&gt;经过以上操作后，尝试启动hdfs，会发现namenode报错后退出，如下：&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;2017-09-13 14:12:37,273 INFO org.apache.hadoop.http.HttpServer2: HttpServer.start() threw a non Bind IOException
java.io.FileNotFoundException: /home/dtdream/.keystore (No such file or directory)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;发现没有keystore文件，这个问题跟hadoop、Kerberos没什么关系，纯粹是https的配置了。&lt;br /&gt;
简单说明https相关原理：https要求集群中有一个CA，它会生成ca_key和ca_cert，想要加入这个集群的节点，需要拿到这2个文件，然后经过一连串的动作生成keystore，并在hadoop的ssl-server.xml和ssl-client.xml中指定这个keystore的路径和密码，这样各个节点间就可以使用https进行通信了。
因此若要继续使用此模式，后续需要进行hdfs中的https配置。详细hdfs的https配置，可参考&lt;a href=&quot;https://zh.hortonworks.com/blog/deploying-https-hdfs/&quot;&gt;DEPLOYING HTTPS IN HDFS&lt;/a&gt;，下面直接帖命令简单说明下过程。&lt;/p&gt;

&lt;p&gt;注：在每台（node1、node2、node3）机器上都创建了/opt/ca 这个目录，存放ca相关文件，以下命令均在集群中各个机器的此目录下执行。&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;生成每个机器的密钥和证书&lt;br /&gt;
首先需要在集群里面的每个机器上创建keyhecertificate，可以使用keytool命令来创建，如：
    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ keytool -keystore {keystore} -alias localhost -validity {validity} -genkey
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
    &lt;p&gt;即通过此命令定义两个关键参数：&lt;br /&gt;
keystore：keystore文件负责存储certificate，里面包括certificate的私钥，因此需要好好保存；&lt;br /&gt;
validity：定义certificate的有效时间。&lt;br /&gt;
keytool命令会设置certificate的一些相关细节，如CN、OU、O、L、ST、C；其中CN要和节点全域名（FQDN）保持一致，通常情况下，在有部署DNS的情况下，客户端将cn与DNS域名进行比较，以确保它确实连接到所需服务器，而不是恶意服务器。&lt;br /&gt;
此操作命令示例（注意密码）：&lt;/p&gt;
    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;#node1  ／opt／ca目录下
keytool -keystore keystore -alias node1 -validity 9999 -genkey -keyalg RSA -keysize 2048 -dname &quot;CN=node1, OU=security, O=hadoop, L=beijing, ST=beijing, C=CN&quot;  
#node2  ／opt／ca目录下
keytool -keystore keystore -alias node2 -validity 9999 -genkey -keyalg RSA -keysize 2048 -dname &quot;CN=node1, OU=security, O=hadoop, L=beijing, ST=beijing, C=CN&quot;  
#node3  ／opt／ca目录下
keytool -keystore keystore -alias node3 -validity 9999 -genkey -keyalg RSA -keysize 2048 -dname &quot;CN=node1, OU=security, O=hadoop, L=beijing, ST=beijing, C=CN&quot;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
    &lt;p&gt;执行完上述命令，会在当前目录下生成keystore文件。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;创建自己的CA  &lt;br /&gt;
经过第一步之后，集群的每个机器中有个自己的公私密钥对以及一个标识机器的证书。但是，证书是没有注册的，这意味着攻击者可以创建这样的证书冒充任何机器。&lt;br /&gt;
因此，为了防止伪造证书，要为注册签名集群中的每台机器的证书。证书颁发机构（CA）负责签署证书。CA的工作就像一个政府签发护照，政府印章（标志）每个护照，使护照变得难以伪造。其他政府核实这些邮票以确保护照是真实的。类似地，CA在证书上签名，加密保证了签名证书难以伪造。因此，只要CA是一个真正可信的权威，客户就保证他们连接到真正的机器。&lt;br /&gt;
下面，使用openssl命令去生成一个新的CA证书，生成的CA仅仅是一个公私密钥对和证书，可以用它签署其他证书。
我们这里将node1作为CA，在node1上执行如下命令（注意密码）：
    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;#node1  ／opt／ca目录下
openssl req -new -x509 -keyout test_ca_key -out test_ca_cert -days 9999 -subj '/C=CN/ST=beijing/L=beijing/O=hadoop/OU=security/CN=node1'
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
    &lt;p&gt;说明：这里cn是CA服务器的地址。&lt;br /&gt;
执行完以上命令，会在当前目录下生成test_ca_cert、test_ca_key文件。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;添加CA到客户机器的信任库&lt;br /&gt;
在生成了CA之后，需要添加CA到每个客户端的信任库中，使客户可以信任这个CA，使用命令：
    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ keytool -keystore {truststore} -alias CARoot -import -file {ca-cert}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
    &lt;p&gt;此步骤操作命令示例： 
即，首先在node1上，将上面生成的test_ca_key和test_ca_cert拷贝到集群中的所有机器上。&lt;/p&gt;
    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;#node1  ／opt／ca目录下
scp test_ca_cert node2:/opt/ca/  
scp test_ca_cert node3:/opt/ca/  
scp test_ca_key node3:/opt/ca/  
scp test_ca_key node2:/opt/ca/
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
    &lt;p&gt;在集群中每台机器上执行如下命令（注意密码）：&lt;/p&gt;
    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;#node1  ／opt／ca目录下  
keytool -keystore truststore -alias CARoot -import -file test_ca_cert
#node2  ／opt／ca目录下  
keytool -keystore truststore -alias CARoot -import -file test_ca_cert
#node3  ／opt／ca目录下  
keytool -keystore truststore -alias CARoot -import -file test_ca_cert
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
    &lt;p&gt;执行完以上命令，会在当前目录下生成truststore文件。&lt;br /&gt;
在步骤1中的ketstore存储的是每一台机器自己的身份，而客户机的truststore存储的是客户端信任的所有证书。导入证书到一个truststore中意味着信任那个证书签名的其它所有证书。如以上所述，信任政府（CA）也意味着信任它签发的所有护照（证书）。这个属性称为信任链，它在大型Hadoop集群上部署HTTPS时特别有用。你可以在集群中用一个CA签名所有认证，然后每个机器就能使用一个相同信任了CA的truststore，通过这种方式，所有的机器可以验证所有其他机器。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;签名证书&lt;br /&gt;
下一步就是要使用步骤2生成的CA来签名步骤1中生成的所有证书。
    &lt;ol&gt;
      &lt;li&gt;首先，你需要从密钥库中导出的证书，使用如下命令：
        &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; $ keytool -keystore -alias localhost -certreq -file {cert-file}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;        &lt;/div&gt;
        &lt;p&gt;即在node1、node2、node3上执行（注意密码）：&lt;/p&gt;

        &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; #node1  ／opt／ca目录下
 keytool -certreq -alias node1 -keystore keystore -file cert  
 #node2  ／opt／ca目录下
 keytool -certreq -alias node2 -keystore keystore -file cert
 #node3  ／opt／ca目录下
 keytool -certreq -alias node3 -keystore keystore -file cert
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;        &lt;/div&gt;
        &lt;p&gt;执行完以上命令，会在当前目录下生成cert文件。&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;之后，使用CA进行签名，使用如下命令：
        &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; $ openssl x509 -req -CA {ca-cert} -CAkey {ca-key} -in {cert-file} -out {cert-signed} -days {validity} -CAcreateserial -passin pass:{ca-password}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;        &lt;/div&gt;
        &lt;p&gt;即在node1、node2、node3上执行（注意密码）：&lt;/p&gt;
        &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; #node1  ／opt／ca目录下
 openssl x509 -req -CA test_ca_cert -CAkey test_ca_key -in cert -out cert_signed -days 9999 -CAcreateserial -passin pass:hadoop@1234
 #这个pass是CA的密码，即Then sign it with the CA。
 #node2  ／opt／ca目录下
 openssl x509 -req -CA test_ca_cert -CAkey test_ca_key -in cert -out cert_signed -days 9999 -CAcreateserial -passin pass:hadoop@1234
 #node3  ／opt／ca目录下
 openssl x509 -req -CA test_ca_cert -CAkey test_ca_key -in cert -out cert_signed -days 9999 -CAcreateserial -passin pass:hadoop@1234
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;        &lt;/div&gt;
        &lt;p&gt;执行完以上命令，会在当前目录下生成cert_signed文件。&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;最后，将CA正式和被签名的证书都导入keystore中，使用如下命令：
        &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; $ keytool -keystore -alias CARoot -import -file {ca-cert}
 $ keytool -keystore -alias localhost -import -file {cert-signed}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;        &lt;/div&gt;
        &lt;p&gt;即在node1、node2、node3上执行（注意密码）：&lt;/p&gt;

        &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; #node1  ／opt／ca目录下
 keytool -keystore keystore -alias CARoot -import -file test_ca_cert
 keytool -keystore keystore -alias node1 -import -file cert_signed
 #node2  ／opt／ca目录下
 keytool -keystore keystore -alias CARoot -import -file test_ca_cert
 keytool -keystore keystore -alias node2 -import -file cert_signed
 #node3  ／opt／ca目录下
 keytool -keystore keystore -alias CARoot -import -file test_ca_cert
 keytool -keystore keystore -alias node3 -import -file cert_signed
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;        &lt;/div&gt;
      &lt;/li&gt;
      &lt;li&gt;补充：以上命令参数说明：&lt;br /&gt;
 keystore:keystore的位置&lt;br /&gt;
 ca-cert:CA证书&lt;br /&gt;
 ca-key:CA私钥&lt;br /&gt;
 ca-password:CA密码&lt;br /&gt;
 cert-file:导出的服务器的未签名证书&lt;br /&gt;
 cert-signed:服务器的签名的证书&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&quot;iiihdfs配置2整合https&quot;&gt;iii.hdfs配置（2整合https）&lt;/h4&gt;
&lt;p&gt;最后需要去配置HDFS中的HTTPs。&lt;br /&gt;
其次，需要配置在$HADOOP_HOME/etc/hadoop目录下的ssl-server.xml和ssl-client.xml，告诉HDFS的密钥库和信任存储区。&lt;br /&gt;
在所有节点上均进行此配置，现在node1上配置好，之后拷贝到其他节点（因为文件设置的都是在一样的路径）。&lt;br /&gt;
说明：这里没来得及深究，有些配置可以省略。以后又时间再补充。@TODO&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;ssl-client.xml&lt;br /&gt;
本次操作配置文件示例：
    &lt;div class=&quot;language-xml highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; &lt;span class=&quot;nt&quot;&gt;&amp;lt;configuration&amp;gt;&lt;/span&gt;
 &lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
   &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;ssl.client.truststore.location&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
   &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;/opt/ca/truststore&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
   &lt;span class=&quot;nt&quot;&gt;&amp;lt;description&amp;gt;&lt;/span&gt;Truststore to be used by clients like distcp. Must be specified.
   &lt;span class=&quot;nt&quot;&gt;&amp;lt;/description&amp;gt;&lt;/span&gt;
 &lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
 &lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
   &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;ssl.client.truststore.password&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
   &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;hadoop@1234&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
   &lt;span class=&quot;nt&quot;&gt;&amp;lt;description&amp;gt;&lt;/span&gt;Optional. Default value is &quot;&quot;.
   &lt;span class=&quot;nt&quot;&gt;&amp;lt;/description&amp;gt;&lt;/span&gt;
 &lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
 &lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
   &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;ssl.client.truststore.type&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
   &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;jks&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
   &lt;span class=&quot;nt&quot;&gt;&amp;lt;description&amp;gt;&lt;/span&gt;Optional. The keystore file format, default value is &quot;jks&quot;.
   &lt;span class=&quot;nt&quot;&gt;&amp;lt;/description&amp;gt;&lt;/span&gt;
 &lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
 &lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
   &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;ssl.client.truststore.reload.interval&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
   &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;10000&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
   &lt;span class=&quot;nt&quot;&gt;&amp;lt;description&amp;gt;&lt;/span&gt;Truststore reload check interval, in milliseconds.
   Default value is 10000 (10 seconds).
   &lt;span class=&quot;nt&quot;&gt;&amp;lt;/description&amp;gt;&lt;/span&gt;
 &lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
 &lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
   &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;ssl.client.keystore.location&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
   &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;/opt/ca/keystore&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
   &lt;span class=&quot;nt&quot;&gt;&amp;lt;description&amp;gt;&lt;/span&gt;Keystore to be used by clients like distcp. Must be specified.
   &lt;span class=&quot;nt&quot;&gt;&amp;lt;/description&amp;gt;&lt;/span&gt;
 &lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
 &lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
   &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;ssl.client.keystore.password&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
   &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;hadoop@1234&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
   &lt;span class=&quot;nt&quot;&gt;&amp;lt;description&amp;gt;&lt;/span&gt;Optional. Default value is &quot;&quot;.
   &lt;span class=&quot;nt&quot;&gt;&amp;lt;/description&amp;gt;&lt;/span&gt;
 &lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
 &lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
   &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;ssl.client.keystore.keypassword&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
   &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;hadoop@1234&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
   &lt;span class=&quot;nt&quot;&gt;&amp;lt;description&amp;gt;&lt;/span&gt;Optional. Default value is &quot;&quot;.
   &lt;span class=&quot;nt&quot;&gt;&amp;lt;/description&amp;gt;&lt;/span&gt;
 &lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
 &lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
   &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;ssl.client.keystore.type&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
   &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;jks&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
   &lt;span class=&quot;nt&quot;&gt;&amp;lt;description&amp;gt;&lt;/span&gt;Optional. The keystore file format, default value is &quot;jks&quot;.
   &lt;span class=&quot;nt&quot;&gt;&amp;lt;/description&amp;gt;&lt;/span&gt;
 &lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
 &lt;span class=&quot;nt&quot;&gt;&amp;lt;/configuration&amp;gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;ssl-server.xml&lt;br /&gt;
本次操作配置文件示例：
    &lt;div class=&quot;language-xml highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; &lt;span class=&quot;nt&quot;&gt;&amp;lt;configuration&amp;gt;&lt;/span&gt;
 &lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
   &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;ssl.server.truststore.location&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
   &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;/opt/ca/truststore&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
   &lt;span class=&quot;nt&quot;&gt;&amp;lt;description&amp;gt;&lt;/span&gt;Truststore to be used by NN and DN. Must be specified.
   &lt;span class=&quot;nt&quot;&gt;&amp;lt;/description&amp;gt;&lt;/span&gt;
 &lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
 &lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
   &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;ssl.server.truststore.password&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
   &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;hadoop@1234&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
   &lt;span class=&quot;nt&quot;&gt;&amp;lt;description&amp;gt;&lt;/span&gt;Optional. Default value is &quot;&quot;.
   &lt;span class=&quot;nt&quot;&gt;&amp;lt;/description&amp;gt;&lt;/span&gt;
 &lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
 &lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
   &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;ssl.server.truststore.type&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
   &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;jks&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
   &lt;span class=&quot;nt&quot;&gt;&amp;lt;description&amp;gt;&lt;/span&gt;Optional. The keystore file format, default value is &quot;jks&quot;.
   &lt;span class=&quot;nt&quot;&gt;&amp;lt;/description&amp;gt;&lt;/span&gt;
 &lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
 &lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
   &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;ssl.server.truststore.reload.interval&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
   &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;10000&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
   &lt;span class=&quot;nt&quot;&gt;&amp;lt;description&amp;gt;&lt;/span&gt;Truststore reload check interval, in milliseconds.
   Default value is 10000 (10 seconds).
   &lt;span class=&quot;nt&quot;&gt;&amp;lt;/description&amp;gt;&lt;/span&gt;
 &lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
 &lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
   &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;ssl.server.keystore.location&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
   &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;/opt/ca/keystore&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
   &lt;span class=&quot;nt&quot;&gt;&amp;lt;description&amp;gt;&lt;/span&gt;Keystore to be used by NN and DN. Must be specified.
   &lt;span class=&quot;nt&quot;&gt;&amp;lt;/description&amp;gt;&lt;/span&gt;
 &lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
 &lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
   &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;ssl.server.keystore.password&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
   &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;hadoop@1234&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
   &lt;span class=&quot;nt&quot;&gt;&amp;lt;description&amp;gt;&lt;/span&gt;Must be specified.
   &lt;span class=&quot;nt&quot;&gt;&amp;lt;/description&amp;gt;&lt;/span&gt;
 &lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
 &lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
   &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;ssl.server.keystore.keypassword&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
   &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;hadoop@1234&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
   &lt;span class=&quot;nt&quot;&gt;&amp;lt;description&amp;gt;&lt;/span&gt;Must be specified.
   &lt;span class=&quot;nt&quot;&gt;&amp;lt;/description&amp;gt;&lt;/span&gt;
 &lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
 &lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
   &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;ssl.server.keystore.type&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
   &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;jks&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
   &lt;span class=&quot;nt&quot;&gt;&amp;lt;description&amp;gt;&lt;/span&gt;Optional. The keystore file format, default value is &quot;jks&quot;.
   &lt;span class=&quot;nt&quot;&gt;&amp;lt;/description&amp;gt;&lt;/span&gt;
 &lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
 &lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
   &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;ssl.server.exclude.cipher.list&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
   &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;TLS_ECDHE_RSA_WITH_RC4_128_SHA,SSL_DHE_RSA_EXPORT_WITH_DES40_CBC_SHA,SSL_RSA_WITH_DES_CBC_SHA,SSL_DHE_RSA_WITH_DES_CBC_SHA,SSL_RSA_EXPORT_WITH_RC4_40_MD5,SSL_RSA_EXPORT_WITH_DES40_CBC_SHA,SSL_RSA_WITH_RC4_128_MD5&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
   &lt;span class=&quot;nt&quot;&gt;&amp;lt;description&amp;gt;&lt;/span&gt;Optional. The weak security cipher suites that you want excluded from SSL communication.&lt;span class=&quot;nt&quot;&gt;&amp;lt;/description&amp;gt;&lt;/span&gt;
 &lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
 &lt;span class=&quot;nt&quot;&gt;&amp;lt;/configuration&amp;gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
    &lt;p&gt;以上，关于Hfds中开启SASL整体配置说明完毕。&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;下面总结一下都做了什么：&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;hdfs-site.xml中开启TLS/SSL HDFS配置；&lt;/li&gt;
  &lt;li&gt;hdfs-site.xml中dfs.datanode.address、dfs.datanode.http.address的端口一定大于1024（非特权端口）；&lt;/li&gt;
  &lt;li&gt;hadoop-env.sh中的HADOOP_SECURE_DN_USER内容一定为空，并且和jsvc模式不同，不需要进行jsvc的环境部署；&lt;/li&gt;
  &lt;li&gt;配置https：生成每个机器的密钥和证书；创建自己的CA；添加CA到客户机器的信任库；签名证书；&lt;/li&gt;
  &lt;li&gt;hdfs中整合https：配置ssl-server.xml和ssl-client.xml。&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;iv测试启动集群&quot;&gt;iv.测试启动（集群）&lt;/h4&gt;
&lt;p&gt;以上，关于hdfs中开启SASL的整体配置完毕，下面即可直接进行集群的启动。&lt;br /&gt;
补充：此处作为补充完整描述下全新集群的启动过程，通常情况下，直接启动即可。&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;全新HA集群启动过程：
    &lt;ol&gt;
      &lt;li&gt;kinit验证&lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;分别启动zookeeper&lt;/p&gt;

        &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; zkServer.sh start
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;        &lt;/div&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;启动三台JournalNode：node1、node2、node3&lt;/p&gt;

        &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; hadoop-daemon.sh start journalnode
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;        &lt;/div&gt;
      &lt;/li&gt;
      &lt;li&gt;在其中一个NameNode上格式化hadoop.tmp.dir并初始化(格式化完成之后，将会在&lt;script type=&quot;math/tex&quot;&gt;\$\{dfs.namenode.name.dir\}/current&lt;/script&gt;目录下生成元数据，&lt;script type=&quot;math/tex&quot;&gt;\$\{dfs.namenode.name.dir\}&lt;/script&gt;是在hdfs-site.xml中配置的，默认值是&lt;script type=&quot;math/tex&quot;&gt;file://\$\{hadoop.tmp.dir\}/dfs/name&lt;/script&gt;，dfs.namenode.name.dir属性可配多个目录，如 /data1/dfs/name，/data2/dfs/name，/data3/dfs/name等。各个目录存储的文件结构和内容都完全一样，相当于备份，这样做的好处是当其中一个目录损坏了，也不会影响到Hadoop的元数据，特别是当其中一个目录是NFS（网络文件系统 Network File System，NFS）之上，即使你这台机器损坏了，元数据也得到保存；&lt;script type=&quot;math/tex&quot;&gt;\$\{hadoop.tmp.dir\}&lt;/script&gt;是在core-si te.xml文件内配置的）
        &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; #node1
 hdfs namenode -format
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;        &lt;/div&gt;
      &lt;/li&gt;
      &lt;li&gt;把格式化后的元数据拷备到另一台NameNode节点上
        &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; #node1
 $ scp -r ${hadoop.tmp.dir} root@node2:${hadoop.tmp.dir}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;        &lt;/div&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;启动NameNode&lt;/p&gt;

        &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; #node1
 hadoop-daemon.sh start namenode
 #node2
 hdfs namenode -bootstrapStandby（Y/N？）
 hadoop-daemon.sh start namenode
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;        &lt;/div&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;初始化zkfc&lt;/p&gt;

        &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; #Node1:
 hdfs zkfc -formatZK
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;        &lt;/div&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;全面停止并全面启动&lt;/p&gt;

        &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; #Node1:
 stop-dfs.sh
 start-dfs.sh
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;        &lt;/div&gt;
      &lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;因为启动过程中用到了hadoopHA，因此，可测试namenode的HA切换。
    &lt;ol&gt;
      &lt;li&gt;
        &lt;p&gt;用命令查看namenode的状态（两台namenode，在hdfs-si te.xml中配置的名字和主机名保持了一直，也是node1，所以这里测试写node1）：&lt;/p&gt;

        &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; hdfs haadmin -getServiceState node1
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;        &lt;/div&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;通过使用上述命令，有时候出现两台namenode都是standby的情况，则可以使用如下命令进行强制切换：&lt;/p&gt;

        &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; hdfs haadmin -transitionToActive --forcemanual node1
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;        &lt;/div&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;再次使用上述命令查看切换状态。&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;hr /&gt;
&lt;p&gt;至此，本篇内容完成。以上内容基本上是完全关于HDFS中的Kerberos部署，HDFS结合Kerberos的整体部署完毕，若配置中使用了HA，则需要进行下文ZK配置之后才能完成完整部署。&lt;/p&gt;</content><author><name>叶子  ( ˘ ³˘)♥</name></author><category term="Kerberos" /><summary type="html">本文主要关于Kerberos的简单应用。因为工作测试需要，自己装了一套集群进行了Kerberos的部署，并且与HDFS、ZK进行整合，然后将操作过程进行了整理，以便后续再查看。本文主要涉及到其与HDFS的整合操作，此文为2018-05-05文章Kerberos具体实践1的后续，上文说明了Kerberos集群的安装以及基本命令的使用；由于篇幅有限，下文在2018-06-29文章Kerberos具体实践3中继续说明Kerberos与ZK整合操作。</summary></entry><entry><title type="html">Docker+Mesos+Marathon监控方法使用总结</title><link href="http://localhost:4000/cloud/2018/06/15/Docker+Mesos+Marathon%E7%9B%91%E6%8E%A7%E6%96%B9%E6%B3%95%E4%BD%BF%E7%94%A8%E6%80%BB%E7%BB%93/" rel="alternate" type="text/html" title="Docker+Mesos+Marathon监控方法使用总结" /><published>2018-06-15T00:00:00+08:00</published><updated>2018-06-15T00:00:00+08:00</updated><id>http://localhost:4000/cloud/2018/06/15/Docker+Mesos+Marathon%E7%9B%91%E6%8E%A7%E6%96%B9%E6%B3%95%E4%BD%BF%E7%94%A8%E6%80%BB%E7%BB%93</id><content type="html" xml:base="http://localhost:4000/cloud/2018/06/15/Docker+Mesos+Marathon%E7%9B%91%E6%8E%A7%E6%96%B9%E6%B3%95%E4%BD%BF%E7%94%A8%E6%80%BB%E7%BB%93/">&lt;blockquote&gt;
  &lt;p&gt;本文主要关于Docker、Mesos、Marathon的监控方法的总结。&lt;br /&gt;
&lt;strong&gt;注意: 本文中使用的版本是Docker1.12.6、Mesos1.3.0、Marathon1.4.5。&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Docker+Mesos+Marathon所搭建的平台监控所用到的后台方法已经基本上写完了，现在用一些时间总结下相关监控方法，满满用心总结的，不过用到的不止这些，还差很多以后再另开文章补充。在总结过程中也重新梳理了很多东西，现在分享出来，希望对大家有用啦，也省的自己以后忘了～哈哈。&lt;/p&gt;

&lt;h1 id=&quot;docker管理-容器相关&quot;&gt;Docker管理-容器相关&lt;/h1&gt;
&lt;h2 id=&quot;前期准备开启docker远程访问&quot;&gt;前期准备：开启Docker远程访问&lt;/h2&gt;
&lt;p&gt;Docker daemon可以有3种远程访问方式的socket：unix、tcp和fd。&lt;br /&gt;
其中Docker支持使用restful api远程获取信息，但是需要提前开启一个Tcp Socket，这样才能实现远程通信。&lt;br /&gt;
默认情况下，Docker守护进程Unix socket（/var/run/docker.sock）来进行本地进程通信，而不会监听任何端口，因此只能在本地使用docker客户端或者使用Docker API进行操作,并且需要root权限或者是docker group成员。如果想在其他主机上操作Docker主机，就需要让Docker守护进程打开一个Tcp Socket，这样才能实现远程通信。&lt;br /&gt;
补充说明：可以使用HTTPs方式，不过目前没有进行配置，可以后续更改。但是，如果你用和Https的socket，需要注意的是只支持TLS1.0及以上的协议，SSLv3或者更低的是不支持的。&lt;br /&gt;
官方网站描述如下&lt;a href=&quot;https://docs.docker.com/v1.12/engine/reference/commandline/dockerd/&quot;&gt;Daemon socket option&lt;/a&gt;。&lt;br /&gt;
我们来使用开启TCP Socket的方式。&lt;br /&gt;
需要更改docker配置文件，修改OPTIONS，具体方式如下：&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;如果找不到docker配置文件，可以以下述方式查找：&lt;br /&gt;
找到docker.service文件：&lt;br /&gt;
systemctl show –property=FragmentPath docker
    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;---@---[~]$systemctl show --property=FragmentPath docker 
FragmentPath=/usr/lib/systemd/system/docker.service
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
    &lt;p&gt;找到docker.service文件并查看，发现docker文件位置：/etc/sysconfig/docker&lt;br /&gt;
&lt;img src=&quot;https://github.com/leafming/bak/blob/master/images/cloud/2018-06-11-dockerservice内容.png?raw=true&quot; alt=&quot;DockerService内容&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;找到文件后编辑文件docker&lt;br /&gt;
在OPTIONS=后加上 -H=unix:///var/run/docker.sock -H=tcp://0.0.0.0:端口&lt;br /&gt;
说明：&lt;br /&gt;
1、确定sock文件位置：/var/run/docker.sock&lt;br /&gt;
2、可用指定ip：指定端口&lt;br /&gt;
3、重启docker&lt;br /&gt;
&lt;img src=&quot;https://github.com/leafming/bak/blob/master/images/cloud/2018-06-11-dockertcpSocket配置.png?raw=true&quot; alt=&quot;DockerService内容&quot; /&gt;&lt;br /&gt;
说明：&lt;br /&gt;
有资料表述，一般情况下执行以下操作即可：&lt;br /&gt;
1、vim /etc/sysconfig/docker（更改docker文件）&lt;br /&gt;
2、在OPTIONS=后加上 -H=unix:///var/run/docker.sock -H=tcp://0.0.0.0:端口即可&lt;br /&gt;
如若不成功，可尝试下述操作：&lt;br /&gt;
1、vim /usr/lib/systemd/system/docker.service （更改docker.service文件）&lt;br /&gt;
2、直接在ExecStart=/user/bin/dockerd后添加-H=tcp://0.0.0.0:端口 -H=unix:///var/run/docker.sock(注意顺序)  &lt;br /&gt;
3、执行命令：systemctl daemon-reload 、systemctl restart docker&lt;/li&gt;
  &lt;li&gt;测试使用：&lt;br /&gt;
配置之后，尝试使用docker restful api来获取信息。&lt;br /&gt;
&lt;img src=&quot;https://github.com/leafming/bak/blob/master/images/cloud/2018-06-11-dockerrestful获取尝试.png?raw=true&quot; alt=&quot;2018-06-11-dockerrestful获取尝试&quot; /&gt;&lt;br /&gt;
或者直接在机器上尝试查询：“sudo docker -H IP:端口 命令”来测试是否能够取到内容。&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;docker-client的选择&quot;&gt;Docker-Client的选择&lt;/h2&gt;
&lt;p&gt;Docker-client的前期准备已经完毕，下面进行DockerAPI的使用。&lt;/p&gt;
&lt;h3 id=&quot;docker版本与docker-api的对应关系-和-相关library&quot;&gt;Docker版本与Docker API的对应关系 和 相关Library&lt;/h3&gt;
&lt;p&gt;Docker提供了Docker Engine API 去连接Docker daemon 来进行Docker的管理。Docker Engine API是Restful API，可以通过http客户端，比如说wget或者curl等来使用。&lt;br /&gt;
Docker官方提供Python和Go的SDK，可以直接使用。而在我们这里使用的是java语言，所以可以直接使用restful API的方式来获取相关信息或者直接使用他人封装好的Library。&lt;/p&gt;
&lt;h4 id=&quot;docker版本和api版本对应&quot;&gt;Docker版本和API版本对应&lt;/h4&gt;
&lt;p&gt;Docker的不同版本对用不同版本的API。具体以一个表格的形式列了出来，具体可以参考官方网站所写的内容:&lt;a href=&quot;https://docs.docker.com/develop/sdk/#docker-ee-and-ce-api-mismatch&quot;&gt;Docker版本和API对应表-API version matrix&lt;/a&gt;。&lt;br /&gt;
通过查看这个表，我们知道，我现在用的docker版本是1.12.6，所以来说，所对应的API版本为1.24。&lt;br /&gt;
关于Docker Engine API 1.24的使用，可以参考官网&lt;a href=&quot;https://docs.docker.com/engine/api/v1.24/&quot;&gt;Docker Engine API 1.24&lt;/a&gt;。&lt;/p&gt;
&lt;h4 id=&quot;docker-unofficial-libraries&quot;&gt;Docker unofficial libraries&lt;/h4&gt;
&lt;p&gt;Docker中出了官方提供的Python和Go的SDK之外，仍然有一些非官方的libraries可以使用，并且可使用的语言类型更加的广泛。关于可以使用的Library，官方在官网上也有所推荐，见&lt;a href=&quot;https://docs.docker.com/develop/sdk/#unofficial-libraries&quot;&gt;官网Unofficial libraries&lt;/a&gt;所示。&lt;br /&gt;
目前，项目里面并没有直接使用Docker Engine API，而是使用Java的第三方Library,第三方Library也是对Docker Engine API的一个封装。关于Java的Library，Docker官方推荐有三种，docker-client、docker-java、docker-java-api，而这次在项目中，使用的是&lt;a href=&quot;https://github.com/spotify/docker-client&quot;&gt;spotify/docker-client&lt;/a&gt;，在下面会将部分所用Library中的方法和Docker Engine API对应着介绍一下。&lt;/p&gt;

&lt;h2 id=&quot;docker-client的使用&quot;&gt;Docker-Client的使用&lt;/h2&gt;
&lt;p&gt;我们使用的是&lt;a href=&quot;https://github.com/spotify/docker-client/blob/master/docs/user_manual.md&quot;&gt;spotify/docker-client&lt;/a&gt;，在github上有详细的使用说明，直接点击链接即可。所以就不详细介绍了，下面就直接列出来使用的几个方法记录一下。&lt;/p&gt;
&lt;h3 id=&quot;引入jar包&quot;&gt;引入jar包&lt;/h3&gt;
&lt;p&gt;我们使用的是spotify/docker-client，可以直接通过maven或者jar包的方式引入，maven如下：&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&amp;lt;dependency&amp;gt;
  &amp;lt;groupId&amp;gt;com.spotify&amp;lt;/groupId&amp;gt;
  &amp;lt;artifactId&amp;gt;docker-client&amp;lt;/artifactId&amp;gt;
  &amp;lt;version&amp;gt;LATEST-VERSION&amp;lt;/version&amp;gt;
&amp;lt;/dependency&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;针对Docker1.12.6，选择的是8.9.1版本。&lt;/p&gt;

&lt;h3 id=&quot;开始使用&quot;&gt;开始使用&lt;/h3&gt;
&lt;p&gt;因为项目中主要用到的是监控，所以基本上都是从服务器上查询的方法，关于对于创建容器、删除容器等操作，因为容器直接归于marathon管理，所以不在Docker这里进行容器创建、删除等操作了。&lt;/p&gt;

&lt;h4 id=&quot;创建和关闭docker连接&quot;&gt;创建和关闭Docker连接&lt;/h4&gt;
&lt;h5 id=&quot;创建连接&quot;&gt;创建连接&lt;/h5&gt;
&lt;p&gt;在之前的操作，开启了Docker RPC端口之后，可以在其他机器上创建远程Docker连接。&lt;br /&gt;
而且我们也没有开启https，所以可以直接使用如下方式：&lt;br /&gt;
传入容器宿主机IP+端口构成的uri，建立和宿主机的连接。&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;// use the builder
String dockerUri =&quot;http://&quot;+hostIp+&quot;:&quot;+port;
final DockerClient docker = DefaultDockerClient.builder().uri(URI.create(dockerUri)).build();
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;除了这种方式，还有其它几种方式创建docker连接，详细参考&lt;a href=&quot;https://github.com/spotify/docker-client/blob/master/docs/user_manual.md#creating-a-docker-client&quot;&gt;Creating a docker-client&lt;/a&gt;。&lt;/p&gt;
&lt;h5 id=&quot;关闭docker连接&quot;&gt;关闭Docker连接&lt;/h5&gt;
&lt;p&gt;关闭连接直接通过创建的DockerClient docker连接对象，调用close方法即可。&lt;/p&gt;
&lt;div class=&quot;language-java highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;// Close the docker client&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;docker&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;close&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;();&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;h4 id=&quot;docker操作&quot;&gt;Docker操作&lt;/h4&gt;
&lt;h5 id=&quot;容器列表&quot;&gt;容器列表&lt;/h5&gt;
&lt;p&gt;获取宿主机上的容器列表，方法如下：&lt;br /&gt;
这个方法能够列出宿主机上全部&lt;strong&gt;正在运行&lt;/strong&gt;的容器的列表。&lt;/p&gt;
&lt;div class=&quot;language-java highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;List&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Container&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;containers&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;docker&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;listContainers&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;DockerClient&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;ListContainersParam&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;allContainers&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;());&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;通过这个方法，可以返回List&lt;Container&gt;，其中的Container对象，可以取到的容器的id、名称、镜像信息、网络信息、状态等内容。&lt;/Container&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://github.com/leafming/bak/blob/master/images/cloud/2018-06-13-container属性.png?raw=true&quot; alt=&quot;container属性&quot; /&gt;&lt;/p&gt;

&lt;p&gt;并且，其中包括网络信息可以通过networkSettings取到，包括内容如下：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://github.com/leafming/bak/blob/master/images/cloud/2018-06-13-networkSettings属性.png?raw=true&quot; alt=&quot;networkSettings&quot; /&gt;&lt;/p&gt;

&lt;h5 id=&quot;容器详情&quot;&gt;容器详情&lt;/h5&gt;
&lt;p&gt;上述获取容器列表的过程中取到的容器信息并不详细，如果想看容器的详细信息可使用inspect方法,需要传入的内容是容器的id，不过通过测试，不需要传入全部的完整id，部分。&lt;/p&gt;
&lt;div class=&quot;language-java highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;ContainerInfo&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;info&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;docker&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;inspectContainer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;containerID&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;通过这个方法可以获取到ContainerInfo对象，其中包括容器的详细信息，如下：&lt;br /&gt;
&lt;img src=&quot;https://github.com/leafming/bak/blob/master/images/cloud/2018-06-13-containerInfo属性.png?raw=true&quot; alt=&quot;containerInfo&quot; /&gt;&lt;/p&gt;
&lt;h6 id=&quot;容器状态对象&quot;&gt;容器状态对象&lt;/h6&gt;
&lt;p&gt;通过 ContainerState state = info.state();可以取到容器的状态对象ContainerState，其中属性如下。&lt;br /&gt;
&lt;img src=&quot;https://github.com/leafming/bak/blob/master/images/cloud/2018-06-13-ContainerState.png?raw=true&quot; alt=&quot;ContainerState&quot; /&gt;&lt;br /&gt;
取对象的state.status()，可以取到当前容器的状态，容器状态总共包括：created、restarting、running、paused、exited、dead共5种。&lt;/p&gt;
&lt;h6 id=&quot;容器配置信息&quot;&gt;容器配置信息&lt;/h6&gt;
&lt;p&gt;通过 ContainerConfig config = containerInfo.config();取到容器的配置信息，其中属性包括如下。&lt;br /&gt;
&lt;img src=&quot;https://github.com/leafming/bak/blob/master/images/cloud/2018-06-13-ContainerConfig属性.png?raw=true&quot; alt=&quot;ContainerConfig&quot; /&gt;&lt;br /&gt;
通过ContainerConfig可以获取到容器的hostname、env配置、启动容器的命令、所用镜像、工作目录、labels等信息。&lt;/p&gt;
&lt;h6 id=&quot;容器hostconfig&quot;&gt;容器HostConfig&lt;/h6&gt;
&lt;p&gt;通过 HostConfig hostConfig = containerInfo.hostConfig();可以取到容器的host配置信息，其中属性如下。&lt;br /&gt;
&lt;img src=&quot;https://github.com/leafming/bak/blob/master/images/cloud/2018-06-13-HostConfig.png?raw=true&quot; alt=&quot;HostConfig&quot; /&gt;&lt;br /&gt;
通过HostConfig对象，可以获取到容器和宿主机之间映射的目录、端口等信息，以及所给容器分配的cpu core数量（hostConfig.cpuShares()取到的数值除以1024）、memory（hostConfig.memory()）、swap的大小（hostConfig.memorySwap()-hostConfig.memory()）等信息。&lt;/p&gt;
&lt;h6 id=&quot;容器网络信息&quot;&gt;容器网络信息&lt;/h6&gt;
&lt;p&gt;通过NetworkSettings networkSettings = containerInfo.networkSettings();可以取到容器的网络信息，此对象和容器列表中取到的内容一致。通过它可以取到容器的网络模式、网关、ip、mac等信息。&lt;/p&gt;
&lt;h5 id=&quot;容器内进程&quot;&gt;容器内进程&lt;/h5&gt;
&lt;p&gt;上述操作均是获取容器的基本信息，如果获取容器内当时的进程信息，可以使用如下方法：&lt;br /&gt;
传入的ps_args为aux，和在容器内执行“ps aux”命令取到的数据一致，即“[USER, PID, %CPU, %MEM, VSZ, RSS, TTY, STAT, START, TIME, COMMAND]”等内容。&lt;br /&gt;
通过如下方法能取到TopResults对象，此对象内包括属性为process和titles，通过获取其中的process，可得到容器内的进程情况。&lt;/p&gt;
&lt;div class=&quot;language-java highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;//例子&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;//final TopResults topResults = docker.topContainer(&quot;containerID&quot;, &quot;ps_args&quot;);&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;TopResults&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;topResults&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;docker&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;topContainer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;containerID&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;aux&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;ImmutableList&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ImmutableList&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;processes&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;topResults&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;processes&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;();&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;h5 id=&quot;容器资源使用情况&quot;&gt;容器资源使用情况&lt;/h5&gt;
&lt;p&gt;在命令行中，我们可以通过docker stats来查看docker容器资源使用情况的信息，通过命令行能查询到如下内容：&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;CONTAINER    CPU %    MEM USAGE / LIMIT    MEM %    NET I/O    BLOCK I/O
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;docker-client也提供了方法，来通过如下方式获取docker stats信息：&lt;/p&gt;
&lt;div class=&quot;language-java highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;ContainerStats&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;stats&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;docker&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;stats&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;containerID&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;通过此方法，能够取到ContainerStats对象，其中包含内容如下：&lt;br /&gt;
&lt;img src=&quot;https://github.com/leafming/bak/blob/master/images/cloud/2018-06-13-ContainerStats.png?raw=true&quot; alt=&quot;ContainerStats&quot; /&gt;&lt;br /&gt;
但是，我们取到的数据并不能直接使用，而需要通过计算，来得到更加直观的数据，下面进行一下详细说明。&lt;br /&gt;
而计算的过程，主要参考&lt;a href=&quot;https://www.2cto.com/net/201701/582048.html&quot;&gt;“dockerstats命令源码分析结果”&lt;/a&gt;文章中，对于docker stats源码的分析。&lt;/p&gt;
&lt;h6 id=&quot;cpu利用率计算&quot;&gt;CPU利用率计算&lt;/h6&gt;
&lt;ol&gt;
  &lt;li&gt;计算分析&lt;br /&gt;
在上述参考文章中提到:
    &lt;blockquote&gt;
      &lt;p&gt;docker daemon会记录这次读取/sys/fs/cgroup/cpuacct/docker/[containerId]/cpuacct.usage的值，作为cpu_total_usage；并记录了上一次读取的该值为pre_cpu_total_usage；读取/proc/stat中cpu field value，并进行累加，得到system_usage;并记录上一次的值为pre_system_usage；读取/sys/fs/cgroup/cpuacct/docker/[containerId]/cpuacct.usage_percpu中的记录，组成数组per_cpu_usage_array。&lt;/p&gt;
    &lt;/blockquote&gt;

    &lt;p&gt;因此，可以得到docker stats计算Cpu Percent的算法如下：&lt;/p&gt;
    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;cpu_delta = cpu_total_usage - pre_cpu_total_usage;
system_delta = system_usage - pre_system_usage;
CPU % = ((cpu_delta / system_delta) * length(per_cpu_usage_array) ) * 100.0
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;代码实现&lt;br /&gt;
所以说，将上述内容中得到的公式所需数据与我们通过取到的数据相对应，通过已经得到的stats对象，用方法可以取到两个CpuStats对象：
    &lt;div class=&quot;language-java highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;CpuStats&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cpuStats&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;stats&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;cpuStats&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;();&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;CpuStats&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;precpuStats&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;stats&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;precpuStats&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;();&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
    &lt;p&gt;然后我们计算cpu利用率，就可以这样来计算：&lt;/p&gt;
    &lt;div class=&quot;language-java highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;String&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cpuPercent&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;---&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;null&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;!=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cpuStats&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;null&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;!=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;precpuStats&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;){&lt;/span&gt;
 &lt;span class=&quot;cm&quot;&gt;/**
 	* 计算cpu利用率 %
 	* cpuDelta = cpuTotalUsage - preCpuTotalUsage;
   	* systemDelta = systemUsage - preSystemUsage;
   	* CPU % = ((cpuDelta / systemDelta) * length(per_cpu_usage_array) ) * 100.0
 	*/&lt;/span&gt;
 	&lt;span class=&quot;n&quot;&gt;Long&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cpuTotalUsage&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cpuStats&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;cpuUsage&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;().&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;totalUsage&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;();&lt;/span&gt;
 	&lt;span class=&quot;n&quot;&gt;Long&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;preCpuTotalUsage&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;precpuStats&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;cpuUsage&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;().&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;totalUsage&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;();&lt;/span&gt;
 	&lt;span class=&quot;n&quot;&gt;Long&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cpuDelta&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cpuTotalUsage&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;preCpuTotalUsage&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;
 	&lt;span class=&quot;n&quot;&gt;Long&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;systemUsage&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cpuStats&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;systemCpuUsage&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;();&lt;/span&gt;
 	&lt;span class=&quot;n&quot;&gt;Long&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;preSystemUsage&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;precpuStats&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;systemCpuUsage&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;();&lt;/span&gt;
 	&lt;span class=&quot;n&quot;&gt;Long&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;systemDelta&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;systemUsage&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;preSystemUsage&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;
 	&lt;span class=&quot;n&quot;&gt;Integer&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;percpuUsageListSize&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cpuStats&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;cpuUsage&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;().&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;percpuUsage&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;().&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;();&lt;/span&gt;
 	&lt;span class=&quot;n&quot;&gt;cpuPercent&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cpuDelta&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;floatValue&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;systemDelta&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;floatValue&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;())&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;percpuUsageListSize&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;floatValue&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;())&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;%&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;
 &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h6 id=&quot;memory利用率计算&quot;&gt;memory利用率计算&lt;/h6&gt;
&lt;ol&gt;
  &lt;li&gt;计算分析&lt;br /&gt;
在上述参考文章中提到:
    &lt;blockquote&gt;
      &lt;p&gt;读取/sys/fs/cgroup/memory/docker/[containerId]/memory.usage_in_bytes的值，作为mem_usage；如果容器限制了内存，则读取/sys/fs/cgroup/memory/docker/[id]/memory.limit_in_bytes作为mem_limit，否则mem_limit = machine_mem。&lt;/p&gt;
    &lt;/blockquote&gt;

    &lt;p&gt;因此可以得到docker stats计算Memory数据的算法如下：&lt;/p&gt;
    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;MEM USAGE = mem_usage
MEM LIMIT = mem_limit
MEM % = (mem_usage / mem_limit) * 100.0
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;代码实现&lt;br /&gt;
通过已经得到的stats对象，用方法可以取到MemoryStats对象。
    &lt;div class=&quot;language-java highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;MemoryStats&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;memoryStats&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;stats&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;memoryStats&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;();&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
    &lt;p&gt;然后根据公式来计算memory利用率：&lt;/p&gt;
    &lt;div class=&quot;language-java highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; &lt;span class=&quot;n&quot;&gt;String&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;memUsageFormat&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;---&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;
 &lt;span class=&quot;n&quot;&gt;String&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;memLimitFormat&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;---&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;
 &lt;span class=&quot;n&quot;&gt;String&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;memPercent&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;---&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;
 &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;null&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;!=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;memoryStats&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;){&lt;/span&gt;
 	&lt;span class=&quot;cm&quot;&gt;/**
      * 计算memory利用率 %
      * MEM USAGE = mem_usage
        MEM LIMIT = mem_limit
        MEM % = (mem_usage / mem_limit) * 100.0
      */&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;Long&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;memUsage&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;memoryStats&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;usage&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;();&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;Long&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;memLimit&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;memoryStats&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;limit&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;();&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;memUsageFormat&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Utils&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;getDynamicSizeUnit&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;memUsage&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;memLimitFormat&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Utils&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;getDynamicSizeUnit&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;memLimit&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;memPercent&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;memUsage&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;floatValue&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;memLimit&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;floatValue&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;())*&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;%&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;
 &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h6 id=&quot;network-io计算&quot;&gt;Network IO计算&lt;/h6&gt;
&lt;ol&gt;
  &lt;li&gt;计算分析&lt;br /&gt;
在上述参考文章中提到:
    &lt;blockquote&gt;
      &lt;p&gt;network stats的计算可以根据“获取属于该容器network namespace veth pairs在主机中对应的veth*虚拟网卡EthInterface数组，然后循环数组中每个网卡设备，读取/sys/class/net//statistics/rx_bytes得到rx_bytes, 读取/sys/class/net//statistics/tx_bytes得到对应的tx_bytes。将所有这些虚拟网卡对应的rx_bytes累加得到该容器的rx_bytes。将所有这些虚拟网卡对应的tx_bytes累加得到该容器的tx_bytes。&lt;/p&gt;
    &lt;/blockquote&gt;

    &lt;p&gt;因此我们可以得到network stats的计算算法如下：&lt;/p&gt;
    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;NET I = rx_bytes
NET O = tx_bytes
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;代码实现&lt;br /&gt;
通过已经得到的stats对象，可以取到 ImmutableMap&amp;lt;String, NetworkStats&amp;gt;。
    &lt;div class=&quot;language-java highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;ImmutableMap&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;NetworkStats&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;networks&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;stats&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;networks&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;();&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
    &lt;p&gt;然后根据公式来计算network io：&lt;/p&gt;
    &lt;div class=&quot;language-java highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; &lt;span class=&quot;n&quot;&gt;String&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rxBytesSumFormat&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;---&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;
 &lt;span class=&quot;n&quot;&gt;String&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;txBytesSumFormat&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;---&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;
 &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;null&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;!=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;networks&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;){&lt;/span&gt;
 	&lt;span class=&quot;cm&quot;&gt;/**
      * docker stats计算Network IO数据的算法：
        NET I = rx_bytes(所有网卡累加)
        NET O = tx_bytes（所有网卡累加）
      */&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;Long&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rxBytesSum&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0L&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;Long&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;txBytesSum&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0L&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Map&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;Entry&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;NetworkStats&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;nl&quot;&gt;entry:&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;networks&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;entrySet&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()){&lt;/span&gt;
  	      &lt;span class=&quot;n&quot;&gt;rxBytesSum&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;entry&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;getValue&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;().&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;rxBytes&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;();&lt;/span&gt;
           &lt;span class=&quot;n&quot;&gt;txBytesSum&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;entry&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;getValue&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;().&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;txBytes&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;();&lt;/span&gt;
        &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
   &lt;span class=&quot;c1&quot;&gt;//Utils.getDynamicSizeUnit()是一个动态单位转换的方法&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;rxBytesSumFormat&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Utils&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;getDynamicSizeUnit&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;rxBytesSum&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;txBytesSumFormat&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Utils&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;getDynamicSizeUnit&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;txBytesSum&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
 &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h6 id=&quot;blk-io计算&quot;&gt;Blk IO计算&lt;/h6&gt;
&lt;ol&gt;
  &lt;li&gt;计算分析&lt;br /&gt;
在上述参考文章中提到:
    &lt;blockquote&gt;
      &lt;p&gt;Blk IO计算可以根据“获取每个块设备的IoServiceBytesRecursive数据：先去读取/sys/fs/cgroup/blkio/docker/[containerId]/blkio.io_serviced_recursive中是否有有效值，如果有，则读取/sys/fs/cgroup/blkio/docker/[containerId]/blkio.io_service_bytes_recursive的值返回； 如果没有，就去读取/sys/fs/cgroup/blkio/docker/[containerId]/blkio.throttle.io_service_bytes中的值返回；将每个块设备的IoServiceBytesRecursive数据中所有read field对应value进行累加，得到该容器的blk_read值；将每个块设备的IoServiceBytesRecursive数据中所有write field对应value进行累加，得到该容器的blk_write值。&lt;/p&gt;
    &lt;/blockquote&gt;

    &lt;p&gt;因此，我们可以得到Blk IO计算算法如下：&lt;/p&gt;
    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;BLOCK I = blk_read
BLOCK O = blk_write
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;代码实现
    &lt;div class=&quot;language-java highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; &lt;span class=&quot;n&quot;&gt;String&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;blkReadFormat&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;---&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;
 &lt;span class=&quot;n&quot;&gt;String&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;blkWriteFormat&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;---&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;
 &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;null&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;!=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;blockIoStats&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;){&lt;/span&gt;
 	&lt;span class=&quot;cm&quot;&gt;/**
      * docker stats计算Block IO数据的算法：
        BLOCK I = blkRead
        BLOCK O = blkWrite
      */&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;ImmutableList&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Object&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;objects&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;blockIoStats&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;ioServiceBytesRecursive&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;();&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;Long&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;blkRead&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0L&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;Long&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;blkWrite&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0L&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;
        &lt;span class=&quot;c1&quot;&gt;//因为是Object，不好遍历，所以转变成了jsonobj遍历&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Object&lt;/span&gt; &lt;span class=&quot;nl&quot;&gt;obj:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;objects&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
        	&lt;span class=&quot;n&quot;&gt;String&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;jsonString&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;JSON&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;toJSONString&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;obj&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
             &lt;span class=&quot;n&quot;&gt;JSONObject&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;jsonObj&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;JSON&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;parseObject&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;jsonString&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
             &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Read&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;equals&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;jsonObj&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;getString&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;op&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;))){&lt;/span&gt;
         	    &lt;span class=&quot;n&quot;&gt;blkRead&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;jsonObj&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;getLong&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;value&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
             &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Write&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;equals&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;jsonObj&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;getString&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;op&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;))){&lt;/span&gt;
         &lt;span class=&quot;n&quot;&gt;blkWrite&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;jsonObj&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;getLong&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;value&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
             &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
        &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;blkReadFormat&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Utils&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;getDynamicSizeUnit&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;blkRead&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;blkWriteFormat&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Utils&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;getDynamicSizeUnit&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;blkWrite&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
 &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h6 id=&quot;获取时间&quot;&gt;获取时间&lt;/h6&gt;
&lt;p&gt;至此，以上将docker stats所需要的数据均计算出来了，之后我们只需获取下当前的采集时间即可。&lt;/p&gt;
&lt;div class=&quot;language-java highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; &lt;span class=&quot;n&quot;&gt;Date&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;read&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;stats&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;read&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;();&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h5 id=&quot;容器其他&quot;&gt;容器其他&lt;/h5&gt;
&lt;p&gt;上面说的基本上是关于docker容器监控所用的方法，剩下的都是直接操作容器的工具，先不写出来了，有需要的可以直接参考官方说明&lt;a href=&quot;https://github.com/spotify/docker-client/blob/master/docs/user_manual.md#creating-a-docker-client&quot;&gt;spotify/docker-client&lt;/a&gt;。&lt;/p&gt;

&lt;h4 id=&quot;容器宿主机监控&quot;&gt;容器宿主机监控&lt;/h4&gt;
&lt;p&gt;以上说明了容器的基础监控，我们在应用中，如果需要监控容器所在宿主机的情况，也可以使用下述方法：&lt;/p&gt;
&lt;div class=&quot;language-java highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;Info&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;info&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;docker&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;info&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;();&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;获取到了Info对象，通过此对象可以取到宿主机上运行的容器状态、资源情况等，具体可获取到的如下。&lt;br /&gt;
&lt;img src=&quot;https://github.com/leafming/bak/blob/master/images/cloud/2018-06-14-dockerhostInfo.png?raw=true&quot; alt=&quot;Info&quot; /&gt;&lt;/p&gt;

&lt;h4 id=&quot;其他&quot;&gt;其他&lt;/h4&gt;
&lt;p&gt;除了以上说的那些，还可以获取、操作Networks、Images等。因为我们这里自己创建的一个镜像库，所以不直接使用docker-client的方法获取镜像信息，下面会统一再说明镜像库的搭建和列表的获取。&lt;br /&gt;
至此，docker-client所用到的方法都说明完毕了，其他没提到的还是直接去看官方说明吧&lt;a href=&quot;https://github.com/spotify/docker-client/blob/master/docs/user_manual.md#creating-a-docker-client&quot;&gt;spotify/docker-client&lt;/a&gt;。&lt;/p&gt;

&lt;h2 id=&quot;engine-api的使用&quot;&gt;Engine API的使用&lt;/h2&gt;
&lt;p&gt;上述进行说明了Docker-client的使用，我们也可以直接通过Engine API v1.24来进行Docker的操作。&lt;br /&gt;
也是开启TCP端口之后，直接发送request到宿主机地址：端口，然后会收到json格式的response。&lt;br /&gt;
这里直接使用工具测试，获取到容器的列表信息，如下图。&lt;br /&gt;
&lt;img src=&quot;https://github.com/leafming/bak/blob/master/images/cloud/2018-06-14-restful获取容器列表.png?raw=true&quot; alt=&quot;2018-06-14-restful获取容器列表&quot; /&gt;&lt;br /&gt;
此后，如果需要，可以直接参考官方说明&lt;a href=&quot;https://docs.docker.com/engine/api/v1.24/&quot;&gt;Engine API v1.24&lt;/a&gt;，不过需要注意的是，我这里使用的docker对应的是v1.24的，其他版本的要选择不同对应版本的api哦，在本文最开始也选择docker-client的“Docker版本和API版本对应”处也说明了，忘记了的话回过头去看哦。&lt;/p&gt;

&lt;h1 id=&quot;docker管理-docker镜像仓库&quot;&gt;Docker管理-Docker镜像仓库&lt;/h1&gt;
&lt;p&gt;我们上述说明了使用Docker-Client获取Docker容器的一些基础信息，而镜像我们是单独部署了一个镜像服务器，因此，不直接使用docker-client来获取镜像列表。下面会先说明镜像服务器的部署，之后说下如何获取镜像服务器中的镜像列表。&lt;/p&gt;
&lt;h2 id=&quot;简单说明镜像服务器的部署&quot;&gt;简单说明镜像服务器的部署&lt;/h2&gt;
&lt;p&gt;Docke官方提供了Docker Hub网站来作为一个公开的集中仓库。然而，本地访问Docker Hub速度往往很慢，并且很多时候我们需要一个本地的私有仓库只供网内使用。&lt;br /&gt;
Docker仓库实际上提供两方面的功能，一个是镜像管理，一个是认证。前者主要由docker-registry项目来实现，通过http服务来上传下载；后者可以通过docker-index（闭源）项目或者利用现成认证方案（如nginx）实现http请求管理。&lt;br /&gt;
目前来说，我们只需要在内网建立一个存储镜像的地方，因此只使用docker registry来搭建一个私有镜像库。&lt;br /&gt;
下面简单说明下仓库搭建过程，也可以直接参考官方部署&lt;a href=&quot;https://docs.docker.com/registry/deploying/&quot;&gt;“Deploy a registry server”&lt;/a&gt;。&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;官方提供了registry镜像，我们直接下载：
    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;docker pull registry
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;默认情况下，会将仓库存放于容器内,这样的话如果容器被删除，则存放于容器中的镜像也会丢失，所以我们需要指定一个本地目录挂载到容器内的存放镜像的目录下。所以，我们以如下命令来启动一个docker容器：
    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;docker run --privileged=true -d -v /datacenter02/registry:/var/lib/registry -p 5000:5000 --restart=always --name registry registry
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;查看启动的容器
    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;---@---[~]#docker ps -a
CONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS              PORTS                    NAMES
458a9e2301a6        registry            &quot;/entrypoint.sh /etc/&quot;   7 months ago        Up 7 months         0.0.0.0:5000-&amp;gt;5000/tcp   registry
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;测试使用&lt;br /&gt;
创建一个小的镜像，然后测试push
    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;docker push 132.-.-.-:5000/busybox（这里的ip没写全，用-代替了，自己写的时候写全）
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
    &lt;p&gt;可以看到push失败，报关于https的错误类似如下。&lt;/p&gt;
    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Error response from daemon: invalid registry endpoint https://132.-.-.-:5000/v1/: Get https://132.-.-.-:5000/v1/_ping: http: server gave HTTP response to HTTPS client. If this private registry supports only HTTP or HTTPS with an unknown CA certificate, please add `--insecure-registry 132.-.-.-:5000` to the daemon's arguments. In the case of HTTPS, if you have access to the registry's CA certificate, no need for the flag; simply place the CA certificate at /etc/docker/certs.d/132.-.-.-:5000/ca.crt
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;配置http访问&lt;br /&gt;
因为Docker从1.3.X之后，与docker registry交互默认使用的是https，然而此处搭建的私有仓库只提供http服务，所以当与私有仓库交互时就会报上面的错误。为了解决这个问题需要在启动docker server时增加启动参数为默认使用http访问。&lt;br /&gt;
我们需要修改docker配置文件，在docker配置文件中增加“–insecure-registry 132.-.-.-:5000”，其中IP为了不泄露用-代替了，自己写的时候需要写全：
    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;# If you have a registry secured with https but do not have proper certs
# distributed, you can tell docker to not look for full authorization by
# adding the registry to the INSECURE_REGISTRY line and uncommenting it.
# INSECURE_REGISTRY='--insecure-registry'
INSECURE_REGISTRY='--insecure-registry 132.-.-.-:5000'
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
    &lt;p&gt;之后重启docker服务。&lt;br /&gt;
之后再次测试，可以发现没有报错啦，push成功。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;命令行仓库管理&lt;br /&gt;
有文章说，查询私有仓库中的所有镜像，使用docker search命令，但是我这里经过尝试，发现会报错：“Error response from daemon: Unexpected status code 404”。&lt;br /&gt;
后来发现，docker search是v1版本的API，我们现在的是v2版本，所以不能使用。&lt;br /&gt;
如果需要查询，则也是直接curl使用v2版本的API：
    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;---@---[~]#curl 132.90.130.13:5000/v2/_catalog
{&quot;repositories&quot;:[&quot;alluxio&quot;,&quot;basic&quot;,&quot;go&quot;,&quot;go1.10&quot;,&quot;go_zhzj&quot;,&quot;hdfs_datanode&quot;,&quot;hello-mine&quot;,&quot;hiveonspark&quot;,&quot;hiveonspark-gx&quot;,&quot;hivespark&quot;,&quot;jdk&quot;,&quot;jtwspark1.6.3&quot;,&quot;kafka&quot;,&quot;ninecon&quot;,&quot;nm&quot;,&quot;rm1&quot;,&quot;rm2&quot;,&quot;spark-2.3.0&quot;,&quot;spark2&quot;,&quot;spark2.2.1&quot;,&quot;spark2.2.1-gx&quot;,&quot;spark2.2.1-jtw&quot;,&quot;spark2.2.1-rx-demo&quot;,&quot;sparkdemo&quot;,&quot;sparkrx1.6.3&quot;,&quot;sparkrx2.2.1&quot;,&quot;tensorflow&quot;]}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
    &lt;p&gt;详细的将在下面说明。&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;镜像仓库器管理&quot;&gt;镜像仓库器管理&lt;/h2&gt;
&lt;p&gt;对于Docker Registry，Docker官方提供了HTTP API V2用于与其交互，用来管理docker images。对于此，在官方网站上也有说明：&lt;a href=&quot;https://docs.docker.com/registry/spec/api/&quot;&gt;HTTP API V2&lt;/a&gt;。&lt;br /&gt;
因为我们只用到了镜像管理功能，所以下面只是用到的说明获取仓库内的镜像列表以及tags的方法，其他的需要自己参考官网啦。&lt;/p&gt;
&lt;h3 id=&quot;镜像列表&quot;&gt;镜像列表&lt;/h3&gt;
&lt;p&gt;我们使用下述方式来获取仓库里面的镜像列表，获取也是请求之后来获取一个包含信息（仓库、镜像名称）的json串，官方给出的request和response例子如下：&lt;br /&gt;
request:&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;GET /v2/_catalog
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;response:&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;200 OK
Content-Type: application/json

{
  &quot;repositories&quot;: [
    &amp;lt;name&amp;gt;,
    ...
  ]
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;我这里直接使用json工具，获取到我们仓库中的镜像列表：&lt;br /&gt;
&lt;img src=&quot;https://github.com/leafming/bak/blob/master/images/cloud/2018-06-14-仓库镜像列表.png?raw=true&quot; alt=&quot;镜像列表&quot; /&gt;&lt;/p&gt;
&lt;h3 id=&quot;镜像tags&quot;&gt;镜像tags&lt;/h3&gt;
&lt;p&gt;但是，对于一个镜像来说，有不同的tags来标明它的版本，所以单单靠上述方法获取镜像的名称还是不够的，还需获取到tags。官方也给出了相关的例子：&lt;br /&gt;
request:&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;GET /v2/&amp;lt;name&amp;gt;/tags/list
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;response:&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;200 OK
Content-Type: application/json

{
    &quot;name&quot;: &amp;lt;name&amp;gt;,
    &quot;tags&quot;: [
        &amp;lt;tag&amp;gt;,
        ...
    ]
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;之后，我也使用json工具，获取了仓库中“spark2.2.1”的tags信息如下：&lt;br /&gt;
&lt;img src=&quot;https://github.com/leafming/bak/blob/master/images/cloud/2018-06-14-镜像tags获取.png?raw=true&quot; alt=&quot;镜像tags获取&quot; /&gt;&lt;/p&gt;

&lt;p&gt;至此，我们就可以得到仓库里面镜像对我们来说的有用的信息了。&lt;/p&gt;

&lt;h3 id=&quot;代码实现&quot;&gt;代码实现&lt;/h3&gt;
&lt;p&gt;而在后台程序里，直接使用了最原始的httpclient写了restful工具类，直接获取镜像名称和相关tags信息，后来封装成一个对象放到list中返回直接使用，也可以直接使用restful的相关框架就比较方便了，就不详细说明了。&lt;/p&gt;
&lt;div class=&quot;language-java highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  &lt;span class=&quot;cm&quot;&gt;/**
     * 获取镜像服务器内的镜像列表
     * http://..../v2/_catalog
     * @throws IOException
     */&lt;/span&gt;
    &lt;span class=&quot;kd&quot;&gt;public&lt;/span&gt;  &lt;span class=&quot;kd&quot;&gt;static&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;List&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;   &lt;span class=&quot;nf&quot;&gt;getImagesList&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;kd&quot;&gt;throws&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;IOException&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;String&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;url&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;http://&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ConstantOp&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;IMAGES_REPOSITORIES_IP&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;:&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ConstantOp&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;IMAGES_REPOSITORIES_PORT&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;/v2/_catalog&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;List&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;images&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ArrayList&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;gt;();&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;RestfulHttpCli&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;HttpResponse&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;response&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;RestfulHttpCli&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;getClient&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;url&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
                &lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;get&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt;              &lt;span class=&quot;c1&quot;&gt;//设置post请求&lt;/span&gt;
                &lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;addHeader&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Content-Type&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;application/json&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
                &lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;addHeader&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Accept&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;application/json&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
                &lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;addHeader&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;charset&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;utf-8&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
                &lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;request&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;();&lt;/span&gt;         &lt;span class=&quot;c1&quot;&gt;//发起请求&lt;/span&gt;
        &lt;span class=&quot;c1&quot;&gt;//响应状态码&lt;/span&gt;
        &lt;span class=&quot;c1&quot;&gt;//  System.out.println(response.getCode());&lt;/span&gt;
        &lt;span class=&quot;c1&quot;&gt;//最终发起请求的地址&lt;/span&gt;
        &lt;span class=&quot;c1&quot;&gt;//  System.out.println(response.getRequestUrl());&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;response&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;getCode&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;200&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;){&lt;/span&gt;
            &lt;span class=&quot;c1&quot;&gt;//请求成功&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;String&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;content&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;response&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;getContent&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;();&lt;/span&gt;
            &lt;span class=&quot;c1&quot;&gt;//格式化json&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;JSONObject&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;jsonObject&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;JSON&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;parseObject&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;content&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;JSONArray&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;repositories&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;jsonObject&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;getJSONArray&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;repositories&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;images&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;repositories&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;toJavaList&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;class&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
        &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;images&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;

    &lt;span class=&quot;cm&quot;&gt;/**
     * 获取镜像服务器内的镜像tags
     * 如http://..../v2/_catalog
     * @throws IOException
     */&lt;/span&gt;
    &lt;span class=&quot;kd&quot;&gt;public&lt;/span&gt;  &lt;span class=&quot;kd&quot;&gt;static&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;String&lt;/span&gt;  &lt;span class=&quot;nf&quot;&gt;getTagsList&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;String&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;image_name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;kd&quot;&gt;throws&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;IOException&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;String&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;url&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;http://&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ConstantOp&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;IMAGES_REPOSITORIES_IP&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;:&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ConstantOp&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;IMAGES_REPOSITORIES_PORT&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;/v2/{image_name}/tags/list&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;String&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tags_str&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;---&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;RestfulHttpCli&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;HttpResponse&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;response&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;RestfulHttpCli&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;getClient&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;url&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
                &lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;get&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt;              &lt;span class=&quot;c1&quot;&gt;//设置post请求&lt;/span&gt;
                &lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;addHeader&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Content-Type&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;application/json&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
                &lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;addHeader&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Accept&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;application/json&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
                &lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;addHeader&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;charset&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;utf-8&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
                &lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;addPathParam&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;image_name&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;image_name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
                &lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;request&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;();&lt;/span&gt;         &lt;span class=&quot;c1&quot;&gt;//发起请求&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;response&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;getCode&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;200&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;){&lt;/span&gt;
            &lt;span class=&quot;c1&quot;&gt;//请求成功&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;String&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;content&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;response&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;getContent&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;();&lt;/span&gt;
            &lt;span class=&quot;c1&quot;&gt;//格式化json&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;JSONObject&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;jsonObject&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;JSON&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;parseObject&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;content&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;JSONArray&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tags&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;jsonObject&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;getJSONArray&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;tags&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;tags_str&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;StringUtils&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;join&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tags&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;,&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
        &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tags_str&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
    
    &lt;span class=&quot;cm&quot;&gt;/**
     * 获取镜像服务器中的image列表，返回 List&amp;lt;ImagesDetails&amp;gt;
     * @return
     * @throws IOException
     */&lt;/span&gt;
    &lt;span class=&quot;kd&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;kd&quot;&gt;static&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;List&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ImagesDetails&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;   &lt;span class=&quot;nf&quot;&gt;getImagesDetailsList&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;kd&quot;&gt;throws&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;IOException&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;List&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ImagesDetails&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;  &lt;span class=&quot;n&quot;&gt;imagesDetailsList&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ArrayList&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;gt;();&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;List&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;imagesList&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;getImagesList&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;();&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;null&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;!=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;imagesList&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;){&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;String&lt;/span&gt; &lt;span class=&quot;nl&quot;&gt;image_name:&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;imagesList&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;ImagesDetails&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;imagesDetails&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ImagesDetails&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;();&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;imagesDetails&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;setName&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;image_name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;imagesDetails&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;setTags&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;getTagsList&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;image_name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;));&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;imagesDetailsList&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;add&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;imagesDetails&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
            &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
        &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;imagesDetailsList&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;至此，完成了镜像仓库列表获取的全部工具类。&lt;/p&gt;

&lt;p&gt;以上也将Docker监控的总结暂时告一段落，下面进行Mesos的说明。&lt;/p&gt;

&lt;h1 id=&quot;mesos管理&quot;&gt;Mesos管理&lt;/h1&gt;
&lt;p&gt;对于Mesos管理，官方提供2中方式：HTTP Endpoints和Operator HTTP API。&lt;/p&gt;
&lt;h2 id=&quot;http-endpoints&quot;&gt;HTTP Endpoints&lt;/h2&gt;
&lt;p&gt;对于Mesos master和Mesos agent均可以直接使用HTTP Endpoints，而且使用方式很简单，如下：&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;http://ip:port/endpoint
如：
http://masterIp:5050/metrics/snapshot
http://slaveIp:5050/metrics/snapshot
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;具体使用可以参考官方网站说明：&lt;a href=&quot;http://mesos.apache.org/documentation/latest/endpoints/#http-endpoints&quot;&gt;HTTP Endpoints&lt;/a&gt;。&lt;br /&gt;
通过观察，发现mesos原生监控页面中，是使用的这种方式，直接在前台进行调用的此api，所以，如果端口没开，当终端访问页面的时候，会无法获取数据。&lt;br /&gt;
下面就是从前台控制台看到的获取的内容，会调用定时获取snapshot和state2个内容。&lt;br /&gt;
&lt;img src=&quot;https://github.com/leafming/bak/blob/master/images/cloud/2018-06-15-mesos监控页面截图.png?raw=true&quot; alt=&quot;2018-06-15-mesos监控页面截图&quot; /&gt; &lt;br /&gt;
不过需要注意的是，如果使用的是Mesos1.1或之后的版本，不建议使用此种方式，可以使用下面说的新的&lt;a href=&quot;http://mesos.apache.org/documentation/latest/operator-http-api/&quot;&gt;v1 Operator HTTP API&lt;/a&gt;。&lt;/p&gt;

&lt;h2 id=&quot;operator-http-api&quot;&gt;Operator HTTP API&lt;/h2&gt;
&lt;p&gt;对于Mesos master和agents均支持/api/v1 endpoint。不过这个api仅支持post请求。并且请求内容需要是json格式（Content-Type: application/json）或者protobuf格式（Content-Type: application/x-protobuf）。&lt;br /&gt;
对于&lt;a href=&quot;http://mesos.apache.org/documentation/latest/operator-http-api/#master-api&quot;&gt;Master&lt;/a&gt;和&lt;a href=&quot;http://mesos.apache.org/documentation/latest/operator-http-api/#agent-api&quot;&gt;Agent&lt;/a&gt;均提供了丰富的api，直接点击连接即可查看官方的说明，我就不在这里一一列出来了，直接说一下用到的一个方法。&lt;/p&gt;
&lt;h3 id=&quot;使用mesos-api&quot;&gt;使用mesos api&lt;/h3&gt;
&lt;p&gt;对于mesos的api，我这里只使用了master的GET_METRICS方法，目的是想自己做一个监控，能监控到mesos中的全部的资源使用情况，如下图mesos原生监控页面里面所示：&lt;br /&gt;
&lt;img src=&quot;https://github.com/leafming/bak/blob/master/images/cloud/2018-06-15-mesos原生监控页面资源情况.png?raw=true&quot; alt=&quot;2018-06-15-mesos原生监控页面资源情况&quot; /&gt;&lt;br /&gt;
所以，为了获取这些内容，可以直接选择官方的master的&lt;a href=&quot;http://mesos.apache.org/documentation/latest/operator-http-api/#get_metrics&quot;&gt;GET_METRICS&lt;/a&gt;方法，官方给出的请求例子如下：&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;GET_METRICS HTTP Request (JSON):

POST /api/v1  HTTP/1.1

Host: masterhost:5050
Content-Type: application/json
Accept: application/json

{
  &quot;type&quot;: &quot;GET_METRICS&quot;,
  &quot;get_metrics&quot;: {
    &quot;timeout&quot;: {
      &quot;nanoseconds&quot;: 5000000000
    }
  }
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;然后我们可以直接使用工具进行获取测试：&lt;br /&gt;
&lt;img src=&quot;https://github.com/leafming/bak/blob/master/images/cloud/2018-06-15-mesosRestfulPost工具截图.png?raw=true&quot; alt=&quot;2018-06-15-mesosRestfulPost工具截图&quot; /&gt;&lt;br /&gt;
通过post方式发送对应json到“http://masterIP:5050/api/v1”即可取到了相应json格式的监控数据。&lt;br /&gt;
而在程序中，也是用了最原始的方法直接使用的httpclient写的restful工具类，通过提交post请求后，获取到对应的响应内容，也可以直接使用restful的框架会比较方便，其他的具体就不详细说了，直接贴下代码：&lt;br /&gt;
不过这里因为取到的json不是全部使用了，所以json解析是对应取到的数据提取自己有用的东西，使用了最笨的方法，求别嫌弃(,,• . •̀,) 。&lt;/p&gt;
&lt;div class=&quot;language-java highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;cm&quot;&gt;/**
     * 生成mesos的访问连接
     * @param hostIp
     * @return
     */&lt;/span&gt;
    &lt;span class=&quot;kd&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;String&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;generateUrl&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;String&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;hostIp&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;){&lt;/span&gt;
        &lt;span class=&quot;c1&quot;&gt;//格式如：http://-.-.-.-:5050/api/v1&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;http://&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;hostIp&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;:&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ConstantOp&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;MESOS_PORT&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;/api/v1&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;

    &lt;span class=&quot;kd&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;MasterMesosMetrics&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;getMasterMetrics&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;String&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mesosMasterIp&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;kd&quot;&gt;throws&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;IOException&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;String&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;url&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;generateUrl&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mesosMasterIp&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;MasterMesosMetrics&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;masterMesosMetrics&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;MasterMesosMetrics&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;();&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;RestfulHttpCli&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;HttpResponse&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;request&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kc&quot;&gt;null&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;request&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;RestfulHttpCli&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;getClient&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;url&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
                &lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;post&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt;   
                &lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;addHeader&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Content-Type&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;application/json&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
                &lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;addHeader&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Accept&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;application/json&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
                &lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;addHeader&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;charset&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;utf-8&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
                &lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;body&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;{\n&quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;
                        &lt;span class=&quot;s&quot;&gt;&quot;  \&quot;type\&quot;: \&quot;GET_METRICS\&quot;,\n&quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;
                        &lt;span class=&quot;s&quot;&gt;&quot;  \&quot;get_metrics\&quot;: {\n&quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;
                        &lt;span class=&quot;s&quot;&gt;&quot;    \&quot;timeout\&quot;: {\n&quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;
                        &lt;span class=&quot;s&quot;&gt;&quot;      \&quot;nanoseconds\&quot;: 5\n&quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;
                        &lt;span class=&quot;s&quot;&gt;&quot;    }\n&quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;
                        &lt;span class=&quot;s&quot;&gt;&quot;  }\n&quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;
                        &lt;span class=&quot;s&quot;&gt;&quot;}&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;request&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;();&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;//        System.out.println(request.getCode());&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;//        System.out.println(request.getRequestUrl());&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;200&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;request&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;getCode&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;())&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;String&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;content&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;request&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;getContent&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;();&lt;/span&gt;
            &lt;span class=&quot;c1&quot;&gt;//格式化json&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;JSONObject&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;contentObject&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;JSON&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;parseObject&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;content&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;JSONObject&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;get_metrics&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;contentObject&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;getJSONObject&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;get_metrics&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;JSONArray&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;metrics&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;get_metrics&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;getJSONArray&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;metrics&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;metrics&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
                &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;metrics&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;();&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;++)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
                    &lt;span class=&quot;c1&quot;&gt;// 遍历 jsonarray 数组，把每一个对象转成 json 对象&lt;/span&gt;
                    &lt;span class=&quot;n&quot;&gt;JSONObject&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;job&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;metrics&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;getJSONObject&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
                    &lt;span class=&quot;n&quot;&gt;Object&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;name&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;job&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;get&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;name&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
                    &lt;span class=&quot;c1&quot;&gt;//agents&lt;/span&gt;
                    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;master/slaves_active&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;equals&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)){&lt;/span&gt;
                        &lt;span class=&quot;n&quot;&gt;masterMesosMetrics&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;setSlavesActive&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;job&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;getInteger&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;value&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;));&lt;/span&gt;
                    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;master/slaves_inactive&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;equals&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)){&lt;/span&gt;
                        &lt;span class=&quot;n&quot;&gt;masterMesosMetrics&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;setSlavesInactive&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;job&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;getInteger&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;value&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;));&lt;/span&gt;
                    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;master/slaves_disconnected&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;equals&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)){&lt;/span&gt;
                        &lt;span class=&quot;n&quot;&gt;masterMesosMetrics&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;setSlavesDisconnected&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;job&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;getInteger&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;value&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;));&lt;/span&gt;
                        &lt;span class=&quot;c1&quot;&gt;//tasks&lt;/span&gt;
                    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;master/tasks_staging&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;equals&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)){&lt;/span&gt;
                        &lt;span class=&quot;n&quot;&gt;masterMesosMetrics&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;setTasksStaging&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;job&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;getInteger&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;value&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;));&lt;/span&gt;
                    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;master/tasks_starting&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;equals&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)){&lt;/span&gt;
                        &lt;span class=&quot;n&quot;&gt;masterMesosMetrics&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;setTasksStarting&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;job&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;getInteger&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;value&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;));&lt;/span&gt;
                    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;master/tasks_running&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;equals&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)){&lt;/span&gt;
                        &lt;span class=&quot;n&quot;&gt;masterMesosMetrics&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;setTasksRunning&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;job&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;getInteger&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;value&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;));&lt;/span&gt;
                    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;master/tasks_unreachable&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;equals&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)){&lt;/span&gt;
                        &lt;span class=&quot;n&quot;&gt;masterMesosMetrics&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;setTasksUnreachable&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;job&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;getInteger&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;value&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;));&lt;/span&gt;
                    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;master/tasks_killing&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;equals&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)){&lt;/span&gt;
                        &lt;span class=&quot;n&quot;&gt;masterMesosMetrics&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;setTasksKilling&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;job&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;getInteger&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;value&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;));&lt;/span&gt;
                    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;master/tasks_finished&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;equals&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)){&lt;/span&gt;
                        &lt;span class=&quot;n&quot;&gt;masterMesosMetrics&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;setTasksFinished&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;job&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;getInteger&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;value&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;));&lt;/span&gt;
                    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;master/tasks_killed&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;equals&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)){&lt;/span&gt;
                        &lt;span class=&quot;n&quot;&gt;masterMesosMetrics&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;setTasksKilled&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;job&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;getInteger&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;value&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;));&lt;/span&gt;
                    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;master/tasks_failed&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;equals&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)){&lt;/span&gt;
                        &lt;span class=&quot;n&quot;&gt;masterMesosMetrics&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;setTasksFailed&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;job&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;getInteger&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;value&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;));&lt;/span&gt;
                    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;master/tasks_lost&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;equals&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)){&lt;/span&gt;
                        &lt;span class=&quot;n&quot;&gt;masterMesosMetrics&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;setTasksLost&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;job&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;getInteger&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;value&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;));&lt;/span&gt;
                        &lt;span class=&quot;c1&quot;&gt;//resources&lt;/span&gt;
                        &lt;span class=&quot;c1&quot;&gt;//cpus&lt;/span&gt;
                    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;master/cpus_total&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;equals&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)){&lt;/span&gt;
                        &lt;span class=&quot;n&quot;&gt;masterMesosMetrics&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;setCpusTotal&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;job&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;getInteger&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;value&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;));&lt;/span&gt;
                    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;master/cpus_used&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;equals&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)){&lt;/span&gt;
                        &lt;span class=&quot;n&quot;&gt;masterMesosMetrics&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;setCpusUsed&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;job&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;getInteger&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;value&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;));&lt;/span&gt;
                    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;master/cpus_percent&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;equals&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)){&lt;/span&gt;
                        &lt;span class=&quot;c1&quot;&gt;//cpuused/cputotal&lt;/span&gt;
                        &lt;span class=&quot;n&quot;&gt;masterMesosMetrics&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;setCpusPercent&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;job&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;getDouble&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;value&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;));&lt;/span&gt;
                        &lt;span class=&quot;c1&quot;&gt;//gpu&lt;/span&gt;
                    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;master/gpus_total&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;equals&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)){&lt;/span&gt;
                        &lt;span class=&quot;n&quot;&gt;masterMesosMetrics&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;setGpusTotal&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;job&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;getInteger&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;value&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;));&lt;/span&gt;
                    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;master/gpus_used&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;equals&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)){&lt;/span&gt;
                        &lt;span class=&quot;n&quot;&gt;masterMesosMetrics&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;setGpusUsed&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;job&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;getInteger&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;value&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;));&lt;/span&gt;
                    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;master/gpus_percent&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;equals&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)){&lt;/span&gt;
                        &lt;span class=&quot;n&quot;&gt;masterMesosMetrics&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;setGpusPercent&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;job&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;getDouble&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;value&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;));&lt;/span&gt;
                        &lt;span class=&quot;c1&quot;&gt;//mem&lt;/span&gt;
                    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;master/mem_total&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;equals&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)){&lt;/span&gt;
                       &lt;span class=&quot;n&quot;&gt;masterMesosMetrics&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;setMemTotal&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;job&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;getInteger&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;value&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;));&lt;/span&gt;
                    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;master/mem_used&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;equals&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)){&lt;/span&gt;
                      &lt;span class=&quot;n&quot;&gt;masterMesosMetrics&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;setMemUsed&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;job&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;getInteger&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;value&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;));&lt;/span&gt;
                    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;master/mem_percent&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;equals&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)){&lt;/span&gt;
                        &lt;span class=&quot;n&quot;&gt;masterMesosMetrics&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;setMemPercent&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;job&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;getDouble&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;value&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;));&lt;/span&gt;
                        &lt;span class=&quot;c1&quot;&gt;//disk&lt;/span&gt;
                    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;master/disk_total&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;equals&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)){&lt;/span&gt;
                        &lt;span class=&quot;n&quot;&gt;masterMesosMetrics&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;setDiskTotal&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;job&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;getInteger&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;value&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;));&lt;/span&gt;
                    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;master/disk_used&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;equals&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)){&lt;/span&gt;
                        &lt;span class=&quot;n&quot;&gt;masterMesosMetrics&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;setDiskUsed&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;job&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;getInteger&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;value&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;));&lt;/span&gt;
                    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;master/disk_percent&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;equals&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)){&lt;/span&gt;
                        &lt;span class=&quot;n&quot;&gt;masterMesosMetrics&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;setDiskPercent&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;job&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;getDouble&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;value&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;));&lt;/span&gt;
                    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;master/uptime_secs&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;equals&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)){&lt;/span&gt;
                        &lt;span class=&quot;n&quot;&gt;masterMesosMetrics&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;setUptimeSecs&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;job&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;getInteger&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;value&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;));&lt;/span&gt;
                    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
                &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
            &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
        &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;masterMesosMetrics&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;至此，关于mesos的监控就这么多了，都是直接使用的httpApi官网都列明白了就不复制过来了，再贴一遍官网连接，有需要的直接去查吧：&lt;a href=&quot;http://mesos.apache.org/documentation/latest/endpoints/#http-endpoints&quot;&gt;HTTP Endpoints&lt;/a&gt;和&lt;a href=&quot;http://mesos.apache.org/documentation/latest/operator-http-api/#operator-http-api&quot;&gt;Operator HTTP API&lt;/a&gt;。&lt;/p&gt;

&lt;h1 id=&quot;marathon管理&quot;&gt;Marathon管理&lt;/h1&gt;
&lt;p&gt;对于Marathon的管理，官方也提供了2种方式，1为直接使用marathon的restful api；2是官方也提供了封装好的方法，直接使用就可以啦。&lt;/p&gt;
&lt;h2 id=&quot;marathon-client&quot;&gt;Marathon-client&lt;/h2&gt;
&lt;p&gt;对于marathon-client，也是对于restful api的一种封装，官方也给出的详细的使用说明:&lt;a href=&quot;https://github.com/mesosphere/marathon-client&quot;&gt;marathon-client&lt;/a&gt;。&lt;br /&gt;
我们使用的marathon版本是Marathon1.4.5，所以来说，可以使用下列依赖：&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&amp;lt;dependency&amp;gt;
  &amp;lt;groupId&amp;gt;com.mesosphere&amp;lt;/groupId&amp;gt;
  &amp;lt;artifactId&amp;gt;marathon-client&amp;lt;/artifactId&amp;gt;
  &amp;lt;version&amp;gt;0.6.0&amp;lt;/version&amp;gt;
&amp;lt;/dependency&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;导入依赖之后，我们就可以直接使用了。&lt;br /&gt;
首先，使用&lt;strong&gt;MarathonClient.getInstance()&lt;/strong&gt;创建Marathon实例对象，之后就可以直接使用其对应的各种方法了，在这里就不和docker-client似的详细说明了，因为这里没有参与过多就不贴详细使用代码啦，官方使用说明挺好的（&lt;a href=&quot;https://github.com/mesosphere/marathon-client&quot;&gt;marathon-client&lt;/a&gt;），所以直接放上来一个小例子来参考吧(IP全用-.-.-.-代替了)。&lt;/p&gt;
&lt;div class=&quot;language-java highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kd&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;kd&quot;&gt;static&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;main&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;String&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;args&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[])&lt;/span&gt; &lt;span class=&quot;kd&quot;&gt;throws&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Exception&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;String&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;endpoint&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;http://-.-.-.-:8080&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;Marathon&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;marathon&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;MarathonClient&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;getInstance&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;endpoint&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;

        &lt;span class=&quot;n&quot;&gt;App&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;app&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;App&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;();&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;app&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;setId&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;spark-with-api&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;app&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;setCmd&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;/bin/bash  /usr/tools/demo.sh user1 user1234&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;app&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;setCpus&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Double&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;));&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;app&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;setMem&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Double&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4096&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;));&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;app&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;setInstances&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Integer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;));&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;Container&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;container&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Container&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;();&lt;/span&gt;

        &lt;span class=&quot;c1&quot;&gt;//设置docker镜像配置&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;Docker&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;docker&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Docker&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;();&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;docker&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;setImage&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;-.-.-.-:5000/sparkwithhadoop_1.6.3:2.2&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;docker&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;setNetwork&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;BRIDGE&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;docker&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;setPrivileged&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;true&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;

        &lt;span class=&quot;c1&quot;&gt;//设置容器的参数&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;Collection&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Parameter&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ArrayList&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Parameter&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;();&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;add&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Parameter&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;net&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;pub_net&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;));&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;add&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Parameter&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;ip&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;-.-.-.-&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;));&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;add&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Parameter&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;hostname&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;master1&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;));&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;docker&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;setParameters&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;

        &lt;span class=&quot;c1&quot;&gt;//设置端口映射&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;Collection&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Port&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;portMappings&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ArrayList&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Port&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;();&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;Port&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;port22&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Port&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;();&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;port22&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;setContainerPort&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;22&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;port22&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;setProtocol&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;tcp&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;portMappings&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;add&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;port22&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
        
        &lt;span class=&quot;n&quot;&gt;Port&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;port7077&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Port&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;();&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;port7077&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;setContainerPort&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;7077&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;port7077&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;setProtocol&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;tcp&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;portMappings&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;add&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;port7077&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
        
        &lt;span class=&quot;n&quot;&gt;Port&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;port7070&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Port&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;();&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;port7070&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;setContainerPort&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;7070&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;port7070&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;setProtocol&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;tcp&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;portMappings&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;add&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;port7070&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;docker&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;setPortMappings&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;portMappings&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
        
        &lt;span class=&quot;n&quot;&gt;container&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;setDocker&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;docker&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;container&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;setType&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;DOCKER&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;//设置容器的挂载目录&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;Collection&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Volume&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;volumes&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ArrayList&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Volume&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;();&lt;/span&gt; 
        &lt;span class=&quot;n&quot;&gt;LocalVolume&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;v1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;LocalVolume&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;();&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;v1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;setContainerPath&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;/usr/tools/hd&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;v1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;setHostPath&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;/app/dcos/&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;v1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;setMode&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;RW&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;volumes&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;add&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;v1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;container&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;setVolumes&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;volumes&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
        
        &lt;span class=&quot;n&quot;&gt;app&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;setContainer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;container&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;//设置健康检查&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;List&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;HealthCheck&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;healthChecks&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ArrayList&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;HealthCheck&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;();&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;HealthCheck&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;h1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;HealthCheck&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;();&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;h1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;setProtocol&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;MESOS_HTTP&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;h1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;setGracePeriodSeconds&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;300&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;h1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;setIntervalSeconds&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;60&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;h1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;setTimeoutSeconds&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;60&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;h1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;setMaxConsecutiveFailures&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;h1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;setPortIndex&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;healthChecks&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;add&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;h1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;app&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;setHealthChecks&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;healthChecks&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;marathon&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;createApp&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;app&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;marathon-restful-api&quot;&gt;Marathon restful api&lt;/h2&gt;
&lt;p&gt;另外一种管理marathon的方式就是直接使用其&lt;a href=&quot;http://mesosphere.github.io/marathon/api-console/index.html&quot;&gt;Marathon REST API&lt;/a&gt;。&lt;br /&gt;
不过它和docker和mesos的有所不同，他们是只有get或post请求，而在marathon中，是正常的restful api使用方式，不同的请求操作有不同的含义。&lt;br /&gt;
拿/v2/apps来举例：&lt;br /&gt;
如果是GET，则可以获取到对应的正在运行的applications的列表。&lt;br /&gt;
如果是POST的话，则是创建或者开启一个新的application，提交的请求将创建的application所需要的参数带着就可以啦。&lt;br /&gt;
具体的这里的restful api的使用方式就不细说了，直接看官方说明之后按照restful api正常使用方式使用就可以啦。&lt;br /&gt;
再贴一遍，官方的详细说明如下：&lt;a href=&quot;http://mesosphere.github.io/marathon/api-console/index.html&quot;&gt;Marathon REST API&lt;/a&gt;。&lt;/p&gt;

&lt;p&gt;好了，marathon的管理方式也说明到这里。&lt;/p&gt;

&lt;hr /&gt;
&lt;p&gt;至此，本篇内容完成。&lt;br /&gt;
本文由2018-06-11开始整理，于2018-06-15整理完成。&lt;/p&gt;</content><author><name>叶子  ( ˘ ³˘)♥</name></author><category term="Docker" /><category term="Mesos" /><category term="Marathon" /><summary type="html">本文主要关于Docker、Mesos、Marathon的监控方法的总结。 注意: 本文中使用的版本是Docker1.12.6、Mesos1.3.0、Marathon1.4.5。 Docker+Mesos+Marathon所搭建的平台监控所用到的后台方法已经基本上写完了，现在用一些时间总结下相关监控方法，满满用心总结的，不过用到的不止这些，还差很多以后再另开文章补充。在总结过程中也重新梳理了很多东西，现在分享出来，希望对大家有用啦，也省的自己以后忘了～哈哈。 Docker管理-容器相关 前期准备：开启Docker远程访问 Docker daemon可以有3种远程访问方式的socket：unix、tcp和fd。 其中Docker支持使用restful api远程获取信息，但是需要提前开启一个Tcp Socket，这样才能实现远程通信。 默认情况下，Docker守护进程Unix socket（/var/run/docker.sock）来进行本地进程通信，而不会监听任何端口，因此只能在本地使用docker客户端或者使用Docker API进行操作,并且需要root权限或者是docker group成员。如果想在其他主机上操作Docker主机，就需要让Docker守护进程打开一个Tcp Socket，这样才能实现远程通信。 补充说明：可以使用HTTPs方式，不过目前没有进行配置，可以后续更改。但是，如果你用和Https的socket，需要注意的是只支持TLS1.0及以上的协议，SSLv3或者更低的是不支持的。 官方网站描述如下Daemon socket option。 我们来使用开启TCP Socket的方式。 需要更改docker配置文件，修改OPTIONS，具体方式如下： 如果找不到docker配置文件，可以以下述方式查找： 找到docker.service文件： systemctl show –property=FragmentPath docker ---@---[~]$systemctl show --property=FragmentPath docker FragmentPath=/usr/lib/systemd/system/docker.service 找到docker.service文件并查看，发现docker文件位置：/etc/sysconfig/docker 找到文件后编辑文件docker 在OPTIONS=后加上 -H=unix:///var/run/docker.sock -H=tcp://0.0.0.0:端口 说明： 1、确定sock文件位置：/var/run/docker.sock 2、可用指定ip：指定端口 3、重启docker 说明： 有资料表述，一般情况下执行以下操作即可： 1、vim /etc/sysconfig/docker（更改docker文件） 2、在OPTIONS=后加上 -H=unix:///var/run/docker.sock -H=tcp://0.0.0.0:端口即可 如若不成功，可尝试下述操作： 1、vim /usr/lib/systemd/system/docker.service （更改docker.service文件） 2、直接在ExecStart=/user/bin/dockerd后添加-H=tcp://0.0.0.0:端口 -H=unix:///var/run/docker.sock(注意顺序) 3、执行命令：systemctl daemon-reload 、systemctl restart docker 测试使用： 配置之后，尝试使用docker restful api来获取信息。 或者直接在机器上尝试查询：“sudo docker -H IP:端口 命令”来测试是否能够取到内容。 Docker-Client的选择 Docker-client的前期准备已经完毕，下面进行DockerAPI的使用。 Docker版本与Docker API的对应关系 和 相关Library Docker提供了Docker Engine API 去连接Docker daemon 来进行Docker的管理。Docker Engine API是Restful API，可以通过http客户端，比如说wget或者curl等来使用。 Docker官方提供Python和Go的SDK，可以直接使用。而在我们这里使用的是java语言，所以可以直接使用restful API的方式来获取相关信息或者直接使用他人封装好的Library。 Docker版本和API版本对应 Docker的不同版本对用不同版本的API。具体以一个表格的形式列了出来，具体可以参考官方网站所写的内容:Docker版本和API对应表-API version matrix。 通过查看这个表，我们知道，我现在用的docker版本是1.12.6，所以来说，所对应的API版本为1.24。 关于Docker Engine API 1.24的使用，可以参考官网Docker Engine API 1.24。 Docker unofficial libraries Docker中出了官方提供的Python和Go的SDK之外，仍然有一些非官方的libraries可以使用，并且可使用的语言类型更加的广泛。关于可以使用的Library，官方在官网上也有所推荐，见官网Unofficial libraries所示。 目前，项目里面并没有直接使用Docker Engine API，而是使用Java的第三方Library,第三方Library也是对Docker Engine API的一个封装。关于Java的Library，Docker官方推荐有三种，docker-client、docker-java、docker-java-api，而这次在项目中，使用的是spotify/docker-client，在下面会将部分所用Library中的方法和Docker Engine API对应着介绍一下。 Docker-Client的使用 我们使用的是spotify/docker-client，在github上有详细的使用说明，直接点击链接即可。所以就不详细介绍了，下面就直接列出来使用的几个方法记录一下。 引入jar包 我们使用的是spotify/docker-client，可以直接通过maven或者jar包的方式引入，maven如下： &amp;lt;dependency&amp;gt; &amp;lt;groupId&amp;gt;com.spotify&amp;lt;/groupId&amp;gt; &amp;lt;artifactId&amp;gt;docker-client&amp;lt;/artifactId&amp;gt; &amp;lt;version&amp;gt;LATEST-VERSION&amp;lt;/version&amp;gt; &amp;lt;/dependency&amp;gt; 针对Docker1.12.6，选择的是8.9.1版本。 开始使用 因为项目中主要用到的是监控，所以基本上都是从服务器上查询的方法，关于对于创建容器、删除容器等操作，因为容器直接归于marathon管理，所以不在Docker这里进行容器创建、删除等操作了。 创建和关闭Docker连接 创建连接 在之前的操作，开启了Docker RPC端口之后，可以在其他机器上创建远程Docker连接。 而且我们也没有开启https，所以可以直接使用如下方式： 传入容器宿主机IP+端口构成的uri，建立和宿主机的连接。 // use the builder String dockerUri =&quot;http://&quot;+hostIp+&quot;:&quot;+port; final DockerClient docker = DefaultDockerClient.builder().uri(URI.create(dockerUri)).build(); 除了这种方式，还有其它几种方式创建docker连接，详细参考Creating a docker-client。 关闭Docker连接 关闭连接直接通过创建的DockerClient docker连接对象，调用close方法即可。 // Close the docker client docker.close(); Docker操作 容器列表 获取宿主机上的容器列表，方法如下： 这个方法能够列出宿主机上全部正在运行的容器的列表。 List&amp;lt;Container&amp;gt; containers = docker.listContainers(DockerClient.ListContainersParam.allContainers()); 通过这个方法，可以返回List，其中的Container对象，可以取到的容器的id、名称、镜像信息、网络信息、状态等内容。 并且，其中包括网络信息可以通过networkSettings取到，包括内容如下： 容器详情 上述获取容器列表的过程中取到的容器信息并不详细，如果想看容器的详细信息可使用inspect方法,需要传入的内容是容器的id，不过通过测试，不需要传入全部的完整id，部分。 ContainerInfo info = docker.inspectContainer(&quot;containerID&quot;); 通过这个方法可以获取到ContainerInfo对象，其中包括容器的详细信息，如下： 容器状态对象 通过 ContainerState state = info.state();可以取到容器的状态对象ContainerState，其中属性如下。 取对象的state.status()，可以取到当前容器的状态，容器状态总共包括：created、restarting、running、paused、exited、dead共5种。 容器配置信息 通过 ContainerConfig config = containerInfo.config();取到容器的配置信息，其中属性包括如下。 通过ContainerConfig可以获取到容器的hostname、env配置、启动容器的命令、所用镜像、工作目录、labels等信息。 容器HostConfig 通过 HostConfig hostConfig = containerInfo.hostConfig();可以取到容器的host配置信息，其中属性如下。 通过HostConfig对象，可以获取到容器和宿主机之间映射的目录、端口等信息，以及所给容器分配的cpu core数量（hostConfig.cpuShares()取到的数值除以1024）、memory（hostConfig.memory()）、swap的大小（hostConfig.memorySwap()-hostConfig.memory()）等信息。 容器网络信息 通过NetworkSettings networkSettings = containerInfo.networkSettings();可以取到容器的网络信息，此对象和容器列表中取到的内容一致。通过它可以取到容器的网络模式、网关、ip、mac等信息。 容器内进程 上述操作均是获取容器的基本信息，如果获取容器内当时的进程信息，可以使用如下方法： 传入的ps_args为aux，和在容器内执行“ps aux”命令取到的数据一致，即“[USER, PID, %CPU, %MEM, VSZ, RSS, TTY, STAT, START, TIME, COMMAND]”等内容。 通过如下方法能取到TopResults对象，此对象内包括属性为process和titles，通过获取其中的process，可得到容器内的进程情况。 //例子 //final TopResults topResults = docker.topContainer(&quot;containerID&quot;, &quot;ps_args&quot;); TopResults topResults = docker.topContainer(&quot;containerID&quot;, &quot;aux&quot;); ImmutableList&amp;lt;ImmutableList&amp;lt;String&amp;gt;&amp;gt; processes = topResults.processes(); 容器资源使用情况 在命令行中，我们可以通过docker stats来查看docker容器资源使用情况的信息，通过命令行能查询到如下内容： CONTAINER CPU % MEM USAGE / LIMIT MEM % NET I/O BLOCK I/O docker-client也提供了方法，来通过如下方式获取docker stats信息： ContainerStats stats = docker.stats(&quot;containerID&quot;); 通过此方法，能够取到ContainerStats对象，其中包含内容如下： 但是，我们取到的数据并不能直接使用，而需要通过计算，来得到更加直观的数据，下面进行一下详细说明。 而计算的过程，主要参考“dockerstats命令源码分析结果”文章中，对于docker stats源码的分析。 CPU利用率计算 计算分析 在上述参考文章中提到: docker daemon会记录这次读取/sys/fs/cgroup/cpuacct/docker/[containerId]/cpuacct.usage的值，作为cpu_total_usage；并记录了上一次读取的该值为pre_cpu_total_usage；读取/proc/stat中cpu field value，并进行累加，得到system_usage;并记录上一次的值为pre_system_usage；读取/sys/fs/cgroup/cpuacct/docker/[containerId]/cpuacct.usage_percpu中的记录，组成数组per_cpu_usage_array。 因此，可以得到docker stats计算Cpu Percent的算法如下： cpu_delta = cpu_total_usage - pre_cpu_total_usage; system_delta = system_usage - pre_system_usage; CPU % = ((cpu_delta / system_delta) * length(per_cpu_usage_array) ) * 100.0 代码实现 所以说，将上述内容中得到的公式所需数据与我们通过取到的数据相对应，通过已经得到的stats对象，用方法可以取到两个CpuStats对象： CpuStats cpuStats = stats.cpuStats(); CpuStats precpuStats = stats.precpuStats(); 然后我们计算cpu利用率，就可以这样来计算： String cpuPercent=&quot;---&quot;; if (null!=cpuStats&amp;amp;&amp;amp;null!=precpuStats){ /** * 计算cpu利用率 % * cpuDelta = cpuTotalUsage - preCpuTotalUsage; * systemDelta = systemUsage - preSystemUsage; * CPU % = ((cpuDelta / systemDelta) * length(per_cpu_usage_array) ) * 100.0 */ Long cpuTotalUsage=cpuStats.cpuUsage().totalUsage(); Long preCpuTotalUsage =precpuStats.cpuUsage().totalUsage(); Long cpuDelta =cpuTotalUsage - preCpuTotalUsage; Long systemUsage =cpuStats.systemCpuUsage(); Long preSystemUsage =precpuStats.systemCpuUsage(); Long systemDelta =systemUsage-preSystemUsage; Integer percpuUsageListSize = cpuStats.cpuUsage().percpuUsage().size(); cpuPercent = ((cpuDelta.floatValue() / systemDelta.floatValue()) * percpuUsageListSize.floatValue()) * 100+&quot;%&quot;; } memory利用率计算 计算分析 在上述参考文章中提到: 读取/sys/fs/cgroup/memory/docker/[containerId]/memory.usage_in_bytes的值，作为mem_usage；如果容器限制了内存，则读取/sys/fs/cgroup/memory/docker/[id]/memory.limit_in_bytes作为mem_limit，否则mem_limit = machine_mem。 因此可以得到docker stats计算Memory数据的算法如下： MEM USAGE = mem_usage MEM LIMIT = mem_limit MEM % = (mem_usage / mem_limit) * 100.0 代码实现 通过已经得到的stats对象，用方法可以取到MemoryStats对象。 MemoryStats memoryStats = stats.memoryStats(); 然后根据公式来计算memory利用率： String memUsageFormat=&quot;---&quot;; String memLimitFormat=&quot;---&quot;; String memPercent=&quot;---&quot;; if (null!=memoryStats){ /** * 计算memory利用率 % * MEM USAGE = mem_usage MEM LIMIT = mem_limit MEM % = (mem_usage / mem_limit) * 100.0 */ Long memUsage= memoryStats.usage(); Long memLimit=memoryStats.limit(); memUsageFormat= Utils.getDynamicSizeUnit(memUsage); memLimitFormat=Utils.getDynamicSizeUnit(memLimit); memPercent=(memUsage.floatValue()/memLimit.floatValue())*100+&quot;%&quot;; } Network IO计算 计算分析 在上述参考文章中提到: network stats的计算可以根据“获取属于该容器network namespace veth pairs在主机中对应的veth*虚拟网卡EthInterface数组，然后循环数组中每个网卡设备，读取/sys/class/net//statistics/rx_bytes得到rx_bytes, 读取/sys/class/net//statistics/tx_bytes得到对应的tx_bytes。将所有这些虚拟网卡对应的rx_bytes累加得到该容器的rx_bytes。将所有这些虚拟网卡对应的tx_bytes累加得到该容器的tx_bytes。 因此我们可以得到network stats的计算算法如下： NET I = rx_bytes NET O = tx_bytes 代码实现 通过已经得到的stats对象，可以取到 ImmutableMap&amp;lt;String, NetworkStats&amp;gt;。 ImmutableMap&amp;lt;String, NetworkStats&amp;gt; networks = stats.networks(); 然后根据公式来计算network io： String rxBytesSumFormat=&quot;---&quot;; String txBytesSumFormat=&quot;---&quot;; if (null!=networks){ /** * docker stats计算Network IO数据的算法： NET I = rx_bytes(所有网卡累加) NET O = tx_bytes（所有网卡累加） */ Long rxBytesSum=0L; Long txBytesSum=0L; for (Map.Entry&amp;lt;String, NetworkStats&amp;gt; entry:networks.entrySet()){ rxBytesSum+=entry.getValue().rxBytes(); txBytesSum+=entry.getValue().txBytes(); } //Utils.getDynamicSizeUnit()是一个动态单位转换的方法 rxBytesSumFormat=Utils.getDynamicSizeUnit(rxBytesSum); txBytesSumFormat=Utils.getDynamicSizeUnit(txBytesSum); } Blk IO计算 计算分析 在上述参考文章中提到: Blk IO计算可以根据“获取每个块设备的IoServiceBytesRecursive数据：先去读取/sys/fs/cgroup/blkio/docker/[containerId]/blkio.io_serviced_recursive中是否有有效值，如果有，则读取/sys/fs/cgroup/blkio/docker/[containerId]/blkio.io_service_bytes_recursive的值返回； 如果没有，就去读取/sys/fs/cgroup/blkio/docker/[containerId]/blkio.throttle.io_service_bytes中的值返回；将每个块设备的IoServiceBytesRecursive数据中所有read field对应value进行累加，得到该容器的blk_read值；将每个块设备的IoServiceBytesRecursive数据中所有write field对应value进行累加，得到该容器的blk_write值。 因此，我们可以得到Blk IO计算算法如下： BLOCK I = blk_read BLOCK O = blk_write 代码实现 String blkReadFormat=&quot;---&quot;; String blkWriteFormat=&quot;---&quot;; if (null!=blockIoStats){ /** * docker stats计算Block IO数据的算法： BLOCK I = blkRead BLOCK O = blkWrite */ ImmutableList&amp;lt;Object&amp;gt; objects = blockIoStats.ioServiceBytesRecursive(); Long blkRead =0L; Long blkWrite =0L; //因为是Object，不好遍历，所以转变成了jsonobj遍历 for (Object obj: objects) { String jsonString= JSON.toJSONString(obj); JSONObject jsonObj = JSON.parseObject(jsonString); if (&quot;Read&quot;.equals(jsonObj.getString(&quot;op&quot;))){ blkRead+=jsonObj.getLong(&quot;value&quot;); }else if (&quot;Write&quot;.equals(jsonObj.getString(&quot;op&quot;))){ blkWrite+=jsonObj.getLong(&quot;value&quot;); } } blkReadFormat=Utils.getDynamicSizeUnit(blkRead); blkWriteFormat=Utils.getDynamicSizeUnit(blkWrite); } 获取时间 至此，以上将docker stats所需要的数据均计算出来了，之后我们只需获取下当前的采集时间即可。 Date read = stats.read(); 容器其他 上面说的基本上是关于docker容器监控所用的方法，剩下的都是直接操作容器的工具，先不写出来了，有需要的可以直接参考官方说明spotify/docker-client。 容器宿主机监控 以上说明了容器的基础监控，我们在应用中，如果需要监控容器所在宿主机的情况，也可以使用下述方法： Info info = docker.info(); 获取到了Info对象，通过此对象可以取到宿主机上运行的容器状态、资源情况等，具体可获取到的如下。 其他 除了以上说的那些，还可以获取、操作Networks、Images等。因为我们这里自己创建的一个镜像库，所以不直接使用docker-client的方法获取镜像信息，下面会统一再说明镜像库的搭建和列表的获取。 至此，docker-client所用到的方法都说明完毕了，其他没提到的还是直接去看官方说明吧spotify/docker-client。 Engine API的使用 上述进行说明了Docker-client的使用，我们也可以直接通过Engine API v1.24来进行Docker的操作。 也是开启TCP端口之后，直接发送request到宿主机地址：端口，然后会收到json格式的response。 这里直接使用工具测试，获取到容器的列表信息，如下图。 此后，如果需要，可以直接参考官方说明Engine API v1.24，不过需要注意的是，我这里使用的docker对应的是v1.24的，其他版本的要选择不同对应版本的api哦，在本文最开始也选择docker-client的“Docker版本和API版本对应”处也说明了，忘记了的话回过头去看哦。 Docker管理-Docker镜像仓库 我们上述说明了使用Docker-Client获取Docker容器的一些基础信息，而镜像我们是单独部署了一个镜像服务器，因此，不直接使用docker-client来获取镜像列表。下面会先说明镜像服务器的部署，之后说下如何获取镜像服务器中的镜像列表。 简单说明镜像服务器的部署 Docke官方提供了Docker Hub网站来作为一个公开的集中仓库。然而，本地访问Docker Hub速度往往很慢，并且很多时候我们需要一个本地的私有仓库只供网内使用。 Docker仓库实际上提供两方面的功能，一个是镜像管理，一个是认证。前者主要由docker-registry项目来实现，通过http服务来上传下载；后者可以通过docker-index（闭源）项目或者利用现成认证方案（如nginx）实现http请求管理。 目前来说，我们只需要在内网建立一个存储镜像的地方，因此只使用docker registry来搭建一个私有镜像库。 下面简单说明下仓库搭建过程，也可以直接参考官方部署“Deploy a registry server”。 官方提供了registry镜像，我们直接下载： docker pull registry 默认情况下，会将仓库存放于容器内,这样的话如果容器被删除，则存放于容器中的镜像也会丢失，所以我们需要指定一个本地目录挂载到容器内的存放镜像的目录下。所以，我们以如下命令来启动一个docker容器： docker run --privileged=true -d -v /datacenter02/registry:/var/lib/registry -p 5000:5000 --restart=always --name registry registry 查看启动的容器 ---@---[~]#docker ps -a CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 458a9e2301a6 registry &quot;/entrypoint.sh /etc/&quot; 7 months ago Up 7 months 0.0.0.0:5000-&amp;gt;5000/tcp registry 测试使用 创建一个小的镜像，然后测试push docker push 132.-.-.-:5000/busybox（这里的ip没写全，用-代替了，自己写的时候写全） 可以看到push失败，报关于https的错误类似如下。 Error response from daemon: invalid registry endpoint https://132.-.-.-:5000/v1/: Get https://132.-.-.-:5000/v1/_ping: http: server gave HTTP response to HTTPS client. If this private registry supports only HTTP or HTTPS with an unknown CA certificate, please add `--insecure-registry 132.-.-.-:5000` to the daemon's arguments. In the case of HTTPS, if you have access to the registry's CA certificate, no need for the flag; simply place the CA certificate at /etc/docker/certs.d/132.-.-.-:5000/ca.crt 配置http访问 因为Docker从1.3.X之后，与docker registry交互默认使用的是https，然而此处搭建的私有仓库只提供http服务，所以当与私有仓库交互时就会报上面的错误。为了解决这个问题需要在启动docker server时增加启动参数为默认使用http访问。 我们需要修改docker配置文件，在docker配置文件中增加“–insecure-registry 132.-.-.-:5000”，其中IP为了不泄露用-代替了，自己写的时候需要写全： # If you have a registry secured with https but do not have proper certs # distributed, you can tell docker to not look for full authorization by # adding the registry to the INSECURE_REGISTRY line and uncommenting it. # INSECURE_REGISTRY='--insecure-registry' INSECURE_REGISTRY='--insecure-registry 132.-.-.-:5000' 之后重启docker服务。 之后再次测试，可以发现没有报错啦，push成功。 命令行仓库管理 有文章说，查询私有仓库中的所有镜像，使用docker search命令，但是我这里经过尝试，发现会报错：“Error response from daemon: Unexpected status code 404”。 后来发现，docker search是v1版本的API，我们现在的是v2版本，所以不能使用。 如果需要查询，则也是直接curl使用v2版本的API： ---@---[~]#curl 132.90.130.13:5000/v2/_catalog {&quot;repositories&quot;:[&quot;alluxio&quot;,&quot;basic&quot;,&quot;go&quot;,&quot;go1.10&quot;,&quot;go_zhzj&quot;,&quot;hdfs_datanode&quot;,&quot;hello-mine&quot;,&quot;hiveonspark&quot;,&quot;hiveonspark-gx&quot;,&quot;hivespark&quot;,&quot;jdk&quot;,&quot;jtwspark1.6.3&quot;,&quot;kafka&quot;,&quot;ninecon&quot;,&quot;nm&quot;,&quot;rm1&quot;,&quot;rm2&quot;,&quot;spark-2.3.0&quot;,&quot;spark2&quot;,&quot;spark2.2.1&quot;,&quot;spark2.2.1-gx&quot;,&quot;spark2.2.1-jtw&quot;,&quot;spark2.2.1-rx-demo&quot;,&quot;sparkdemo&quot;,&quot;sparkrx1.6.3&quot;,&quot;sparkrx2.2.1&quot;,&quot;tensorflow&quot;]} 详细的将在下面说明。 镜像仓库器管理 对于Docker Registry，Docker官方提供了HTTP API V2用于与其交互，用来管理docker images。对于此，在官方网站上也有说明：HTTP API V2。 因为我们只用到了镜像管理功能，所以下面只是用到的说明获取仓库内的镜像列表以及tags的方法，其他的需要自己参考官网啦。 镜像列表 我们使用下述方式来获取仓库里面的镜像列表，获取也是请求之后来获取一个包含信息（仓库、镜像名称）的json串，官方给出的request和response例子如下： request: GET /v2/_catalog response: ``` 200 OK Content-Type: application/json</summary></entry><entry><title type="html">HDFS权限以及目录限额相关</title><link href="http://localhost:4000/bigdata/2018/06/04/HDFS%E6%9D%83%E9%99%90%E4%BB%A5%E5%8F%8A%E7%9B%AE%E5%BD%95%E9%99%90%E9%A2%9D%E7%9B%B8%E5%85%B3/" rel="alternate" type="text/html" title="HDFS权限以及目录限额相关" /><published>2018-06-04T00:00:00+08:00</published><updated>2018-06-04T00:00:00+08:00</updated><id>http://localhost:4000/bigdata/2018/06/04/HDFS%E6%9D%83%E9%99%90%E4%BB%A5%E5%8F%8A%E7%9B%AE%E5%BD%95%E9%99%90%E9%A2%9D%E7%9B%B8%E5%85%B3</id><content type="html" xml:base="http://localhost:4000/bigdata/2018/06/04/HDFS%E6%9D%83%E9%99%90%E4%BB%A5%E5%8F%8A%E7%9B%AE%E5%BD%95%E9%99%90%E9%A2%9D%E7%9B%B8%E5%85%B3/">&lt;blockquote&gt;
  &lt;p&gt;本文主要关于HDFS的用户权限设置以及目录的限额控制的总结。本文主要分3部分进行总结，1为HDFS的用户权限设置，2为目录的限额控制，最后简单说明一下单纯使用HDFS ACL可能造成的安全隐患。&lt;br /&gt;
&lt;strong&gt;注意: 本文中使用的版本是Hadoop 2.6.0-cdh5.11.0&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;平台中需要对于使用租户的权限以及所用文件空间进行控制，所以查找了关于HDFS用户权限以及目录限额控制的相关方法和权限控制JAVA API，并且翻阅源码的时候也找到了相关HDFS存储限额控制的JAVA API，过了这么长时间今天终于想起来要总结一下。不过有点需要注明，目前为止单纯的使用HDFS ACL控制权限有用户伪造的隐患，此种隐患会在本文最后进行说明。&lt;/p&gt;

&lt;p&gt;# 
(๑•́ ₃ •̀๑) 呃，一直占位没来得及整理～容我拖延症再飞一会～
—  &lt;br /&gt;
至此，本篇内容完成。&lt;/p&gt;</content><author><name>叶子  ( ˘ ³˘)♥</name></author><category term="Hadoop" /><summary type="html">本文主要关于HDFS的用户权限设置以及目录的限额控制的总结。本文主要分3部分进行总结，1为HDFS的用户权限设置，2为目录的限额控制，最后简单说明一下单纯使用HDFS ACL可能造成的安全隐患。 注意: 本文中使用的版本是Hadoop 2.6.0-cdh5.11.0 平台中需要对于使用租户的权限以及所用文件空间进行控制，所以查找了关于HDFS用户权限以及目录限额控制的相关方法和权限控制JAVA API，并且翻阅源码的时候也找到了相关HDFS存储限额控制的JAVA API，过了这么长时间今天终于想起来要总结一下。不过有点需要注明，目前为止单纯的使用HDFS ACL控制权限有用户伪造的隐患，此种隐患会在本文最后进行说明。 # (๑•́ ₃ •̀๑) 呃，一直占位没来得及整理～容我拖延症再飞一会～ — 至此，本篇内容完成。</summary></entry></feed>