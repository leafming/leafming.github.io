---
layout: post
title: "Filebeat-轻量型日志采集器概述"
date: 2019-06-26
updated: 2019-06-26
description: 本文主要关于Filebeat轻量级的日志数据采集组件的概述。
categories:
- BigData
tags:
- Elastic
---
> 本文主要关于Filebeat轻量级的日志数据采集组件的概述。  
> **注意: 本文中使用版本：6.8.1，CentOS7环境测试运行。**  
  
最近需要做平台整体的日志采集，因此测试选型Filebeat进行日志采集。Elastic Stack提供多种BEATS轻量型数据采集器，Filebeat是轻量级的日志数据采集器。其作为服务器上的agent安装，Filebeat监视日志目录或特定日志文件，tail file模式收集日志文件，并将它们转发给Elasticsearch或Logstash等。官方参考：[FILEBEAT](https://www.elastic.co/cn/products/beats/filebeat)。此文简单翻译整理下filebeat的相关内容，做一次初步理解。  
  
# 测试环境  
filebeat-6.8.1-linux-x86_64  
elasticsearch-6.8.1  
kibana-6.8.1-linux-x86_64  
系统环境Centos7   

# 安装filebeat  
下载filebeat-6.8.1-linux-x86_64.tar.gz，解压即可。  
  
# Filebeat的工作原理
## 主要组件介绍  
Filebeat由两个主要组件组成：inputs 和 harvesters。这些组件一起工作来读取文件（tail file）并将事件数据发送到指定的output。  
启动Filebeat时，它会启动一个或多个input，这些input将查找我们指定的日志数据的位置。对于Filebeat找到的每个日志，Filebeat都会启动一个收集器（harvester）。每个收集器（harvester）为新内容读取单个日志，并将新日志数据发送到libbeat，libbeat聚合events并将聚合数据发送到我们为Filebeat配置的output中。  
Filebeat 是Elastic Beat，基于libbeat框架。  
![2019-06-25-filebeat工作原理](https://github.com/leafming/bak/blob/master/images/es/2019-06-25-filebeat工作原理.png?raw=true)
  
## harvester  
harvester :负责读取单个文件的内容。  
收集时，会为每个文件都启动一个harvester。  
Harvester会逐行读取每个文件，并将内容发送到output。  
harvester负责打开和关闭文件，这意味着file descriptor在harvester运行时保持打开状态。  
如果文件在被收集时removed或renamed，Filebeat会继续读取该文件。这会导致在harvester关闭之前，磁盘上的空间是保留的。默认情况下，Filebeat使文件保持打开状态，直到close_inactive状态。  
关闭harvester会产生以下结果：  
1）文件处理程序已关闭，如果在收集器仍在读取文件时删除了文件，则释放底层资源。  
（The file handler is closed, freeing up the underlying resources if the file was deleted while the harvester was still reading the file.)  
2）文件的采集只会在scan_frequency过后重新开始。  
3）如果在harvester关闭的情况下移动或移除文件，则不会继续处理文件。  
要控制harvester何时关闭，使用close_ *配置选项。  
  
## input  
Input负责管理harvester并找到所有要读取的文件来源source。  
如果输入类型为log，则input将查找与定义的全部路径匹配的所有文件，并为每个文件启动收集器（harvester）。每个input都在自己的Go协程中运行。  
以下示例将Filebeat配置为从与指定的匹配的所有日志文件中收集行：  
```
filebeat.inputs:
- type: log
  paths:
    - /var/log/*.log
    - /var/path2/*.log
```  
Filebeat目前支持多种input类型。每种输入类型都可以定义多次。该log input检查每个文件看harvester是否需要启动，是否已经在运行，或该文件是否可以被忽略不计（见ignore_older）。如果自harvester关闭后文件的大小发生变化，则只会拾取新行。  
注：Filebeat input只能读取本地文件， 没有功能可以连接到远程主机来读取存储的文件或日志。  
  
# Filebeat状态维护  
## Filebeat如何保持文件的状态？  
Filebeat 保存每个文件的state，并经常将state刷新到磁盘上的注册文件中。  
该状态用于记住harvester正在读取的最后偏移量，并确保所有日志行已经被发送。  
如果输出（例如Elasticsearch或Logstash）无法访问，Filebeat会跟踪最后发送的行，并在输出再次可用时继续读取文件。  
在Filebeat运行时，每个input内存中也会保存的文件state信息，当重新启动Filebeat时，将使用注册文件的数据来重建state，Filebeat将使每个harvester从保存的最后偏移量继续读取。  
每个input为它找到的每个文件都保留一个state。由于文件可以被重命名或移动，因此文件名和路径不足以识别文件。对于每个文件，Filebeat会存储唯一标识符以检测文件是否先前已采集过。  
需要注意的是：如果使用场景涉及到，及每天创建大量新文件，您可能会发现注册表文件增长过大。详见官网：[Registry file is too large?](https://www.elastic.co/guide/en/beats/filebeat/6.8/faq.html#reduce-registry-size)  
## Filebeat如何确保至少一次交付  
Filebeat保证events将至少一次传递到配置的output，不会丢失数据，因为它将每个event的传递状态都存储在注册表文件中。  
在output阻塞或未确认所有事件的情况下，Filebeat将继续尝试发送事件，直到接收端确认已收到。  
如果Filebeat在发送event的过程中关闭，它不会等待output确认收到所有events。如果event已经发送到output，但在Filebeat关闭前未确认，也会在重新启动Filebeat时再次发送。这可以确保每个事件至少发送一次，但是会有重复。  
也可以通过设置shutdown_timeout选项来配置Filebeat以在关闭之前等待特定的时间。  
注意：  
Filebeat的至少一次交付保证有一个限制，涉及日志轮换和旧文件的删除。  
如果将日志文件写入磁盘并且写入速度超过Filebeat可以处理的速度，或者在输出不可用时删除了文件，则可能会丢失数据。  
在Linux上，Filebeat也可能因inode重用而跳过行。有关inode重用问题的更多详细信息，详见[常见问题解答](https://www.elastic.co/guide/en/beats/filebeat/6.8/faq.html#reduce-registry-size)。  
  

  
  
  
  
  
  
  

---    
至此，本篇内容完成。  
